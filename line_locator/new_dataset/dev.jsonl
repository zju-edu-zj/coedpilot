{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask> \n <mask> Patterns for Flask\n <mask> ==================\n <mask> \n <mask> Certain things are common enough that the chances are high you will find\n <mask> them in most web applications.  For example quite a lot of applications\n <mask> are using relational databases and user authentication.  In that case,\n <mask> chances are they will open a database connection at the beginning of the\n <mask> request and get the information of the currently logged in user.  At the\n <mask> end of the request, the database connection is closed again.\n <mask> \n <mask> There are more user contributed snippets and patterns in the `Flask\n <mask> Snippet Archives <http://flask.pocoo.org/snippets/>`_.\n <mask> \n <mask> .. toctree::\n <mask>    :maxdepth: 2 </s> update patterns, snippets, extensions docs </s> remove :doc:`extensiondev`. </s> add :doc:`/extensiondev`.", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/patterns/index.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> loaded upfront.  The trick is to actually load the view function as needed.\n <mask> This can be accomplished with a helper class that behaves just like a\n <mask> function but internally imports the real function on first use::\n <mask> \n <mask>     from werkzeug import import_string, cached_property\n <mask> \n <mask>     class LazyView(object):\n <mask> \n <mask>         def __init__(self, import_name):\n <mask>             self.__module__, self.__name__ = import_name.rsplit('.', 1) </s> add `Discord server`_ to get some ideas for nice looking APIs.  Especially if you do </s> remove     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n    app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/patterns/lazyloading.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> docs for more information.\n <mask> \n <mask> Read more on :ref:`application-errors`.\n <mask> \n <mask> Hooking in WSGI Middlewares\n <mask> ---------------------------\n <mask> \n <mask> If you want to add a WSGI middleware to your application you can wrap the\n <mask> internal WSGI application.  For example if you want to use one of the\n <mask> middlewares from the Werkzeug package to work around bugs in lighttpd, you\n <mask> can do it like this:: </s> remove If you want to add a WSGI middleware to your application you can wrap the\ninternal WSGI application.  For example if you want to use one of the\nmiddlewares from the Werkzeug package to work around bugs in lighttpd, you\ncan do it like this:: </s> add To add WSGI middleware to your Flask application, wrap the application's\n``wsgi_app`` attribute. For example, to apply Werkzeug's\n:class:`~werkzeug.middlware.proxy_fix.ProxyFix` middleware for running\nbehind Nginx: </s> remove     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n    app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app) </s> add .. code-block:: python\n\n    from werkzeug.middleware.proxy_fix import ProxyFix\n    app.wsgi_app = ProxyFix(app.wsgi_app)\n\nWrapping ``app.wsgi_app`` instead of ``app`` means that ``app`` still\npoints at your Flask application, not at the middleware, so you can\ncontinue to use and configure ``app`` directly.", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> Hooking in WSGI Middlewares\n <mask> ---------------------------\n <mask> \n <mask> If you want to add a WSGI middleware to your application you can wrap the\n <mask> internal WSGI application.  For example if you want to use one of the\n <mask> middlewares from the Werkzeug package to work around bugs in lighttpd, you\n <mask> can do it like this::\n <mask> \n <mask>     from werkzeug.contrib.fixers import LighttpdCGIRootFix\n <mask>     app.wsgi_app = LighttpdCGIRootFix(app.wsgi_app)\n <mask> \n <mask> Using Flask Extensions\n <mask> ----------------------\n <mask>  </s> add Hooking in WSGI Middleware\n-------------------------- </s> add `Discord server`_ to get some ideas for nice looking APIs.  Especially if you do </s> remove Flask also has the concept of approved extensions.  Approved extensions\nare tested as part of Flask itself to ensure extensions do not break on\nnew releases.  If you want your own extension to be approved you have to\nfollow these guidelines: </s> add     extension author would like to move beyond the project, the project\n    should find a new maintainer and transfer access to the repository,\n    documentation, PyPI, and any other services. If no maintainer\n    is available, give access to the Pallets core team.\n1.  The naming scheme is *Flask-ExtensionName* or *ExtensionName-Flask*.\n    It must provide exactly one package or module named\n    ``flask_extension_name``.\n2.  The extension must be BSD or MIT licensed. It must be open source\n    and publicly available.\n3.  The extension's API must have the following characteristics:\n\n    -   It must support multiple applications running in the same Python\n        process. Use ``current_app`` instead of ``self.app``, store\n        configuration and state per application instance.\n    -   It must be possible to use the factory pattern for creating\n        applications. Use the ``ext.init_app()`` pattern.\n\n4.  From a clone of the repository, an extension with its dependencies\n    must be installable with ``pip install -e .``.\n5.  It must ship a testing suite that can be invoked with ``tox -e py``\n    or ``pytest``. If not using ``tox``, the test dependencies should be\n    specified in a ``requirements.txt`` file. The tests must be part of\n    the sdist distribution.\n6.  The documentation must use the ``flask`` theme from the\n    `Official Pallets Themes`_. A link to the documentation or project\n    website must be in the PyPI metadata or the readme.\n7.  The active versions of Python should be supported. As of 2020 this\n    means Python 3.5 and newer. </s> add to contact the developers on the mailing list or Discord server.  The best way for", "html_url": "https://github.com/pallets/flask/commit/e01b68e7ee66f7c5ec221bcb9e0cd3526153664d", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return \"Hello World\"\n <mask> \n <mask>     rv = client.get(\"/\", \"http://www.example.com:8080/test/\")\n <mask>     cookie = rv.headers[\"set-cookie\"].lower()\n <mask>     assert \"domain=.example.com\" in cookie\n <mask>     assert \"path=/\" in cookie\n <mask>     assert \"secure\" in cookie </s> remove     @app.route(\"/clear\")\n    def clear():\n        flask.session.pop(\"testing\", None)\n        return \"Goodbye World\" </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\") </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value) </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert \"secure\" in cookie\n <mask>     assert \"httponly\" not in cookie\n <mask>     assert \"samesite\" in cookie\n <mask> \n <mask>     @app.route(\"/clear\")\n <mask>     def clear():\n <mask>         flask.session.pop(\"testing\", None)\n <mask>         return \"Goodbye World\"\n <mask> \n <mask>     rv = client.get(\"/clear\", \"http://www.example.com:8080/test/\")\n <mask>     cookie = rv.headers[\"set-cookie\"].lower()\n <mask>     assert \"session=;\" in cookie\n <mask>     assert \"domain=.example.com\" in cookie\n <mask>     assert \"path=/\" in cookie </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\")", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rv = client.get(\"/E3\")\n <mask>     assert rv.data == b\"E2\"\n <mask> \n <mask> \n <mask> def test_trapping_of_bad_request_key_errors(app, client):\n <mask>     @app.route(\"/key\")\n <mask>     def fail():\n <mask>         flask.request.form[\"missing_key\"]\n <mask> \n <mask>     @app.route(\"/abort\") </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\" </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\") </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     @app.route(\"/abort\")\n <mask>     def allow_abort():\n <mask>         flask.abort(400)\n <mask> \n <mask>     rv = client.get(\"/key\")\n <mask>     assert rv.status_code == 400\n <mask>     assert b\"missing_key\" not in rv.data\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = True\n <mask>     with pytest.raises(KeyError) as e:\n <mask>         client.get(\"/key\")\n <mask>     assert e.errisinstance(BadRequest)\n <mask>     assert \"missing_key\" in e.value.get_description()\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = False\n <mask>     app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\") </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\" </s> add     app.config[\"DEBUG\"] = True </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     with pytest.raises(AssertionError) as e: </s> add     with pytest.raises(AssertionError) as exc_info:", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert \"missing_key\" in e.value.get_description()\n <mask>     rv = client.get(\"/abort\")\n <mask>     assert rv.status_code == 400\n <mask> \n <mask>     app.debug = False\n <mask>     app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n <mask>     with pytest.raises(KeyError):\n <mask>         client.get(\"/key\")\n <mask>     with pytest.raises(BadRequest):\n <mask>         client.get(\"/abort\")\n <mask> \n <mask> \n <mask> def test_trapping_of_all_http_exceptions(app, client):\n <mask>     app.config[\"TRAP_HTTP_EXCEPTIONS\"] = True\n <mask>  </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add         assert exc_info.errisinstance(BadRequest)\n        assert \"missing_key\" in exc_info.value.get_description() </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> add     app.config[\"DEBUG\"] = True", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     assert not app.got_first_request\n <mask>     assert client.get(\"/\").data == b\"Awesome\"\n <mask> \n <mask>     with pytest.raises(AssertionError) as e:\n <mask>         app.add_url_rule(\"/foo\", endpoint=\"late\")\n <mask> \n <mask>     assert \"A setup function was called\" in str(e.value)\n <mask> \n <mask>     app.debug = False </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value) </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={}) </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\" </s> add     app.config[\"DEBUG\"] = True", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     with pytest.raises(AssertionError) as e:\n <mask>         app.add_url_rule(\"/foo\", endpoint=\"late\")\n <mask> \n <mask>     assert \"A setup function was called\" in str(e.value)\n <mask> \n <mask>     app.debug = False\n <mask> \n <mask>     @app.route(\"/foo\")\n <mask>     def working():\n <mask>         return \"Meh\"\n <mask> \n <mask>     assert client.get(\"/foo\").data == b\"Meh\"\n <mask>     assert app.got_first_request\n <mask> \n <mask> \n <mask> def test_before_first_request_functions(app, client):\n <mask>     got = []\n <mask>  </s> remove     with pytest.raises(AssertionError) as e: </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\" </s> add     app.config[\"DEBUG\"] = True </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\") </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace keep", "code_tokens": " <mask>     assert app.got_first_request\n <mask> \n <mask> \n <mask> def test_routing_redirect_debugging(monkeypatch, app, client):\n <mask>     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n <mask>     def foo():\n <mask>         return \"success\"\n <mask> \n <mask>     app.debug = False\n <mask>     rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>     assert rv.data == b\"success\"\n <mask>  </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = False\n    app.config[\"TRAP_BAD_REQUEST_ERRORS\"] = True\n    with pytest.raises(KeyError):\n        client.get(\"/key\")\n    with pytest.raises(BadRequest):\n        client.get(\"/abort\") </s> add     if expect_abort:\n        rv = client.get(\"/abort\")\n        assert rv.status_code == 400\n    else:\n        with pytest.raises(BadRequest):\n            client.get(\"/abort\") </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={}) </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     app.debug = False\n <mask>     rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>     assert rv.data == b\"success\"\n <mask> \n <mask>     app.debug = True\n <mask> \n <mask>     with client:\n <mask>         rv = client.post(\"/foo\", data={}, follow_redirects=True)\n <mask>         assert rv.data == b\"success\"\n <mask>         rv = client.get(\"/foo\", data={}, follow_redirects=True)\n <mask>         assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={}) </s> remove     app.debug = False\n    rv = client.post(\"/foo\", data={}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> add     @app.route(\"/user/\", methods=[\"GET\", \"POST\"])\n    def user():\n        return flask.request.form[\"status\"] </s> remove     @app.route(\"/foo/\", methods=[\"GET\", \"POST\"])\n    def foo():\n        return \"success\" </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={}) </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> remove     app.debug = True\n    with pytest.raises(KeyError) as e:\n        client.get(\"/key\")\n    assert e.errisinstance(BadRequest)\n    assert \"missing_key\" in e.value.get_description()\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as exc_info:\n <mask>         client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True)\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={}) </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value) </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> add     with pytest.raises(AssertionError) as exc_info: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\") </s> add     assert \"setup method 'add_url_rule'\" in str(exc_info.value)", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         assert rv.data == b\"success\"\n <mask> \n <mask>     monkeypatch.setattr(RequestRedirect, \"code\", 301)\n <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={})\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n <mask> \n <mask> \n <mask> def test_route_decorator_custom_endpoint(app, client): </s> remove     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value) </s> add     assert \"canonical URL 'http://localhost/user/'\" in str(exc_info.value) </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> remove     with pytest.raises(AssertionError) as e: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\")", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     with client, pytest.raises(AssertionError) as e:\n <mask>         client.post(\"/foo\", data={})\n <mask> \n <mask>     assert \"canonical URL 'http://localhost/foo/'\" in str(e.value)\n <mask> \n <mask> \n <mask> def test_route_decorator_custom_endpoint(app, client):\n <mask>     app.debug = True\n <mask>  </s> remove     with client, pytest.raises(AssertionError) as e:\n        client.post(\"/foo\", data={}) </s> add     with client, pytest.raises(AssertionError) as exc_info:\n        client.post(\"/user\", data={\"status\": \"error\"}, follow_redirects=True) </s> remove     app.debug = True\n\n    with client:\n        rv = client.post(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\"\n        rv = client.get(\"/foo\", data={}, follow_redirects=True)\n        assert rv.data == b\"success\" </s> add     # default redirect code preserves form data\n    rv = client.post(\"/user\", data={\"status\": \"success\"}, follow_redirects=True)\n    assert rv.data == b\"success\" </s> remove     assert \"A setup function was called\" in str(e.value)\n\n    app.debug = False\n\n    @app.route(\"/foo\")\n    def working():\n        return \"Meh\"\n\n    assert client.get(\"/foo\").data == b\"Meh\"\n    assert app.got_first_request </s> remove     with pytest.raises(AssertionError) as e: </s> remove     rv = client.get(\"/key\")\n    assert rv.status_code == 400\n    assert b\"missing_key\" not in rv.data\n    rv = client.get(\"/abort\")\n    assert rv.status_code == 400 </s> add     if expect_key:\n        rv = client.get(\"/key\")\n        assert rv.status_code == 400\n        assert b\"missing_key\" not in rv.data\n    else:\n        with pytest.raises(KeyError) as exc_info:\n            client.get(\"/key\")", "html_url": "https://github.com/pallets/flask/commit/e044b00047da9bf94e7eb88049a17fe1dcf78f4e", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     necessary to interface with as it's used internally in the dispatching\n <mask>     to click.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self):\n <mask>         self.app_import_path = None\n <mask>         self.debug = None\n <mask>         self._loaded_app = None\n <mask> \n <mask>     def get_app_import_path(self):\n <mask>         \"\"\"Return the actual application import path or fails if it is\n <mask>         not yet set. </s> remove         name = 'flask'", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     f.__flask_without_appcontext__ = True\n <mask>     return f\n <mask> \n <mask> \n <mask> class FlaskClickGroup(click.Group):\n <mask>     \"\"\"Special subclass of the a regular click group that supports\n <mask>     loading more commands from the configured Flask app.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, help=None): </s> remove cli = FlaskClickGroup(help='''\\ </s> add cli = FlaskGroup(help='''\\", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return click.Group.invoke_subcommand(\n <mask>                 self, ctx, cmd, cmd_name, args)\n <mask> \n <mask> \n <mask> cli = FlaskClickGroup(help='''\\\n <mask> This shell command acts as general utility script for Flask applications.\n <mask> \n <mask> It loads the application configured (either through the FLASK_APP environment\n <mask> variable or the --app parameter) and then provides commands either provided\n <mask> by the application or Flask itself. </s> remove class FlaskClickGroup(click.Group): </s> add class FlaskGroup(click.Group):", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate.\n <mask>         sys.argv = ['-m', this_module] + sys.argv[1:]\n <mask>     else:\n <mask>         name = 'flask'\n <mask> \n <mask>     cli.main(args=args, prog_name=name, obj=ScriptInfo(),\n <mask>              auto_envvar_prefix='FLASK')\n <mask> \n <mask>  </s> remove     def __init__(self):\n        self.app_import_path = None\n        self.debug = None </s> add     def __init__(self, app_import_path=None, debug=None):\n        self.app_import_path = app_import_path\n        self.debug = debug", "html_url": "https://github.com/pallets/flask/commit/e059bf311c6a75150275b434c53544f7528749bc", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Now, whenever you want to work on a project, you only have to activate the\n <mask> corresponding environment.  On OS X and Linux, do the following::\n <mask> \n <mask>     $ source venv/bin/activate\n <mask> \n <mask> If you are a Windows user, the following command is for you::\n <mask> \n <mask>     $ venv\\scripts\\activate\n <mask>  </s> Use \".\" not \"source\" for shell sourcing.\n\nShell portability from mitsuhiko. </s> remove     $ source venv/bin/activate </s> add     $ . venv/bin/activate </s> remove     $ source venv/bin/activate </s> add     $ . venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     $ cd flask\n <mask>     $ virtualenv venv --distribute\n <mask>     New python executable in venv/bin/python\n <mask>     Installing distribute............done.\n <mask>     $ source venv/bin/activate\n <mask>     $ python setup.py develop\n <mask>     ...\n <mask>     Finished processing dependencies for Flask\n <mask> \n <mask> This will pull in the dependencies and activate the git head as the current </s> remove     $ source venv/bin/activate </s> remove     $ source venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     $ mkdir flask\n <mask>     $ cd flask\n <mask>     $ virtualenv venv --distribute\n <mask>     $ source venv/bin/activate\n <mask>     New python executable in venv/bin/python\n <mask>     Installing distribute............done.\n <mask>     $ pip install Flask==dev\n <mask>     ...\n <mask>     Finished processing dependencies for Flask==dev </s> remove     $ source venv/bin/activate </s> remove     $ source venv/bin/activate", "html_url": "https://github.com/pallets/flask/commit/e070ede050fdb2ce155e13e29f5588c9831fa6b5", "file_name": "docs/installation.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Unreleased\n <mask> \n <mask> \n <mask> Version 1.0.3\n <mask> -------------\n <mask> \n <mask> Unreleased </s> remove             request=self.request", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def copy_current_request_context(f):\n <mask>     \"\"\"A helper function that decorates a function to retain the current\n <mask>     request context.  This is useful when working with greenlets.  The moment\n <mask>     the function is decorated a copy of the request context is created and\n <mask>     then pushed when the function is called.\n <mask> \n <mask>     Example::\n <mask> \n <mask>         import gevent\n <mask>         from flask import copy_current_request_context </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove             request=self.request </s> add             request=self.request,\n            session=self.session </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935 </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @app.route('/')\n <mask>         def index():\n <mask>             @copy_current_request_context\n <mask>             def do_some_work():\n <mask>                 # do some work here, it can access flask.request like you\n <mask>                 # would otherwise in the view function.\n <mask>                 ...\n <mask>             gevent.spawn(do_some_work)\n <mask>             return 'Regular response'\n <mask> \n <mask>     .. versionadded:: 0.10 </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             flask.session['fizz'] = 'buzz' </s> add             request=self.request,\n            session=self.session </s> add             flask.session['fizz'] = 'buzz' </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None):", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n <mask>     that situation, otherwise your unittests will leak memory.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, app, environ, request=None):\n <mask>         self.app = app\n <mask>         if request is None:\n <mask>             request = app.request_class(environ)\n <mask>         self.request = request\n <mask>         self.url_adapter = app.create_url_adapter(self.request) </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove         self.session = None </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> add             flask.session['fizz'] = 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             request = app.request_class(environ)\n <mask>         self.request = request\n <mask>         self.url_adapter = app.create_url_adapter(self.request)\n <mask>         self.flashes = None\n <mask>         self.session = None\n <mask> \n <mask>         # Request contexts can be pushed multiple times and interleaved with\n <mask>         # other request contexts.  Now only if the last level is popped we\n <mask>         # get rid of them.  Additionally if an application context is missing\n <mask>         # one is created implicitly so for each level we add this information </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> add             flask.session['fizz'] = 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         .. versionadded:: 0.10\n <mask>         \"\"\"\n <mask>         return self.__class__(self.app,\n <mask>             environ=self.request.environ,\n <mask>             request=self.request,\n <mask>             session=self.session </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             request=self.request,\n            session=self.session </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         .. versionadded:: 0.10\n <mask>         \"\"\"\n <mask>         return self.__class__(self.app,\n <mask>             environ=self.request.environ,\n <mask>             request=self.request\n <mask>         )\n <mask> \n <mask>     def match_request(self):\n <mask>         \"\"\"Can be overridden by a subclass to hook into the matching\n <mask>         of the request. </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add         .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object. </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context. </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> add -   :meth:`flask.RequestContext.copy` includes the current session\n    object in the request context copy. This prevents ``flask.session`` \n    pointing to an out-of-date object. (`#2935`)\n\n.. _#2935: https://github.com/pallets/flask/issues/2935", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         greenlets = []\n <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             reqctx = flask._request_ctx_stack.top.copy()\n <mask> \n <mask>             def g():\n <mask>                 assert not flask.request </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None):", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                     assert flask.current_app == app\n <mask>                     assert flask.request.path == '/'\n <mask>                     assert flask.request.args['foo'] == 'bar'\n <mask>                 assert not flask.request\n <mask>                 return 42\n <mask> \n <mask>             greenlets.append(greenlet(g)) </s> add                 assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> add             request=self.request,\n            session=self.session", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             reqctx = flask._request_ctx_stack.top.copy()\n <mask> \n <mask>             @flask.copy_current_request_context\n <mask>             def g(): </s> Fix #2935: Copy current session object in copy_current_request_context (#2936)\n\nAdd session to RequestContext.copy() </s> add             flask.session['fizz'] = 'buzz' </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function. </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> add             request=self.request,\n            session=self.session </s> remove         self.session = None </s> add     then pushed when the function is called.  The current session is also\n    included in the copied request context.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 assert flask.current_app == app\n <mask>                 assert flask.request.path == '/'\n <mask>                 assert flask.request.args['foo'] == 'bar'\n <mask>                 return 42\n <mask> \n <mask>             greenlets.append(greenlet(g))\n <mask>             return 'Hello World!' </s> add                     assert flask.session.get('fizz') == 'buzz' </s> add             flask.session['fizz'] = 'buzz' </s> remove     def __init__(self, app, environ, request=None): </s> add     def __init__(self, app, environ, request=None, session=None): </s> add             request=self.request,\n            session=self.session </s> remove                 # do some work here, it can access flask.request like you\n                # would otherwise in the view function. </s> add                 # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function.", "html_url": "https://github.com/pallets/flask/commit/e08bcf9f9700180a09f77f52604ea6de36fb83a8", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import os\n <mask> from functools import update_wrapper\n <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask>  </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options)", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.url_prefix = url_prefix\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"A helper method to register a rule (and optionally a view function)\n <mask>         to the application.  The endpoint is automatically prefixed with the\n <mask>         blueprint's name.\n <mask>         \"\"\"\n <mask>         if self.url_prefix: </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options) </s> remove                  url_prefix=None, subdomain=None): </s> add                  url_prefix=None, subdomain=None, url_defaults=None): </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults'))", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         if self.url_prefix:\n <mask>             rule = self.url_prefix + rule\n <mask>         options.setdefault('subdomain', self.subdomain)\n <mask>         if endpoint is None: </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options) </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> remove                  url_prefix=None, subdomain=None): </s> add                  url_prefix=None, subdomain=None, url_defaults=None):", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         if endpoint is None:\n <mask>             endpoint = _endpoint_from_view_func(view_func)\n <mask>         self.app.add_url_rule(rule, '%s.%s' % (self.blueprint.name, endpoint),\n <mask>                               view_func, defaults=defaults, **options)\n <mask> \n <mask>  </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> remove                  url_prefix=None, subdomain=None): </s> add                  url_prefix=None, subdomain=None, url_defaults=None):", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         options.setdefault('subdomain', self.subdomain)\n <mask>         if endpoint is None:\n <mask>             endpoint = _endpoint_from_view_func(view_func)\n <mask>         self.app.add_url_rule(rule, '%s.%s' % (self.blueprint.name, endpoint),\n <mask>                               view_func, **options)\n <mask> \n <mask> \n <mask> class Blueprint(_PackageBoundObject):\n <mask>     \"\"\"Represents a blueprint.\n <mask>  </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> remove                  url_prefix=None, subdomain=None): </s> add                  url_prefix=None, subdomain=None, url_defaults=None):", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     _got_registered_once = False\n <mask> \n <mask>     def __init__(self, name, import_name, static_folder=None,\n <mask>                  static_url_path=None, template_folder=None,\n <mask>                  url_prefix=None, subdomain=None):\n <mask>         _PackageBoundObject.__init__(self, import_name, template_folder)\n <mask>         self.name = name\n <mask>         self.url_prefix = url_prefix\n <mask>         self.subdomain = subdomain\n <mask>         self.static_folder = static_folder </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> add         if url_defaults is None:\n            url_defaults = {}\n        self.url_defaults = url_defaults </s> add         defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults')) </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options)", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.deferred_functions = []\n <mask>         self.view_functions = {}\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the </s> add         \"\"\"A helper method to register a rule (and optionally a view function)\n        to the application.  The endpoint is automatically prefixed with the\n        blueprint's name.\n        \"\"\" </s> add         self.url_defaults = dict(self.blueprint.url_defaults)\n        self.url_defaults.update(self.options.get('url_defaults', ())) </s> remove                               view_func, **options) </s> add                               view_func, defaults=defaults, **options)", "html_url": "https://github.com/pallets/flask/commit/e17e74d3a74b5d32a622587b2b9da9840bf3a7e0", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     with the documentation. It will return ``False`` if python-dotenv is\n <mask>     not installed, or if the given path isn't a file. :issue:`2937`\n <mask> -   Signaling support has a stub for the ``connect_via`` method when\n <mask>     the Blinker library is not installed. :pr:`3208`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994 </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``. </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items] </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898 </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n)", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> .. _#3059: https://github.com/pallets/flask/pull/3059\n <mask> .. _#3179: https://github.com/pallets/flask/pull/3179\n <mask> .. _#3125: https://github.com/pallets/flask/pull/3125\n <mask> \n <mask> -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n <mask> \n <mask> .. _#2898: https://github.com/pallets/flask/pull/2898\n <mask> \n <mask> Version 1.0.3\n <mask> -------------\n <mask> \n <mask> Released 2019-05-17 </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``. </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules') </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n)", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> These can be added to the ``.flaskenv`` file just like ``FLASK_APP`` to\n <mask> control default command options.\n <mask> \n <mask> To define a list of files the reloader should watch additionally to the modules\n <mask> as in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\n <mask> you can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n <mask> ``FLASK_RUN_EXTRA_FILES`` environment variable.\n <mask> \n <mask> .. code-block:: none\n <mask> \n <mask>     # on windows use ``;`` instead of ``:`` to separate paths\n <mask>     export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n <mask>     flask run\n <mask>      * Running on http://127.0.0.1:8000/\n <mask>      * Detected change in '/path/to/file1', reloading\n <mask> \n <mask> On command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``.\n <mask> \n <mask> Disable dotenv\n <mask> ~~~~~~~~~~~~~~\n <mask> \n <mask> The ``flask`` command will show a message if it detects dotenv files but </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> add class SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(self, value, param, ctx):\n        items = self.split_envvar_value(value)\n        super_convert = super(SeparatedPathType, self).convert\n        return [super_convert(item, param, ctx) for item in items] </s> remove @click.option('--extra-files', '-f',\n              multiple=True, default=None, type=click.Path(),\n              help='Files reloader should watch additionally to the modules') </s> add @click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        \" are separated by '{}'.\".format(os.path.pathsep)\n    ),\n) </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> @click.command(\"run\", short_help=\"Run a development server.\")\n <mask> @click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n <mask> @click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n <mask> @click.option(\n <mask>     \"--cert\", type=CertParamType(), help=\"Specify a certificate file to use HTTPS.\"\n <mask> ) </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897`", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"--with-threads/--without-threads\",\n <mask>     default=True,\n <mask>     help=\"Enable or disable multithreading.\",\n <mask> )\n <mask> @click.option('--extra-files', '-f',\n <mask>               multiple=True, default=None, type=click.Path(),\n <mask>               help='Files reloader should watch additionally to the modules')\n <mask> @pass_script_info\n <mask> def run_command(info, host, port, reload, debugger, eager_loading,\n <mask>                 with_threads, cert, extra_files):\n <mask>     \"\"\"Run a local development server.\n <mask>  </s> add SeparatedPathType to accept multiple paths\n\nMultiple paths for the reloader's `--extra-files` are accepted as one\noption, separated by ':'. </s> remove To define a list of files the reloader should watch additionally to the modules\nas in ``extra_files`` argument used in the ``app.run`` and ``werkzeug.serving.run_simple``\nyou can either use the ``--extra-files`` (or multiple ``-f``) option or define the\n``FLASK_RUN_EXTRA_FILES`` environment variable.\n\n.. code-block:: none\n\n    # on windows use ``;`` instead of ``:`` to separate paths\n    export FLASK_RUN_EXTRA_FILES=/path/to/file1:/path/to/file2\n    flask run\n     * Running on http://127.0.0.1:8000/\n     * Detected change in '/path/to/file1', reloading\n\nOn command line the same can be achieved with ``flask run -f /path/to/file1 -f /path/to/file2``. </s> add -   Add an ``--extra-files`` option to the ``flask run`` CLI command to\n    specify extra files that will trigger the reloader on change.\n    :issue:`2897` </s> remove -   Added support to ``extra_files`` argument in `flask run` CLI. (`#2898`_)\n\n.. _#2898: https://github.com/pallets/flask/pull/2898", "html_url": "https://github.com/pallets/flask/commit/e18cc4d71d1c0ded4a2a7afb417c5ea03ebb0861", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>                          root path.\n <mask>         :param silent: set to ``True`` if you want silent failure for missing\n <mask>                        files.\n <mask> \n <mask>         .. versionadded:: 0.7\n <mask>            `silent` parameter.\n <mask>         \"\"\"\n <mask>         filename = os.path.join(self.root_path, filename)\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             mapping of loaded data from the file.\n <mask>         :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n <mask>             implements a ``read`` method.\n <mask>         :param silent: Ignore the file if it doesn't exist.\n <mask> \n <mask>         .. versionadded:: 2.0\n <mask>         \"\"\"\n <mask>         filename = os.path.join(self.root_path, filename)\n <mask> \n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             absolute path or relative to the config root path.\n <mask>         :param silent: Ignore the file if it doesn't exist.\n <mask> \n <mask>         .. deprecated:: 2.0.0\n <mask>             Will be removed in Flask 2.1. Use :meth:`from_file` instead.\n <mask>             This was removed early in 2.0.0, was added back in 2.0.1.\n <mask> \n <mask>         .. versionadded:: 0.11\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: Always returns ``True``.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n <mask>         keys.\n <mask> \n <mask>         .. versionadded:: 0.11\n <mask>         \"\"\"\n <mask>         mappings: t.Dict[str, t.Any] = {}\n </s> document return value for config loading methods </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully. </s> add         :return: ``True`` if the file was loaded successfully.", "html_url": "https://github.com/pallets/flask/commit/e18ed45c8863ac645f3ce17a155034b8384e726f", "file_name": "src/flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> -   :meth:`jsonify` supports :class:`dataclasses.dataclass` objects.\n <mask>     :pr:`3195`\n <mask> -   Allow customizing the :attr:`Flask.url_map_class` used for routing.\n <mask>     :pr:`3069`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n <mask> .. _#3059: https://github.com/pallets/flask/pull/3059\n <mask> .. _#3179: https://github.com/pallets/flask/pull/3179 </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80), </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0),", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if server_name:\n <mask>             sn_host, _, sn_port = server_name.partition(\":\")\n <mask> \n <mask>         host = host or sn_host or _host\n <mask>         port = int(port or sn_port or _port)\n <mask> \n <mask>         options.setdefault(\"use_reloader\", self.debug)\n <mask>         options.setdefault(\"use_debugger\", self.debug)\n <mask>         options.setdefault(\"threaded\", True)\n <mask>  </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\" </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app): </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926` </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80), </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> remove     \"host,port,expect_host,expect_port\", </s> add     \"host,port,server_name,expect_host,expect_port\",", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace", "code_tokens": " <mask>     assert rv[\"result\"] == \"running on %s:%s ...\" % (hostname, port)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"host,port,expect_host,expect_port\",\n <mask>     (\n <mask>         (None, None, \"pocoo.org\", 8080),\n <mask>         (\"localhost\", None, \"localhost\", 8080),\n <mask>         (None, 80, \"pocoo.org\", 80),\n <mask>         (\"localhost\", 80, \"localhost\", 80), </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\" </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app): </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> remove         port = int(port or sn_port or _port) </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (None, 80, \"pocoo.org\", 80),\n <mask>         (\"localhost\", 80, \"localhost\", 80),\n <mask>     ),\n <mask> )\n <mask> def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app):\n <mask>     def run_simple_mock(hostname, port, *args, **kwargs):\n <mask>         assert hostname == expect_host\n <mask>         assert port == expect_port\n <mask> \n <mask>     monkeypatch.setattr(werkzeug.serving, \"run_simple\", run_simple_mock) </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80), </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> remove     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\" </s> add     app.config[\"SERVER_NAME\"] = server_name </s> remove     \"host,port,expect_host,expect_port\", </s> add     \"host,port,server_name,expect_host,expect_port\", </s> remove         port = int(port or sn_port or _port) </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert hostname == expect_host\n <mask>         assert port == expect_port\n <mask> \n <mask>     monkeypatch.setattr(werkzeug.serving, \"run_simple\", run_simple_mock)\n <mask>     app.config[\"SERVER_NAME\"] = \"pocoo.org:8080\"\n <mask>     app.run(host, port)\n <mask> \n <mask> \n <mask> def test_max_cookie_size(app, client, recwarn):\n <mask>     app.config[\"MAX_COOKIE_SIZE\"] = 100 </s> Fix 0 port value being overriden by default\n\nBy explicitly comparing port value with None,\ninstead of using its bool() value. </s> remove def test_run_from_config(monkeypatch, host, port, expect_host, expect_port, app): </s> add def test_run_from_config(monkeypatch, host, port, server_name, expect_host, expect_port, app): </s> remove         port = int(port or sn_port or _port) </s> add         # pick the first value that's not None (0 is allowed)\n        port = int(next((p for p in (port, sn_port) if p is not None), _port)) </s> remove     \"host,port,expect_host,expect_port\", </s> add     \"host,port,server_name,expect_host,expect_port\", </s> remove         (None, None, \"pocoo.org\", 8080),\n        (\"localhost\", None, \"localhost\", 8080),\n        (None, 80, \"pocoo.org\", 80),\n        (\"localhost\", 80, \"localhost\", 80), </s> add         (None, None, \"pocoo.org:8080\", \"pocoo.org\", 8080),\n        (\"localhost\", None, \"pocoo.org:8080\", \"localhost\", 8080),\n        (None, 80, \"pocoo.org:8080\", \"pocoo.org\", 80),\n        (\"localhost\", 80, \"pocoo.org:8080\", \"localhost\", 80),\n        (\"localhost\", 0, \"localhost:8080\", \"localhost\", 0),\n        (None, None, \"localhost:8080\", \"localhost\", 8080),\n        (None, None, \"localhost:0\", \"localhost\", 0), </s> add -   The development server port can be set to 0, which tells the OS to\n    pick an available port. :issue:`2926`", "html_url": "https://github.com/pallets/flask/commit/e1cc16f8bea15f11f63eacaa6089cd6e6b8b1965", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> from sqlite3 import dbapi2 as sqlite3\n <mask> from flask import Flask, request, session, g, redirect, url_for, abort, \\\n <mask>      render_template, flash, _app_ctx_stack\n <mask> \n <mask> # configuration </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> from __future__ import with_statement\n <mask> import time\n <mask> from sqlite3 import dbapi2 as sqlite3\n <mask> from hashlib import md5\n <mask> from datetime import datetime\n <mask> from flask import Flask, request, session, url_for, redirect, \\ </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     unichr = chr\n <mask>     range_type = range\n <mask>     text_type = str\n <mask>     string_types = (str,)\n <mask> \n <mask>     iterkeys = lambda d: iter(d.keys())\n <mask>     itervalues = lambda d: iter(d.values())\n <mask>     iteritems = lambda d: iter(d.items()) </s> add     integer_types = (int, long) </s> add     from urllib.parse import urlparse </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types): </s> add     \"\"\"not used currently\"\"\" </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     implements_to_string = _identity\n <mask>     encode_filename = _identity\n <mask>     get_next = lambda x: x.__next__\n <mask> \n <mask> else:\n <mask>     unichr = unichr\n <mask>     text_type = unicode\n <mask>     range_type = xrange\n <mask>     string_types = (str, unicode)\n <mask>     integer_types = (int, long) </s> add     integer_types = (int, long) </s> add     integer_types = (int, ) </s> remove     if isinstance(filename_or_fp, basestring): </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types): </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types): </s> add         if isinstance(code_or_exception, integer_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     unichr = unichr\n <mask>     text_type = unicode\n <mask>     range_type = xrange\n <mask>     string_types = (str, unicode)\n <mask> \n <mask>     iterkeys = lambda d: d.iterkeys()\n <mask>     itervalues = lambda d: d.itervalues()\n <mask>     iteritems = lambda d: d.iteritems()\n <mask> \n <mask>     import cPickle as pickle </s> add     integer_types = (int, ) </s> remove     if isinstance(filename_or_fp, basestring): </s> add     if isinstance(filename_or_fp, string_types): </s> add             if isinstance(status, string_types): </s> remove                 filename.encode('utf-8') if isinstance(filename, unicode) </s> add                 filename.encode('utf-8') if isinstance(filename, text_type)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/_compat.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> from threading import Lock\n <mask> from datetime import timedelta\n <mask> from itertools import chain </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     _default_template_ctx_processor\n <mask> from .signals import request_started, request_finished, got_request_exception, \\\n <mask>     request_tearing_down, appcontext_tearing_down\n <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask> \n <mask> def _make_timedelta(value): </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv </s> add         return self.create_jinja_environment() </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> add         if isinstance(code_or_exception, integer_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @locked_cached_property\n <mask>     def jinja_env(self):\n <mask>         \"\"\"The Jinja2 environment used to load templates.\"\"\"\n <mask>         rv = self.create_jinja_environment()\n <mask> \n <mask>         # Hack to support the init_jinja_globals method which is supported\n <mask>         # until 1.0 but has an API deficiency.\n <mask>         if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n <mask>            Flask.init_jinja_globals.__func__:\n <mask>             from warnings import warn\n <mask>             warn(DeprecationWarning('This flask class uses a customized '\n <mask>                 'init_jinja_globals() method which is deprecated. '\n <mask>                 'Move the code from that method into the '\n <mask>                 'create_jinja_environment() method instead.'))\n <mask>             self.__dict__['jinja_env'] = rv\n <mask>             self.init_jinja_globals()\n <mask> \n <mask>         return rv\n <mask> \n <mask>     @property\n <mask>     def got_first_request(self):\n <mask>         \"\"\"This attribute is set to `True` if the application started\n <mask>         handling the first request. </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @setupmethod\n <mask>     def _register_error_handler(self, key, code_or_exception, f):\n <mask>         if isinstance(code_or_exception, HTTPException):\n <mask>             code_or_exception = code_or_exception.code\n <mask>         if isinstance(code_or_exception, (int, long)):\n <mask>             assert code_or_exception != 500 or key is None, \\\n <mask>                 'It is currently not possible to register a 500 internal ' \\\n <mask>                 'server error on a per-blueprint level.'\n <mask>             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n <mask>         else: </s> add            and isinstance(filename, string_types): </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           @app.template_test()\n <mask>           def is_prime(n):\n <mask>               if n == 2:\n <mask>                   return True\n <mask>               for i in xrange(2, int(math.ceil(math.sqrt(n))) + 1):\n <mask>                   if n % i == 0:\n <mask>                       return False\n <mask>               return True\n <mask> \n <mask>         .. versionadded:: 0.10 </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add             reraise(exc_type, exc_value, tb) </s> remove         raise exc_type, exc_value, tb </s> add         reraise(exc_type, exc_value, tb) </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv </s> add         return self.create_jinja_environment() </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for typecheck, handler in chain(blueprint_handlers, app_handlers):\n <mask>             if isinstance(e, typecheck):\n <mask>                 return handler(e)\n <mask> \n <mask>         raise exc_type, exc_value, tb\n <mask> \n <mask>     def handle_exception(self, e):\n <mask>         \"\"\"Default exception handling that kicks in when an exception\n <mask>         occurs that is not caught.  In debug mode the exception will\n <mask>         be re-raised immediately, otherwise it is logged and the handler </s> remove                 raise exc_type, exc_value, tb </s> add                 reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next </s> add                     reraise(exc_type, exc_value, tb.tb_next)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # raise it with the whole traceback in case we can do that\n <mask>             # (the function was actually called from the except part)\n <mask>             # otherwise, we just raise the error again\n <mask>             if exc_value is e:\n <mask>                 raise exc_type, exc_value, tb\n <mask>             else:\n <mask>                 raise e\n <mask> \n <mask>         self.log_exception((exc_type, exc_value, tb))\n <mask>         if handler is None: </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         raise exc_type, exc_value, tb </s> add         reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # When we create a response object directly, we let the constructor\n <mask>             # set the headers and status.  We do this because there can be\n <mask>             # some extra logic involved when creating these objects with\n <mask>             # specific values (like defualt content type selection).\n <mask>             if isinstance(rv, basestring):\n <mask>                 rv = self.response_class(rv, headers=headers, status=status)\n <mask>                 headers = status = None\n <mask>             else:\n <mask>                 rv = self.response_class.force_type(rv, request.environ)\n <mask>  </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types): </s> remove                 raise exc_type, exc_value, tb </s> add                 reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next </s> add                     reraise(exc_type, exc_value, tb.tb_next)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             else:\n <mask>                 rv = self.response_class.force_type(rv, request.environ)\n <mask> \n <mask>         if status is not None:\n <mask>             if isinstance(status, basestring):\n <mask>                 rv.status = status\n <mask>             else:\n <mask>                 rv.status_code = status\n <mask>         if headers:\n <mask>             rv.headers.extend(headers) </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types): </s> remove     if isinstance(filename_or_fp, basestring): </s> add     if isinstance(filename_or_fp, string_types): </s> add     from urllib.parse import urlparse", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # At this point we want to reraise the exception.  If the error is\n <mask>         # still the same one we can reraise it with the original traceback,\n <mask>         # otherwise we raise it from here.\n <mask>         if error is exc_value:\n <mask>             raise exc_type, exc_value, tb\n <mask>         raise error\n <mask> \n <mask>     def preprocess_request(self):\n <mask>         \"\"\"Called before the actual request dispatching and will\n <mask>         call every as :meth:`before_request` decorated function. </s> remove                 raise exc_type, exc_value, tb </s> add                 reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next </s> add                     reraise(exc_type, exc_value, tb.tb_next) </s> remove         raise exc_type, exc_value, tb </s> add         reraise(exc_type, exc_value, tb) </s> add             if isinstance(rv, string_types): </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import os\n <mask> import errno\n <mask> \n <mask> from werkzeug.utils import import_string\n <mask> \n <mask> \n <mask> class ConfigAttribute(object):\n <mask>     \"\"\"Makes an attribute forward to the config\"\"\"\n <mask> \n <mask>     def __init__(self, name, get_converter=None): </s> add from flask._compat import reraise, StringIO </s> add from flask._compat import reraise </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         package because the package might be installed system wide.\n <mask> \n <mask>         :param obj: an import name or object\n <mask>         \"\"\"\n <mask>         if isinstance(obj, basestring):\n <mask>             obj = import_string(obj)\n <mask>         for key in dir(obj):\n <mask>             if key.isupper():\n <mask>                 self[key] = getattr(obj, key)\n <mask>  </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types): </s> remove            and isinstance(filename, basestring): </s> add            and isinstance(filename, string_types): </s> remove         for entry, value in sys.modules.items(): </s> add         for entry, value in list(sys.modules.items()): </s> remove     if isinstance(filename_or_fp, basestring): </s> add     if isinstance(filename_or_fp, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import sys\n <mask> import os\n <mask> \n <mask> \n <mask> class ExtensionImporter(object):\n <mask>     \"\"\"This importer redirects imports from this submodule to other locations.\n <mask>     This makes it possible to transition from the old flaskext.name to the\n <mask>     newer flask_name without people having a hard time. </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import string_types </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv </s> add from flask._compat import reraise, StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/exthook.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 # If it's an important traceback we reraise it, otherwise\n <mask>                 # we swallow it and try the next choice.  The skipped frame\n <mask>                 # is the one from __import__ above which we don't care about\n <mask>                 if self.is_important_traceback(realname, tb):\n <mask>                     raise exc_type, exc_value, tb.tb_next\n <mask>                 continue\n <mask>             module = sys.modules[fullname] = sys.modules[realname]\n <mask>             if '.' not in modname:\n <mask>                 setattr(sys.modules[self.wrapper_module], modname, module)\n <mask>             return module </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove                 raise exc_type, exc_value, tb </s> add                 reraise(exc_type, exc_value, tb) </s> add         for entry, value in list(sys.modules.items()): </s> remove         raise exc_type, exc_value, tb </s> add         reraise(exc_type, exc_value, tb) </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/exthook.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import sys\n <mask> import pkgutil\n <mask> import posixpath\n <mask> import mimetypes </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.exceptions import NotFound\n <mask> import six\n <mask> \n <mask> # this was moved in 0.7\n <mask> try:\n <mask>     from werkzeug.wsgi import wrap_file </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                           :meth:`~Flask.get_send_file_max_age` of\n <mask>                           :data:`~flask.current_app`.\n <mask>     \"\"\"\n <mask>     mtime = None\n <mask>     if isinstance(filename_or_fp, basestring):\n <mask>         filename = filename_or_fp\n <mask>         file = None\n <mask>     else:\n <mask>         from warnings import warn\n <mask>         file = filename_or_fp </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types): </s> remove         if isinstance(obj, basestring): </s> remove            and isinstance(filename, basestring): </s> add            and isinstance(filename, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv.set_etag('flask-%s-%s-%s' % (\n <mask>             os.path.getmtime(filename),\n <mask>             os.path.getsize(filename),\n <mask>             adler32(\n <mask>                 filename.encode('utf-8') if isinstance(filename, unicode)\n <mask>                 else filename\n <mask>             ) & 0xffffffff\n <mask>         ))\n <mask>         if conditional:\n <mask>             rv = rv.make_conditional(request) </s> remove            and isinstance(filename, basestring): </s> add            and isinstance(filename, string_types): </s> remove             if isinstance(status, basestring): </s> add             if isinstance(status, string_types): </s> remove     if isinstance(filename_or_fp, basestring): </s> add     if isinstance(filename_or_fp, string_types): </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> from contextlib import contextmanager\n <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> from urlparse import urlparse\n <mask> \n <mask> from contextlib import contextmanager\n <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> from urlparse import urlparse\n <mask>  </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import flask\n <mask> import warnings\n <mask> import unittest\n <mask> from StringIO import StringIO\n <mask> from functools import update_wrapper\n <mask> from contextlib import contextmanager\n <mask> from werkzeug.utils import import_string, find_modules\n <mask> \n <mask>  </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import reraise, StringIO </s> remove from StringIO import StringIO </s> remove from StringIO import StringIO </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from contextlib import contextmanager\n <mask> from werkzeug.utils import import_string, find_modules\n <mask> \n <mask> \n <mask> def add_to_path(path):\n <mask>     \"\"\"Adds an entry to sys.path if it's not already there.  This does </s> add from flask._compat import string_types </s> add from flask._compat import urlparse </s> remove from __future__ import with_statement </s> add from flask._compat import reraise", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if exc_type is None:\n <mask>             self.test_case.fail('Expected exception of type %r' %\n <mask>                                 exception_name)\n <mask>         elif not issubclass(exc_type, self.exc_type):\n <mask>             raise exc_type, exc_value, tb\n <mask>         return True\n <mask> \n <mask> \n <mask> class BetterLoader(unittest.TestLoader):\n <mask>     \"\"\"A nicer loader that solves two problems.  First of all we are setting </s> remove         raise exc_type, exc_value, tb </s> add         reraise(exc_type, exc_value, tb) </s> remove                 raise exc_type, exc_value, tb </s> add                 reraise(exc_type, exc_value, tb) </s> remove             raise exc_type, exc_value, tb </s> add             reraise(exc_type, exc_value, tb) </s> remove                     raise exc_type, exc_value, tb.tb_next </s> add                     reraise(exc_type, exc_value, tb.tb_next)", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import re\n <mask> import uuid\n <mask> import flask\n <mask> import pickle\n <mask> import unittest </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def fail_func():\n <mask>             1/0\n <mask> \n <mask>         c = app.test_client()\n <mask>         for x in xrange(3):\n <mask>             with self.assert_raises(ZeroDivisionError):\n <mask>                 c.get('/fail')\n <mask> \n <mask>         self.assert_(flask._request_ctx_stack.top is not None)\n <mask>         self.assert_(flask._app_ctx_stack.top is not None) </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase, catch_warnings\n <mask> \n <mask>  </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from flask.testsuite import FlaskTestCase, catch_warnings\n <mask> \n <mask> \n <mask> class DeprecationsTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_init_jinja_globals(self):\n <mask>         class MyFlask(flask.Flask):\n <mask>             def init_jinja_globals(self):\n <mask>                 self.jinja_env.globals['foo'] = '42'\n <mask> \n <mask>         with catch_warnings() as log:\n <mask>             app = MyFlask(__name__)\n <mask>             @app.route('/')\n <mask>             def foo():\n <mask>                 return app.jinja_env.globals['foo']\n <mask> \n <mask>             c = app.test_client()\n <mask>             self.assert_equal(c.get('/').data, '42')\n <mask>             self.assert_equal(len(log), 1)\n <mask>             self.assert_('init_jinja_globals' in str(log[0]['message']))\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase)) </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add         for x in range(3): </s> add         for x in range(2): </s> remove         rv = self.create_jinja_environment()\n\n        # Hack to support the init_jinja_globals method which is supported\n        # until 1.0 but has an API deficiency.\n        if getattr(self.init_jinja_globals, 'im_func', None) is not \\\n           Flask.init_jinja_globals.__func__:\n            from warnings import warn\n            warn(DeprecationWarning('This flask class uses a customized '\n                'init_jinja_globals() method which is deprecated. '\n                'Move the code from that method into the '\n                'create_jinja_environment() method instead.'))\n            self.__dict__['jinja_env'] = rv\n            self.init_jinja_globals()\n\n        return rv </s> add         return self.create_jinja_environment()", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # we clear this out for various reasons.  The most important one is\n <mask>         # that a real flaskext could be in there which would disable our\n <mask>         # fake package.  Secondly we want to make sure that the flaskext\n <mask>         # import hook does not break on reloading.\n <mask>         for entry, value in sys.modules.items():\n <mask>             if (entry.startswith('flask.ext.') or\n <mask>                 entry.startswith('flask_') or\n <mask>                 entry.startswith('flaskext.') or\n <mask>                 entry == 'flaskext') and value is not None:\n <mask>                 sys.modules.pop(entry, None) </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add     from urlparse import urlparse </s> remove             if isinstance(rv, basestring): </s> add             if isinstance(rv, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from flask.ext.oldext_package.submodule import test_function\n <mask>         self.assert_equal(test_function(), 42)\n <mask> \n <mask>     def test_flaskext_broken_package_no_module_caching(self):\n <mask>         for x in xrange(2):\n <mask>             with self.assert_raises(ImportError):\n <mask>                 import flask.ext.broken\n <mask> \n <mask>     def test_no_error_swallowing(self):\n <mask>         try: </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> add from flask._compat import urlparse", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import os\n <mask> import flask\n <mask> import unittest\n <mask> from logging import StreamHandler\n <mask> from StringIO import StringIO\n <mask> from flask.testsuite import FlaskTestCase, catch_warnings, catch_stderr\n <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> import six\n <mask>  </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # This test only works on CPython 2.7.\n <mask>         if sys.version_info >= (2, 7) and \\\n <mask>                 not hasattr(sys, 'pypy_translation_info'):\n <mask>             with self.assert_no_leak():\n <mask>                 for x in xrange(10):\n <mask>                     fire()\n <mask> \n <mask>     def test_safe_join_toplevel_pardir(self):\n <mask>         from flask.helpers import safe_join\n <mask>         with self.assert_raises(NotFound): </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove            and isinstance(filename, basestring): </s> add            and isinstance(filename, string_types):", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/regression.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import flask\n <mask> import unittest\n <mask> from StringIO import StringIO\n <mask> from logging import StreamHandler\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n <mask> class FlaskSubclassingTestCase(FlaskTestCase): </s> add from flask._compat import StringIO </s> remove from StringIO import StringIO </s> remove from StringIO import StringIO", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/subclassing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from logging import StreamHandler\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n <mask> class FlaskSubclassingTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_suppressed_exception_logging(self):\n <mask>         class SuppressedFlask(flask.Flask): </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3 </s> remove from StringIO import StringIO </s> remove from StringIO import StringIO </s> add from flask._compat import string_types </s> remove \n    def test_init_jinja_globals(self):\n        class MyFlask(flask.Flask):\n            def init_jinja_globals(self):\n                self.jinja_env.globals['foo'] = '42'\n\n        with catch_warnings() as log:\n            app = MyFlask(__name__)\n            @app.route('/')\n            def foo():\n                return app.jinja_env.globals['foo']\n\n            c = app.test_client()\n            self.assert_equal(c.get('/').data, '42')\n            self.assert_equal(len(log), 1)\n            self.assert_('init_jinja_globals' in str(log[0]['message']))", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/subclassing.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> \n <mask> \n </s> ported some more stuff to py 3.3\n\nremoved init_jinja_globals hack from app.py after consulting mitsuhiko\n(didn't work on py 3.3 \"as is\")\n\nremoved with_statement future imports, not needed any more\n\nneeds more work on 2.7 as well as on 3.3", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2011 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from __future__ import with_statement\n <mask> \n <mask> import flask\n <mask> import unittest\n <mask> from flask.testsuite import FlaskTestCase\n <mask> import six\n <mask>  </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement </s> remove from __future__ import with_statement", "html_url": "https://github.com/pallets/flask/commit/e1d356fb713f3272db2a23f9f898c34c5dc79dc0", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     app = getattr(module, 'app', None)\n <mask>     if app is not None and callable(app):\n <mask>         return app\n <mask> \n <mask>     # Otherwise find the first object named Flask\n <mask>     matches = []\n <mask>     for key, value in iteritems(module.__dict__):\n <mask>         if isinstance(value, Flask):\n <mask>             matches.append(value)\n <mask>  </s> remove     is known by it's import name.  By default the app ID can also be a </s> add     is known by its import name.  By default the app ID can also be a </s> remove     \"\"\"Special applicationt that dispatches to a flask application which </s> add     \"\"\"Special application that dispatches to a flask application which", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def prepare_exec_for_file(filename):\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers\n <mask>     if filename.endswith('.py'):\n <mask>         filename = filename[:-3]\n <mask>     elif os.path.split(filename)[1] == '__init__.py':\n <mask>         filename = os.path.dirname(filename)\n <mask>     filename = os.path.realpath(filename) </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to </s> remove     is known by it's import name.  By default the app ID can also be a </s> add     is known by its import name.  By default the app ID can also be a", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class DispatchingApp(object):\n <mask>     \"\"\"Special applicationt that dispatches to a flask application which\n <mask>     is imported by name on first request.  This is safer than importing\n <mask>     the application upfront because it means that we can forward all\n <mask>     errors for import problems into the browser as error.\n <mask>     \"\"\"\n <mask> \n <mask> class DispatchingApp(object):\n <mask>     \"\"\"Special applicationt that dispatches to a flask application which\n <mask>     is imported by name on first request.  This is safer than importing\n <mask>     the application upfront because it means that we can forward all\n <mask>     errors for import problems into the browser as error.\n <mask>     \"\"\"\n <mask>  </s> Fix typos in docstrings and comments in run.py </s> remove     is known by it's import name.  By default the app ID can also be a </s> add     is known by its import name.  By default the app ID can also be a </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to </s> add     # Extra startup messages.  This depends a bit on Werkzeug internals to </s> remove     # Otherwise find the first object named Flask </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     # Chop off file extensions or package markers </s> add     # Chop off file extensions or package markers.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     use_reloader=False, use_debugger=False,\n <mask>                     use_eager_loading=None, magic_app_id=True,\n <mask>                     **options):\n <mask>     \"\"\"Useful function to start a Werkzeug server for an application that\n <mask>     is known by it's import name.  By default the app ID can also be a\n <mask>     full file name in which case Flask attempts to reconstruct the import\n <mask>     name from it and do the right thing.\n <mask> \n <mask>     :param app_id: the import name of the application module.  If a colon\n <mask>                    is provided, everything afterwards is the application </s> remove     \"\"\"Special applicationt that dispatches to a flask application which </s> add     \"\"\"Special application that dispatches to a flask application which </s> remove     # Extra startup messages.  This depends a but on Werkzeug internals to </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error. </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     # Otherwise find the first object named Flask </s> add     # Otherwise find exactly one Flask instance, or fail.", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if use_eager_loading is None:\n <mask>         use_eager_loading = not use_reloader\n <mask> \n <mask>     # Extra startup messages.  This depends a but on Werkzeug internals to\n <mask>     # not double execute when the reloader kicks in.\n <mask>     if os.environ.get('WERKZEUG_RUN_MAIN') != 'true':\n <mask>         print ' * Serving Flask app \"%s\"' % app_id\n <mask>         if debug is not None:\n <mask>             print ' * Forcing debug %s' % (debug and 'on' or 'off') </s> remove     # Otherwise find the first object named Flask </s> add     # Otherwise find exactly one Flask instance, or fail. </s> remove     is known by it's import name.  By default the app ID can also be a </s> add     is known by its import name.  By default the app ID can also be a </s> remove     the application upfront because it means that we can forward all\n    errors for import problems into the browser as error. </s> add     the application up front because it means that we can forward all\n    errors for import problems into the browser as errors. </s> remove     \"\"\"Special applicationt that dispatches to a flask application which </s> add     \"\"\"Special application that dispatches to a flask application which", "html_url": "https://github.com/pallets/flask/commit/e21afed0bba82668c6e4f5f433d0ccfcf54b3577", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import platform\n <mask> import re\n <mask> import sys\n <mask> import traceback\n <mask> import warnings\n <mask> from functools import update_wrapper\n <mask> from operator import attrgetter\n <mask> from threading import Lock\n <mask> from threading import Thread\n <mask>  </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class NoAppException(click.UsageError):\n <mask>     \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n <mask> \n <mask> \n <mask> def find_best_app(script_info, module):\n <mask>     \"\"\"Given a module instance this tries to find the best possible\n <mask>     application in the module or raises an exception.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask>  </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove         args = kwargs = None </s> remove         return find_best_app(script_info, module) </s> add         return find_best_app(module) </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app_factory = getattr(module, attr_name, None)\n <mask> \n <mask>         if inspect.isfunction(app_factory):\n <mask>             try:\n <mask>                 app = call_factory(script_info, app_factory)\n <mask> \n <mask>                 if isinstance(app, Flask):\n <mask>                     return app\n <mask>             except TypeError as e:\n <mask>                 if not _called_with_wrong_args(app_factory): </s> remove deprecated script_info factory arg </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove def locate_app(script_info, module_name, app_name, raise_if_not_found=True): </s> add def locate_app(module_name, app_name, raise_if_not_found=True): </s> remove             app = call_factory(self, self.create_app) </s> add             app = self.create_app() </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False) </s> add                     app = locate_app(import_name, None, raise_if_not_found=False) </s> remove         args = kwargs = None", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \" to specify one.\"\n <mask>     )\n <mask> \n <mask> \n <mask> def call_factory(script_info, app_factory, args=None, kwargs=None):\n <mask>     \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n <mask>     of arguments. Checks for the existence of a script_info argument and calls\n <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     sig = inspect.signature(app_factory)\n <mask>     args = [] if args is None else args\n <mask>     kwargs = {} if kwargs is None else kwargs\n <mask> \n <mask>     if \"script_info\" in sig.parameters:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\"\n <mask>             \" passed to the app factory function in Flask 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>         kwargs[\"script_info\"] = script_info\n <mask> \n <mask>     if not args and len(sig.parameters) == 1:\n <mask>         first_parameter = next(iter(sig.parameters.values()))\n <mask> \n <mask>         if (\n <mask>             first_parameter.default is inspect.Parameter.empty\n <mask>             # **kwargs is reported as an empty default, ignore it\n <mask>             and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n <mask>         ):\n <mask>             warnings.warn(\n <mask>                 \"Script info is deprecated and will not be passed as the\"\n <mask>                 \" single argument to the app factory function in Flask\"\n <mask>                 \" 2.1.\",\n <mask>                 DeprecationWarning,\n <mask>             )\n <mask>             args.append(script_info)\n <mask> \n <mask>     return app_factory(*args, **kwargs)\n <mask> \n <mask> \n <mask> def _called_with_wrong_args(f):\n <mask>     \"\"\"Check whether calling a function raised a ``TypeError`` because\n <mask>     the call failed or because something in the factory raised the\n <mask>     error.\n <mask>  </s> remove deprecated script_info factory arg </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove         args = kwargs = None </s> add         args = []\n        kwargs = {} </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove def find_best_app(script_info, module): </s> add def find_best_app(module): </s> remove             app = call_factory(self, self.create_app) </s> add             app = self.create_app()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # https://docs.python.org/2/library/sys.html#sys.exc_info\n <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name):\n <mask>     \"\"\"Check if the given string is a variable name or a function. Call\n <mask>     a function to get the app instance, or return the variable directly.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask>  </s> remove def find_best_app(script_info, module): </s> add def find_best_app(module): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove         return find_app_by_string(script_info, module, app_name) </s> add         return find_app_by_string(module, app_name)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ) from None\n <mask> \n <mask>     if isinstance(expr, ast.Name):\n <mask>         name = expr.id\n <mask>         args = kwargs = None\n <mask>     elif isinstance(expr, ast.Call):\n <mask>         # Ensure the function name is an attribute name only.\n <mask>         if not isinstance(expr.func, ast.Name):\n <mask>             raise NoAppException(\n <mask>                 f\"Function reference must be a simple name: {app_name!r}.\" </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # If the attribute is a function, call it with any args and kwargs\n <mask>     # to get the real application.\n <mask>     if inspect.isfunction(attr):\n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args, kwargs)\n <mask>         except TypeError as e:\n <mask>             if not _called_with_wrong_args(attr):\n <mask>                 raise\n <mask> \n <mask>             raise NoAppException( </s> remove         args = kwargs = None </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove                 app = call_factory(script_info, app_factory) </s> add                 app = app_factory() </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove def locate_app(script_info, module_name, app_name, raise_if_not_found=True): </s> add def locate_app(module_name, app_name, raise_if_not_found=True):", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return \".\".join(module_name[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\n <mask>     __traceback_hide__ = True  # noqa: F841\n <mask> \n <mask>     try:\n <mask>         __import__(module_name)\n <mask>     except ImportError as e: </s> remove deprecated script_info factory arg </s> remove                 app = call_factory(script_info, app_factory) </s> add                 app = app_factory() </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False) </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     module = sys.modules[module_name]\n <mask> \n <mask>     if app_name is None:\n <mask>         return find_best_app(script_info, module)\n <mask>     else:\n <mask>         return find_app_by_string(script_info, module, app_name)\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value): </s> remove         return find_app_by_string(script_info, module, app_name) </s> add         return find_app_by_string(module, app_name) </s> remove             app = call_factory(self, self.create_app) </s> add             app = self.create_app() </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove def find_best_app(script_info, module): </s> add def find_best_app(module): </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False) </s> add                     app = locate_app(import_name, None, raise_if_not_found=False)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if app_name is None:\n <mask>         return find_best_app(script_info, module)\n <mask>     else:\n <mask>         return find_app_by_string(script_info, module, app_name)\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value):\n <mask>     if not value or ctx.resilient_parsing:\n <mask>         return </s> remove         return find_best_app(script_info, module) </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name): </s> remove             app = call_factory(self, self.create_app) </s> add             app = self.create_app() </s> remove def find_best_app(script_info, module): </s> add def find_best_app(module): </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self, self.create_app)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = (\n <mask>                     re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n <mask>                 )[:2] </s> remove                 app = locate_app(self, import_name, name) </s> add                 app = locate_app(import_name, name) </s> remove         return find_app_by_string(script_info, module, app_name) </s> add         return find_app_by_string(module, app_name) </s> remove         return find_best_app(script_info, module) </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False) </s> add                     app = locate_app(import_name, None, raise_if_not_found=False)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>                     re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n <mask>                 )[:2]\n <mask>                 import_name = prepare_import(path)\n <mask>                 app = locate_app(self, import_name, name)\n <mask>             else:\n <mask>                 for path in (\"wsgi.py\", \"app.py\"):\n <mask>                     import_name = prepare_import(path)\n <mask>                     app = locate_app(self, import_name, None, raise_if_not_found=False)\n <mask> \n <mask>                     if app:\n <mask>                         break </s> remove             app = call_factory(self, self.create_app) </s> add             app = self.create_app() </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False) </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove         locate_app(info, iname, aname) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove                 app = call_factory(script_info, app_factory) </s> add                 app = app_factory()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> )\n <mask> \n <mask> \n <mask> def main() -> None:\n <mask>     if int(click.__version__[0]) < 8:\n <mask>         warnings.warn(\n <mask>             \"Using the `flask` cli with Click 7 is deprecated and\"\n <mask>             \" will not be supported starting with Flask 2.1.\"\n <mask>             \" Please upgrade to Click 8 as soon as possible.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>     # TODO omit sys.argv once https://github.com/pallets/click/issues/536 is fixed\n <mask>     cli.main(args=sys.argv[1:])\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     main() </s> remove deprecated script_info factory arg </s> add </s> remove             app = call_factory(script_info, attr, args, kwargs) </s> add             app = attr(*args, **kwargs) </s> remove -   Update Click dependency to >= 8.0. </s> add -   Drop support for Python 3.6. :pr:`4335`\n-   Update Click dependency to >= 8.0. :pr:`4008`\n-   Remove previously deprecated code. :pr:`4337`\n\n    -   The CLI does not pass ``script_info`` to app factory functions. </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove         args = kwargs = None </s> add         args = []\n        kwargs = {} </s> remove def find_app_by_string(script_info, module, app_name): </s> add def find_app_by_string(module, app_name):", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_find_best_app(test_apps):\n <mask>     script_info = ScriptInfo()\n <mask> \n <mask>     class Module:\n <mask>         app = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.app\n <mask> \n <mask>     class Module:\n <mask>         app = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.app\n <mask> \n <mask>     class Module:\n <mask>         application = Flask(\"appname\")\n <mask>  </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         application = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.application\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.app </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     script_info = ScriptInfo()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\") </s> remove deprecated script_info factory arg </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.app </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(**kwargs):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     with pytest.deprecated_call(match=\"Script info\"):\n <mask>         app = find_best_app(script_info, Module)\n <mask> \n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     with pytest.deprecated_call(match=\"script_info\"):\n <mask>         app = find_best_app(script_info, Module)\n <mask> \n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod </s> remove deprecated script_info factory arg </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.app </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     app = find_best_app(script_info, Module)\n <mask>     assert isinstance(app, Flask)\n <mask>     assert app.name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\") </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(script_info, Module) == Module.app </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\")\n <mask> \n <mask>         @staticmethod </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     assert find_best_app(script_info, Module) == Module.myapp\n <mask> \n <mask>     class Module:\n <mask>         pass\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module) </s> add     pytest.raises(TypeError, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Module:\n <mask>         pass\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         myapp1 = Flask(\"appname1\")\n <mask>         myapp2 = Flask(\"appname2\")\n <mask>  </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     assert find_best_app(script_info, Module) == Module.application </s> add     assert find_best_app(Module) == Module.application", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     class Module:\n <mask>         myapp1 = Flask(\"appname1\")\n <mask>         myapp2 = Flask(\"appname2\")\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo, bar):\n <mask>             return Flask(\"appname2\") </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module) </s> remove     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(foo=None, script_info=None):\n            return Flask(\"appname\")\n\n    with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo, bar):\n <mask>             return Flask(\"appname2\")\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             raise TypeError(\"bad bad factory!\") </s> remove deprecated script_info factory arg </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module) </s> add     pytest.raises(TypeError, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     app = find_best_app(script_info, Module) </s> add     app = find_best_app(Module)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             raise TypeError(\"bad bad factory!\")\n <mask> \n <mask>     pytest.raises(TypeError, find_best_app, script_info, Module)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"value,path,result\",\n <mask>     ( </s> remove deprecated script_info factory arg </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     pytest.raises(NoAppException, find_best_app, script_info, Module) </s> add     pytest.raises(NoAppException, find_best_app, Module) </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result </s> add     assert locate_app(iname, aname).name == result </s> remove     assert find_best_app(script_info, Module) == Module.myapp </s> add     assert find_best_app(Module) == Module.myapp", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"),\n <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result):\n <mask>     info = ScriptInfo()\n <mask>     assert locate_app(info, iname, aname).name == result\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"iname,aname\",\n <mask>     ( </s> remove deprecated script_info factory arg </s> remove     info = ScriptInfo() </s> remove         locate_app(info, iname, aname) </s> add         locate_app(iname, aname) </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False) </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove     pytest.raises(TypeError, find_best_app, script_info, Module) </s> add     pytest.raises(TypeError, find_best_app, Module) </s> remove def call_factory(script_info, app_factory, args=None, kwargs=None):\n    \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n    of arguments. Checks for the existence of a script_info argument and calls\n    the app_factory depending on that and the arguments provided.\n    \"\"\"\n    sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs\n\n    if \"script_info\" in sig.parameters:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in Flask 2.1.\",\n            DeprecationWarning,\n        )\n        kwargs[\"script_info\"] = script_info\n\n    if not args and len(sig.parameters) == 1:\n        first_parameter = next(iter(sig.parameters.values()))\n\n        if (\n            first_parameter.default is inspect.Parameter.empty\n            # **kwargs is reported as an empty default, ignore it\n            and first_parameter.kind is not inspect.Parameter.VAR_KEYWORD\n        ):\n            warnings.warn(\n                \"Script info is deprecated and will not be passed as the\"\n                \" single argument to the app factory function in Flask\"\n                \" 2.1.\",\n                DeprecationWarning,\n            )\n            args.append(script_info)\n\n    return app_factory(*args, **kwargs) </s> remove     script_info = ScriptInfo()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace", "code_tokens": " <mask>     ),\n <mask> )\n <mask> def test_locate_app_raises(test_apps, iname, aname):\n <mask>     info = ScriptInfo()\n <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         locate_app(info, iname, aname) </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result </s> add     assert locate_app(iname, aname).name == result </s> remove     info = ScriptInfo()\n    app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False) </s> add     app = locate_app(\"notanapp.py\", None, raise_if_not_found=False) </s> remove         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> add         locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False) </s> remove     script_info = ScriptInfo()", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         locate_app(info, iname, aname)\n <mask> \n <mask> \n <mask> def test_locate_app_suppress_raise(test_apps):\n <mask>     info = ScriptInfo()\n <mask>     app = locate_app(info, \"notanapp.py\", None, raise_if_not_found=False)\n <mask>     assert app is None\n <mask> \n <mask>     # only direct import error is suppressed\n <mask>     with pytest.raises(NoAppException):\n <mask>         locate_app(info, \"cliapp.importerrorapp\", None, raise_if_not_found=False)\n <mask> \n <mask> \n <mask> def test_get_version(test_apps, capsys):\n <mask>     from flask import __version__ as flask_version </s> remove         locate_app(info, iname, aname) </s> remove     info = ScriptInfo()\n    assert locate_app(info, iname, aname).name == result </s> add     assert locate_app(iname, aname).name == result </s> remove                     app = locate_app(self, import_name, None, raise_if_not_found=False) </s> add                     app = locate_app(import_name, None, raise_if_not_found=False)", "html_url": "https://github.com/pallets/flask/commit/e21e003f62b57c35e1832c0bf14e9cd27f4e5bea", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     For more information, head over to the :ref:`Quickstart <url-building>`.\n <mask> \n <mask>     To integrate applications, :class:`Flask` has a hook to intercept URL build\n <mask>     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n <mask>     results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n <mask>     not have a URL for the given endpoint and values.  When it does, the\n <mask>     :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if\n <mask>     it is not `None`, which can return a string to use as the result of\n <mask>     `url_for` (instead of `url_for`'s default to raise the\n <mask>     :exc:`~werkzeug.routing.BuildError` exception) or re-raise the exception.\n <mask>     An example::\n <mask>  </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove         def external_url_handler(error, endpoint, **values): </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `url_for` (instead of `url_for`'s default to raise the\n <mask>     :exc:`~werkzeug.routing.BuildError` exception) or re-raise the exception.\n <mask>     An example::\n <mask> \n <mask>         def external_url_handler(error, endpoint, **values):\n <mask>             \"Looks up an external URL when `url_for` cannot build a URL.\"\n <mask>             # This is an example of hooking the build_error_handler.\n <mask>             # Here, lookup_url is some utility function you've built\n <mask>             # which looks up the endpoint in some external URL registry.\n <mask>             url = lookup_url(endpoint, **values) </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     raise error\n <mask>             # url_for will use this result, instead of raising BuildError.\n <mask>             return url\n <mask> \n <mask>         app.build_error_handler = external_url_handler\n <mask> \n <mask>     Here, `error` is the instance of :exc:`~werkzeug.routing.BuildError`, and\n <mask>     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n <mask>     that this is for building URLs outside the current application, and not for\n <mask>     handling 404 NotFound errors. </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove     `endpoint` and `**values` are the arguments passed into `url_for`.  Note </s> add     `endpoint` and `values` are the arguments passed into `url_for`.  Note </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if </s> remove         def external_url_handler(error, endpoint, **values): </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app.build_error_handler = external_url_handler\n <mask> \n <mask>     Here, `error` is the instance of :exc:`~werkzeug.routing.BuildError`, and\n <mask>     `endpoint` and `**values` are the arguments passed into `url_for`.  Note\n <mask>     that this is for building URLs outside the current application, and not for\n <mask>     handling 404 NotFound errors.\n <mask> \n <mask>     .. versionadded:: 0.10\n <mask>        The `_scheme` parameter was added. </s> Update url_for documentation\n\nPrevious documentation referenced a non-existent property on the Flask\nobject called \"build_error_handler\".\n\nThis should actually reference Flask.url_build_error_handlers. </s> remove         app.build_error_handler = external_url_handler </s> add         app.url_build_error_handlers.append(external_url_handler) </s> remove     errors through :attr:`Flask.build_error_handler`.  The `url_for` function\n    results in a :exc:`~werkzeug.routing.BuildError` when the current app does\n    not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.build_error_handler` if </s> add     errors through :attr:`Flask.url_build_error_handlers`.  The `url_for`\n    function results in a :exc:`~werkzeug.routing.BuildError` when the current\n    app does not have a URL for the given endpoint and values.  When it does, the\n    :data:`~flask.current_app` calls its :attr:`~Flask.url_build_error_handlers` if </s> remove         def external_url_handler(error, endpoint, **values): </s> add         def external_url_handler(error, endpoint, values):", "html_url": "https://github.com/pallets/flask/commit/e31a2a80ec4254e8ac8127558bc29cfd23d05511", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> - Added support for explicit root paths when using Python 3.3's namespace\n <mask>   packages.\n <mask> \n <mask> Version 0.10.2\n <mask> --------------\n <mask>  </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)')", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def run_application(app_id, host='127.0.0.1', port=5000, debug=None,\n <mask>                     use_reloader=False, use_debugger=False,\n <mask>                     use_eager_loading=None, magic_app_id=True):\n <mask>     \"\"\"Useful function to start a Werkzeug server for an application that\n <mask>     is known by it's import name.  By default the app ID can also be a\n <mask>     full file name in which case Flask attempts to reconstruct the import\n <mask>     name from it and do the right thing.\n <mask>  </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger) </s> add                use_debugger=use_debugger, **options) </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :param magic_app_id: if this is enabled then the app id can also be a\n <mask>                          filename instead of an import module and Flask\n <mask>                          will attempt to reconstruct the import name.\n <mask>     \"\"\"\n <mask>     if magic_app_id:\n <mask>         if os.path.isfile(app_id) or os.sep in app_id or \\\n <mask>            os.altsep is not None and os.altsep in app_id: </s> remove                     use_eager_loading=None, magic_app_id=True): </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             print ' * Forcing debug %s' % (debug and 'on' or 'off')\n <mask> \n <mask>     app = DispatchingApp(app_id, debug, use_eager_loading)\n <mask>     run_simple(host, port, app, use_reloader=use_reloader,\n <mask>                use_debugger=use_debugger)\n <mask> \n <mask> \n <mask> def main(as_module=False):\n <mask>     this_module = __package__ + '.run'\n <mask>  </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> remove                     use_eager_loading=None, magic_app_id=True): </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> remove                     use_eager_loading=opts.with_eager_loading) </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                       'to unexpected crashes.')\n <mask>     parser.add_option('--without-eager-loading', action='store_false',\n <mask>                       dest='with_eager_loading',\n <mask>                       help='Disable the eager-loading.')\n <mask>     opts, args = parser.parse_args()\n <mask>     if len(args) != 1:\n <mask>         parser.error('Expected exactly one argument which is the import '\n <mask>                      'name of the application.')\n <mask>  </s> remove                     use_eager_loading=None, magic_app_id=True): </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design. </s> remove                     use_eager_loading=opts.with_eager_loading) </s> add                     use_eager_loading=opts.with_eager_loading,\n                    threaded=opts.with_threads)", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     run_application(args[0], opts.host, opts.port, debug=opts.debug,\n <mask>                     use_reloader=opts.with_reloader,\n <mask>                     use_debugger=opts.with_debugger,\n <mask>                     use_eager_loading=opts.with_eager_loading)\n <mask> \n <mask> \n <mask> if __name__ == '__main__':\n <mask>     main(as_module=True) </s> add     parser.add_option('--with-threads', action='store_true',\n                      dest='with_threads',\n                      help='Enable multi-threading to handle multiple '\n                      'requests concurrently.')\n    parser.add_option('--without-threads', action='store_false',\n                      dest='with_threads',\n                      help='Disables multi-threading. (default)') </s> remove                use_debugger=use_debugger) </s> add                use_debugger=use_debugger, **options) </s> add     :param options: the options to be forwarded to the underlying\n                    Werkzeug server.  See\n                    :func:`werkzeug.serving.run_simple` for more\n                    information. </s> remove                     use_eager_loading=None, magic_app_id=True): </s> add                     use_eager_loading=None, magic_app_id=True,\n                    **options): </s> add - Added ``flask-run`` and the ``flask.run`` module to start the local\n  debug server.  This is recommended over the old ``flask.run()`` method\n  as it works faster and more reliable due to a different design.", "html_url": "https://github.com/pallets/flask/commit/e46bca4051e51f3812d4a0b25f60f7b7959668c2", "file_name": "flask/run.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> import hashlib\n <mask> import warnings\n <mask> from collections import MutableMapping\n <mask> from datetime import datetime\n <mask> \n <mask> from itsdangerous import BadSignature, URLSafeTimedSerializer\n <mask> from werkzeug.datastructures import CallbackDict\n <mask>  </s> remove class SessionMixin(MutableMapping): </s> add class SessionMixin(collections_abc.MutableMapping):", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.datastructures import CallbackDict\n <mask> \n <mask> from flask.helpers import is_ip, total_seconds\n <mask> from flask.json.tag import TaggedJSONSerializer\n <mask> \n <mask> \n <mask> class SessionMixin(collections_abc.MutableMapping):\n <mask>     \"\"\"Expands a basic dictionary with session attributes.\"\"\" </s> remove class SessionMixin(MutableMapping): </s> add class SessionMixin(collections_abc.MutableMapping): </s> remove from collections import MutableMapping", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from flask.helpers import is_ip, total_seconds\n <mask> from flask.json.tag import TaggedJSONSerializer\n <mask> \n <mask> \n <mask> class SessionMixin(MutableMapping):\n <mask>     \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n <mask> \n <mask>     @property\n <mask>     def permanent(self):\n <mask>         \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\" </s> remove from collections import MutableMapping", "html_url": "https://github.com/pallets/flask/commit/e4ebbd3f5befca0f6891def3ebf292f756ec5f3b", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def add_to_path(path):\n <mask>     def _samefile(x, y):\n <mask>         try:\n <mask>             return os.path.samefile(x, y)\n <mask>         except (IOError, OSError): </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             pass\n <mask>     sys.path.append(path)\n <mask> \n <mask> \n <mask> def setup_paths():\n <mask>     add_to_path(os.path.abspath(os.path.join(\n <mask>         os.path.dirname(__file__), 'test_apps')))\n <mask> \n <mask> \n <mask> def iter_suites():\n <mask>     for module in find_modules(__name__):\n <mask>         mod = import_string(module)\n <mask>         if hasattr(mod, 'suite'):\n <mask>             yield mod.suite() </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def iter_suites():\n <mask>     for module in find_modules(__name__):\n <mask>         mod = import_string(module)\n <mask>         if hasattr(mod, 'suite'):\n <mask>             yield mod.suite() </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def find_all_tests(suite):\n <mask>     suites = [suite]\n <mask>     while suites:\n <mask>         s = suites.pop()\n <mask>         try:\n <mask>             suites.extend(s) </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             rv.addTest(test)\n <mask>         return rv\n <mask> \n <mask> \n <mask> def suite():\n <mask>     \"\"\"A testsuite that has all the Flask tests.  You can use this\n <mask>     function to integrate the Flask tests into your own testsuite\n <mask>     in case you want to test that monkeypatches to Flask do not </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         return rv\n <mask> \n <mask> \n <mask> def suite():\n <mask>     setup_paths()\n <mask>     suite = unittest.TestSuite()\n <mask>     for other_suite in iter_suites():\n <mask>         suite.addTest(other_suite)\n <mask>     return suite </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> remove import unittest\nfrom flask.testsuite import BetterLoader\ntry:\n    unittest.main(testLoader=BetterLoader(), defaultTest='suite')\nexcept Exception, e:\n    print 'Error: %s' % e </s> add from flask.testsuite import main\nmain()", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "flask/testsuite/__init__.py"}
{"docstring_tokens": "replace replace replace replace replace replace", "code_tokens": " <mask> import unittest\n <mask> from flask.testsuite import BetterLoader\n <mask> try:\n <mask>     unittest.main(testLoader=BetterLoader(), defaultTest='suite')\n <mask> except Exception, e:\n <mask>     print 'Error: %s' % e </s> add     \"\"\"Yields all the tests and their names from a given suite.\"\"\" </s> add     \"\"\"A testsuite that has all the Flask tests.  You can use this\n    function to integrate the Flask tests into your own testsuite\n    in case you want to test that monkeypatches to Flask do not\n    break it.\n    \"\"\"\n    setup_path() </s> add def setup_path():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps'))) </s> remove def setup_paths():\n    add_to_path(os.path.abspath(os.path.join(\n        os.path.dirname(__file__), 'test_apps')))", "html_url": "https://github.com/pallets/flask/commit/e509d25d32965a8afd7ca98d67ee6f5a6af11cc8", "file_name": "run-tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @app.route('/user/<username>')\n <mask>     def show_user_profile(username):\n <mask>         # show the user profile for that user\n <mask>         return 'User %s' % username\n <mask> \n <mask>     @app.route('/post/<int:post_id>')\n <mask>     def show_post(post_id):\n <mask>         # show the post with the given id, the id is an integer\n <mask>         return 'Post %d' % post_id </s> remove         return '{}\\'s profile'.format(username) </s> add         return '{}\\'s profile'.format(escape(username))", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @app.route('/path/<path:subpath>')\n <mask>     def show_subpath(subpath):\n <mask>         # show the subpath after /path/\n <mask>         return 'Subpath %s' % subpath\n <mask> \n <mask> Converter types:\n <mask> \n <mask> ========== ==========================================\n <mask> ``string`` (default) accepts any text without a slash </s> remove     from flask import Flask, url_for </s> add     from flask import Flask, escape, url_for", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return 'login'\n <mask> \n <mask>     @app.route('/user/<username>')\n <mask>     def profile(username):\n <mask>         return '{}\\'s profile'.format(username)\n <mask> \n <mask>     with app.test_request_context():\n <mask>         print(url_for('index'))\n <mask>         print(url_for('login'))\n <mask>         print(url_for('login', next='/')) </s> Fix some HTML injection paths in examples\n\nThese are unlikely to be copy-pasted by users but it's best practice to avoid it and other examples do. </s> remove         return 'User %s' % username </s> add         return 'User %s' % escape(username) </s> remove         return 'Subpath %s' % subpath </s> add         return 'Subpath %s' % escape(subpath)", "html_url": "https://github.com/pallets/flask/commit/e5b0fe68414cd3af9c1e91c82fa0c0ef4145c8c2", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   refreshed each request and get their lifetime extended, if set to\n <mask>   `False` it will only be modified if the session actually modifies.\n <mask>   Non permanent sessions are not affected by this and will always\n <mask>   expire if the browser window closes.\n <mask> \n <mask> Version 0.10.2\n <mask> --------------\n <mask> \n <mask> (bugfix release, release date to be announced)\n <mask>  </s> add         if not (force or self.is_json):", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 400)\n <mask> \n <mask>     def test_json_body_encoding(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.testing = True\n <mask>         @app.route('/') </s> add     @property\n    def is_json(self):\n        \"\"\"Indicates if this request is JSON or not.  By default a request\n        is considered to include JSON data if the mimetype is\n        ``application/json`` or ``application/*+json``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mt = self.mimetype\n        if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         # XXX: deprecate property\n <mask>         return self.get_json()\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the incoming JSON request data and returns it.  If\n <mask>         parsing fails the :meth:`on_json_loading_failed` method on the\n <mask>         request object will be invoked.  By default this function will\n <mask>         only load the json data if the mimetype is ``application/json`` </s> remove         if self.mimetype != 'application/json' and not force: </s> add         if not (force or self.is_json): </s> add - Made Flask support custom JSON mimetypes for incoming data. </s> add     def test_json_custom_mimetypes(self):\n        app = flask.Flask(__name__)\n        @app.route('/json', methods=['POST'])\n        def return_json():\n            return flask.request.get_json()\n        c = app.test_client()\n        rv = c.post('/json', data='\"foo\"', content_type='application/x+json')\n        self.assert_equal(rv.data, b'foo')", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv = getattr(self, '_cached_json', _missing)\n <mask>         if rv is not _missing:\n <mask>             return rv\n <mask> \n <mask>         if self.mimetype != 'application/json' and not force:\n <mask>             return None\n <mask> \n <mask>         # We accept a request charset against the specification as\n <mask>         # certain clients have been using this in the past.  This\n <mask>         # fits our general approach of being nice in what we accept\n </s> Added support for custom JSON mimetypes </s> add     @property\n    def is_json(self):\n        \"\"\"Indicates if this request is JSON or not.  By default a request\n        is considered to include JSON data if the mimetype is\n        ``application/json`` or ``application/*+json``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mt = self.mimetype\n        if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False\n </s> add - Made Flask support custom JSON mimetypes for incoming data. </s> add     def test_json_custom_mimetypes(self):\n        app = flask.Flask(__name__)\n        @app.route('/json', methods=['POST'])\n        def return_json():\n            return flask.request.get_json()\n        c = app.test_client()\n        rv = c.post('/json', data='\"foo\"', content_type='application/x+json')\n        self.assert_equal(rv.data, b'foo')\n", "html_url": "https://github.com/pallets/flask/commit/e5bba9deb5c9ab9c66bea5c17e96741777fe46ab", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask> ~~~~~~~~~~~~\n <mask> \n <mask> - Create a branch to identify the issue you would like to work on::\n <mask> \n <mask>         git branch your-branch-name </s> remove         git checkout your-branch-name\n\n- Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n\n        git add -A\n        git commit </s> add         git checkout -b your-branch-name origin/master </s> remove - Then switch to make sure that we are working on that branch by using:: </s> add     If you're submitting a feature addition or change, branch off of the\n    \"master\" branch::", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace keep", "code_tokens": " <mask>         git branch your-branch-name\n <mask> \n <mask> - Then switch to make sure that we are working on that branch by using::\n <mask> \n <mask>         git checkout your-branch-name\n <mask> \n <mask> - Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n <mask> \n <mask>         git add -A\n <mask>         git commit\n <mask>  </s> add instructions for bug and feature branches </s> remove - Create a branch to identify the issue you would like to work on:: </s> add -   Create a branch to identify the issue you would like to work on. If\n    you're submitting a bug or documentation fix, branch off of the\n    latest \".x\" branch:: </s> remove         git branch your-branch-name </s> add         git checkout -b your-branch-name origin/1.0.x", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>         git checkout -b your-branch-name origin/master\n <mask> \n <mask> - Try to follow `PEP8`_, but you may ignore the line length limit if following\n <mask>   it would make the code uglier.\n <mask> - Include tests that cover any code changes you make. Make sure the test fails\n <mask>   without your patch. `Run the tests. <contributing-testsuite_>`_. </s> remove         git checkout your-branch-name\n\n- Using your favorite editor, make your changes, `committing as you go`_ by using the following::\n\n        git add -A\n        git commit </s> add         git checkout -b your-branch-name origin/master </s> remove - Create a branch to identify the issue you would like to work on:: </s> add -   Create a branch to identify the issue you would like to work on. If\n    you're submitting a bug or documentation fix, branch off of the\n    latest \".x\" branch:: </s> remove         git branch your-branch-name </s> add         git checkout -b your-branch-name origin/1.0.x </s> remove - Then switch to make sure that we are working on that branch by using:: </s> add     If you're submitting a feature addition or change, branch off of the\n    \"master\" branch::", "html_url": "https://github.com/pallets/flask/commit/e61fd5f6cb1c7ebba86a9eef9c5e645d9c4032d1", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask>         __import__(module_name)\n <mask>     except ImportError as e:\n <mask>         # Reraise the ImportError if it occurred within the imported module.\n <mask>         # Determine this by checking whether the trace has a depth > 1.\n <mask>         if sys.exc_info()[2].tb_next:\n <mask>             raise NoAppException(\n <mask>                 f\"While importing {module_name!r}, an ImportError was raised.\"\n <mask>             ) from e\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n <mask>         else:\n <mask>             return\n </s> made ImportError verbose in cli.py </s> remove             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n </s> add             raise NoAppException(f\"Could not import {module_name!r}.\") from None </s> add -   Revert a change to the CLI that caused it to hide ``ImportError``\n    tracebacks when importing the application. :issue:`4307`", "html_url": "https://github.com/pallets/flask/commit/e679a85b80df354f8632f8ab3e40135f16f5e6d0", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise NoAppException(\n <mask>                 f\"While importing {module_name!r}, an ImportError was raised.\"\n <mask>             ) from e\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(f\"Could not import {module_name!r}.\") from e\n <mask>         else:\n <mask>             return\n <mask> \n <mask>     module = sys.modules[module_name]\n <mask>  </s> remove                 f\"While importing {module_name!r}, an ImportError was raised.\"\n            ) from e </s> add                 f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None </s> remove     except ImportError as e: </s> add     except ImportError: </s> add -   Revert a change to the CLI that caused it to hide ``ImportError``\n    tracebacks when importing the application. :issue:`4307`", "html_url": "https://github.com/pallets/flask/commit/e679a85b80df354f8632f8ab3e40135f16f5e6d0", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> In order to use jQuery, you have to download it first and place it in the\n <mask> static folder of your application and then ensure it's loaded.  Ideally\n <mask> you have a layout template that is used for all pages where you just have\n <mask> to add a script statement to your `head` to load jQuery:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>    <script type=text/javascript src=\"{{\n <mask>      url_for('static', filename='jquery.js') }}\"></script> </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove     <script type=text/javascript\n      src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script> </s> add     <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.js\"></script>\n    <script>window.jQuery || document.write('<script src=\"{{\n      url_for('static', filename='jquery.js') }}\">\\x3C/script>')</script> </s> remove will already be in the browser cache.  Downside is that if you don't have\nnetwork connectivity during development jQuery will not load. </s> add will already be in the browser cache. </s> remove In this case you don't have to put jQuery into your static folder, it will\ninstead be loaded from Google directly.  This has the advantage that your </s> add In this case you have to put jQuery into your static folder as a fallback, but it will\nfirst try to load it directly from Google. This has the advantage that your", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> <http://code.google.com/apis/ajaxlibs/documentation/>`_ to load jQuery:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>     <script type=text/javascript\n <mask>       src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n <mask> \n <mask> In this case you don't have to put jQuery into your static folder, it will\n <mask> instead be loaded from Google directly.  This has the advantage that your\n <mask> website will probably load faster for users if they went to at least one\n <mask> other website before using the same jQuery version from Google because it </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove to add a script statement to your `head` to load jQuery: </s> add to add a script statement to the bottom of your `<body>` to load jQuery: </s> remove will already be in the browser cache.  Downside is that if you don't have\nnetwork connectivity during development jQuery will not load. </s> add will already be in the browser cache. </s> remove In this case you don't have to put jQuery into your static folder, it will\ninstead be loaded from Google directly.  This has the advantage that your </s> add In this case you have to put jQuery into your static folder as a fallback, but it will\nfirst try to load it directly from Google. This has the advantage that your", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep replace replace keep keep replace replace keep keep", "code_tokens": " <mask>       src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script>\n <mask> \n <mask> In this case you don't have to put jQuery into your static folder, it will\n <mask> instead be loaded from Google directly.  This has the advantage that your\n <mask> website will probably load faster for users if they went to at least one\n <mask> other website before using the same jQuery version from Google because it\n <mask> will already be in the browser cache.  Downside is that if you don't have\n <mask> network connectivity during development jQuery will not load.\n <mask> \n <mask> Where is My Site? </s> Improving documentation for loading jQuery. Now using Google CDN with fallback to local jQuery. </s> remove to add a script statement to your `head` to load jQuery: </s> add to add a script statement to the bottom of your `<body>` to load jQuery: </s> remove     <script type=text/javascript\n      src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js\"></script> </s> add     <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.js\"></script>\n    <script>window.jQuery || document.write('<script src=\"{{\n      url_for('static', filename='jquery.js') }}\">\\x3C/script>')</script>", "html_url": "https://github.com/pallets/flask/commit/e6b9f509ba3c47f748d5c6da5f6de5500248dbfd", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Step 4: Database Connections\n <mask> ----------------------------\n <mask> \n <mask> You now have a function for establishing a database connection with\n <mask> `connect_db`, but by itself, it is not particularly useful.  Creating and\n <mask> closing database connections all the time is very inefficient, so you will\n <mask> need to keep it around for longer.  Because database connections\n <mask> encapsulate a transaction, you will need to make sure that only one\n <mask> request at a time uses the connection. An elegant way to do this is by </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application::", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/dbcon.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    introduction\n <mask>    folders\n <mask>    schema\n <mask>    setup\n <mask>    setuptools\n <mask>    dbcon\n <mask>    dbinit\n <mask>    views\n <mask>    templates\n <mask>    css </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain:: </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain::", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/index.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask>         return rv\n <mask> \n <mask> In the next section you will see how to run the application.\n <mask> \n <mask> Continue with :ref:`tutorial-setuptools`. </s> remove Assuming you have seen the testing section above and have either written </s> add Assuming you have seen the :ref:`testing` section and have either written", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/setup.rst"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> example of how to perform unit testing in the :ref:`testing` section of the\n <mask> documentation.  Go there to see how easy it is to test Flask applications.\n <mask> \n <mask> Adding Tests to flaskr\n <mask> ======================\n <mask> \n <mask> Assuming you have seen the testing section above and have either written\n <mask> your own tests for ``flaskr`` or have followed along with the examples\n <mask> provided, you might be wondering about ways to organize the project.\n <mask> \n <mask> Adding Tests to flaskr\n <mask> ======================\n <mask> \n <mask> Assuming you have seen the testing section above and have either written\n <mask> your own tests for ``flaskr`` or have followed along with the examples\n <mask> provided, you might be wondering about ways to organize the project.\n <mask>  </s> Clean up tutorial docs for installable app pattern with flaskr (#2002)\n\n* Clean up tutorial docs for installable app pattern\r\n\r\n- reading sequentially through the tutorial works.\r\n- fixes references to `export FLASK_APP=flaskr.flaskr`\r\n\r\n* Fixes titles for each section of flaskr tutorial\r\n\r\n* Revert grammar\r\n\r\n* Emphasize the Packaging Guide\r\n\r\n- adds more general packaging resource\r\n- removes the emphasis put on setuptools\r\n\r\n* rephrase and remove note admonitions\r\n\r\n- expanded on few points\r\n- removed note blocks, they are unneccessary\r\n\r\n* Remove note about reinstalling to update cli\r\n\r\n- I had mistakenly thought it was necessary to\r\n  re-install the app to update the cli.\r\n- the `--editable` flag detects the change and\r\n  the cli updates without issue. </s> remove Continue with :ref:`tutorial-setuptools`. </s> add Continue with :ref:`tutorial-packaging`. </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> add You currently have a function for establishing a database connection with </s> remove Step 8: The Templates </s> add Step 7: The Templates", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>         tests/\n <mask>             context.py\n <mask>             test_flaskr.py\n <mask>         setup.py\n <mask>         MANIFEST.in\n <mask> \n <mask> For now go ahead a create the :file:`tests/` directory as well as the\n <mask> :file:`context.py` and :file:`test_flaskr.py` files, if you haven't\n <mask> already. The context file is used as an import helper. The contents\n <mask> of that file are::\n <mask> \n <mask>     import sys, os\n <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__)) </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../') </s> add At this point you can run the tests. Here ``pytest`` will be used. </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain:: </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> add         pip install -e .\n        pip install pytest", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep replace keep replace replace keep keep keep", "code_tokens": " <mask> already. The context file is used as an import helper. The contents\n <mask> of that file are::\n <mask> \n <mask>     import sys, os\n <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__))\n <mask>     sys.path.insert(0, basedir + '/../')\n <mask> \n <mask>     from flaskr import flaskr\n <mask>  </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are:: </s> remove     from flaskr import flaskr </s> add Adding tests to flaskr\n----------------------", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep", "code_tokens": " <mask> \n <mask>     basedir = os.path.dirname(os.path.abspath(__file__))\n <mask>     sys.path.insert(0, basedir + '/../')\n <mask> \n <mask>     from flaskr import flaskr\n <mask> \n <mask> Testing + Setuptools\n <mask> ====================\n <mask> \n <mask> One way to handle testing is to integrate it with ``setuptools``. All it </s> remove     basedir = os.path.dirname(os.path.abspath(__file__))\n    sys.path.insert(0, basedir + '/../') </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain:: </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are:: </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file.", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Testing + Setuptools\n <mask> ====================\n <mask> \n <mask> One way to handle testing is to integrate it with ``setuptools``. All it\n <mask> requires is adding a couple of lines to the :file:`setup.py` file and\n <mask> creating a new file :file:`setup.cfg`. Go ahead and update the\n <mask> :file:`setup.py` to contain::\n <mask> \n <mask>     from setuptools import setup\n <mask> \n <mask>     setup(\n <mask>         name='flaskr', </s> remove Testing + Setuptools\n==================== </s> add         pip install -e .\n        pip install pytest </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are:: </s> add For now go ahead a create the :file:`tests/` directory as well as the \n:file:`test_flaskr.py` file.", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> \n <mask> This is one possible way to run and manage testing.  Here ``pytest`` is\n <mask> used, but there are other options such as ``nose``.  Integrating testing\n <mask> with ``setuptools`` is convenient because it is not necessary to actually\n <mask> download ``pytest`` or any other testing framework one might use. </s> Clean up tutorial docs for installable app pattern with flaskr (#2002) </s> add download ``pytest`` or any other testing framework one might use. </s> remove     from flaskr import flaskr </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove Adding Tests to flaskr\n====================== </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain:: </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> add         pip install -e .\n        pip install pytest", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> This is one possible way to run and manage testing.  Here ``pytest`` is\n <mask> used, but there are other options such as ``nose``.  Integrating testing\n <mask> with ``setuptools`` is convenient because it is not necessary to actually\n <mask> download ``pytest`` or any other testing framework one might use. </s> remove download ``pytest`` or any other testing framework one might use. </s> add .. note:: Make sure that ``pytest`` is installed in the same virtualenv \n    as flaskr. Otherwise ``pytest`` test will not be able to import the \n    required components to test the application:: </s> remove One way to handle testing is to integrate it with ``setuptools``. All it\nrequires is adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. Go ahead and update the\n:file:`setup.py` to contain:: </s> add Run and watch the tests pass, within the top-level :file:`flaskr/` \ndirectory as::\n\n    py.test\n\nTesting + setuptools\n--------------------\n\nOne way to handle testing is to integrate it with ``setuptools``. Here\nthat requires adding a couple of lines to the :file:`setup.py` file and\ncreating a new file :file:`setup.cfg`. One benefit of running the tests \nthis way is that you do not have to install ``pytest``. Go ahead and \nupdate the :file:`setup.py` file to contain:: </s> remove Testing + Setuptools\n==================== </s> add         pip install -e .\n        pip install pytest", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/testing.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. _tutorial-views:\n <mask> \n <mask> Step 7: The View Functions\n <mask> ==========================\n <mask> \n <mask> Now that the database connections are working, you can start writing the\n <mask> view functions.  You will need four of them:\n <mask>  </s> remove For now go ahead a create the :file:`tests/` directory as well as the\n:file:`context.py` and :file:`test_flaskr.py` files, if you haven't\nalready. The context file is used as an import helper. The contents\nof that file are::", "html_url": "https://github.com/pallets/flask/commit/e6f9d2b41417b442946acfede9200d361ac401cc", "file_name": "docs/tutorial/views.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> Useful Internals\n <mask> ----------------\n <mask> \n <mask> .. data:: _request_ctx_stack\n <mask> \n <mask>    The internal :class:`~werkzeug.local.LocalStack` that is used to implement\n <mask>    all the context local objects used in Flask.  This is a documented\n <mask>    instance and can be used by extensions and application code but the </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>           ctx = _request_ctx_stack.top\n <mask>           if ctx is not None:\n <mask>               return ctx.session\n <mask> \n <mask>    .. versionchanged:: 0.4\n <mask> \n <mask>    The request context is automatically popped at the end of the request\n <mask>    for you.  In debug mode the request context is kept around if\n <mask>    exceptions happen so that interactive debuggers have a chance to\n <mask>    introspect the data.  With 0.4 this can also be forced for requests\n <mask>    that did not fail and outside of `DEBUG` mode.  By setting\n <mask>    ``'flask._preserve_context'`` to `True` on the WSGI environment the\n <mask>    context will not pop itself at the end of the request.  This is used by\n <mask>    the :meth:`~flask.Flask.test_client` for example to implement the\n <mask>    deferred cleanup functionality.\n <mask> \n <mask>    You might find this helpful for unittests where you need the\n <mask>    information from the context local around for a little longer.  Make\n <mask>    sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n <mask>    that situation, otherwise your unittests will leak memory.\n <mask> \n <mask> Signals\n <mask> -------\n <mask> \n <mask> .. when modifying this list, also update the one in signals.rst\n <mask>  </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== ========================================= </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove class _RequestContext(object): </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app) </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>    It is sent *before* the standard exception handling kicks in and even\n <mask>    in debug mode, where no exception handling happens.  The exception\n <mask>    itself is passed to the subscriber as `exception`.\n <mask> \n <mask> .. currentmodule:: None\n <mask> \n <mask> .. class:: flask.signals.Namespace\n <mask> \n <mask>    An alias for :class:`blinker.base.Namespace` if blinker is available, </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask>       do nothing but will fail with a :exc:`RuntimeError` for all other\n <mask>       operations, including connecting.\n <mask> \n <mask> .. _blinker: http://pypi.python.org/pypi/blinker\n <mask> \n <mask> .. _notes-on-proxies:\n <mask> \n <mask> Notes On Proxies\n <mask> ----------------\n <mask> \n <mask> Some of the objects provided by Flask are proxies to other objects.  The\n <mask> reason behind this is that these proxies are shared between threads and\n <mask> they have to dispatch to the actual object bound to a thread behind the\n <mask> scenes as necessary.\n <mask> \n <mask> Most of the time you don't have to care about that, but there are some\n <mask> exceptions where it is good to know that this object is an actual proxy:\n <mask> \n <mask> -   The proxy objects do not fake their inherited types, so if you want to\n <mask>     perform actual instance checks, you have to do that on the instance\n <mask>     that is being proxied (see `_get_current_object` below).\n <mask> -   if the object reference is important (so for example for sending\n <mask>     :ref:`signals`)\n <mask> \n <mask> If you need to get access to the underlying object that is proxied, you\n <mask> can use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n <mask> \n <mask>     app = current_app._get_current_object()\n <mask>     my_signal.send(app) </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> add .. autoclass:: flask.ctx.RequestContext\n   :members: </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> The following configuration values are used internally by Flask:\n <mask> \n <mask> .. tabularcolumns:: |p{6.5cm}|p{8.5cm}|\n <mask> \n <mask> =============================== =========================================\n <mask> ``DEBUG``                       enable/disable debug mode\n <mask> ``TESTING``                     enable/disable testing mode\n <mask> ``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n <mask>                                 propagation of exceptions.  If not set or\n <mask>                                 explicitly set to `None` this is\n <mask>                                 implicitly true if either `TESTING` or\n <mask>                                 `DEBUG` is true.\n <mask> ``SECRET_KEY``                  the secret key\n <mask> ``SESSION_COOKIE_NAME``         the name of the session cookie\n <mask> ``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n <mask>                                 :class:`datetime.timedelta` object.\n <mask> ``USE_X_SENDFILE``              enable/disable x-sendfile\n <mask> ``LOGGER_NAME``                 the name of the logger\n <mask> ``SERVER_NAME``                 the name of the server.  Required for\n <mask>                                 subdomain support (e.g.: ``'localhost'``)\n <mask> ``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n <mask>                                 reject incoming requests with a\n <mask>                                 content length greater than this by\n <mask>                                 returning a 413 status code.\n <mask> =============================== =========================================\n <mask> \n <mask> .. admonition:: More on ``SERVER_NAME``\n <mask> \n <mask>    The ``SERVER_NAME`` key is used for the subdomain support.  Because\n <mask>    Flask cannot guess the subdomain part without the knowledge of the </s> add     #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #: </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app) </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. versionadded:: 0.6\n <mask>    ``MAX_CONTENT_LENGTH``\n <mask> \n <mask> .. versionadded:: 0.7\n <mask>    ``PROPAGATE_EXCEPTIONS``\n <mask> \n <mask> Configuring from Files\n <mask> ----------------------\n <mask> \n <mask> Configuration becomes more useful if you can configure from a file, and </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== ========================================= </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection. </s> remove         return _RequestContext(self, environ)", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> that these functions are not only there for interactive shell usage, but\n <mask> also for unittesting and other situations that require a faked request\n <mask> context.\n <mask> \n <mask> Diving into Context Locals\n <mask> --------------------------\n <mask> \n <mask> Say you have a utility function that returns the URL the user should be\n <mask> redirected to.  Imagine it would always redirect to the URL's ``next``\n <mask> parameter or the HTTP referrer or the index page::\n <mask> \n <mask>     from flask import request, url_for\n <mask> \n <mask>     def redirect_url():\n <mask>         return request.args.get('next') or \\\n <mask>                request.referrer or \\\n <mask>                url_for('index')\n <mask> \n <mask> As you can see, it accesses the request object.  If you try to run this\n <mask> from a plain Python shell, this is the exception you will see:\n <mask> \n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request' </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`: </s> remove         regardless of whether there was an exception or not. </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove \n.. _notes-on-proxies:\n\nNotes On Proxies\n----------------\n\nSome of the objects provided by Flask are proxies to other objects.  The\nreason behind this is that these proxies are shared between threads and\nthey have to dispatch to the actual object bound to a thread behind the\nscenes as necessary.\n\nMost of the time you don't have to care about that, but there are some\nexceptions where it is good to know that this object is an actual proxy:\n\n-   The proxy objects do not fake their inherited types, so if you want to\n    perform actual instance checks, you have to do that on the instance\n    that is being proxied (see `_get_current_object` below).\n-   if the object reference is important (so for example for sending\n    :ref:`signals`)\n\nIf you need to get access to the underlying object that is proxied, you\ncan use the :meth:`~werkzeug.local.LocalProxy._get_current_object` method::\n\n    app = current_app._get_current_object()\n    my_signal.send(app)", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep replace replace replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request'\n <mask> \n <mask> That makes a lot of sense because we currently do not have a request we\n <mask> could access.  So we have to make a request and bind it to the current\n <mask> context.  The :attr:`~flask.Flask.test_request_context` method can create\n <mask> us a request context:\n <mask> \n <mask> >>> ctx = app.test_request_context('/?next=http://example.com/')\n <mask>  </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace keep", "code_tokens": " <mask> us a request context:\n <mask> \n <mask> >>> ctx = app.test_request_context('/?next=http://example.com/')\n <mask> \n <mask> This context can be used in two ways.  Either with the `with` statement\n <mask> (which unfortunately is not very handy for shell sessions).  The\n <mask> alternative way is to call the `push` and `pop` methods:\n <mask>  </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`: </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> add Creating a Request Context\n-------------------------- </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> alternative way is to call the `push` and `pop` methods:\n <mask> \n <mask> >>> ctx.push()\n <mask> \n <mask> From that point onwards you can work with the request object:\n <mask> \n <mask> >>> redirect_url()\n <mask> u'http://example.com/'\n <mask> \n <mask> Until you call `pop`:\n <mask> \n <mask> >>> ctx.pop()\n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module> </s> Started work on new request dispatching.  Unittests not yet updated </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> add Creating a Request Context\n-------------------------- </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Until you call `pop`:\n <mask> \n <mask> >>> ctx.pop()\n <mask> >>> redirect_url()\n <mask> Traceback (most recent call last):\n <mask>   File \"<stdin>\", line 1, in <module>\n <mask> AttributeError: 'NoneType' object has no attribute 'request'\n <mask> \n <mask> \n <mask> Firing Before/After Request\n <mask> ---------------------------\n <mask> \n <mask> By just creating a request context, you still don't have run the code that </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`: </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove is normally run before a request.  This probably results in your database\nbeing unavailable, the current user not being stored on the </s> add is normally run before a request.  This might result in your database\nbeing unavailable if you are connecting to the database in a\nbefore-request callback or the current user not being stored on the </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Firing Before/After Request\n <mask> ---------------------------\n <mask> \n <mask> By just creating a request context, you still don't have run the code that\n <mask> is normally run before a request.  This probably results in your database\n <mask> being unavailable, the current user not being stored on the\n <mask> :data:`~flask.g` object etc.\n <mask> \n <mask> This however can easily be done yourself.  Just call\n <mask> :meth:`~flask.Flask.preprocess_request`:\n <mask>  </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> add Creating a Request Context\n-------------------------- </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection. </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> >>> app.process_response(app.response_class())\n <mask> <Response 0 bytes [200 OK]>\n <mask> >>> ctx.pop()\n <mask> \n <mask> \n <mask> Further Improving the Shell Experience\n <mask> --------------------------------------\n <mask>  </s> remove From that point onwards you can work with the request object:\n\n>>> redirect_url()\nu'http://example.com/'\n\nUntil you call `pop`: </s> add From that point onwards you can work with the request object until you\ncall `pop`: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove >>> redirect_url()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'NoneType' object has no attribute 'request' </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep add keep", "code_tokens": " <mask>         from flask import got_request_exception\n <mask>         got_request_exception.connect(log_exception, app)\n <mask> \n <mask> .. _blinker: http://pypi.python.org/pypi/blinker </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove      request_finished, got_request_exception </s> add      request_finished, got_request_exception, request_tearing_down </s> remove from .ctx import _RequestContext </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> add    ``PROPAGATE_EXCEPTIONS``, ``PRESERVE_CONTEXT_ON_EXCEPTION``", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "docs/signals.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> from .session import Session\n <mask> \n <mask> # the signals\n <mask> from .signals import signals_available, template_rendered, request_started, \\\n <mask>      request_finished, got_request_exception\n <mask> \n <mask> # only import json if it's available\n <mask> if json_available:\n <mask>     from .helpers import json </s> remove from .signals import request_started, request_finished, got_request_exception </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove from .ctx import _RequestContext </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app) </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> add            (tb is None or not self.app.preserve_context_on_exception):", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .helpers import _PackageBoundObject, url_for, get_flashed_messages, \\\n <mask>     _tojson_filter, _endpoint_from_view_func\n <mask> from .wrappers import Request, Response\n <mask> from .config import ConfigAttribute, Config\n <mask> from .ctx import _RequestContext\n <mask> from .globals import _request_ctx_stack, request\n <mask> from .session import Session, _NullSession\n <mask> from .module import _ModuleSetupState\n <mask> from .templating import _DispatchingJinjaLoader, \\\n <mask>     _default_template_ctx_processor </s> remove from .signals import request_started, request_finished, got_request_exception </s> remove      request_finished, got_request_exception </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add    ``PROPAGATE_EXCEPTIONS``, ``PRESERVE_CONTEXT_ON_EXCEPTION`` </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .session import Session, _NullSession\n <mask> from .module import _ModuleSetupState\n <mask> from .templating import _DispatchingJinjaLoader, \\\n <mask>     _default_template_ctx_processor\n <mask> from .signals import request_started, request_finished, got_request_exception\n <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask>  </s> remove from .ctx import _RequestContext </s> remove      request_finished, got_request_exception </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: additional runtime cost which should not be enabled by default.\n <mask>     #:\n <mask>     #: This attribute can also be configured from the config with the\n <mask>     #: `TESTING` configuration key.  Defaults to `False`.\n <mask>     testing = ConfigAttribute('TESTING')\n <mask> \n <mask>     #: If a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value </s> Started work on new request dispatching.  Unittests not yet updated </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== ========================================= </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         'DEBUG':                                False,\n <mask>         'TESTING':                              False,\n <mask>         'PROPAGATE_EXCEPTIONS':                 None,\n <mask>         'SECRET_KEY':                           None,\n <mask>         'SESSION_COOKIE_NAME':                  'session',\n <mask>         'PERMANENT_SESSION_LIFETIME':           timedelta(days=31),\n <mask>         'USE_X_SENDFILE':                       False,\n <mask>         'LOGGER_NAME':                          None, </s> remove         app.debug = True </s> remove from .signals import request_started, request_finished, got_request_exception </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> remove from .ctx import _RequestContext </s> remove      request_finished, got_request_exception </s> add      request_finished, got_request_exception, request_tearing_down </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app) </s> add The functions registered as :meth:`~flask.Flask.teardown_request` are\nautomatically called when the context is popped.  So this is the perfect\nplace to automatically tear down resources that were needed by the request\ncontext (such as database connections).", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if rv is not None:\n <mask>             return rv\n <mask>         return self.testing or self.debug\n <mask> \n <mask>     @property\n <mask>     def logger(self):\n <mask>         \"\"\"A :class:`logging.Logger` object for this application.  The\n <mask>         default configuration is to log to stderr if the application is\n <mask>         in debug mode.  This logger can be used to (surprise) log messages. </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove =============================== =========================================\n``DEBUG``                       enable/disable debug mode\n``TESTING``                     enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``        explicitly enable or disable the\n                                propagation of exceptions.  If not set or\n                                explicitly set to `None` this is\n                                implicitly true if either `TESTING` or\n                                `DEBUG` is true.\n``SECRET_KEY``                  the secret key\n``SESSION_COOKIE_NAME``         the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n                                :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``              enable/disable x-sendfile\n``LOGGER_NAME``                 the name of the logger\n``SERVER_NAME``                 the name of the server.  Required for\n                                subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``          If set to a value in bytes, Flask will\n                                reject incoming requests with a\n                                content length greater than this by\n                                returning a 413 status code.\n=============================== ========================================= </s> add ================================= =========================================\n``DEBUG``                         enable/disable debug mode\n``TESTING``                       enable/disable testing mode\n``PROPAGATE_EXCEPTIONS``          explicitly enable or disable the\n                                  propagation of exceptions.  If not set or\n                                  explicitly set to `None` this is\n                                  implicitly true if either `TESTING` or\n                                  `DEBUG` is true.\n``PRESERVE_CONTEXT_ON_EXCEPTION`` By default if the application is in\n                                  debug mode the request context is not\n                                  popped on exceptions to enable debuggers\n                                  to introspect the data.  This can be\n                                  disabled by this key.  You can also use\n                                  this setting to force-enable it for non\n                                  debug execution which might be useful to\n                                  debug production applications (but also\n                                  very risky).\n``SECRET_KEY``                    the secret key\n``SESSION_COOKIE_NAME``           the name of the session cookie\n``PERMANENT_SESSION_LIFETIME``    the lifetime of a permanent session as\n                                  :class:`datetime.timedelta` object.\n``USE_X_SENDFILE``                enable/disable x-sendfile\n``LOGGER_NAME``                   the name of the logger\n``SERVER_NAME``                   the name of the server.  Required for\n                                  subdomain support (e.g.: ``'localhost'``)\n``MAX_CONTENT_LENGTH``            If set to a value in bytes, Flask will\n                                  reject incoming requests with a\n                                  content length greater than this by\n                                  returning a 413 status code.\n================================= ========================================= </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.before_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     def after_request(self, f):\n <mask>         \"\"\"Register a function to be run after each request. Your function\n <mask>         must take one parameter, a :attr:`response_class` object and return\n <mask>         a new response object or the same (see :meth:`process_response`).\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         \"\"\"Register a function to be run after each request.  Your function\n <mask>         must take one parameter, a :attr:`response_class` object and return\n <mask>         a new response object or the same (see :meth:`process_response`).\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask>  </s> remove         \"\"\"Register a function to be run after each request. Your function </s> add         \"\"\"Register a function to be run after each request.  Your function </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return f\n <mask> \n <mask>     def teardown_request(self, f):\n <mask>         \"\"\"Register a function to be run at the end of each request,\n <mask>         regardless of whether there was an exception or not.\n <mask>         \"\"\"\n <mask>         self.teardown_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f): </s> remove         \"\"\"Register a function to be run after each request. Your function </s> add         \"\"\"Register a function to be run after each request.  Your function </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove         .. versionchanged:: 0.4\n           The :meth:`after_request` functions are now called even if an\n           error handler took over request processing.  This ensures that\n           even if an exception happens database have the chance to\n           properly close the connection. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Does the request dispatching.  Matches the URL and returns the\n <mask>         return value of the view or error handler.  This does not have to\n <mask>         be a response object.  In order to convert the return value to a\n <mask>         proper response object, call :func:`make_response`.\n <mask>         \"\"\"\n <mask>         req = _request_ctx_stack.top.request\n <mask>         if req.routing_exception is not None:\n <mask>             raise req.routing_exception\n <mask>         rule = req.url_rule\n <mask>         # if we provide automatic options for this URL and the </s> remove             if req.routing_exception is not None:\n                raise req.routing_exception\n            rule = req.url_rule\n            # if we provide automatic options for this URL and the\n            # request came with the OPTIONS method, reply automatically\n            if getattr(rule, 'provide_automatic_options', False) \\\n               and req.method == 'OPTIONS':\n                return self.make_default_options_response()\n            # otherwise dispatch to the handler for that endpoint\n            return self.view_functions[rule.endpoint](**req.view_args) </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask>         req = _request_ctx_stack.top.request\n <mask>         try:\n <mask>             if req.routing_exception is not None:\n <mask>                 raise req.routing_exception\n <mask>             rule = req.url_rule\n <mask>             # if we provide automatic options for this URL and the\n <mask>             # request came with the OPTIONS method, reply automatically\n <mask>             if getattr(rule, 'provide_automatic_options', False) \\\n <mask>                and req.method == 'OPTIONS':\n <mask>                 return self.make_default_options_response()\n <mask>             # otherwise dispatch to the handler for that endpoint\n <mask>             return self.view_functions[rule.endpoint](**req.view_args)\n <mask>         except HTTPException, e:\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>     def make_default_options_response(self): </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove         \"\"\"Binds the request context.\"\"\" </s> remove                 request_started.send(self)\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv) </s> add                 response = self.full_dispatch_request()", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return response\n <mask> \n <mask>     def do_teardown_request(self):\n <mask>         \"\"\"Called after the actual request dispatching and will\n <mask>         call every as :meth:`teardown_request` decorated function.\n <mask>         \"\"\"\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         mod = request.module\n <mask>         if mod and mod in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[mod])) </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         \"\"\"Register a function to be run after each request. Your function </s> add         \"\"\"Register a function to be run after each request.  Your function </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove         \"\"\"Pops the request context.\"\"\" </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n <mask>         environment and binds it to the current context.  This must be used in </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> remove         return _RequestContext(self, environ) </s> add         return RequestContext(self, environ) </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`:", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a request context from the given environment and binds\n <mask>         it to the current context.  This must be used in combination with\n <mask>         the `with` statement because the request is only bound to the\n <mask>         current context for the duration of the `with` block.\n <mask> \n <mask>         Example usage::\n <mask> \n <mask>             with app.request_context(environ):\n <mask>                 do_something_with(request) </s> remove >>> ctx = app.test_request_context('/?next=http://example.com/') </s> add >>> ctx = app.test_request_context() </s> remove That makes a lot of sense because we currently do not have a request we\ncould access.  So we have to make a request and bind it to the current\ncontext.  The :attr:`~flask.Flask.test_request_context` method can create\nus a request context: </s> add The easiest way to create a proper request context from the shell is by\nusing the :attr:`~flask.Flask.test_request_context` method which creates\nus a :class:`~flask.ctx.RequestContext`: </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>            is now passed the ctx object.\n <mask> \n <mask>         :param environ: a WSGI environment\n <mask>         \"\"\"\n <mask>         return _RequestContext(self, environ)\n <mask> \n <mask>     def test_request_context(self, *args, **kwargs):\n <mask>         \"\"\"Creates a WSGI environment from the given values (see\n <mask>         :func:`werkzeug.create_environ` for more information, this\n <mask>         function accepts the same arguments). </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> remove class _RequestContext(object):", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace keep keep", "code_tokens": " <mask>         can continue to call methods on it.\n <mask> \n <mask>         .. versionchanged:: 0.4\n <mask>            The :meth:`after_request` functions are now called even if an\n <mask>            error handler took over request processing.  This ensures that\n <mask>            even if an exception happens database have the chance to\n <mask>            properly close the connection.\n <mask> \n <mask>         .. versionchanged:: 0.7\n <mask>            The :meth:`teardown_request` functions get called at the very end of\n <mask>            processing the request. If an exception was thrown, it gets passed to\n <mask>            each teardown_request function.\n <mask> \n <mask>         :param environ: a WSGI environment </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided. </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> add .. data:: flask.request_tearing_down\n   :noindex:\n\n   This signal is sent when the request is tearing down.  This is always\n   called, even if an exception is caused.  Currently functions listening\n   to this signal are called after the regular teardown handlers, but this\n   is not something you can rely on.\n\n   Example subscriber::\n\n        def close_db_connection(sender):\n            session.close()\n\n        from flask import request_tearing_down\n        request_tearing_down.connect(close_db_connection, app) </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             try:\n <mask>                 request_started.send(self)\n <mask>                 rv = self.preprocess_request()\n <mask>                 if rv is None:\n <mask>                     rv = self.dispatch_request()\n <mask>                 response = self.make_response(rv)\n <mask>             except Exception, e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             try:\n <mask>                 response = self.process_response(response)\n <mask>             except Exception, e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             finally:\n <mask>                 self.do_teardown_request()\n <mask>             request_finished.send(self, response=response)\n <mask>             return response(environ, start_response)\n <mask> \n <mask>     def __call__(self, environ, start_response): </s> remove             return self.handle_http_exception(e) </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove         \"\"\"Binds the request context.\"\"\" </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     return _request_ctx_stack.top is not None\n <mask> \n <mask> \n <mask> class _RequestContext(object):\n <mask>     \"\"\"The request context contains all request relevant information.  It is\n <mask>     created at the beginning of the request and pushed to the\n <mask>     `_request_ctx_stack` and removed at the end of it.  It will create the\n <mask>     URL adapter and request object for the WSGI environment provided.\n <mask>     \"\"\" </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> add </s> remove            The :meth:`teardown_request` functions get called at the very end of\n           processing the request. If an exception was thrown, it gets passed to\n           each teardown_request function. </s> add            The behavior of the before and after request callbacks was changed\n           under error conditions and a new callback was added that will\n           always execute at the end of the request, independent on if an\n           error ocurred or not.  See :ref:`callbacks-and-errors`. </s> remove         regardless of whether there was an exception or not. </s> add         regardless of whether there was an exception or not.  These functions\n        are executed when the request context is popped, even if not an\n        actual request was performed.\n\n        Example::\n\n            ctx = app.test_request_context()\n            ctx.push()\n            ...\n            ctx.pop()\n\n        When ``ctx.pop()`` is executed in the above example, the teardown\n        functions are called just before the request context moves from the\n        stack of active contexts.  This becomes relevant if you are using\n        such constructs in tests.\n\n        Generally teardown functions must take every necesary step to avoid\n        that they will fail.  If they do execute code that might fail they\n        will have to surround the execution of these code by try/except\n        statements and log ocurring errors. </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> add         As of Flask 0.7 this function might not be executed at the end of the\n        request in case an unhandled exception ocurred. </s> add .. data:: request_tearing_down\n\n   This signal is sent when the application is tearing down the request.\n   This is always called, even if an error happened.  No arguments are\n   provided.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except HTTPException, e:\n <mask>             self.request.routing_exception = e\n <mask> \n <mask>     def push(self):\n <mask>         \"\"\"Binds the request context.\"\"\"\n <mask>         _request_ctx_stack.push(self)\n <mask> \n <mask>         # Open the session at the moment that the request context is\n <mask>         # available. This allows a custom open_session method to use the\n <mask>         # request context (e.g. flask-sqlalchemy). </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove             return self.handle_http_exception(e) </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove            (tb is None or not self.app.debug): </s> add            (tb is None or not self.app.preserve_context_on_exception): </s> remove This context can be used in two ways.  Either with the `with` statement\n(which unfortunately is not very handy for shell sessions).  The\nalternative way is to call the `push` and `pop` methods: </s> add Normally you would use the `with` statement to make this request object\nactive, but in the shell it's easier to use the\n:meth:`~flask.ctx.RequestContext.push` and\n:meth:`~flask.ctx.RequestContext.pop` methods by hand: </s> remove         \"\"\"Pops the request context.\"\"\" </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.session is None:\n <mask>             self.session = _NullSession()\n <mask> \n <mask>     def pop(self):\n <mask>         \"\"\"Pops the request context.\"\"\"\n <mask>         _request_ctx_stack.pop()\n <mask> \n <mask>     def __enter__(self):\n <mask>         self.push()\n <mask>         return self </s> remove         \"\"\"Binds the request context.\"\"\" </s> add         \"\"\"Binds the request context to the current context.\"\"\" </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove         \"\"\"Creates a request context from the given environment and binds\n        it to the current context.  This must be used in combination with\n        the `with` statement because the request is only bound to the\n        current context for the duration of the `with` block. </s> add         \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given\n        environment and binds it to the current context.  This must be used in\n        combination with the `with` statement because the request is only bound\n        to the current context for the duration of the `with` block. </s> remove         call every as :meth:`teardown_request` decorated function. </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask>         # access the request object in the interactive shell.  Furthermore\n <mask>         # the context can be force kept alive for the test client.\n <mask>         # See flask.testing for how this works.\n <mask>         if not self.request.environ.get('flask._preserve_context') and \\\n <mask>            (tb is None or not self.app.debug):\n <mask>             self.pop() </s> add             request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request() </s> remove         \"\"\"Binds the request context.\"\"\" </s> add         \"\"\"Binds the request context to the current context.\"\"\" </s> remove    .. versionchanged:: 0.4\n\n   The request context is automatically popped at the end of the request\n   for you.  In debug mode the request context is kept around if\n   exceptions happen so that interactive debuggers have a chance to\n   introspect the data.  With 0.4 this can also be forced for requests\n   that did not fail and outside of `DEBUG` mode.  By setting\n   ``'flask._preserve_context'`` to `True` on the WSGI environment the\n   context will not pop itself at the end of the request.  This is used by\n   the :meth:`~flask.Flask.test_client` for example to implement the\n   deferred cleanup functionality.\n\n   You might find this helpful for unittests where you need the\n   information from the context local around for a little longer.  Make\n   sure to properly :meth:`~werkzeug.LocalStack.pop` the stack yourself in\n   that situation, otherwise your unittests will leak memory. </s> add         .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`. </s> remove Diving into Context Locals\n--------------------------\n\nSay you have a utility function that returns the URL the user should be\nredirected to.  Imagine it would always redirect to the URL's ``next``\nparameter or the HTTP referrer or the index page::\n\n    from flask import request, url_for\n\n    def redirect_url():\n        return request.args.get('next') or \\\n               request.referrer or \\\n               url_for('index')\n\nAs you can see, it accesses the request object.  If you try to run this\nfrom a plain Python shell, this is the exception you will see: </s> add Generally it's recommended that you read the :ref:`request-context`\nchapter of the documentation first. </s> remove class _RequestContext(object):", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> # the API documentation in docs/api.rst as well as docs/signals.rst\n <mask> template_rendered = _signals.signal('template-rendered')\n <mask> request_started = _signals.signal('request-started')\n <mask> request_finished = _signals.signal('request-finished')\n <mask> got_request_exception = _signals.signal('got-request-exception') </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments. </s> add The functions registered as :meth:`~flask.Flask.teardown_request` are\nautomatically called when the context is popped.  So this is the perfect\nplace to automatically tear down resources that were needed by the request\ncontext (such as database connections). </s> remove      request_finished, got_request_exception </s> add      request_finished, got_request_exception, request_tearing_down </s> remove from .signals import request_started, request_finished, got_request_exception </s> add from .signals import request_started, request_finished, got_request_exception, \\\n    request_tearing_down </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             t.join()\n <mask> \n <mask>     def test_max_content_length(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.debug = True\n <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False </s> add         @app.before_request\n        def always_first():\n            flask.request.form['myfile']\n            assert False </s> remove             try:\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e))\n            finally:\n                self.do_teardown_request()\n            request_finished.send(self, response=response) </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove             return self.handle_http_exception(e) </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> add         call every as :meth:`teardown_request` decorated function.  This is\n        not actually called by the :class:`Flask` object itself but is always\n        triggered when the request context is popped.  That way we have a\n        tighter control over certain resources under testing environments.", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     def test_max_content_length(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413)\n <mask>         def catcher(error): </s> remove         app.debug = True </s> remove         \"\"\"Pops the request context.\"\"\" </s> add         \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n        \"\"\"\n        self.app.do_teardown_request() </s> remove             try:\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e))\n            finally:\n                self.do_teardown_request()\n            request_finished.send(self, response=response) </s> add     @property\n    def preserve_context_on_exception(self):\n        \"\"\"Returns the value of the `PRESERVE_CONTEXT_ON_EXCEPTION`\n        configuration value in case it's set, otherwise a sensible default\n        is returned.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        rv = self.config['PRESERVE_CONTEXT_ON_EXCEPTION']\n        if rv is not None:\n            return rv\n        return self.debug </s> remove             return self.handle_http_exception(e) </s> add             rv = self.handle_http_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response </s> remove         \"\"\"Binds the request context.\"\"\" </s> add         \"\"\"Binds the request context to the current context.\"\"\"", "html_url": "https://github.com/pallets/flask/commit/e71a5ff8de93801c30ed6daecac4b8502aa86813", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> FastCGI\n <mask> =======\n <mask> \n <mask> FastCGI is a deployment option on servers like `nginx`_, `lighttpd`_, and\n <mask> `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\n <mask> for other options.  To use your WSGI application with any of them you will need\n <mask> a FastCGI server first.  The most popular one is `flup`_ which we will use for\n <mask> this guide.  Make sure to have it installed to follow along.\n <mask> \n <mask> .. admonition:: Watch Out\n <mask> \n <mask>    Please make sure in advance that any ``app.run()`` calls you might\n <mask>    have in your application file are inside an ``if __name__ == </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols. </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``. </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`. </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/fastcgi.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep keep replace", "code_tokens": " <mask> =====\n <mask> \n <mask> uWSGI is a deployment option on servers like `nginx`_, `lighttpd`_, and\n <mask> `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\n <mask> for other options.  To use your WSGI application with uWSGI protocol you will\n <mask> need a uWSGI server first. uWSGI is both a protocol and an application server;\n <mask> the application server can serve uWSGI, FastCGI, and HTTP protocols.\n <mask> \n <mask> The most popular uWSGI server is `uwsgi`_, which we will use for this\n <mask> guide.  Make sure to have it installed to follow along. </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along. </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``. </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`. </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     $ uwsgi -s /tmp/yourapplication.sock --manage-script-name --mount /yourapplication=myapp:app\n <mask> \n <mask> The ``--manage-script-name`` will move the handling of ``SCRIPT_NAME`` to uwsgi,\n <mask> since its smarter about that. It is used together with the ``--mount`` directive\n <mask> which will make requests to ``/yourapplication`` be directed to ``myapp:app``.\n <mask> If your application is accessible at root level, you can use a single ``/``\n <mask> instead of ``/yourapplication``. ``myapp`` refers to the name of the file of\n <mask> your flask application (without extension) or the module which provides ``app``.\n <mask> ``app`` is the callable inside of your application (usually the line reads\n <mask> ``app = Flask(__name__)``.\n <mask> \n <mask> If you want to deploy your flask application inside of a virtual environment,\n <mask> you need to also add ``--virtualenv /path/to/virtual/environment``. You might\n <mask> also need to add ``--plugin python`` or ``--plugin python3`` depending on which\n <mask> python version you use for your project. </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along. </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols. </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`. </s> add For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Running `uWSGI HTTP Router`_::\n <mask> \n <mask>     uwsgi --http 127.0.0.1:5000 --module myproject:app\n <mask> \n <mask> For a more optimized setup, see :ref:`configuring uWSGI and NGINX <deploying-uwsgi>`.\n <mask> \n <mask> .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n <mask> .. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n <mask> \n <mask> Gevent </s> remove `cherokee`_; see :ref:`deploying-fastcgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with uWSGI protocol you will\nneed a uWSGI server first. uWSGI is both a protocol and an application server;\nthe application server can serve uWSGI, FastCGI, and HTTP protocols. </s> add `cherokee`_; see :doc:`fastcgi` and :doc:`wsgi-standalone` for other options.\nTo use your WSGI application with uWSGI protocol you will need a uWSGI server\nfirst. uWSGI is both a protocol and an application server; the application\nserver can serve uWSGI, FastCGI, and HTTP protocols. </s> remove `cherokee`_; see :ref:`deploying-uwsgi` and :ref:`deploying-wsgi-standalone`\nfor other options.  To use your WSGI application with any of them you will need\na FastCGI server first.  The most popular one is `flup`_ which we will use for\nthis guide.  Make sure to have it installed to follow along. </s> add `cherokee`_; see :doc:`uwsgi` and :doc:`wsgi-standalone` for other options. To\nuse your WSGI application with any of them you will need a FastCGI server first.\nThe most popular one is `flup`_ which we will use for this guide. Make sure to\nhave it installed to follow along. </s> remove since its smarter about that. It is used together with the ``--mount`` directive\nwhich will make requests to ``/yourapplication`` be directed to ``myapp:app``.\nIf your application is accessible at root level, you can use a single ``/``\ninstead of ``/yourapplication``. ``myapp`` refers to the name of the file of\nyour flask application (without extension) or the module which provides ``app``.\n``app`` is the callable inside of your application (usually the line reads\n``app = Flask(__name__)``. </s> add since it is smarter about that. It is used together with the ``--mount``\ndirective which will make requests to ``/yourapplication`` be directed to\n``myapp:app``. If your application is accessible at root level, you can use a\nsingle ``/`` instead of ``/yourapplication``. ``myapp`` refers to the name of\nthe file of your flask application (without extension) or the module which\nprovides ``app``. ``app`` is the callable inside of your application (usually\nthe line reads ``app = Flask(__name__)``.", "html_url": "https://github.com/pallets/flask/commit/e771016a5bac3c08987907a2ec63385d58b81be0", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Fixed an issue causing exceptions raised before entering a request or app\n <mask>   context to be passed to teardown handlers.\n <mask> \n <mask> Version 0.10.1\n <mask> --------------\n <mask> \n <mask> (bugfix release, released on June 14th 2013)\n <mask> \n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add             if url.query:\n                path += '?' + url.query </s> add     def test_full_url_request(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n\n        @app.route('/action', methods=['POST'])\n        def action():\n            return 'x'\n\n        with app.test_client() as c:\n            rv = c.post('http://domain.com/action?vodka=42', data={'gin': 43})\n            self.assert_equal(rv.status_code, 200)\n            self.assert_('gin' in flask.request.form)\n            self.ssert_('vodka' in flask.request.args)\n", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         if app_root:\n <mask>             base_url += app_root.lstrip('/')\n <mask>         if url.netloc:\n <mask>             path = url.path\n <mask>     return EnvironBuilder(path, base_url, *args, **kwargs)\n <mask> \n <mask> \n <mask> class FlaskClient(Client):\n <mask>     \"\"\"Works like a regular Werkzeug test client but has some knowledge about\n <mask>     how Flask works to defer the cleanup of the request context stack to the\n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add - Fixed an issue with query parameters getting removed from requests in\n  the test client when absolute URLs were requested. </s> add     def test_full_url_request(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n\n        @app.route('/action', methods=['POST'])\n        def action():\n            return 'x'\n\n        with app.test_client() as c:\n            rv = c.post('http://domain.com/action?vodka=42', data={'gin': 43})\n            self.assert_equal(rv.status_code, 200)\n            self.assert_('gin' in flask.request.form)\n            self.ssert_('vodka' in flask.request.args)\n", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(called, [None, None])\n <mask> \n <mask> \n <mask> class SubdomainTestCase(FlaskTestCase):\n <mask> \n <mask>     def setUp(self):\n <mask>         self.app = flask.Flask(__name__)\n <mask>         self.app.config['SERVER_NAME'] = 'example.com'\n </s> Fixe a bug in the test client causing url parameters to be removed.  This fixes #968 </s> add             if url.query:\n                path += '?' + url.query </s> add - Fixed an issue with query parameters getting removed from requests in\n  the test client when absolute URLs were requested.", "html_url": "https://github.com/pallets/flask/commit/e7c587789ae22a626196cea26340253dd9b70bf1", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return\n <mask> \n <mask>         # Add a \"Vary: Cookie\" header if the session was accessed at all.\n <mask>         if session.accessed:\n <mask>             response.headers.add('Vary', 'Cookie')\n <mask> \n <mask>         if not self.should_set_cookie(app, session):\n <mask>             return\n <mask> \n <mask>         httponly = self.get_cookie_httponly(app) </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie' </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> remove     def expect(path, header=True): </s> add     def expect(path, header_value='Cookie'): </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response </s> remove     expect('/no-vary-header', False) </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     def setdefault():\n <mask>         return flask.session.setdefault('test', 'default')\n <mask> \n <mask>     @app.route('/no-vary-header')\n <mask>     def no_vary_header():\n <mask>         return ''\n <mask> \n <mask>     def expect(path, header_value='Cookie'): </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove     def expect(path, header=True): </s> add     def expect(path, header_value='Cookie'): </s> remove     expect('/no-vary-header', False) </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None) </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie' </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> remove             response.headers.add('Vary', 'Cookie') </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @app.route('/no-vary-header')\n <mask>     def no_vary_header():\n <mask>         return ''\n <mask> \n <mask>     def expect(path, header=True):\n <mask>         rv = client.get(path)\n <mask> \n <mask>         if header:\n <mask>             assert rv.headers['Vary'] == 'Cookie'\n <mask>         else: </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie' </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response </s> remove             response.headers.add('Vary', 'Cookie') </s> add             self._patch_vary_cookie_header(response) </s> remove     expect('/no-vary-header', False) </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def expect(path, header=True):\n <mask>         rv = client.get(path)\n <mask> \n <mask>         if header:\n <mask>             assert rv.headers['Vary'] == 'Cookie'\n <mask>         else:\n <mask>             assert 'Vary' not in rv.headers\n <mask> \n <mask>     expect('/set')\n <mask>     expect('/get') </s> Don't overwrite Vary header when setting for cookie access #2317 </s> remove     def expect(path, header=True): </s> add     def expect(path, header_value='Cookie'): </s> remove     expect('/no-vary-header', False) </s> add     expect('/vary-cookie-header-set')\n    expect('/vary-header-set', 'Accept-Encoding, Accept-Language, Cookie')\n    expect('/no-vary-header', None) </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response </s> remove             response.headers.add('Vary', 'Cookie') </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     expect('/set')\n <mask>     expect('/get')\n <mask>     expect('/getitem')\n <mask>     expect('/setdefault')\n <mask>     expect('/no-vary-header', False)\n <mask> \n <mask> \n <mask> def test_flashes(app, req_ctx):\n <mask>     app.secret_key = 'testkey'\n <mask>  </s> remove         if header:\n            assert rv.headers['Vary'] == 'Cookie' </s> add         if header_value:\n            # The 'Vary' key should exist in the headers only once.\n            assert len(rv.headers.get_all('Vary')) == 1\n            assert rv.headers['Vary'] == header_value </s> add     @app.route('/vary-cookie-header-set')\n    def vary_cookie_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Cookie'\n        flask.session['test'] = 'test'\n        return response\n\n    @app.route('/vary-header-set')\n    def vary_header_set():\n        response = flask.Response()\n        response.headers['Vary'] = 'Accept-Encoding, Accept-Language'\n        flask.session['test'] = 'test'\n        return response </s> remove     def expect(path, header=True): </s> add     def expect(path, header_value='Cookie'): </s> remove             response.headers.add('Vary', 'Cookie') </s> add             self._patch_vary_cookie_header(response)", "html_url": "https://github.com/pallets/flask/commit/e7cd68ba58b78309a342fbce68f6ef1edef3e5e5", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     def _record(self, func):\n <mask>         self._register_events.append(func)\n <mask> \n <mask> \n <mask> class Flask(_PackageBoundObject):\n <mask>     \"\"\"The flask object implements a WSGI application and acts as the central\n <mask>     object.  It is passed the name of the module or package of the\n <mask>     application.  Once it is created it will act as a central registry for </s> remove     permanent_session_lifetime = timedelta(days=31) </s> remove     def __init__(self, import_name):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     static_path = '/static'\n <mask> \n <mask>     #: if a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     secret_key = ConfigAttribute('secret_key')\n <mask>  </s> remove     secret_key = None </s> add     secret_key = ConfigAttribute('secret_key') </s> remove     session_cookie_name = 'session' </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     permanent_session_lifetime = timedelta(days=31) </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove     use_x_sendfile = False </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep keep", "code_tokens": " <mask>     #: if a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     secret_key = None\n <mask> \n <mask>     #: The secure cookie uses this for the name of the session cookie\n <mask>     session_cookie_name = 'session'\n <mask> \n <mask>     #: A :class:`~datetime.timedelta` which is used to set the expiration </s> remove     permanent_session_lifetime = timedelta(days=31) </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove     use_x_sendfile = False </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #: A :class:`~datetime.timedelta` which is used to set the expiration\n <mask>     #: date of a permanent session.  The default is 31 days which makes a\n <mask>     #: permanent session survive for roughly one month.\n <mask>     permanent_session_lifetime = timedelta(days=31)\n <mask> \n <mask>     #: Enable this if you want to use the X-Sendfile feature.  Keep in\n <mask>     #: mind that the server has to support this.  This only affects files\n <mask>     #: sent with the :func:`send_file` method.\n <mask>     #: </s> remove     session_cookie_name = 'session' </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> remove     use_x_sendfile = False </s> add     use_x_sendfile = ConfigAttribute('use_x_sendfile') </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     #: mind that the server has to support this.  This only affects files\n <mask>     #: sent with the :func:`send_file` method.\n <mask>     #:\n <mask>     #: .. versionadded:: 0.2\n <mask>     use_x_sendfile = False\n <mask> \n <mask>     #: the logging format used for the debug logger.  This is only used when\n <mask>     #: the application is in debug mode, otherwise the attached logging\n <mask>     #: handler does the formatting.\n <mask>     #: </s> remove     permanent_session_lifetime = timedelta(days=31) </s> add     permanent_session_lifetime = ConfigAttribute('session.permanent_lifetime') </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False </s> add     session_cookie_name = ConfigAttribute('session.cookie_name') </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug') </s> add     #: default configuration parameters\n    default_config = ImmutableDict({\n        'debug':                                False,\n        'secret_key':                           None,\n        'session.cookie_name':                  'session',\n        'session.permanent_lifetime':           timedelta(days=31),\n        'use_x_sendfile':                       False\n    })\n\n    def __init__(self, import_name, config=None):", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         autoescape=True,\n <mask>         extensions=['jinja2.ext.autoescape', 'jinja2.ext.with_']\n <mask>     )\n <mask> \n <mask>     def __init__(self, import_name):\n <mask>         _PackageBoundObject.__init__(self, import_name)\n <mask> \n <mask>         #: the debug flag.  Set this to `True` to enable debugging of\n <mask>         #: the application.  In debug mode the debugger will kick in\n <mask>         #: when an unhandled exception ocurrs and the integrated server </s> remove         #: the debug flag.  Set this to `True` to enable debugging of\n        #: the application.  In debug mode the debugger will kick in\n        #: when an unhandled exception ocurrs and the integrated server\n        #: will automatically reload the application if changes in the\n        #: code are detected.\n        self.debug = False </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(self, import_name):\n <mask>         _PackageBoundObject.__init__(self, import_name)\n <mask> \n <mask>         #: the debug flag.  Set this to `True` to enable debugging of\n <mask>         #: the application.  In debug mode the debugger will kick in\n <mask>         #: when an unhandled exception ocurrs and the integrated server\n <mask>         #: will automatically reload the application if changes in the\n <mask>         #: code are detected.\n <mask>         self.debug = False\n <mask> \n <mask>         #: a dictionary of all view functions registered.  The keys will\n <mask>         #: be function names which are also used to generate URLs and\n <mask>         #: the values are the function objects themselves.\n <mask>         #: to register a view function, use the :meth:`route` decorator. </s> add     #: the debug flag.  Set this to `True` to enable debugging of the\n    #: application.  In debug mode the debugger will kick in when an unhandled\n    #: exception ocurrs and the integrated server will automatically reload\n    #: the application if changes in the code are detected.\n    debug = ConfigAttribute('debug')", "html_url": "https://github.com/pallets/flask/commit/e84140aba2786655bbddcedb363d16de1e285441", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - Implemented :meth:`~flask.testing.TestClient.session_transaction` to\n <mask>   easily modify sessions from the test environment.\n <mask> \n <mask> Version 0.7.3\n <mask> -------------\n <mask> \n <mask> Bugfix release, release date to be decided </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -----------\n <mask> \n <mask> .. currentmodule:: flask.testing\n <mask> \n <mask> .. autoclass:: TestClient\n <mask>    :members:\n <mask> \n <mask> \n <mask> Application Globals\n <mask> ------------------- </s> remove         See :class:`~flask.testing.TestClient` for more information. </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/') </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with app.test_client() as c:\n <mask>                 rv = c.get('/?vodka=42')\n <mask>                 assert request.args['vodka'] == '42'\n <mask> \n <mask>         See :class:`~flask.testing.TestClient` for more information.\n <mask> \n <mask>         .. versionchanged:: 0.4\n <mask>            added support for `with` block usage for the client.\n <mask> \n <mask>         .. versionadded:: 0.7 </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/') </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Creates a WSGI environment from the given values (see\n <mask>         :func:`werkzeug.test.EnvironBuilder` for more information, this\n <mask>         function accepts the same arguments).\n <mask>         \"\"\"\n <mask>         from werkzeug.test import create_environ\n <mask>         environ_overrides = kwargs.setdefault('environ_overrides', {})\n <mask>         if self.config.get('SERVER_NAME'):\n <mask>             server_name = self.config.get('SERVER_NAME')\n <mask>             if ':' not in server_name:\n <mask>                 http_host, http_port = server_name, '80'\n <mask>             else:\n <mask>                 http_host, http_port = server_name.split(':', 1)\n <mask> \n <mask>             environ_overrides.setdefault('SERVER_NAME', server_name)\n <mask>             environ_overrides.setdefault('HTTP_HOST', server_name)\n <mask>             environ_overrides.setdefault('SERVER_PORT', http_port)\n <mask>         return self.request_context(create_environ(*args, **kwargs))\n <mask> \n <mask>     def wsgi_app(self, environ, start_response):\n <mask>         \"\"\"The actual WSGI application.  This is not implemented in\n <mask>         `__call__` so that middlewares can be applied without losing a\n <mask>         reference to the class.  So instead of doing this:: </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs) </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/') </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> add - Refactored test client internally.  The ``APPLICATION_ROOT`` configuration\n  variable as well as ``SERVER_NAME`` are now properly used by the test client\n  as defaults.", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.test import Client, EnvironBuilder\n <mask> from flask import _request_ctx_stack\n <mask> \n <mask> \n <mask> class FlaskClient(Client):\n <mask>     \"\"\"Works like a regular Werkzeug test client but has some knowledge about\n <mask>     how Flask works to defer the cleanup of the request context stack to the\n <mask>     end of a with body when used in a with statement.  For general information\n <mask>     about how to use this class refer to :class:`werkzeug.test.Client`.\n <mask>  </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add - Refactored test client internally.  The ``APPLICATION_ROOT`` configuration\n  variable as well as ``SERVER_NAME`` are now properly used by the test client\n  as defaults. </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/') </s> remove         See :class:`~flask.testing.TestClient` for more information. </s> add         See :class:`~flask.testing.FlaskClient` for more information. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         as_tuple = kwargs.pop('as_tuple', False)\n <mask>         buffered = kwargs.pop('buffered', False)\n <mask>         follow_redirects = kwargs.pop('follow_redirects', False)\n <mask> \n <mask>         old = _request_ctx_stack.top\n <mask>         try:\n <mask>             return Client.open(self, builder,\n <mask>                                as_tuple=as_tuple, </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> remove         builder = EnvironBuilder(*args, **kwargs)\n\n        if self.application.config.get('SERVER_NAME'):\n            server_name = self.application.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, None\n            else:\n                http_host, http_port = server_name.split(':', 1)\n            if builder.base_url == 'http://localhost/':\n                # Default Generated Base URL\n                if http_port != None:\n                    builder.host = http_host + ':' + http_port\n                else:\n                    builder.host = http_host </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/') </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         as_tuple = kwargs.pop('as_tuple', False)\n <mask>         buffered = kwargs.pop('buffered', False)\n <mask>         follow_redirects = kwargs.pop('follow_redirects', False)\n <mask> \n <mask>         builder = EnvironBuilder(*args, **kwargs)\n <mask> \n <mask>         if self.application.config.get('SERVER_NAME'):\n <mask>             server_name = self.application.config.get('SERVER_NAME')\n <mask>             if ':' not in server_name:\n <mask>                 http_host, http_port = server_name, None\n <mask>             else:\n <mask>                 http_host, http_port = server_name.split(':', 1)\n <mask>             if builder.base_url == 'http://localhost/':\n <mask>                 # Default Generated Base URL\n <mask>                 if http_port != None:\n <mask>                     builder.host = http_host + ':' + http_port\n <mask>                 else:\n <mask>                     builder.host = http_host\n <mask>         old = _request_ctx_stack.top\n <mask>         try:\n <mask>             return Client.open(self, builder,\n <mask>                                as_tuple=as_tuple,\n <mask>                                buffered=buffered, </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs) </s> add     def test_environ_defaults_from_config(self):\n        app = flask.Flask(__name__)\n        app.testing = True\n        app.config['SERVER_NAME'] = 'example.com:1234'\n        app.config['APPLICATION_ROOT'] = '/foo'\n        @app.route('/')\n        def index():\n            return flask.request.url\n\n        ctx = app.test_request_context()\n        self.assertEqual(ctx.request.url, 'http://example.com:1234/foo/')\n        with app.test_client() as c:\n            rv = c.get('/')\n            self.assertEqual(rv.data, 'http://example.com:1234/foo/')", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> class TestToolsTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_session_transactions(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.testing = True\n <mask>         app.secret_key = 'testing'\n <mask>  </s> The test client and test_request_context are now both using the same logic internally for creating the environ.  Also they use APPLICATION_ROOT now. </s> add def make_test_environ_builder(app, path='/', base_url=None, *args, **kwargs):\n    \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n    http_host = app.config.get('SERVER_NAME')\n    app_root = app.config.get('APPLICATION_ROOT')\n    if base_url is None:\n        base_url = 'http://%s/' % (http_host or 'localhost')\n        if app_root:\n            base_url += app_root.lstrip('/')\n    return EnvironBuilder(path, base_url, *args, **kwargs) </s> add         builder = make_test_environ_builder(self.application, *args, **kwargs) </s> remove         from werkzeug.test import create_environ\n        environ_overrides = kwargs.setdefault('environ_overrides', {})\n        if self.config.get('SERVER_NAME'):\n            server_name = self.config.get('SERVER_NAME')\n            if ':' not in server_name:\n                http_host, http_port = server_name, '80'\n            else:\n                http_host, http_port = server_name.split(':', 1)\n\n            environ_overrides.setdefault('SERVER_NAME', server_name)\n            environ_overrides.setdefault('HTTP_HOST', server_name)\n            environ_overrides.setdefault('SERVER_PORT', http_port)\n        return self.request_context(create_environ(*args, **kwargs)) </s> add         from flask.testing import make_test_environ_builder\n        builder = make_test_environ_builder(self, *args, **kwargs)\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close() </s> add .. autoclass:: FlaskClient", "html_url": "https://github.com/pallets/flask/commit/e853a0f73959ad12cdabc2d74324cdc9329ae794", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> -   Show an error when a blueprint name contains a dot. The ``.`` has\n <mask>     special meaning, it is used to separate (nested) blueprint names and\n <mask>     the endpoint name. :issue:`4041`\n <mask> \n <mask> \n <mask> Version 2.0.0\n <mask> ------------- </s> fix url_prefix argument when nesting blueprints </s> add             bp_options = bp_options.copy()\n            bp_url_prefix = bp_options.get(\"url_prefix\")\n\n            if bp_url_prefix is None:\n                bp_url_prefix = blueprint.url_prefix\n\n            if state.url_prefix is not None and bp_url_prefix is not None:\n                bp_options[\"url_prefix\"] = (\n                    state.url_prefix.rstrip(\"/\") + \"/\" + bp_url_prefix.lstrip(\"/\")", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def register(self, app: \"Flask\", options: dict) -> None:\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register all\n <mask>         views and callbacks registered on the blueprint with the\n <mask>         application. Creates a :class:`.BlueprintSetupState` and calls\n <mask>         each :meth:`record` callbackwith it.\n <mask> \n <mask>         :param app: The application this blueprint is being registered\n <mask>             with.\n <mask>         :param options: Keyword arguments forwarded from\n <mask>             :meth:`~Flask.register_blueprint`. </s> fix url_prefix argument when nesting blueprints </s> add             bp_options = bp_options.copy()\n            bp_url_prefix = bp_options.get(\"url_prefix\")\n\n            if bp_url_prefix is None:\n                bp_url_prefix = blueprint.url_prefix\n\n            if state.url_prefix is not None and bp_url_prefix is not None:\n                bp_options[\"url_prefix\"] = (\n                    state.url_prefix.rstrip(\"/\") + \"/\" + bp_url_prefix.lstrip(\"/\") </s> add -   Combine URL prefixes when nesting blueprints that were created with\n    a ``url_prefix`` value. :issue:`4037`", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>         for blueprint, bp_options in self._blueprints:\n <mask>             url_prefix = options.get(\"url_prefix\", \"\")\n <mask>             if \"url_prefix\" in bp_options:\n <mask>                 url_prefix = (\n <mask>                     url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n <mask>                 )\n <mask> \n <mask>             bp_options[\"url_prefix\"] = url_prefix\n <mask>             bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n </s> fix url_prefix argument when nesting blueprints </s> remove         each :meth:`record` callbackwith it.\n </s> add         each :meth:`record` callback with it. </s> add -   Combine URL prefixes when nesting blueprints that were created with\n    a ``url_prefix`` value. :issue:`4037`", "html_url": "https://github.com/pallets/flask/commit/e93704fbfd5f40e48f8fe9034b6b0fe420d28fb3", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   stack yet. This allows ``stream_with_context`` generators to access the same\n <mask>   session that the containing view uses. (`#2354`_)\n <mask> \n <mask> .. _#1489: https://github.com/pallets/flask/pull/1489\n <mask> .. _#1621: https://github.com/pallets/flask/pull/1621\n <mask> .. _#1898: https://github.com/pallets/flask/pull/1898 </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> - Mimetype guessing in ``send_file`` now fails loudly and doesn't fall back to\n <mask>   ``application/octet-stream``. See pull request ``#1988``.\n <mask> - Make ``flask.safe_join`` able to join multiple paths like ``os.path.join``\n <mask>   (pull request ``#1730``).\n <mask> - Added `json` keyword argument to :meth:`flask.testing.FlaskClient.open`\n <mask>   (and related ``get``, ``post``, etc.), which makes it more convenient to\n <mask>   send JSON requests from the test client.\n <mask> - Added ``is_json`` and ``get_json`` to :class:``flask.wrappers.Response``\n <mask>   in order to make it easier to build assertions when testing JSON responses.\n <mask> - Revert a behavior change that made the dev server crash instead of returning\n <mask>   a Internal Server Error (pull request ``#2006``).\n <mask> - Correctly invoke response handlers for both regular request dispatching as\n <mask>   well as error handlers.\n <mask> - Disable logger propagation by default for the app logger. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header. </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing. </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask> -----------------\n <mask> \n <mask> .. versionadded:: 1.0\n <mask> \n <mask> Flask has great support for JSON, and is a popular choice for building REST\n <mask> APIs. Testing both JSON requests and responses using the test client is very\n <mask> convenient::\n <mask> \n <mask>     from flask import jsonify\n <mask>  </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove from . import json\nfrom .globals import _app_ctx_stack", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         return jsonify(token=generate_token(email, password))\n <mask> \n <mask>     with app.test_client() as c:\n <mask>         email = 'john@example.com'\n <mask>         password = 'secret'\n <mask>         resp = c.post('/api/auth', json={'login': email, 'password': password})\n <mask> \n <mask>         json_data = resp.get_json()\n <mask>         assert verify_token(email, json_data['token'])\n <mask> \n <mask> Note that if the ``json`` argument is provided then the test client will put\n <mask> JSON-serialized data in the request body, and also set the\n <mask> ``Content-Type: application/json`` HTTP header. </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header. </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well. </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data) </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace", "code_tokens": " <mask> \n <mask>         json_data = resp.get_json()\n <mask>         assert verify_token(email, json_data['token'])\n <mask> \n <mask> Note that if the ``json`` argument is provided then the test client will put\n <mask> JSON-serialized data in the request body, and also set the\n <mask> ``Content-Type: application/json`` HTTP header. </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json() </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well. </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> remove     from flask import jsonify </s> add     from flask import request, jsonify", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from urlparse import urlsplit as url_parse\n <mask> \n <mask> \n <mask> def make_test_environ_builder(\n <mask>     app, path='/', base_url=None, subdomain=None, url_scheme=None, json=None,\n <mask>     *args, **kwargs\n <mask> ):\n <mask>     \"\"\"Creates a new test builder with some application defaults thrown in.\"\"\"\n <mask> \n <mask>     assert ( </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header. </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove Flask has great support for JSON, and is a popular choice for building REST\nAPIs. Testing both JSON requests and responses using the test client is very\nconvenient:: </s> add Flask has great support for JSON, and is a popular choice for building JSON\nAPIs. Making requests with JSON data and examining JSON data in responses is\nvery convenient:: </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json() </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove         if 'data' in kwargs:\n            raise ValueError('Client cannot provide both `json` and `data`') </s> add         assert 'data' not in kwargs, (\n            \"Client cannot provide both 'json' and 'data'.\"\n        )", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep replace replace keep replace keep keep keep", "code_tokens": " <mask>     if 'json' in kwargs:\n <mask>         if 'data' in kwargs:\n <mask>             raise ValueError('Client cannot provide both `json` and `data`')\n <mask> \n <mask>         kwargs['data'] = json_dumps(kwargs.pop('json'))\n <mask> \n <mask>         # Only set Content-Type when not explicitly provided\n <mask>         if 'content_type' not in kwargs: </s> remove         # Only set Content-Type when not explicitly provided </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well. </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data) </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise ValueError('Client cannot provide both `json` and `data`')\n <mask> \n <mask>         kwargs['data'] = json_dumps(kwargs.pop('json'))\n <mask> \n <mask>         # Only set Content-Type when not explicitly provided\n <mask>         if 'content_type' not in kwargs:\n <mask>             kwargs['content_type'] = 'application/json'\n <mask> \n <mask>     return EnvironBuilder(path, base_url, *args, **kwargs)\n <mask>  </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json')) </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json')) </s> remove         if 'data' in kwargs:\n            raise ValueError('Client cannot provide both `json` and `data`') </s> add         assert 'data' not in kwargs, (\n            \"Client cannot provide both 'json' and 'data'.\"\n        ) </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data) </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/testing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.exceptions import BadRequest\n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> \n <mask> from flask import json\n <mask> from flask.globals import current_app </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove Flask has great support for JSON, and is a popular choice for building REST\nAPIs. Testing both JSON requests and responses using the test client is very\nconvenient:: </s> add Flask has great support for JSON, and is a popular choice for building JSON\nAPIs. Making requests with JSON data and examining JSON data in responses is\nvery convenient:: </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2015 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from . import json\n <mask> from .globals import _app_ctx_stack\n <mask>  </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove     app, path='/', base_url=None, subdomain=None, url_scheme=None, json=None, </s> add     app, path='/', base_url=None, subdomain=None, url_scheme=None,", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from flask import json\n <mask> from flask.globals import current_app\n <mask> \n <mask> \n <mask> class JSONMixin(object): </s> remove from . import json\nfrom .globals import _app_ctx_stack </s> add from flask import json\nfrom flask.globals import current_app </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ):", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase\n <mask> from werkzeug.exceptions import BadRequest\n <mask> \n <mask> from . import json\n <mask> from .globals import _app_ctx_stack\n <mask> \n <mask> \n <mask> class JSONMixin(object):\n <mask>     \"\"\"Common mixin for both request and response objects to provide JSON\n <mask>     parsing capabilities. </s> remove from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> add from werkzeug.wrappers import Request as RequestBase, Response as ResponseBase </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class JSONMixin(object):\n <mask>     \"\"\"Common mixin for both request and response objects to provide JSON\n <mask>     parsing capabilities.\n <mask> \n <mask>     .. versionadded:: 0.12\n <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Indicates if this request/response is in JSON format or not.  By </s> remove from . import json\nfrom .globals import _app_ctx_stack </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> add     _cached_json = Ellipsis </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Check if the mimetype indicates JSON data, either\n <mask>         :mimetype:`application/json` or :mimetype:`application/*+json`.\n <mask> \n <mask>         .. versionadded:: 0.11 </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def is_json(self):\n <mask>         \"\"\"Indicates if this request/response is in JSON format or not.  By\n <mask>         default it is considered to include JSON data if the mimetype is\n <mask>         :mimetype:`application/json` or :mimetype:`application/*+json`.\n <mask> \n <mask>         .. versionadded:: 1.0\n <mask>         \"\"\"\n <mask>         mt = self.mimetype </s> remove         if mt == 'application/json':\n            return True\n        if mt.startswith('application/') and mt.endswith('+json'):\n            return True\n        return False </s> add         return (\n            mt == 'application/json'\n            or (mt.startswith('application/')) and mt.endswith('+json')\n        ) </s> add     _cached_json = Ellipsis </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         .. versionadded:: 1.0\n <mask>         \"\"\"\n <mask>         mt = self.mimetype\n <mask>         if mt == 'application/json':\n <mask>             return True\n <mask>         if mt.startswith('application/') and mt.endswith('+json'):\n <mask>             return True\n <mask>         return False\n <mask> \n <mask>     @property\n <mask>     def json(self):\n <mask>         \"\"\"If this request/response is in JSON format then this property will\n <mask>         contain the parsed JSON data.  Otherwise it will be ``None``.\n <mask> \n <mask>         The :meth:`get_json` method should be used instead.\n <mask>         \"\"\"\n <mask>         from warnings import warn </s> remove         The :meth:`get_json` method should be used instead. </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove             'json is deprecated.  Use get_json() instead.'), stacklevel=2) </s> add             \"'json' is deprecated. Use 'get_json()' instead.\"\n        ), stacklevel=2)", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask>         The :meth:`get_json` method should be used instead.\n <mask>         \"\"\"\n <mask>         from warnings import warn\n <mask>         warn(DeprecationWarning(\n <mask>             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json() </s> remove             'json is deprecated.  Use get_json() instead.'), stacklevel=2) </s> add             \"'json' is deprecated. Use 'get_json()' instead.\"\n        ), stacklevel=2) </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace replace replace replace keep keep", "code_tokens": " <mask>         from warnings import warn\n <mask>         warn(DeprecationWarning(\n <mask>             'json is deprecated.  Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json()\n <mask> \n <mask>     def _get_data_for_json(self, cache):\n <mask>         getter = getattr(self, 'get_data', None)\n <mask>         if getter is not None:\n <mask>             return getter(cache=cache)\n <mask>         return self.data\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True): </s> remove         The :meth:`get_json` method should be used instead. </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         try:\n            return getattr(self, '_cached_json')\n        except AttributeError:\n            pass </s> add         if cache and self._cached_json is not Ellipsis:\n            return self._cached_json", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace replace keep", "code_tokens": " <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the JSON request/response data and returns it.  By default\n <mask>         this function will return ``None`` if the mimetype is not\n <mask>         :mimetype:`application/json` but this can be overridden by the\n <mask>         ``force`` parameter. If parsing fails the\n <mask>         :meth:`on_json_loading_failed` method on the request object will be\n <mask>         invoked.\n <mask> \n <mask>         :param force: if set to ``True`` the mimetype is ignored.\n <mask>         :param silent: if set to ``True`` this method will fail silently\n <mask>                        and return ``None``.\n <mask>         :param cache: if set to ``True`` the parsed JSON data is remembered\n <mask>                       on the object.\n <mask>         \"\"\"\n <mask>         try:\n <mask>             return getattr(self, '_cached_json')\n <mask>         except AttributeError:\n <mask>             pass\n <mask>  </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data </s> remove         \"\"\"If this request/response is in JSON format then this property will\n        contain the parsed JSON data.  Otherwise it will be ``None``. </s> add         \"\"\"This will contain the parsed JSON data if the mimetype indicates\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), otherwise it\n        will be ``None``. </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is </s> add         \"\"\"Check if the mimetype indicates JSON data, either </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep replace replace replace replace keep keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         # We accept MIME charset header against the specification as certain\n <mask>         # clients have been using this in the past.  For responses, we assume\n <mask>         # that if the response charset was set explicitly then the data had\n <mask>         # been encoded correctly as well.\n <mask>         charset = self.mimetype_params.get('charset')\n <mask>         try:\n <mask>             data = self._get_data_for_json(cache)\n <mask>             if charset is not None:\n <mask>                 rv = json.loads(data, encoding=charset)\n <mask>             else:\n <mask>                 rv = json.loads(data)\n <mask>         except ValueError as e:\n <mask>             if silent:\n <mask>                 rv = None\n <mask>             else: </s> remove         try:\n            return getattr(self, '_cached_json')\n        except AttributeError:\n            pass </s> add         if cache and self._cached_json is not Ellipsis:\n            return self._cached_json </s> remove         email = 'john@example.com'\n        password = 'secret'\n        resp = c.post('/api/auth', json={'login': email, 'password': password})\n\n        json_data = resp.get_json() </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json')) </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json')) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove         # Only set Content-Type when not explicitly provided", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep replace replace replace keep keep replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask>     def on_json_loading_failed(self, e):\n <mask>         \"\"\"Called if decoding of the JSON data failed.  The return value of\n <mask>         this method is used by :meth:`get_json` when an error occurred.  The\n <mask>         default implementation just raises a :class:`BadRequest` exception.\n <mask> \n <mask>         .. versionchanged:: 0.10\n <mask>            Removed buggy previous behavior of generating a random JSON\n <mask>            response.  If you want that behavior back you can trivially\n <mask>            add it by subclassing.\n <mask> \n <mask>         .. versionadded:: 0.8\n <mask>         \"\"\" </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug: </s> remove - Added `json` keyword argument to :meth:`flask.testing.FlaskClient.open`\n  (and related ``get``, ``post``, etc.), which makes it more convenient to\n  send JSON requests from the test client.\n- Added ``is_json`` and ``get_json`` to :class:``flask.wrappers.Response``\n  in order to make it easier to build assertions when testing JSON responses. </s> remove         The :meth:`get_json` method should be used instead. </s> add         .. deprecated:: 1.0\n            Use :meth:`get_json` instead. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>            add it by subclassing.\n <mask> \n <mask>         .. versionadded:: 0.8\n <mask>         \"\"\"\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None and ctx.app.debug:\n <mask>             raise BadRequest('Failed to decode JSON object: {0}'.format(e))\n <mask>         raise BadRequest()\n <mask> \n <mask> \n <mask> class Request(RequestBase, JSONMixin): </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing. </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH'] </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception.", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def max_content_length(self):\n <mask>         \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None:\n <mask>             return ctx.app.config['MAX_CONTENT_LENGTH']\n <mask> \n <mask>     @property\n <mask>     def endpoint(self):\n <mask>         \"\"\"The endpoint that matched the request.  This in combination with\n <mask>         :attr:`view_args` can be used to reconstruct the same or a </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing. </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> add     .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug and \\\n           self.mimetype != 'multipart/form-data' and not self.files: </s> add         if (\n            current_app\n            and current_app.debug\n            and self.mimetype != 'multipart/form-data'\n            and not self.files\n        ): </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug: </s> add         if current_app is not None and current_app.debug: </s> remove         \"\"\"Indicates if this request/response is in JSON format or not.  By\n        default it is considered to include JSON data if the mimetype is </s> add         \"\"\"Check if the mimetype indicates JSON data, either", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         RequestBase._load_form_data(self)\n <mask> \n <mask>         # In debug mode we're replacing the files multidict with an ad-hoc\n <mask>         # subclass that raises a different error for key errors.\n <mask>         ctx = _app_ctx_stack.top\n <mask>         if ctx is not None and ctx.app.debug and \\\n <mask>            self.mimetype != 'multipart/form-data' and not self.files:\n <mask>             from .debughelpers import attach_enctype_error_multidict\n <mask>             attach_enctype_error_multidict(self)\n <mask> \n <mask> \n <mask> class Response(ResponseBase, JSONMixin): </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None and ctx.app.debug: </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing. </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH'] </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         # We accept MIME charset header against the specification as certain\n        # clients have been using this in the past.  For responses, we assume\n        # that if the response charset was set explicitly then the data had\n        # been encoded correctly as well. </s> add         # We accept MIME charset against the specification as certain clients\n        # have used this in the past. For responses, we assume that if the\n        # charset is set then the data has been encoded correctly as well. </s> remove         kwargs['data'] = json_dumps(kwargs.pop('json')) </s> add         # push a context so flask.json can use app's json attributes\n        with app.app_context():\n            kwargs['data'] = json_dumps(kwargs.pop('json'))", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     :meth:`~flask.Flask.make_response` will take care of that for you.\n <mask> \n <mask>     If you want to replace the response object used you can subclass this and\n <mask>     set :attr:`~flask.Flask.response_class` to your subclass.\n <mask>     \"\"\"\n <mask> \n <mask>     default_mimetype = 'text/html'\n <mask> \n <mask>     def _get_data_for_json(self, cache): </s> remove            Removed buggy previous behavior of generating a random JSON\n           response.  If you want that behavior back you can trivially\n           add it by subclassing. </s> add            Raise a :exc:`BadRequest` error instead of returning an error\n           message as JSON. If you want that behavior you can add it by\n           subclassing. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         \"\"\"Parses the JSON request/response data and returns it.  By default\n        this function will return ``None`` if the mimetype is not\n        :mimetype:`application/json` but this can be overridden by the\n        ``force`` parameter. If parsing fails the\n        :meth:`on_json_loading_failed` method on the request object will be\n        invoked.\n\n        :param force: if set to ``True`` the mimetype is ignored.\n        :param silent: if set to ``True`` this method will fail silently\n                       and return ``None``.\n        :param cache: if set to ``True`` the parsed JSON data is remembered\n                      on the object. </s> add         \"\"\"Parse and return the data as JSON. If the mimetype does not indicate\n        JSON (:mimetype:`application/json`, see :meth:`is_json`), this returns\n        ``None`` unless ``force`` is true. If parsing fails,\n        :meth:`on_json_loading_failed` is called and its return value is used\n        as the return value.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence parsing errors and return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent calls. </s> add - Add ``json`` keyword argument for the test client request methods. This will\n  dump the given object as JSON and set the appropriate content type.\n  (`#2358`_)\n- Extract JSON handling to a mixin applied to both the request and response\n  classes used by Flask. This adds the ``is_json`` and ``get_json`` methods to\n  the response to make testing JSON response much easier. (`#2358`_) </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header. </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove         getter = getattr(self, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return self.data", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def test_json_request_and_response(app, client):\n <mask>     @app.route('/echo', methods=['POST'])\n <mask>     def echo():\n <mask>         return jsonify(flask.request.json)\n <mask> \n <mask>     with client:\n <mask>         json_data = {'drink': {'gin': 1, 'tonic': True}, 'price': 10}\n <mask>         rv = client.post('/echo', json=json_data)\n <mask>  </s> add         rv = c.post('/api/auth', json={\n            'username': 'flask', 'password': 'secret'\n        })\n        json_data = rv.get_json() </s> remove             data = self._get_data_for_json(cache)\n            if charset is not None:\n                rv = json.loads(data, encoding=charset)\n            else:\n                rv = json.loads(data) </s> add             data = self._get_data_for_json(cache=cache)\n            rv = json.loads(data, encoding=charset) </s> remove     from flask import jsonify </s> add     from flask import request, jsonify </s> remove Note that if the ``json`` argument is provided then the test client will put\nJSON-serialized data in the request body, and also set the\n``Content-Type: application/json`` HTTP header. </s> add Passing the ``json`` argument in the test client methods sets the request data\nto the JSON-serialized object and sets the content type to\n``application/json``. You can get the JSON data from the request or response\nwith ``get_json``. </s> remove         \"\"\"Called if decoding of the JSON data failed.  The return value of\n        this method is used by :meth:`get_json` when an error occurred.  The\n        default implementation just raises a :class:`BadRequest` exception. </s> add         \"\"\"Called if :meth:`get_json` parsing fails and isn't silenced. If\n        this method returns a value, it is used as the return value for\n        :meth:`get_json`. The default implementation raises a\n        :class:`BadRequest` exception. </s> remove         ctx = _app_ctx_stack.top\n        if ctx is not None:\n            return ctx.app.config['MAX_CONTENT_LENGTH']", "html_url": "https://github.com/pallets/flask/commit/e97253e4c1a0380f0b70108e8f984b0d9b87ac11", "file_name": "tests/test_testing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>    reqcontext\n <mask>    blueprints\n <mask>    extensions\n <mask>    shell\n <mask>    patterns/index\n <mask>    deploying/index\n <mask>    becomingbig\n <mask>  </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`. </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this: </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove     app.debug = True\n    app.run()", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep replace keep keep", "code_tokens": " <mask>     def hello_world():\n <mask>         return 'Hello World!'\n <mask> \n <mask>     if __name__ == '__main__':\n <mask>         app.run()\n <mask> \n <mask> Just save it as `hello.py` (or something similar) and run it with your Python\n <mask> interpreter.  Make sure to not call your application `flask.py` because this\n <mask> would conflict with Flask itself.\n <mask> \n <mask> ::\n <mask> \n <mask>     $ python hello.py </s> remove     $ python hello.py </s> add     $ python -m flask -a hello run </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module. </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong. </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this: </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this:", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> would conflict with Flask itself.\n <mask> \n <mask> ::\n <mask> \n <mask>     $ python hello.py\n <mask>      * Running on http://127.0.0.1:5000/\n <mask> \n <mask> Now head over to `http://127.0.0.1:5000/ <http://127.0.0.1:5000/>`_, and you\n <mask> should see your hello world greeting.\n <mask>  </s> add To run the application you can either use the ``flask`` command or\npython's ``-m`` switch with Flask::\n\n    $ flask -a hello run\n     * Running on http://127.0.0.1:5000/\n\nor alternatively:: </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong. </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this: </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>    should trigger our function.\n <mask> 4. The function is given a name which is also used to generate URLs for that\n <mask>    particular function, and returns the message we want to display in the\n <mask>    user's browser.\n <mask> 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n <mask>    with our application.  The ``if __name__ == '__main__':`` makes sure the\n <mask>    server only runs if the script is executed directly from the Python\n <mask>    interpreter and not used as an imported module.\n <mask> \n <mask> To stop the server, hit control-C.\n <mask> \n <mask> .. _public-server:\n <mask>  </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong. </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this:: </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> add There are more parameters that are explained in the :ref:`server` docs.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask>    default because in debugging mode a user of the application can execute\n <mask>    arbitrary Python code on your computer.\n <mask> \n <mask>    If you have `debug` disabled or trust the users on your network, you can\n <mask>    make the server publicly available simply by changing the call of the\n <mask>    :meth:`~flask.Flask.run` method to look like this::\n <mask> \n <mask>        app.run(host='0.0.0.0')\n <mask> \n <mask>    This tells your operating system to listen on all public IPs.\n <mask>  </s> remove The :meth:`~flask.Flask.run` method is nice to start a local\ndevelopment server, but you would have to restart it manually after each\nchange to your code.  That is not very nice and Flask can do better.  If\nyou enable debug support the server will reload itself on code changes,\nand it will also provide you with a helpful debugger if things go wrong. </s> add The ``flask`` script is nice to start a local development server, but\nyou would have to restart it manually after each change to your code.\nThat is not very nice and Flask can do better.  If you enable debug\nsupport the server will reload itself on code changes, and it will also\nprovide you with a helpful debugger if things go wrong. </s> add To run the application you can either use the ``flask`` command or\npython's ``-m`` switch with Flask::\n\n    $ flask -a hello run\n     * Running on http://127.0.0.1:5000/\n\nor alternatively:: </s> remove Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \ninstead of hard-coding them into your templates?  There are three good reasons \nfor this: </s> add Why would you want to build URLs using the URL reversing function\n:func:`~flask.url_for` instead of hard-coding them into your templates?\nThere are three good reasons for this: </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object:: </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace keep", "code_tokens": " <mask> \n <mask> Debug Mode\n <mask> ----------\n <mask> \n <mask> The :meth:`~flask.Flask.run` method is nice to start a local\n <mask> development server, but you would have to restart it manually after each\n <mask> change to your code.  That is not very nice and Flask can do better.  If\n <mask> you enable debug support the server will reload itself on code changes,\n <mask> and it will also provide you with a helpful debugger if things go wrong.\n <mask> \n <mask> There are two ways to enable debugging.  Either set that flag on the\n <mask> application object::\n <mask>  </s> remove 5. Finally we use the :meth:`~flask.Flask.run` function to run the local server\n   with our application.  The ``if __name__ == '__main__':`` makes sure the\n   server only runs if the script is executed directly from the Python\n   interpreter and not used as an imported module. </s> add 5. Finally we use the Flask development server to run the local server\n   with our application. </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this:: </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line::", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> application object::\n <mask> \n <mask>     app.debug = True\n <mask>     app.run()\n <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask> \n <mask>     app.debug = True\n <mask>     app.run()\n <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask>  </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object:: </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove     app.run(debug=True) </s> remove Both methods have the exact same effect. </s> remove     if __name__ == '__main__':\n        app.run()", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> Or pass it as a parameter to run::\n <mask> \n <mask>     app.run(debug=True)\n <mask> \n <mask> Both methods have the exact same effect.\n <mask> \n <mask> .. admonition:: Attention\n <mask> \n <mask>    Even though the interactive debugger does not work in forking environments </s> remove     app.debug = True\n    app.run() </s> remove There are two ways to enable debugging.  Either set that flag on the\napplication object:: </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> below.  It tells Flask to behave as though it is handling a request, even\n <mask> though we are interacting with it through a Python shell.  Have a look at the\n <mask> explanation below. :ref:`context-locals`).\n <mask> \n <mask> Why would you want to build URLs using the URL reversing function :func:`~flask.url_for` \n <mask> instead of hard-coding them into your templates?  There are three good reasons \n <mask> for this:\n <mask> \n <mask> 1. Reversing is often more descriptive than hard-coding the URLs.  More\n <mask>    importantly, it allows you to change URLs in one go, without having to\n <mask>    remember to change URLs all over the place.\n <mask> 2. URL building will handle escaping of special characters and Unicode </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command:: </s> remove    If you have `debug` disabled or trust the users on your network, you can\n   make the server publicly available simply by changing the call of the\n   :meth:`~flask.Flask.run` method to look like this:: </s> add    If you have the debugger disabled or trust the users on your network,\n   you can make the server publicly available simply by adding\n   ``--host=0.0.0.0`` to the command line:: </s> add Command Line Interface\n----------------------\n\nStarting with Flask 1.0 the recommended way to work with the shell is the\n``flask shell`` command which does a lot of this automatically for you.\nFor instance the shell is automatically initialized with a loaded\napplication context.\n\nFor more information see :ref:`cli`.", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> Generally it's recommended that you read the :ref:`request-context`\n <mask> chapter of the documentation first.\n <mask> \n <mask> Creating a Request Context\n <mask> --------------------------\n <mask> \n <mask> The easiest way to create a proper request context from the shell is by </s> add There are different ways to enable the debug mode.  The most obvious one\nis the ``--debug`` parameter to the ``flask`` command::", "html_url": "https://github.com/pallets/flask/commit/e9d1fc47bf42bb13fce8799ad7727206610a7eb4", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>    installation\n <mask>    quickstart\n <mask>    tutorial/index\n <mask>    testing\n <mask>    patterns/index\n <mask>    deploying/index\n <mask>    becomingbig\n <mask> \n <mask> API Reference </s> add For some better examples, checkout the :ref:`uploading-files` pattern. </s> add if 'dev' in version:\n    version = version.split('dev')[0]", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             f.save('/var/www/uploads/' + secure_filename(f.filename))\n <mask>         ...\n <mask> \n <mask> Cookies\n <mask> ```````\n <mask> \n <mask> To access cookies you can use the :attr:`~flask.request.cookies`\n <mask> attribute.  Again this is a dictionary with all the cookies the client </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response) </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e)) </s> remove         except Exception, e:\n            return self.handle_exception(e)", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     #:\n <mask>     #: .. versionadded:: 0.5\n <mask>     debug_log_format = (\n <mask>         '-' * 80 + '\\n' +\n <mask>         '%(levelname)s in %(module)s, %(filename)s:%(lineno)d]:\\n' +\n <mask>         '%(message)s\\n' +\n <mask>         '-' * 80\n <mask>     )\n <mask> \n <mask>     #: options that are passed directly to the Jinja2 environment </s> remove         except Exception, e:\n            return self.handle_exception(e) </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured')", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @cached_property\n <mask>     def logger(self):\n <mask>         \"\"\"A :class:`logging.Logger` object for this application.  The\n <mask>         default configuration is to log to stderr if the application is\n <mask>         in debug mode.\n <mask>         \"\"\"\n <mask>         from logging import getLogger, StreamHandler, Formatter, DEBUG\n <mask>         class DebugHandler(StreamHandler):\n <mask>             def emit(x, record):\n <mask>                 if self.debug: </s> remove         except Exception, e:\n            return self.handle_exception(e)", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 raise req.routing_exception\n <mask>             return self.view_functions[req.endpoint](**req.view_args)\n <mask>         except HTTPException, e:\n <mask>             return self.handle_http_exception(e)\n <mask>         except Exception, e:\n <mask>             return self.handle_exception(e)\n <mask> \n <mask>     def make_response(self, rv):\n <mask>         \"\"\"Converts the return value from a view function to a real\n <mask>         response object that is an instance of :attr:`response_class`.\n <mask>  </s> remove             rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n            response = self.make_response(rv)\n            response = self.process_response(response) </s> add             try:\n                rv = self.preprocess_request()\n                if rv is None:\n                    rv = self.dispatch_request()\n                response = self.make_response(rv)\n                response = self.process_response(response)\n            except Exception, e:\n                response = self.make_response(self.handle_exception(e))", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                                a list of headers and an optional\n <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             rv = self.preprocess_request()\n <mask>             if rv is None:\n <mask>                 rv = self.dispatch_request()\n <mask>             response = self.make_response(rv)\n <mask>             response = self.process_response(response)\n <mask>             return response(environ, start_response)\n <mask> \n <mask>     def request_context(self, environ):\n <mask>         \"\"\"Creates a request context from the given environment and binds\n <mask>         it to the current context.  This must be used in combination with </s> remove         except Exception, e:\n            return self.handle_exception(e) </s> add         in debug mode.  This logger can be used to (surprise) log messages.\n        Here some examples::\n\n            app.logger.debug('A value for debugging')\n            app.logger.warning('A warning ocurred (%d apples)', 42)\n            app.logger.error('An error occoured')", "html_url": "https://github.com/pallets/flask/commit/ea5e654e9e19aab5089f9a71e679bcca11581e86", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if isinstance(code_or_exception, integer_types):\n <mask>             assert code_or_exception != 500 or key is None, \\\n <mask>                 'It is currently not possible to register a 500 internal ' \\\n <mask>                 'server error on a per-blueprint level.'\n <mask>             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n <mask>         else:\n <mask>             self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n <mask>                 .append((code_or_exception, f))\n <mask> \n <mask>     @setupmethod\n <mask>     def template_filter(self, name=None):\n <mask>         \"\"\"A decorator that is used to register custom template filter.\n <mask>         You can specify a name for the filter, otherwise the function </s> Fixed and intuitivized exception handling </s> remove \n        blueprint_handlers = ()\n        handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers is not None:\n            blueprint_handlers = handlers.get(None, ())\n        app_handlers = self.error_handler_spec[None].get(None, ())\n        for typecheck, handler in chain(blueprint_handlers, app_handlers):\n            if isinstance(e, typecheck):\n                return handler(e) </s> remove         reraise(exc_type, exc_value, tb) </s> add         handler = self._find_error_handler(e)\n        \n        if handler is None:\n            reraise(exc_type, exc_value, tb)\n        return handler(e) </s> remove         if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> add         \n        handler = self._find_error_handler(e) </s> remove         handlers = self.error_handler_spec.get(request.blueprint)", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace keep", "code_tokens": " <mask>         \"\"\"\n <mask>         handlers = self.error_handler_spec.get(request.blueprint)\n <mask>         # Proxy exceptions don't have error codes.  We want to always return\n <mask>         # those unchanged as errors\n <mask>         if e.code is None:\n <mask>             return e\n <mask>         if handlers and e.code in handlers:\n <mask>             handler = handlers[e.code]\n <mask>         else:\n <mask>             handler = self.error_handler_spec[None].get(e.code)\n <mask>         if handler is None: </s> remove \n        blueprint_handlers = ()\n        handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers is not None:\n            blueprint_handlers = handlers.get(None, ())\n        app_handlers = self.error_handler_spec[None].get(None, ())\n        for typecheck, handler in chain(blueprint_handlers, app_handlers):\n            if isinstance(e, typecheck):\n                return handler(e) </s> remove         reraise(exc_type, exc_value, tb) </s> add         handler = self._find_error_handler(e)\n        \n        if handler is None:\n            reraise(exc_type, exc_value, tb)\n        return handler(e) </s> remove             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> add         \n        handlers[code_or_exception] = f", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep keep keep keep replace keep", "code_tokens": " <mask>         # ensure not to trash sys.exc_info() at that point in case someone\n <mask>         # wants the traceback preserved in handle_http_exception.  Of course\n <mask>         # we cannot prevent users from trashing it themselves in a custom\n <mask>         # trap_http_exception method so that's their fault then.\n <mask> \n <mask>         blueprint_handlers = ()\n <mask>         handlers = self.error_handler_spec.get(request.blueprint)\n <mask>         if handlers is not None:\n <mask>             blueprint_handlers = handlers.get(None, ())\n <mask>         app_handlers = self.error_handler_spec[None].get(None, ())\n <mask>         for typecheck, handler in chain(blueprint_handlers, app_handlers):\n <mask>             if isinstance(e, typecheck):\n <mask>                 return handler(e)\n <mask> \n <mask>         if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>         reraise(exc_type, exc_value, tb)\n <mask> \n <mask>         if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n <mask>             return self.handle_http_exception(e)\n <mask> \n <mask>         reraise(exc_type, exc_value, tb)\n <mask>  </s> remove         if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> add         \n        handler = self._find_error_handler(e) </s> remove         handlers = self.error_handler_spec.get(request.blueprint) </s> remove             self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> add         \n        handlers[code_or_exception] = f", "html_url": "https://github.com/pallets/flask/commit/eae48d97b085626c1860a900a27ff63c439e0edb", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> -   Refactor ``register_error_handler`` to consolidate error checking.\n <mask>     Rewrite some error messages to be more consistent. :issue:`4559`\n <mask> \n <mask> \n <mask> Version 2.1.2\n <mask> -------------\n <mask>  </s> remove         if self._got_registered_once and self.warn_on_modifications: </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> remove     warn_on_modifications = False", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     .. versionadded:: 0.7\n <mask>     \"\"\"\n <mask> \n <mask>     warn_on_modifications = False\n <mask>     _got_registered_once = False\n <mask> \n <mask>     #: Blueprint local JSON encoder class to use. Set to ``None`` to use\n <mask>     #: the app's :class:`~flask.Flask.json_encoder`.\n <mask>     json_encoder = None </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.cli_group = cli_group\n <mask>         self._blueprints: t.List[t.Tuple[\"Blueprint\", dict]] = []\n <mask> \n <mask>     def _is_setup_finished(self) -> bool:\n <mask>         return self.warn_on_modifications and self._got_registered_once\n <mask> \n <mask>     def record(self, func: t.Callable) -> None:\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state` </s> always warn on blueprint setupmethod after registration </s> remove         if self._got_registered_once and self.warn_on_modifications: </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state`\n <mask>         method.\n <mask>         \"\"\"\n <mask>         if self._got_registered_once and self.warn_on_modifications:\n <mask>             from warnings import warn\n <mask> \n <mask>             warn(\n <mask>                 Warning(\n <mask>                     \"The blueprint was already registered once but is\" </s> always warn on blueprint setupmethod after registration </s> remove         return self.warn_on_modifications and self._got_registered_once", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             warn(\n <mask>                 Warning(\n <mask>                     \"The blueprint was already registered once but is\"\n <mask>                     \" getting modified now. These changes will not show\"\n <mask>                     \" up.\"\n <mask>                 )\n <mask>             )\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def record_once(self, func: t.Callable) -> None: </s> always warn on blueprint setupmethod after registration </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from .typing import URLDefaultCallable\n <mask> from .typing import URLValuePreprocessorCallable\n <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .wrappers import Response\n <mask>     from .typing import ErrorHandlerCallable\n <mask> \n <mask> # a singleton sentinel value for parameter defaults\n <mask> _sentinel = object()\n <mask>  </s> add     from .wrappers import Response </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .typing import ErrorHandlerCallable\n <mask> \n <mask> # a singleton sentinel value for parameter defaults\n <mask> _sentinel = object()\n <mask> \n <mask> F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n <mask>  </s> always warn on blueprint setupmethod after registration </s> remove         if self._got_registered_once and self.warn_on_modifications: </s> add         if self._got_registered_once:\n            # TODO: Upgrade this to an error and unify it setupmethod in 2.3 </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         raise NotImplementedError\n <mask> \n <mask>     def endpoint(self, endpoint: str) -> t.Callable:\n <mask>         \"\"\"Decorate a view function to register it for the given\n <mask>         endpoint. Used if a rule is added without a ``view_func`` with\n <mask>         :meth:`add_url_rule`.\n <mask>  </s> add -   Use Blueprint decorators and functions intended for setup after\n    registering the blueprint will show a warning. In the next version,\n    this will become an error just like the application setup methods.\n    :issue:`4571`", "html_url": "https://github.com/pallets/flask/commit/eb36135cfe6a17350617e47b70b9ad383206eded", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Unreleased\n <mask> \n <mask> -   Add an ``app.redirect`` method, which ``flask.redirect`` will call.\n <mask>     This makes it possible for an app to override how redirects work.\n <mask>     :issue:`4569`\n <mask> -   Refactor ``register_error_handler`` to consolidate error checking.\n <mask>     Rewrite some error messages to be more consistent. :issue:`4559`\n <mask>  </s> add     def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class() </s> add     #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter()", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from .globals import g as g\n <mask> from .globals import request as request\n <mask> from .globals import session as session\n <mask> from .helpers import flash as flash\n <mask> from .helpers import get_flashed_messages as get_flashed_messages\n <mask> from .helpers import get_template_attribute as get_template_attribute\n <mask> from .helpers import make_response as make_response\n <mask> from .helpers import redirect as redirect </s> remove from werkzeug.exceptions import abort as abort </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.datastructures import Headers\n <mask> from werkzeug.datastructures import ImmutableDict\n <mask> from werkzeug.exceptions import BadRequest\n <mask> from werkzeug.exceptions import BadRequestKeyError\n <mask> from werkzeug.exceptions import HTTPException\n <mask> from werkzeug.exceptions import InternalServerError </s> add from werkzeug.exceptions import abort as _wz_abort </s> remove from werkzeug.exceptions import abort as abort </s> add from .helpers import abort as abort", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: The class that is used for response objects.  See\n <mask>     #: :class:`~flask.Response` for more information.\n <mask>     response_class = Response\n <mask> \n <mask>     #: The class that is used for the Jinja environment.\n <mask>     #:\n <mask>     #: .. versionadded:: 0.11\n <mask>     jinja_environment = Environment\n <mask> \n <mask>     #: The class that is used for the :data:`~flask.g` instance. </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567` </s> remove from werkzeug.exceptions import abort as abort", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.config = self.make_config(instance_relative_config)\n <mask> \n <mask>         #: A list of functions that are called when :meth:`url_for` raises a\n <mask>         #: :exc:`~werkzeug.routing.BuildError`.  Each function registered here\n <mask>         #: is called with `error`, `endpoint` and `values`.  If a function\n <mask>         #: returns ``None`` or raises a :exc:`BuildError` the next function is </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567`", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         defaults[\"DEBUG\"] = get_debug_flag()\n <mask>         return self.config_class(root_path, defaults)\n <mask> \n <mask>     def auto_find_instance_path(self) -> str:\n <mask>         \"\"\"Tries to locate the instance path if it was not provided to the\n <mask>         constructor of the application class.  It will basically calculate\n <mask>         the path to a folder named ``instance`` next to your main file or </s> add         #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        self.aborter = self.make_aborter() </s> add -   Add ``aborter_class`` and ``aborter`` attributes to the Flask app\n    object. ``flask.abort`` will call ``app.aborter``. This makes it\n    possible for an app to override how aborts work, including custom\n    status codes. :issue:`4567` </s> add from werkzeug.exceptions import Aborter", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> from functools import update_wrapper\n <mask> from threading import RLock\n <mask> \n <mask> import werkzeug.utils\n <mask> from werkzeug.routing import BuildError\n <mask> from werkzeug.urls import url_quote\n <mask> from werkzeug.utils import redirect as _wz_redirect\n <mask> \n <mask> from .globals import _app_ctx_stack </s> add from .helpers import abort as abort </s> remove from werkzeug.exceptions import abort as abort", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     from werkzeug.wrappers import Response as BaseResponse\n <mask>     from .wrappers import Response\n <mask> \n <mask> \n <mask> def get_env() -> str:\n <mask>     \"\"\"Get the environment the app is running in, indicated by the\n <mask>     :envvar:`FLASK_ENV` environment variable. The default is </s> remove from werkzeug.exceptions import abort as abort </s> add from .helpers import abort as abort", "html_url": "https://github.com/pallets/flask/commit/eb5dd9f5ef255c578cbbe13c1cb4dd11389d5519", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/test.txt')\n <mask>         self.assert_equal(rv.data.strip(), b'Admin File')\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask>         rv.close()\n <mask> \n <mask>         with app.test_request_context(): </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         rv.close()\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n <mask>                               '/admin/static/test.txt')\n <mask> \n <mask>         with app.test_request_context(): </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/test.txt')\n <mask>         self.assert_equal(rv.data.strip(), b'Admin File')\n <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), b'/* nested file */')\n <mask>         rv.close()\n <mask> \n <mask>         # try/finally, in case other tests use this app for Blueprint tests. </s> add         rv.close() </s> add         rv.close() </s> add         rv.close() </s> add             rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(value, 'attachment')\n <mask>             self.assert_equal(options['filename'], 'index.html')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file(StringIO('Test'), as_attachment=True,\n <mask>                                  attachment_filename='index.txt',\n <mask>                                  add_etags=False)\n <mask>             self.assert_equal(rv.mimetype, 'text/plain') </s> add                 rv.close() </s> add             rv.close() </s> add                 rv.close() </s> add                 rv.close() </s> add             rv.close() </s> add             rv.close()", "html_url": "https://github.com/pallets/flask/commit/eb622fb34f0b2433b21b6b5454273a597b77a6d4", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n <mask> from flask._compat import StringIO, text_type\n <mask> from flask.helpers import get_debug_flag, make_response\n <mask> \n <mask> \n <mask> def has_encoding(name):\n <mask>     try: </s> remove     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz): </s> add     @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname): </s> add         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected", "html_url": "https://github.com/pallets/flask/commit/eb9618347c680a038e2e6310228d85a53b080f93", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             rv = client.get(url)\n <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n <mask>     def test_jsonify_aware_datetimes(self, tz):\n <mask>         \"\"\"Test if aware datetime.datetime objects are converted into GMT.\"\"\"\n <mask>         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n <mask>         dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n <mask>         gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n <mask>         expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n <mask>         assert flask.json.JSONEncoder().encode(dt) == expected\n <mask> \n </s> Use pytz again for tests\n\nThis is because datetime.timezone is Python 3 only.  The only\nalternative would be to hand-spin a datetime.tzinfo subclass, an\noverkill.\n\nThis reverts commit 0e6cab357690614791ab4ca0da0ac65dbb803041. </s> add from pytz import timezone </s> add     pytz", "html_url": "https://github.com/pallets/flask/commit/eb9618347c680a038e2e6310228d85a53b080f93", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace replace keep", "code_tokens": " <mask> \n <mask>     def test_uninstalled_module_paths(self):\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         app = flask.Flask(__name__)\n <mask>         self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n <mask> \n <mask>         app = flask.Flask(__name__, instance_path=here)\n <mask>         self.assertEqual(app.instance_path, here)\n <mask> \n <mask>         try:\n </s> Split up a test into two </s> add         app = flask.Flask(__name__, instance_path=here)\n        self.assertEqual(app.instance_path, here)\n\n    def test_uninstalled_module_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        app = flask.Flask(__name__)\n        self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n", "html_url": "https://github.com/pallets/flask/commit/eb9a14e1581fd379f25986bb206fe0d8fdc6b1a3", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             self.fail('Expected value error')\n <mask> \n <mask>     def test_uninstalled_package_paths(self):\n <mask>         from blueprintapp import app\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n <mask>  </s> remove         app = flask.Flask(__name__)\n        self.assertEqual(app.instance_path, os.path.join(here, 'instance'))\n\n        app = flask.Flask(__name__, instance_path=here)\n        self.assertEqual(app.instance_path, here) </s> remove     def test_uninstalled_module_paths(self): </s> add     def test_explicit_instance_paths(self):", "html_url": "https://github.com/pallets/flask/commit/eb9a14e1581fd379f25986bb206fe0d8fdc6b1a3", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   instruct Flask to explain how it locates templates.  This should help\n <mask>   users debug when the wrong templates are loaded.\n <mask> - Enforce blueprint handling in the order they were registered for template\n <mask>   loading.\n <mask> - Ported testsuite to py.test.\n <mask> - Deprecated ``request.json`` in favour of ``request.get_json()``.\n <mask> - Add \"pretty\" and \"compressed\" separators definitions in jsonify() method.\n <mask>   Reduces JSON response size when JSONIFY_PRETTYPRINT_REGULAR=False by removing\n <mask>   unnecessary white space included by default after separators.\n <mask>  </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> as `ValueError` you will need to change this.\n <mask> \n <mask> Due to a bug in the test client Flask 0.7 did not trigger teardown\n <mask> handlers when the test client was used in a with statement.  This was\n <mask> since fixed but might require some changes in your testsuites if you\n <mask> relied on this behavior.\n <mask> \n <mask> Version 0.7\n <mask> -----------\n <mask>  </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code. </s> remove         # memory.  This is usually only a problem in testsuite since this </s> add         # memory.  This is usually only a problem in test suite since this </s> remove - Ported testsuite to py.test.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # on the stack.  The rationale is that you want to access that\n <mask>         # information under debug situations.  However if someone forgets to\n <mask>         # pop that context again we want to make sure that on the next push\n <mask>         # it's invalidated, otherwise we run at risk that something leaks\n <mask>         # memory.  This is usually only a problem in testsuite since this\n <mask>         # functionality is not active in production environments.\n <mask>         top = _request_ctx_stack.top\n <mask>         if top is not None and top.preserved:\n <mask>             top.pop(top._preserved_exc)\n <mask>  </s> Unify the uses of \"testsuite\" vs \"test suite\".\n\nUse \"test suite\", which is more prevailing in the source code.", "html_url": "https://github.com/pallets/flask/commit/ebab6718f7dbafaa2e893f2347e6fdc6acad8504", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # a lock used for logger initialization\n <mask> _logger_lock = Lock()\n <mask> \n <mask> \n <mask> def _make_timedelta(value):\n <mask>     if not isinstance(value, timedelta):\n <mask>         return timedelta(seconds=value)\n <mask>     return value </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove             if exc is None:", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if not self.session_interface.is_null_session(ctx.session):\n <mask>             self.save_session(ctx.session, response)\n <mask>         return response\n <mask> \n <mask>     def do_teardown_request(self, exc=None):\n <mask>         \"\"\"Called after the actual request dispatching and will\n <mask>         call every as :meth:`teardown_request` decorated function.  This is\n <mask>         not actually called by the :class:`Flask` object itself but is always\n <mask>         triggered when the request context is popped.  That way we have a\n <mask>         tighter control over certain resources under testing environments. </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_appcontext(self, exc=None): </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove             if exc is None:", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         .. versionchanged:: 0.9\n <mask>            Added the `exc` argument.  Previously this was always using the\n <mask>            current exception information.\n <mask>         \"\"\"\n <mask>         if exc is None:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove         if exc is None: </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove     def do_teardown_request(self, exc=None): </s> add     def do_teardown_request(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for func in funcs:\n <mask>             func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=None):\n <mask>         \"\"\"Called when an application context is popped.  This works pretty\n <mask>         much the same as :meth:`do_teardown_request` but for the application\n <mask>         context.\n <mask> \n <mask>         .. versionadded:: 0.9 </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> remove     def do_teardown_request(self, exc=None): </s> add     def do_teardown_request(self, exc=_sentinel): </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         context.\n <mask> \n <mask>         .. versionadded:: 0.9\n <mask>         \"\"\"\n <mask>         if exc is None:\n <mask>             exc = sys.exc_info()[1]\n <mask>         for func in reversed(self.teardown_appcontext_funcs):\n <mask>             func(exc)\n <mask>         appcontext_tearing_down.send(self, exc=exc)\n <mask>  </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_appcontext(self, exc=None): </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove         if exc is None: </s> remove             if exc is None: </s> remove             if exc is None:", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from .signals import appcontext_pushed, appcontext_popped\n <mask> from ._compat import BROKEN_PYPY_CTXMGR_EXIT, reraise\n <mask> \n <mask> \n <mask> class _AppCtxGlobals(object):\n <mask>     \"\"\"A plain object.\"\"\"\n <mask> \n <mask>     def get(self, name, default=None):\n <mask>         return self.__dict__.get(name, default)\n <mask>  </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_app_tearing_down_with_handled_exception():\n    cleanup_stuff = []\n    app = flask.Flask(__name__)\n    @app.teardown_appcontext\n    def cleanup(exception):\n        cleanup_stuff.append(exception)\n\n    with app.app_context():\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n\n    assert cleanup_stuff == [None] </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> remove     def do_teardown_request(self, exc=None): </s> add     def do_teardown_request(self, exc=_sentinel): </s> add def test_teardown_with_handled_exception():\n    buffer = []\n    app = flask.Flask(__name__)\n    @app.teardown_request\n    def end_of_request(exception):\n        buffer.append(exception)\n\n    with app.test_request_context():\n        assert buffer == []\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n    assert buffer == [None] </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove     def do_teardown_appcontext(self, exc=None): </s> add     def do_teardown_appcontext(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     def pop(self, exc=None):\n <mask>         \"\"\"Pops the app context.\"\"\"\n <mask>         self._refcnt -= 1\n <mask>         if self._refcnt <= 0:\n <mask>             if exc is None:\n <mask>                 exc = sys.exc_info()[1]\n <mask>             self.app.do_teardown_appcontext(exc) </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> remove     def do_teardown_request(self, exc=None): </s> add     def do_teardown_request(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.session = self.app.open_session(self.request)\n <mask>         if self.session is None:\n <mask>             self.session = self.app.make_null_session()\n <mask> \n <mask>     def pop(self, exc=None):\n <mask>         \"\"\"Pops the request context and unbinds it by doing that.  This will\n <mask>         also trigger the execution of functions registered by the\n <mask>         :meth:`~flask.Flask.teardown_request` decorator.\n <mask> \n <mask>         .. versionchanged:: 0.9 </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove     def do_teardown_request(self, exc=None): </s> add     def do_teardown_request(self, exc=_sentinel): </s> remove         if exc is None: </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove     def do_teardown_appcontext(self, exc=None): </s> add     def do_teardown_appcontext(self, exc=_sentinel): </s> remove             if exc is None: </s> add             if exc is _sentinel:", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         clear_request = False\n <mask>         if not self._implicit_app_ctx_stack:\n <mask>             self.preserved = False\n <mask>             self._preserved_exc = None\n <mask>             if exc is None:\n <mask>                 exc = sys.exc_info()[1]\n <mask>             self.app.do_teardown_request(exc)\n <mask> \n <mask>             # If this interpreter supports clearing the exception information\n <mask>             # we do that now.  This will only go into effect on Python 2.x, </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove         if exc is None: </s> add         if exc is _sentinel: </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel):", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         pass\n <mask> \n <mask>     assert cleanup_stuff == [None]\n <mask> \n <mask> def test_custom_app_ctx_globals_class():\n <mask>     class CustomRequestGlobals(object):\n <mask>         def __init__(self):\n <mask>             self.spam = 'eggs'\n <mask>     app = flask.Flask(__name__) </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_teardown_with_handled_exception():\n    buffer = []\n    app = flask.Flask(__name__)\n    @app.teardown_request\n    def end_of_request(exception):\n        buffer.append(exception)\n\n    with app.test_request_context():\n        assert buffer == []\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n    assert buffer == [None] </s> remove             if exc is None: </s> add             if exc is _sentinel: </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "tests/test_appctx.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context():\n <mask>         assert buffer == []\n <mask>     assert buffer == [None]\n <mask> \n <mask> def test_proper_test_request_context():\n <mask>     app = flask.Flask(__name__)\n <mask>     app.config.update(\n <mask>         SERVER_NAME='localhost.localdomain:5000'\n <mask>     ) </s> Switch away from using None as default value for the exception when tearing down a context.\n\nWhen an exception has been handled when using the request / app context in a with statement, `sys.exc_info()` will still contain the exception information even though it has been handled already. The `__exit__` methods pass in `None` for the exception value in that case, which needs to be distinguisable from the default value for the `exc` parameter. Use a dedicated singleton sentinel value instead. </s> add def test_app_tearing_down_with_handled_exception():\n    cleanup_stuff = []\n    app = flask.Flask(__name__)\n    @app.teardown_appcontext\n    def cleanup(exception):\n        cleanup_stuff.append(exception)\n\n    with app.app_context():\n        try:\n            raise Exception('dummy')\n        except Exception:\n            pass\n\n    assert cleanup_stuff == [None] </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> remove     def pop(self, exc=None): </s> add     def pop(self, exc=_sentinel): </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object()", "html_url": "https://github.com/pallets/flask/commit/ec0d208bc14c49c611ae05d391b1edb35af854c7", "file_name": "tests/test_reqctx.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     a dict will call ``jsonify`` to produce a ``application/json``\n <mask>     response. :pr:`3111`\n <mask> \n <mask> .. _#2935: https://github.com/pallets/flask/issues/2935\n <mask> .. _#2957: https://github.com/pallets/flask/issues/2957\n <mask> .. _#2994: https://github.com/pallets/flask/pull/2994\n <mask> .. _#3059: https://github.com/pallets/flask/pull/3059 </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli)", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                 host=static_host,\n <mask>                 view_func=self.send_static_file,\n <mask>             )\n <mask> \n <mask>         #: The click command line context for this application.  Commands\n <mask>         #: registered here show up in the :command:`flask` command once the\n <mask>         #: application has been discovered.  The default commands are\n <mask>         #: provided by Flask itself and can be overridden.\n <mask>         #:\n <mask>         #: This is an instance of a :class:`click.Group` object.\n <mask>         self.cli = cli.AppGroup(self.name)\n <mask> \n <mask>     @locked_cached_property\n <mask>     def name(self):\n <mask>         \"\"\"The name of the application.  This is usually the import name\n <mask>         with the difference that it's guessed from the run file if the </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup() </s> add         self.cli_group = cli_group </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command. </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask> \n <mask> class BlueprintSetupState(object):\n <mask>     \"\"\"Temporary holder object for registering a blueprint with the\n <mask>     application.  An instance of this class is created by the\n <mask>     :meth:`~flask.Blueprint.make_setup_state` method and later passed </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name) </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup() </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`. </s> add     .. versionchanged:: 1.1.0\n        Blueprints have a ``cli`` group to register nested CLI commands.\n        The ``cli_group`` parameter controls the name of the group under\n        the ``flask`` command.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             url_defaults = {}\n <mask>         self.url_values_defaults = url_defaults\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is\n <mask>         registered on the application.  This function is called with the\n <mask>         state as argument as returned by the :meth:`make_setup_state`\n <mask>         method. </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         for deferred in self.deferred_functions:\n <mask>             deferred(state)\n <mask> \n <mask>     def route(self, rule, **options):\n <mask>         \"\"\"Like :meth:`Flask.route` but for a blueprint.  The endpoint for the\n <mask>         :func:`url_for` function is prefixed with the name of the blueprint.\n <mask>         \"\"\"\n <mask> \n <mask>         def decorator(f): </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add -   Blueprints have a ``cli`` Click group like ``app.cli``. CLI commands\n    registered with a blueprint will be available as a group under the\n    ``flask`` command. :issue:`1357`.", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import pytest\n <mask> from _pytest.monkeypatch import notset\n <mask> from click.testing import CliRunner\n <mask> \n <mask> from flask import Flask, current_app\n <mask> from flask.cli import (\n <mask>     AppGroup,\n <mask>     FlaskGroup,\n <mask>     NoAppException,\n <mask>     ScriptInfo, </s> Add Blueprint level cli command registration\n\nImplements #1357.\nAdds ability to register click cli commands onto blueprint. </s> add         # circular import\n        from .cli import AppGroup\n\n        #: The Click command group for registration of CLI commands\n        #: on the application and associated blueprints. These commands\n        #: are accessible via the :command:`flask` command once the\n        #: application has been discovered and blueprints registered.\n        self.cli = AppGroup() </s> add # a singleton sentinel value for parameter defaults\n_sentinel = object() </s> remove         #: The click command line context for this application.  Commands\n        #: registered here show up in the :command:`flask` command once the\n        #: application has been discovered.  The default commands are\n        #: provided by Flask itself and can be overridden.\n        #:\n        #: This is an instance of a :class:`click.Group` object.\n        self.cli = cli.AppGroup(self.name) </s> add         # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name </s> add         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n\n        if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add         self.cli_group = cli_group </s> add         cli_group=_sentinel,", "html_url": "https://github.com/pallets/flask/commit/ec1ccd753084c6ff3215b9a64ba46d6af56715bd", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         'SESSION_COOKIE_HTTPONLY':              True,\n <mask>         'SESSION_COOKIE_SECURE':                False,\n <mask>         'SESSION_REFRESH_EACH_REQUEST':         True,\n <mask>         'MAX_CONTENT_LENGTH':                   None,\n <mask>         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60, # 12 hours\n <mask>         'TRAP_BAD_REQUEST_ERRORS':              False,\n <mask>         'TRAP_HTTP_EXCEPTIONS':                 False,\n <mask>         'EXPLAIN_TEMPLATE_LOADING':             False,\n <mask>         'PREFERRED_URL_SCHEME':                 'http',\n <mask>         'JSON_AS_ASCII':                        True, </s> remove                 content = fd.read() # Read and process the file content... </s> add                 content = fd.read()  # Read and process the file content...", "html_url": "https://github.com/pallets/flask/commit/ec3d5800f2c8d6803c426babb0b6df0fa36f866f", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         @app.route('/wiki/<path:filename>')\n <mask>         def wiki_page(filename):\n <mask>             filename = safe_join(app.config['WIKI_FOLDER'], filename)\n <mask>             with open(filename, 'rb') as fd:\n <mask>                 content = fd.read() # Read and process the file content...\n <mask> \n <mask>     :param directory: the base directory.\n <mask>     :param filename: the untrusted filename relative to that directory.\n <mask>     :raises: :class:`~werkzeug.exceptions.NotFound` if the resulting path\n <mask>              would fall out of `directory`. </s> remove         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60, # 12 hours </s> add         'SEND_FILE_MAX_AGE_DEFAULT':            12 * 60 * 60,  # 12 hours", "html_url": "https://github.com/pallets/flask/commit/ec3d5800f2c8d6803c426babb0b6df0fa36f866f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         #:    app = Flask(__name__)\n <mask>         #:    app.url_map.converters['list'] = ListConverter\n <mask>         self.url_map = Map()\n <mask> \n <mask>         # if there is a static folder, register it for the application.\n <mask>         if self.has_static_folder:\n <mask>             self.add_url_rule(self.static_path + '/<path:filename>',\n <mask>                               endpoint='static',\n <mask>                               view_func=self.send_static_file)\n <mask> \n <mask>         #: The Jinja2 environment.  It is created from the\n <mask>         #: :attr:`jinja_options`.\n <mask>         self.jinja_env = self.create_jinja_environment()\n <mask>         self.init_jinja_globals()\n </s> Always register URL rules.  This fixes #81 </s> remove         template_folder = os.path.join(self.root_path, 'templates')\n        if os.path.isdir(template_folder):\n            return FileSystemLoader(template_folder)\n </s> add         return FileSystemLoader(os.path.join(self.root_path, 'templates')) </s> add - static rules are now even in place if there is no static folder\n  for the module.  This was implemented to aid GAE which will\n  remove the static folder if it's part of a mapping in the .yml\n  file.", "html_url": "https://github.com/pallets/flask/commit/ed16ae2183ad44a7ba89aedd331a180455ed0836", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"The Jinja loader for this package bound object.\n <mask> \n <mask>         .. versionadded:: 0.5\n <mask>         \"\"\"\n <mask>         template_folder = os.path.join(self.root_path, 'templates')\n <mask>         if os.path.isdir(template_folder):\n <mask>             return FileSystemLoader(template_folder)\n <mask> \n <mask>     def send_static_file(self, filename):\n <mask>         \"\"\"Function used internally to send static files from the static\n <mask>         folder to the browser.\n <mask> \n </s> Always register URL rules.  This fixes #81 </s> add - static rules are now even in place if there is no static folder\n  for the module.  This was implemented to aid GAE which will\n  remove the static folder if it's part of a mapping in the .yml\n  file. </s> remove         # if there is a static folder, register it for the application.\n        if self.has_static_folder:\n            self.add_url_rule(self.static_path + '/<path:filename>',\n                              endpoint='static',\n                              view_func=self.send_static_file)\n </s> add         # register the static folder for the application.  Do that even\n        # if the folder does not exist.  First of all it might be created\n        # while the server is running (usually happens during development)\n        # but also because google appengine stores static files somewhere\n        # else when mapped with the .yml file.\n        self.add_url_rule(self.static_path + '/<path:filename>',\n                          endpoint='static',\n                          view_func=self.send_static_file)", "html_url": "https://github.com/pallets/flask/commit/ed16ae2183ad44a7ba89aedd331a180455ed0836", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> -   It is no longer required to decorate custom CLI commands on\n <mask>     ``app.cli`` or ``blueprint.cli`` with ``@with_appcontext``, an app\n <mask>     context will already be active at that point. :issue:`2410`\n <mask> \n <mask> \n <mask> Version 2.1.3\n <mask> -------------\n <mask> \n <mask> Unreleased </s> remove             return datetime.utcnow() + app.permanent_session_lifetime </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default implementation returns now + the permanent session\n <mask>         lifetime configured on the application.\n <mask>         \"\"\"\n <mask>         if session.permanent:\n <mask>             return datetime.utcnow() + app.permanent_session_lifetime\n <mask>         return None\n <mask> \n <mask>     def should_set_cookie(self, app: \"Flask\", session: SessionMixin) -> bool:\n <mask>         \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n <mask>         should be set for this session cookie for this response. If the session </s> session expiration datetime is UTC timezone-aware </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645` </s> remove     now = datetime.utcnow().replace(microsecond=0) </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> add from datetime import timezone </s> add from datetime import timezone", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "src/flask/sessions.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> import uuid\n <mask> import warnings\n <mask> import weakref\n <mask> from datetime import datetime\n <mask> from platform import python_implementation\n <mask> from threading import Thread\n <mask> \n <mask> import pytest\n <mask> import werkzeug.serving </s> session expiration datetime is UTC timezone-aware </s> add from datetime import timezone </s> remove     now = datetime.utcnow().replace(microsecond=0) </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove             return datetime.utcnow() + app.permanent_session_lifetime </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rv = client.get(\"/\")\n <mask>     assert \"set-cookie\" in rv.headers\n <mask>     match = re.search(r\"(?i)\\bexpires=([^;]+)\", rv.headers[\"set-cookie\"])\n <mask>     expires = parse_date(match.group())\n <mask>     expected = datetime.utcnow() + app.permanent_session_lifetime\n <mask>     assert expires.year == expected.year\n <mask>     assert expires.month == expected.month\n <mask>     assert expires.day == expected.day\n <mask> \n <mask>     rv = client.get(\"/test\") </s> session expiration datetime is UTC timezone-aware </s> remove     now = datetime.utcnow().replace(microsecond=0) </s> add     now = datetime.now(timezone.utc).replace(microsecond=0) </s> remove             return datetime.utcnow() + app.permanent_session_lifetime </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add from datetime import timezone </s> add from datetime import timezone </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     assert client.get(\"/\").data == b\"42\"\n <mask> \n <mask> \n <mask> def test_session_special_types(app, client):\n <mask>     now = datetime.utcnow().replace(microsecond=0)\n <mask>     the_uuid = uuid.uuid4()\n <mask> \n <mask>     @app.route(\"/\")\n <mask>     def dump_session_contents():\n <mask>         flask.session[\"t\"] = (1, 2, 3) </s> session expiration datetime is UTC timezone-aware </s> remove     expected = datetime.utcnow() + app.permanent_session_lifetime </s> add     expected = datetime.now(timezone.utc) + app.permanent_session_lifetime </s> remove             return datetime.utcnow() + app.permanent_session_lifetime </s> add             return datetime.now(timezone.utc) + app.permanent_session_lifetime </s> add from datetime import timezone </s> add from datetime import timezone </s> add -   ``SessionInterface.get_expiration_time`` uses a timezone-aware\n    value. :pr:`4645`", "html_url": "https://github.com/pallets/flask/commit/ed42e9292811a95f2a68e06a9ae50cb5872216a3", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> - after request functions are now called in reverse order of\n <mask>   registration.\n <mask> - OPTIONS is now automatically implemented by Flask unless the\n <mask>   application explictly adds 'OPTIONS' as method to the URL rule.\n <mask>   In this case no automatic OPTIONS handling kicks in.\n <mask> - static rules are now even in place if there is no static folder\n <mask>   for the module.  This was implemented to aid GAE which will\n <mask>   remove the static folder if it's part of a mapping in the .yml\n <mask>   file. </s> remove - refactored the way url adapters are created.  This process is now </s> add - refactored the way URL adapters are created.  This process is now </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove of course) that give you basic and painless unicode support: </s> add of course) that give you basic and painless Unicode support:", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   creating response object instances in views.\n <mask> - added signalling support based on blinker.  This feature is currently\n <mask>   optional and supposed to be used by extensions and applications.  If\n <mask>   you want to use it, make sure to have `blinker`_ installed.\n <mask> - refactored the way url adapters are created.  This process is now\n <mask>   fully customizable with the :meth:`~flask.Flask.create_url_adapter`\n <mask>   method.\n <mask> - modules can now register for a subdomain instead of just an URL\n <mask>   prefix.  This makes it possible to bind a whole module to a\n <mask>   configurable subdomain. </s> Minor spelling fixes\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove   application explictly adds 'OPTIONS' as method to the URL rule. </s> add   application explicitly adds 'OPTIONS' as method to the URL rule. </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> add -   internally you will always use Unicode exclusively for text except </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> Werkzeug and Flask will be ported to Python 3 as soon as a solution for\n <mask> WSGI is found, and we will provide helpful tips how to upgrade existing\n <mask> applications to Python 3.  Until then, we strongly recommend using Python\n <mask> 2.6 and 2.7 with activated Python 3 warnings during development, as well\n <mask> as the unicode literals `__future__` feature. </s> remove unicode.  What does working with unicode in Python 2.x mean? </s> add Unicode.  What does working with Unicode in Python 2.x mean? </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add -   internally you will always use Unicode exclusively for text except", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask> Unicode in Flask\n <mask> ================\n <mask> \n <mask> Flask like Jinja2 and Werkzeug is totally unicode based when it comes to\n <mask> text.  Not only these libraries, also the majority of web related Python\n <mask> libraries that deal with text.  If you don't know unicode so far, you </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove as the unicode literals `__future__` feature. </s> add as the Unicode literals `__future__` feature.", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> should probably read `The Absolute Minimum Every Software Developer\n <mask> Absolutely, Positively Must Know About Unicode and Character Sets\n <mask> <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n <mask> documentation just tries to cover the very basics so that you have a\n <mask> pleasant experience with unicode related things.\n <mask> \n <mask> Automatic Conversion\n <mask> --------------------\n <mask> \n <mask> Flask has a few assumptions about your application (which you can change </s> remove libraries that deal with text.  If you don't know unicode so far, you </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to </s> remove of course) that give you basic and painless unicode support: </s> add of course) that give you basic and painless Unicode support: </s> remove -   internally you will always use unicode exclusively for text except </s> add -   internally you will always use Unicode exclusively for text except </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask> Flask has a few assumptions about your application (which you can change\n <mask> of course) that give you basic and painless unicode support:\n <mask> \n <mask> -   the encoding for text on your website is UTF-8\n <mask> -   internally you will always use unicode exclusively for text except\n <mask>     for literal strings with only ASCII character points.\n <mask> -   encoding and decoding happens whenever you are talking over a protocol </s> add pleasant experience with Unicode related things. </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove Anyways.  To load such a file with unicode you can use the built-in </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep", "code_tokens": " <mask> character sets and which ones are used, are transmitted in an HTTP header.\n <mask> To not make this too complex Flask just assumes that if you are sending\n <mask> unicode out you want it to be UTF-8 encoded.  Flask will do the encoding\n <mask> and setting of the appropriate headers for you.\n <mask> \n <mask> The same is true if you are talking to databases with the help of\n <mask> SQLAlchemy or a similar ORM system.  Some databases have a protocol that\n <mask> already transmits unicode and if they do not, SQLAlchemy or your other ORM\n <mask> should take care of that. </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove -   internally you will always use unicode exclusively for text except </s> add -   internally you will always use Unicode exclusively for text except", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> The Golden Rule\n <mask> ---------------\n <mask> \n <mask> So the rule of thumb: if you are not dealing with binary data, work with\n <mask> unicode.  What does working with unicode in Python 2.x mean?\n <mask> \n <mask> -   as long as you are using ASCII charpoints only (basically numbers,\n <mask>     some special characters of latin letters without umlauts or anything\n <mask>     fancy) you can use regular string literals (``'Hello World'``).\n <mask> -   if you need anything else than ASCII in a string you have to mark </s> remove already transmits unicode and if they do not, SQLAlchemy or your other ORM </s> add already transmits Unicode and if they do not, SQLAlchemy or your other ORM </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove -   internally you will always use unicode exclusively for text except </s> add -   internally you will always use Unicode exclusively for text except </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Encoding and Decoding Yourself\n <mask> ------------------------------\n <mask> \n <mask> If you are talking with a filesystem or something that is not really based\n <mask> on unicode you will have to ensure that you decode properly when working\n <mask> with unicode interface.  So for example if you want to load a file on the\n <mask> filesystem and embed it into a Jinja2 template you will have to decode it\n <mask> from the encoding of that file.  Here the old problem that text files do\n <mask> not specify their encoding comes into play.  So do yourself a favour and\n <mask> limit yourself to UTF-8 for text files as well.\n <mask>  </s> remove Anyways.  To load such a file with unicode you can use the built-in </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> remove -   internally you will always use unicode exclusively for text except </s> add -   internally you will always use Unicode exclusively for text except </s> remove libraries that deal with text.  If you don't know unicode so far, you </s> add libraries that deal with text.  If you don't know Unicode so far, you </s> remove Flask like Jinja2 and Werkzeug is totally unicode based when it comes to </s> add Flask like Jinja2 and Werkzeug is totally Unicode based when it comes to", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from the encoding of that file.  Here the old problem that text files do\n <mask> not specify their encoding comes into play.  So do yourself a favour and\n <mask> limit yourself to UTF-8 for text files as well.\n <mask> \n <mask> Anyways.  To load such a file with unicode you can use the built-in\n <mask> :meth:`str.decode` method::\n <mask> \n <mask>     def read_file(filename, charset='utf-8'):\n <mask>         with open(filename, 'r') as f:\n <mask>             return f.read().decode(charset) </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> remove To go from unicode into a specific charset such as UTF-8 you can use the </s> add To go from Unicode into a specific charset such as UTF-8 you can use the </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def read_file(filename, charset='utf-8'):\n <mask>         with open(filename, 'r') as f:\n <mask>             return f.read().decode(charset)\n <mask> \n <mask> To go from unicode into a specific charset such as UTF-8 you can use the\n <mask> :meth:`unicode.encode` method::\n <mask> \n <mask>     def write_file(filename, contents, charset='utf-8'):\n <mask>         with open(filename, 'w') as f:\n <mask>             f.write(contents.encode(charset)) </s> remove Anyways.  To load such a file with unicode you can use the built-in </s> add Anyways.  To load such a file with Unicode you can use the built-in </s> remove on unicode you will have to ensure that you decode properly when working\nwith unicode interface.  So for example if you want to load a file on the </s> add on Unicode you will have to ensure that you decode properly when working\nwith Unicode interface.  So for example if you want to load a file on the </s> add Unicode.  What does working with Unicode in Python 2.x mean? </s> remove unicode out you want it to be UTF-8 encoded.  Flask will do the encoding </s> add Unicode out you want it to be UTF-8 encoded.  Flask will do the encoding", "html_url": "https://github.com/pallets/flask/commit/ed517c7215fc17a46f85c2c0324d519572b67f6b", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     f.__flask_without_appcontext__ = True\n <mask>     return f\n <mask> \n <mask> \n <mask> class FlaskGroup(click.Group):\n <mask>     \"\"\"Special subclass of the a regular click group that supports\n <mask>     loading more commands from the configured Flask app.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, help=None):\n <mask>         def set_app_id(ctx, value):\n <mask>             if value is not None:\n <mask>                 if os.path.isfile(value):\n <mask>                     value = prepare_exec_for_file(value)\n <mask>                 elif '.' not in sys.path:\n <mask>                     sys.path.insert(0, '.')\n <mask>             ctx.ensure_object(ScriptInfo).app_import_path = value\n <mask>         def set_debug(ctx, value):\n <mask>             ctx.ensure_object(ScriptInfo).debug = value\n <mask> \n <mask>         click.Group.__init__(self, help=help, params=[\n <mask>             click.Option(['-a', '--app'],\n <mask>                          help='The application to run',\n <mask>                          callback=set_app_id, is_eager=True),\n <mask>             click.Option(['--debug/--no-debug'],\n <mask>                          help='Enable or disable debug mode.',\n <mask>                          default=None, callback=set_debug)\n <mask>         ])\n <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.find_object(ScriptInfo)\n <mask>         # Find the command in the application first, if we can find it.\n <mask>         # If the app is not available, we just ignore this silently. </s> Refactored loading logic to super properly. </s> remove         return click.Group.get_command(self, ctx, name) </s> add         return super(ContextGroupMixin, self).get_command(ctx, name) </s> remove             return click.Group.invoke_subcommand(\n                self, ctx, cmd, cmd_name, args) </s> add             return super(ContextGroupMixin, self).invoke_subcommand(\n                ctx, cmd, cmd_name, args)\n\n\nclass FlaskGroup(ContextGroupMixin, click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ]) </s> remove         rv = set(click.Group.list_commands(self, ctx)) </s> add         rv = set(super(ContextGroupMixin, self).list_commands(ctx))", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>         except NoAppException:\n <mask>             pass\n <mask>         return click.Group.get_command(self, ctx, name)\n <mask> \n <mask>     def list_commands(self, ctx):\n <mask>         # The commands available is the list of both the application (if\n <mask>         # available) plus the builtin commands.\n <mask>         rv = set(click.Group.list_commands(self, ctx)) </s> remove class FlaskGroup(click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ]) </s> add class ContextGroupMixin(object): </s> remove             return click.Group.invoke_subcommand(\n                self, ctx, cmd, cmd_name, args) </s> add             return super(ContextGroupMixin, self).invoke_subcommand(\n                ctx, cmd, cmd_name, args)\n\n\nclass FlaskGroup(ContextGroupMixin, click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ])", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         with_context = cmd.callback is None or \\\n <mask>            not getattr(cmd.callback, '__flask_without_appcontext__', False)\n <mask> \n <mask>         with ctx.find_object(ScriptInfo).conditional_context(with_context):\n <mask>             return click.Group.invoke_subcommand(\n <mask>                 self, ctx, cmd, cmd_name, args)\n <mask> \n <mask> \n <mask> cli = FlaskGroup(help='''\\\n <mask> This shell command acts as general utility script for Flask applications.\n <mask>  </s> remove         return click.Group.get_command(self, ctx, name) </s> add         return super(ContextGroupMixin, self).get_command(ctx, name) </s> remove class FlaskGroup(click.Group):\n    \"\"\"Special subclass of the a regular click group that supports\n    loading more commands from the configured Flask app.\n    \"\"\"\n\n    def __init__(self, help=None):\n        def set_app_id(ctx, value):\n            if value is not None:\n                if os.path.isfile(value):\n                    value = prepare_exec_for_file(value)\n                elif '.' not in sys.path:\n                    sys.path.insert(0, '.')\n            ctx.ensure_object(ScriptInfo).app_import_path = value\n        def set_debug(ctx, value):\n            ctx.ensure_object(ScriptInfo).debug = value\n\n        click.Group.__init__(self, help=help, params=[\n            click.Option(['-a', '--app'],\n                         help='The application to run',\n                         callback=set_app_id, is_eager=True),\n            click.Option(['--debug/--no-debug'],\n                         help='Enable or disable debug mode.',\n                         default=None, callback=set_debug)\n        ]) </s> add class ContextGroupMixin(object): </s> remove         rv = set(click.Group.list_commands(self, ctx)) </s> add         rv = set(super(ContextGroupMixin, self).list_commands(ctx))", "html_url": "https://github.com/pallets/flask/commit/ed7b4ccac1b646aa725007db7fd3ec2d359beaf4", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     dependency to >= 0.15. :issue:`3022`\n <mask> -   Support ``static_url_path`` that ends with a forward slash.\n <mask>     :issue:`3134`\n <mask> -   :meth:`jsonify` supports :class:`dataclasses.dataclass` objects.\n <mask>     :pr:`3195`\n <mask> -   Allow customizing the :attr:`Flask.url_map_class` used for routing.\n <mask>     :pr:`3069` </s> strip static url trailing slash at assignment </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove     def _get_static_url_path(self): </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove def test_static_url_null_path(app): </s> add def test_static_url_empty_path(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         _PackageBoundObject.__init__(\n <mask>             self, import_name, template_folder=template_folder, root_path=root_path\n <mask>         )\n <mask> \n <mask>         if static_url_path is not None:\n <mask>             self.static_url_path = static_url_path\n <mask> \n <mask>         if static_folder is not None:\n <mask>             self.static_folder = static_folder\n <mask> \n <mask>         if instance_path is None:\n <mask>             instance_path = self.auto_find_instance_path()\n <mask>         elif not os.path.isabs(instance_path):\n <mask>             raise ValueError( </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     def _get_static_url_path(self): </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert (\n <mask>                 bool(static_host) == host_matching\n <mask>             ), \"Invalid static_host/host_matching combination\"\n <mask>             self.add_url_rule(\n <mask>                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n <mask>                 endpoint=\"static\",\n <mask>                 host=static_host,\n <mask>                 view_func=self.send_static_file,\n <mask>             )\n <mask>  </s> strip static url trailing slash at assignment </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app): </s> remove def test_static_url_null_path(app): </s> add def test_static_url_empty_path(app): </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         state = self.make_setup_state(app, options, first_registration)\n <mask> \n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(\n <mask>                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\",\n <mask>                 view_func=self.send_static_file,\n <mask>                 endpoint=\"static\",\n <mask>             )\n <mask> \n <mask>         for deferred in self.deferred_functions: </s> strip static url trailing slash at assignment </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove     def _get_static_url_path(self): </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\"", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         doc=\"The absolute path to the configured static folder.\",\n <mask>     )\n <mask>     del _get_static_folder, _set_static_folder\n <mask> \n <mask>     def _get_static_url_path(self):\n <mask>         if self._static_url_path is not None:\n <mask>             return self._static_url_path\n <mask> \n <mask>         if self.static_folder is not None:\n <mask>             basename = os.path.basename(self.static_folder) </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\" </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> add -   Support empty ``static_folder`` without requiring setting an empty\n    ``static_url_path`` as well. :pr:`3124` </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\",", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep replace keep replace replace", "code_tokens": " <mask>             basename = os.path.basename(self.static_folder)\n <mask>             return \"/\" + basename if basename else \"\"\n <mask> \n <mask>     def _set_static_url_path(self, value):\n <mask>         self._static_url_path = value </s> strip static url trailing slash at assignment </s> remove     def _get_static_url_path(self): </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _set_static_url_path(self, value):\n <mask>         self._static_url_path = value\n <mask> \n <mask>     static_url_path = property(\n <mask>         _get_static_url_path,\n <mask>         _set_static_url_path,\n <mask>         doc=\"The URL prefix that the static route will be registered for.\",\n <mask>     )\n <mask>     del _get_static_url_path, _set_static_url_path\n <mask> \n <mask>     @property\n <mask>     def has_static_folder(self):\n <mask>         \"\"\"This is ``True`` if the package bound object's container has a\n <mask>         folder for static files. </s> strip static url trailing slash at assignment </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     def _get_static_url_path(self): </s> add     @property\n    def static_url_path(self):\n        \"\"\"The URL prefix that the static route will be accessible from.\n\n        If it was not configured during init, it is derived from\n        :attr:`static_folder`.\n        \"\"\" </s> add -   Support empty ``static_folder`` without requiring setting an empty\n    ``static_url_path`` as well. :pr:`3124` </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app):", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context():\n <mask>         assert flask.url_for(\"static\", filename=\"index.html\") == \"/foo/index.html\"\n <mask> \n <mask> \n <mask> def test_static_url_null_path(app):\n <mask>     app = flask.Flask(__name__, static_folder='', static_url_path='')\n <mask>     rv = app.test_client().open('/static/index.html', method='GET')\n <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask>  </s> strip static url trailing slash at assignment </s> remove def test_static_url_null_path_defaulting(app): </s> add def test_static_url_empty_path_default(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove             return \"/\" + basename if basename else \"\" </s> add             return (\"/\" + basename).rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask> \n <mask> \n <mask> def test_static_url_null_path_defaulting(app):\n <mask>     app = flask.Flask(__name__, static_folder='')\n <mask>     rv = app.test_client().open('/static/index.html', method='GET')\n <mask>     assert rv.status_code == 200\n <mask>     rv.close()\n <mask>  </s> strip static url trailing slash at assignment </s> remove def test_static_url_null_path(app): </s> add def test_static_url_empty_path(app): </s> remove                 self.static_url_path.rstrip(\"/\") + \"/<path:filename>\", </s> add                 self.static_url_path + \"/<path:filename>\", </s> remove     def _set_static_url_path(self, value):\n        self._static_url_path = value </s> add     @static_url_path.setter\n    def static_url_path(self, value):\n        if value is not None:\n            value = value.rstrip(\"/\") </s> remove     static_url_path = property(\n        _get_static_url_path,\n        _set_static_url_path,\n        doc=\"The URL prefix that the static route will be registered for.\",\n    )\n    del _get_static_url_path, _set_static_url_path </s> add         self._static_url_path = value </s> remove         if static_url_path is not None:\n            self.static_url_path = static_url_path\n\n        if static_folder is not None:\n            self.static_folder = static_folder </s> add         self.static_url_path = static_url_path\n        self.static_folder = static_folder", "html_url": "https://github.com/pallets/flask/commit/ed9ab2d3b6fc005b3807ddf484e85160233ffc82", "file_name": "tests/test_basic.py"}
{"docstring_tokens": "replace keep replace replace keep keep keep keep keep", "code_tokens": " <mask> .. mongoengine-pattern:\n <mask> \n <mask> MongoEngine in Flask\n <mask> ====================\n <mask> \n <mask> Using a document database rather than a full DBMS gets more common these days.\n <mask> This pattern shows how to use MongoEngine, a document mapper library, to\n <mask> integrate with MongoDB.\n <mask>  </s> remove Using a document database rather than a full DBMS gets more common these days.\nThis pattern shows how to use MongoEngine, a document mapper library, to\nintegrate with MongoDB.\n\nThis pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\nlibraries installed:: </s> add A running MongoDB server and `Flask-MongoEngine`_ are required. :: </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'}) </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove For more information about MongoEngine, head over to the\n`website <http://docs.mongoengine.org/>`_. </s> add Flask-MongoEngine adds helpful utilities on top of MongoEngine. Check\nout their `documentation <Flask-MongoEngine_>`_ as well.", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> MongoEngine in Flask\n <mask> ====================\n <mask> \n <mask> Using a document database rather than a full DBMS gets more common these days.\n <mask> This pattern shows how to use MongoEngine, a document mapper library, to\n <mask> integrate with MongoDB.\n <mask> \n <mask> This pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\n <mask> libraries installed::\n <mask> \n <mask>     pip install flask-mongoengine\n <mask> \n <mask> .. _MongoEngine: http://mongoengine.org\n <mask> .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_ </s> remove MongoEngine in Flask\n==================== </s> add Using a document database like MongoDB is a common alternative to\nrelational SQL databases. This pattern shows how to use\n`MongoEngine`_, a document mapper library, to integrate with MongoDB. </s> add MongoDB with MongoEngine\n======================== </s> remove .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_ </s> add .. _Flask-MongoEngine: https://flask-mongoengine.readthedocs.io </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'}) </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_.", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     pip install flask-mongoengine\n <mask> \n <mask> .. _MongoEngine: http://mongoengine.org\n <mask> .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_\n <mask> \n <mask> Configuration\n <mask> -------------\n <mask> \n <mask> Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then </s> remove Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\ncreating a ``MongoEngine`` instance:: </s> add Basic setup can be done by defining ``MONGODB_SETTINGS`` on\n``app.config`` and creating a ``MongoEngine`` instance. :: </s> remove Using a document database rather than a full DBMS gets more common these days.\nThis pattern shows how to use MongoEngine, a document mapper library, to\nintegrate with MongoDB.\n\nThis pattern requires a running MongoDB server, MongoEngine_ and Flask-MongoEngine_\nlibraries installed:: </s> add A running MongoDB server and `Flask-MongoEngine`_ are required. :: </s> add MongoDB with MongoEngine\n======================== </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Configuration\n <mask> -------------\n <mask> \n <mask> Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\n <mask> creating a ``MongoEngine`` instance::\n <mask> \n <mask>     from flask import Flask\n <mask>     from flask_mongoengine import MongoEngine\n <mask> \n <mask>     app = Flask(__name__) </s> remove .. _Flask-MongoEngine: http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/>`_ </s> add .. _Flask-MongoEngine: https://flask-mongoengine.readthedocs.io </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'}) </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_.", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from flask_mongoengine import MongoEngine\n <mask> \n <mask>     app = Flask(__name__)\n <mask>     app.config['MONGODB_SETTINGS'] = {\n <mask>         'host': \"mongodb://localhost:27017/mydb\"\n <mask>     }\n <mask>     db = MongoEngine(app)\n <mask> \n <mask> \n <mask> Mapping Documents </s> remove Basic setup can be done by defining ``MONGODB_SETTINGS`` on App config and then\ncreating a ``MongoEngine`` instance:: </s> add Basic setup can be done by defining ``MONGODB_SETTINGS`` on\n``app.config`` and creating a ``MongoEngine`` instance. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'}) </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> add     import mongoengine as me </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document:: </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Mapping Documents\n <mask> -----------------\n <mask> \n <mask> To declare models that will represent your Mongo documents, just create a class that\n <mask> inherits from ``Document`` and declare each of the fields::\n <mask> \n <mask>     from mongoengine import *\n <mask> \n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         title = StringField(required=True)\n <mask>         year = IntField()\n <mask>         rated = StringField()\n <mask>         director = StringField() </s> remove         title = StringField(required=True)\n        year = IntField()\n        rated = StringField()\n        director = StringField()\n        actors = ListField() </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document:: </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove     class Imdb(EmbeddedDocument): </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep replace replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         title = StringField(required=True)\n <mask>         year = IntField()\n <mask>         rated = StringField()\n <mask>         director = StringField()\n <mask>         actors = ListField()\n <mask> \n <mask> If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\n <mask> the embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n <mask> \n <mask>     class Imdb(EmbeddedDocument): </s> remove     class Imdb(EmbeddedDocument): </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask> If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\n <mask> the embedded document and ``EmbeddedDocumentField`` to declare it on the parent document::\n <mask> \n <mask>     class Imdb(EmbeddedDocument):\n <mask> \n <mask>         imdb_id = StringField()\n <mask>         rating = DecimalField()\n <mask>         votes = IntField()\n <mask> \n <mask> \n <mask>     class Movie(Document): </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document:: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         votes = me.IntField()\n <mask> \n <mask>         ...\n <mask>         imdb = me.EmbeddedDocumentField(Imdb)\n <mask> \n <mask>  </s> simplify mongoengine doc, redirect from mongokit </s> remove         imdb = EmbeddedDocumentField(Imdb) </s> add         imdb = me.EmbeddedDocumentField(Imdb) </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document:: </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove     class Imdb(EmbeddedDocument): </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> remove         'host': \"mongodb://localhost:27017/mydb\" </s> add         \"db\": \"myapp\", </s> add     import mongoengine as me", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         ...\n <mask>         imdb = EmbeddedDocumentField(Imdb)\n <mask> \n <mask> \n <mask> Creating Data\n <mask> -------------\n <mask>  </s> simplify mongoengine doc, redirect from mongokit </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField() </s> add     class Movie(me.Document): </s> remove Just create the objects and call ``save()``:: </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> add     import mongoengine as me </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection </s> add Documentation\n-------------", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Creating Data\n <mask> -------------\n <mask> \n <mask> Just create the objects and call ``save()``::\n <mask> \n <mask>     bttf = Movie(title=\"Back To The Future\", year=1985)\n <mask>     bttf.actors = [\n <mask>         \"Michael J. Fox\",\n <mask>         \"Christopher Lloyd\" </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask> -------\n <mask> \n <mask> Use the class ``objects`` attribute to make queries::\n <mask> \n <mask>     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Use the class ``objects`` attribute to make queries::\n <mask> \n <mask>     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique\n <mask> \n <mask> ``objects`` is an iterable. Query operators may be user by concatenating it with the document\n <mask> key using a double-underscore::\n <mask> \n <mask>     some_theron_movie = Movie.objects(actors__in=[\"Charlize Theron\"]).first()\n <mask> \n <mask>     for recents in Movie.objects(year__gte=2017):\n <mask>         print(recents.title) </s> remove     bttf = Movies.objects(title=\"Back To The Future\").get()  # Throw error if not unique </s> add     bttf = Movies.objects(title=\"Back To The Future\").get_or_404() </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection </s> remove     class Imdb(EmbeddedDocument):", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     for recents in Movie.objects(year__gte=2017):\n <mask>         print(recents.title)\n <mask> \n <mask> Available operators are as follows:\n <mask> \n <mask> * ``ne`` -- not equal to\n <mask> * ``lt`` -- less than\n <mask> * ``lte`` -- less than or equal to\n <mask> * ``gt`` -- greater than\n <mask> * ``gte`` -- greater than or equal to\n <mask> * ``not`` -- negate a standard check, may be used before other operators (e.g.\n <mask>   ``Q(age__not__mod=5)``)\n <mask> * ``in`` -- value is in list (a list of values should be provided)\n <mask> * ``nin`` -- value is not in list (a list of values should be provided)\n <mask> * ``mod`` -- ``value % x == y``, where ``x`` and ``y`` are two provided values\n <mask> * ``all`` -- every item in list of values provided is in array\n <mask> * ``size`` -- the size of the array is\n <mask> * ``exists`` -- value for field exists\n <mask> \n <mask> String queries\n <mask> ::::::::::::::\n <mask> \n <mask> The following operators are available as shortcuts to querying with regular\n <mask> expressions:\n <mask> \n <mask> * ``exact`` -- string field exactly matches value </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore:: </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> remove Use the class ``objects`` attribute to make queries:: </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. :: </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace keep", "code_tokens": " <mask> \n <mask> String queries\n <mask> ::::::::::::::\n <mask> \n <mask> The following operators are available as shortcuts to querying with regular\n <mask> expressions:\n <mask> \n <mask> * ``exact`` -- string field exactly matches value\n <mask> * ``iexact`` -- string field exactly matches value (case insensitive)\n <mask> * ``contains`` -- string field contains value\n <mask> * ``icontains`` -- string field contains value (case insensitive)\n <mask> * ``startswith`` -- string field starts with value\n <mask> * ``istartswith`` -- string field starts with value (case insensitive)\n <mask> * ``endswith`` -- string field ends with value\n <mask> * ``iendswith`` -- string field ends with value (case insensitive)\n <mask> * ``match``  -- performs an $elemMatch so you can match an entire document within an array\n <mask> \n <mask> Some Tips\n <mask> ---------\n <mask> \n <mask> * Attributes can be set as ``unique``\n <mask> * ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n <mask> * You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n <mask> * If you don't want your class name to be the same name as the collection, you can define\n <mask>   a ``meta`` class member and use the ``collection`` parameter::\n <mask> \n <mask>     class Movie(Document):\n <mask> \n <mask>         meta ={'collection': 'movie_documents'}\n <mask> \n <mask> Accessing PyMongo MongoClient\n <mask> -----------------------------\n <mask> \n <mask> If, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n <mask> \n <mask>     from mongoengine.connection import get_connection\n <mask> \n <mask>     conn = get_connection()\n <mask>     collection = conn.mydb.movie\n <mask>     collection({'title': u'Days of Thunder'})\n <mask>  </s> remove Use the class ``objects`` attribute to make queries:: </s> add Use the class ``objects`` attribute to make queries. A keyword argument\nlooks for an equal value on the field. :: </s> remove ``objects`` is an iterable. Query operators may be user by concatenating it with the document\nkey using a double-underscore:: </s> add Query operators may be used by concatenating them with the field name\nusing a double-underscore. ``objects``, and queries returned by\ncalling it, are iterable. :: </s> add Instantiate your document class with keyword arguments for the fields.\nYou can also assign values to the field attributes after instantiation.\nThen call ``doc.save()``. :: </s> remove To declare models that will represent your Mongo documents, just create a class that\ninherits from ``Document`` and declare each of the fields::\n\n    from mongoengine import *\n\n\n    class Movie(Document): </s> add To declare a model that represents a Mongo document, create a class that\ninherits from ``Document`` and declare each of the fields. ::", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     conn = get_connection()\n <mask>     collection = conn.mydb.movie\n <mask>     collection({'title': u'Days of Thunder'})\n <mask> \n <mask> For more information about MongoEngine, head over to the\n <mask> `website <http://docs.mongoengine.org/>`_. </s> remove     conn = get_connection()\n    collection = conn.mydb.movie\n    collection({'title': u'Days of Thunder'}) </s> add There are many more ways to define and query documents with MongoEngine.\nFor more information, check out the `official documentation\n<MongoEngine_>`_. </s> remove The following operators are available as shortcuts to querying with regular\nexpressions:\n\n* ``exact`` -- string field exactly matches value\n* ``iexact`` -- string field exactly matches value (case insensitive)\n* ``contains`` -- string field contains value\n* ``icontains`` -- string field contains value (case insensitive)\n* ``startswith`` -- string field starts with value\n* ``istartswith`` -- string field starts with value (case insensitive)\n* ``endswith`` -- string field ends with value\n* ``iendswith`` -- string field ends with value (case insensitive)\n* ``match``  -- performs an $elemMatch so you can match an entire document within an array\n\nSome Tips\n---------\n\n* Attributes can be set as ``unique``\n* ``MongoEngine`` creates the ``_id`` attribute automatically to acess ``ObjectIds``\n* You can add choices to string fields: ``StringField(choices=['Apple', 'Banana'])``\n* If you don't want your class name to be the same name as the collection, you can define\n  a ``meta`` class member and use the ``collection`` parameter::\n\n    class Movie(Document):\n\n        meta ={'collection': 'movie_documents'}\n\nAccessing PyMongo MongoClient\n-----------------------------\n\nIf, for some reason, you want to access PyMongo instance, use ``get_connection`` function::\n\n    from mongoengine.connection import get_connection </s> remove If the model has embedded documents, use ``EmbeddedDocument`` to defined the fields of\nthe embedded document and ``EmbeddedDocumentField`` to declare it on the parent document:: </s> add     class Movie(me.Document):\n        title = me.StringField(required=True)\n        year = me.IntField()\n        rated = me.StringField()\n        director = me.StringField()\n        actors = me.ListField() </s> remove     class Imdb(EmbeddedDocument): </s> add If the document has nested fields, use ``EmbeddedDocument`` to\ndefined the fields of the embedded document and\n``EmbeddedDocumentField`` to declare it on the parent document. :: </s> add     import mongoengine as me </s> remove         imdb_id = StringField()\n        rating = DecimalField()\n        votes = IntField()\n\n\n    class Movie(Document): </s> add     class Imdb(me.EmbeddedDocument):\n        imdb_id = me.StringField()\n        rating = me.DecimalField()\n        votes = me.IntField()", "html_url": "https://github.com/pallets/flask/commit/edef8cb38b968228b0721d3cf93ac246e81e6c82", "file_name": "docs/patterns/mongoengine.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ===========================\n <mask> \n <mask> .. versionadded:: 0.3\n <mask> \n <mask> Applications fail, server fail.  Sooner or later you will see an exception\n <mask> in production.  Even if your code is 100% correct, you will still see\n <mask> exceptions from time to time.  Why?  Because everything else involved will\n <mask> fail.  Here some situations where perfectly fine code can lead to server\n <mask> errors:\n <mask>  </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`. </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`.", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -   a backend server overloaded\n <mask> -   a programming error in a library you are using\n <mask> -   network connection of the server to another system failed.\n <mask> \n <mask> And that's just a small sample of issues you could be facing.  So how to\n <mask> deal with that sort of problem?  By default if your application runs in\n <mask> production mode, Flask will display a very simple page for you and log the\n <mask> exception to the :attr:`~flask.Flask.logger`.\n <mask> \n <mask> But there is more you can do, and we will cover some better setups to deal </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`. </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`.", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> Error Mails\n <mask> -----------\n <mask> \n <mask> If the application runs in production mode (which it will do on your\n <mask> server) you won't see any log messages by default.  Why that?  Flask tries\n <mask> to be a zero-configuration framework and where should it drop the logs for\n <mask> you if there is no configuration.  Guessing is not a good idea because\n <mask> chances are, the place it guessed is not the place where the user has the\n <mask> permission to create a logfile.  Also, for most small applications nobody\n <mask> will look at the logs anyways.\n <mask> \n <mask> In fact, I promise you right now that if you configure a logfile for the\n <mask> application errors you will never look at it except for debugging an issue </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove And that's just a small sample of issues you could be facing.  So how to </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions:: </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove send you that message as mail.  But a log record stores more information </s> add send you that message as mail.  A log record stores more information, </s> remove     called for exception formatting.  It is passed a :attr:`~sys.exc_info` </s> add     called for exception formatting.  It is passed an :attr:`~sys.exc_info`", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> when a user reported it for you.  What you want instead is a mail the\n <mask> second the exception happened.  Then you get an alert and you can do\n <mask> something about it.\n <mask> \n <mask> Flask is using the Python builtin logging system and that one can actually\n <mask> send you mails for errors which is probably what you want.  Here is how\n <mask> you can configure the Flask logger to send you mails for exceptions::\n <mask> \n <mask>     ADMINS = ['yourname@example.com']\n <mask>     if not app.debug:\n <mask>         import logging\n <mask>         from logging.handlers import SMTPHandler </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`. </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove     called for exception formatting.  It is passed a :attr:`~sys.exc_info` </s> add     called for exception formatting.  It is passed an :attr:`~sys.exc_info` </s> remove send you that message as mail.  But a log record stores more information </s> add send you that message as mail.  A log record stores more information,", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> So what just happened?  We created a new\n <mask> :class:`~logging.handlers.SMTPHandler` that will send mails with the mail\n <mask> server listening on ``127.0.0.1`` to all the `ADMINS` from the address\n <mask> *server-error@example.com* with the subject \"YourApplication Failed\".  If\n <mask> your mail server requires credentials these can also provided, for that\n <mask> check out the documentation for the :class:`~logging.handlers.SMTPHandler`.\n <mask> \n <mask> We also tell the handler to only send errors and more critical messages.\n <mask> Because we certainly don't want to get a mail for warnings or other\n <mask> useless logs that might happen during request handling.\n <mask>  </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions:: </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove send you that message as mail.  But a log record stores more information </s> add send you that message as mail.  A log record stores more information, </s> remove And that's just a small sample of issues you could be facing.  So how to </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove A formatter can be instanciated with a format string.  Note that </s> add A formatter can be instantiated with a format string.  Note that", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep replace keep keep keep keep replace", "code_tokens": " <mask> By default a handler will only write the message string into a file or\n <mask> send you that message as mail.  But a log record stores more information\n <mask> and it makes a lot of sense to configure your logger to also contain that\n <mask> information so that you have a better idea of why that error happened, and\n <mask> more importantly, where it did.\n <mask> \n <mask> A formatter can be instanciated with a format string.  Note that </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove your mail server requires credentials these can also provided, for that\ncheck out the documentation for the :class:`~logging.handlers.SMTPHandler`. </s> add your mail server requires credentials, these can also be provided.  For\nthat check out the documentation for the\n:class:`~logging.handlers.SMTPHandler`. </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions:: </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> :meth:`~logging.Formatter.formatTime`:\n <mask>     called for `asctime` formatting.  If you want a different time format\n <mask>     you can override this method.\n <mask> :meth:`~logging.Formatter.formatException`\n <mask>     called for exception formatting.  It is passed a :attr:`~sys.exc_info`\n <mask>     tuple and has to return a string.  The default is usually fine, you\n <mask>     don't have to override it.\n <mask> \n <mask> For more information, head over to the official documentation.\n <mask>  </s> remove send you that message as mail.  But a log record stores more information </s> add send you that message as mail.  A log record stores more information, </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions:: </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove A formatter can be instanciated with a format string.  Note that </s> add A formatter can be instantiated with a format string.  Note that </s> remove Other libraries might log themselves as well.  For example, SQLAlchemy use\nlogging heavily in the core.  While there is a method to configure all </s> add Other libraries might log themselves as well.  For example, SQLAlchemy uses\nlogging heavily in its core.  While there is a method to configure all", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Other Libraries\n <mask> ---------------\n <mask> \n <mask> So far we only configured the logger your application created itself.\n <mask> Other libraries might log themselves as well.  For example, SQLAlchemy use\n <mask> logging heavily in the core.  While there is a method to configure all\n <mask> loggers at once in the :mod:`logging` package, I would not recommend using\n <mask> it.  There might be a situation in which you want to have multiple\n <mask> separate applications running side by side in the same Python interpreter\n <mask> and then it becomes impossible to have different logging setups for those.\n <mask>  </s> Error Handling documentation fixes (grammar, etc) </s> remove server) you won't see any log messages by default.  Why that?  Flask tries\nto be a zero-configuration framework and where should it drop the logs for\nyou if there is no configuration.  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has the </s> add server) you won't see any log messages by default.  Why is that?  Flask\ntries to be a zero-configuration framework.  Where should it drop the logs\nfor you if there is no configuration?  Guessing is not a good idea because\nchances are, the place it guessed is not the place where the user has </s> remove Flask is using the Python builtin logging system and that one can actually\nsend you mails for errors which is probably what you want.  Here is how\nyou can configure the Flask logger to send you mails for exceptions:: </s> add Flask uses the Python builtin logging system, and it can actually send\nyou mails for errors which is probably what you want.  Here is how you can\nconfigure the Flask logger to send you mails for exceptions:: </s> remove And that's just a small sample of issues you could be facing.  So how to </s> add And that's just a small sample of issues you could be facing.  So how do we </s> remove send you that message as mail.  But a log record stores more information </s> add send you that message as mail.  A log record stores more information, </s> remove A formatter can be instanciated with a format string.  Note that </s> add A formatter can be instantiated with a format string.  Note that", "html_url": "https://github.com/pallets/flask/commit/ee5eafa7951bf636bdf345cb072f89947e265867", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> this behavior was changed and :func:`~flask.jsonify` now supports serializing\n <mask> arrays.\n <mask> \n <mask> \n <mask> SSL/HTTPS\n <mask> ---------\n <mask> \n <mask> For implementing HTTPS on your server.\n <mask> \n <mask> Below are some packages that implement this protocol:\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Content Security Policy (CSP)\n <mask> ----------------------------------------------------------------------------- </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This section contains a list of headers supported by Flask and some packages that implements them.\n <mask> \n <mask> Content Security Policy (CSP)\n <mask> -----------------------------------------------------------------------------\n <mask> \n <mask> Enhance security and prevents common web vulnerabilities such as cross-site scripting and MITM related attacks.\n <mask> \n <mask> Example:\n <mask>  </s> remove This section contains a list of headers supported by Flask and some packages that implements them. </s> add This section contains a list of headers supported by Flask.\nTo configure HTTPS and handle the headers listed below we suggest the package `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`. </s> remove \nSSL/HTTPS\n---------\n\nFor implementing HTTPS on your server.\n\nBelow are some packages that implement this protocol:\n\n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Enhance security and prevents common web vulnerabilities such as cross-site scripting and MITM related attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Content-Security-Policy: default-src https:; script-src 'nonce-{random}'; object-src 'none'\n <mask> \n <mask> \n <mask> See also `Content Security Policy <https://csp.withgoogle.com/docs/index.html>`_. </s> Suggest only one package, change the sourcecode block to none </s> remove ----------------------------------------------------------------------------- </s> add ----------------------------- </s> remove .. sourcecode:: html </s> remove .. sourcecode:: html </s> remove .. sourcecode:: html", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-csp <https://github.com/twaldear/flask-csp>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> ------------------------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Redirects http requests to https on all urls, preventing MITM attacks.\n <mask> \n <mask> Example: </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Redirects http requests to https on all urls, preventing MITM attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Strict-Transport-Security: max-age=<expire-time \n <mask>    Strict-Transport-Security: max-age=<expire-time>; includeSubDomains \n <mask>    Strict-Transport-Security: max-age=<expire-time>; preload \n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace keep", "code_tokens": " <mask>    Strict-Transport-Security: max-age=<expire-time>; preload \n <mask> \n <mask> See also `Strict Transport Security <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> X-FRAME-OPTIONS (Clickjacking protection)\n <mask> -------------------------------------------------------------------------------------------------------------------------\n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove \nSSL/HTTPS\n---------\n\nFor implementing HTTPS on your server.\n\nBelow are some packages that implement this protocol:\n\n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -------------------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Prevents the client from clicking page elements outside of the website, avoiding hijacking or UI redress attacks.\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    X-Frame-Options: DENY \n <mask>    X-Frame-Options: SAMEORIGIN\n <mask>    X-Frame-Options: ALLOW-FROM https://example.com/\n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-sslify <https://github.com/kennethreitz/flask-sslify>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask>    X-Frame-Options: ALLOW-FROM https://example.com/\n <mask> \n <mask> See also `X-Frame-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> X-Content-Type-Options\n <mask> -------------------------------------------------------------------------------------------------------------\n <mask>  </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-csp <https://github.com/twaldear/flask-csp>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -------------------------------------------------------------------------------------------------------------\n <mask> \n <mask> Prevents XSS by blocking requests on clients and forcing them to read the content type instead of first opening it.\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    X-Content-Type-Options: nosniff\n <mask> \n <mask> See also `X-Content-Type-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options>`_. \n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask> See also `X-Content-Type-Options <https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options>`_. \n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> Cookie options\n <mask> ----------------------------------------------------------------------------------------------------------\n <mask> \n <mask> For setting cookies on client-side storage.\n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> For setting cookies on client-side storage.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask>    \n <mask>    Set-Cookie: [cookie-name]=[cookie-value] \n <mask> \n <mask> See also `HTTP cookies <https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Secure_and_HttpOnly_cookies>`_ .\n <mask>  </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> See also `HTTP cookies <https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Secure_and_HttpOnly_cookies>`_ .\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> HTTP Public Key Pinning (HPKP)\n <mask> -------------------------------------------------------------------------------------------------------\n <mask> \n <mask> For associating clients with web servers through a certificate key and prevent MITM attacks.\n <mask> \n <mask> Example: </s> remove \n* `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n\nReferences\n-----------\n\n* https://docs.djangoproject.com/en/1.11/topics/security/\n* https://blog.appcanary.com/2017/http-security-headers.html\n* https://developer.mozilla.org\n* https://csp.withgoogle.com/docs/index.html </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> For associating clients with web servers through a certificate key and prevent MITM attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: html\n <mask> \n <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask> * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n <mask> * `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_\n <mask> \n <mask> References\n <mask> -----------\n <mask> \n <mask> * https://docs.djangoproject.com/en/1.11/topics/security/\n <mask> * https://blog.appcanary.com/2017/http-security-headers.html\n <mask> * https://developer.mozilla.org\n <mask> * https://csp.withgoogle.com/docs/index.html </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_ </s> remove * `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_\n* `flask-secure-headers <https://github.com/twaldear/flask-secure-headers>`_", "html_url": "https://github.com/pallets/flask/commit/ee7cb9d6b2ff404be33bcc0487f8b0fee806436d", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> repos:\n <mask>   - repo: https://github.com/asottile/pyupgrade\n <mask>     rev: v2.1.0\n <mask>     hooks:\n <mask>       - id: pyupgrade\n <mask>         args: [\"--py36-plus\"]\n <mask>   - repo: https://github.com/asottile/reorder_python_imports\n <mask>     rev: v2.1.0\n <mask>     hooks:\n <mask>       - id: reorder-python-imports\n <mask>         name: Reorder Python imports (src, tests) </s> remove     rev: 3.7.9 </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rev: 19.10b0\n <mask>     hooks:\n <mask>       - id: black\n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.7.9\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies:\n <mask>           - flake8-bugbear\n <mask>           - flake8-implicit-str-concat </s> remove     rev: v2.5.0 </s> remove     rev: v2.1.0 </s> remove     rev: v2.1.0 </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         additional_dependencies:\n <mask>           - flake8-bugbear\n <mask>           - flake8-implicit-str-concat\n <mask>   - repo: https://github.com/pre-commit/pre-commit-hooks\n <mask>     rev: v2.5.0\n <mask>     hooks:\n <mask>       - id: check-byte-order-marker\n <mask>       - id: trailing-whitespace\n <mask>       - id: end-of-file-fixer </s> remove     rev: 3.7.9 </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> version: 2\n <mask> python:\n <mask>   install:\n <mask>     - method: pip\n <mask>       path: .\n <mask> sphinx:\n <mask>   builder: dirhtml </s> use pip-compile to pin dev requirements </s> remove     - requirements: docs/requirements.txt </s> add </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt </s> remove -   Install the `pre-commit framework`_. </s> add </s> remove     rev: v2.5.0 </s> add     rev: v3.1.0 </s> remove     rev: 3.7.9 </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0 </s> add     rev: v2.4.3", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".readthedocs.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> python:\n <mask>   install:\n <mask>     - method: pip\n <mask>       path: .\n <mask>     - requirements: docs/requirements.txt\n <mask> sphinx:\n <mask>   builder: dirhtml </s> use pip-compile to pin dev requirements </s> add     - requirements: requirements/docs.txt </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt </s> remove -   Install the `pre-commit framework`_. </s> add </s> remove     rev: v2.5.0 </s> add     rev: v3.1.0 </s> remove     rev: 3.7.9 </s> add     rev: 3.8.2 </s> remove     rev: v2.1.0 </s> add     rev: v2.4.3", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": ".readthedocs.yaml"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> include CONTRIBUTING.rst\n <mask> include LICENSE.rst\n <mask> include tox.ini\n <mask> graft artwork\n <mask> graft docs\n <mask> prune docs/_build\n <mask> graft examples\n <mask> graft tests\n <mask> global-exclude *.pyc </s> use pip-compile to pin dev requirements </s> remove deps = -r docs/requirements.txt </s> add deps = -r requirements/docs.txt </s> add     -r requirements/tests.txt </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    }, </s> add     extras_require={\"dotenv\": [\"python-dotenv\"]}, </s> remove -   Install the `pre-commit framework`_. </s> add </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt </s> remove     - requirements: docs/requirements.txt </s> add", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "MANIFEST.in"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>         \"Jinja2>=2.10.1\",\n <mask>         \"itsdangerous>=0.24\",\n <mask>         \"click>=5.1\",\n <mask>     ],\n <mask>     extras_require={\n <mask>         \"dotenv\": [\"python-dotenv\"],\n <mask>         \"dev\": [\n <mask>             \"pytest\",\n <mask>             \"coverage\",\n <mask>             \"tox\",\n <mask>             \"sphinx\",\n <mask>             \"pallets-sphinx-themes\",\n <mask>             \"sphinxcontrib-log-cabinet\",\n <mask>             \"sphinx-issues\",\n <mask>         ],\n <mask>     },\n <mask> ) </s> remove deps = -r docs/requirements.txt </s> remove     pytest\n    greenlet\n    blinker\n    python-dotenv </s> remove -   Install the `pre-commit framework`_. </s> remove         $ pip install -e \".[dev]\"", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> skip_missing_interpreters = true\n <mask> \n <mask> [testenv]\n <mask> deps =\n <mask>     pytest\n <mask>     greenlet\n <mask>     blinker\n <mask>     python-dotenv\n <mask> \n <mask>     lowest: Werkzeug==0.15.5\n <mask>     lowest: Jinja2==2.10\n <mask>     lowest: itsdangerous==0.24\n <mask>     lowest: Click==5.1 </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    }, </s> remove -   Install the `pre-commit framework`_. </s> remove         $ pip install -e \".[dev]\"", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> skip_install = true\n <mask> commands = pre-commit run --all-files --show-diff-on-failure\n <mask> \n <mask> [testenv:docs]\n <mask> deps = -r docs/requirements.txt\n <mask> commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html </s> remove     pytest\n    greenlet\n    blinker\n    python-dotenv </s> remove         $ pip install -e \".[dev]\" </s> add         $ pip install -e . -r requirements/dev.txt </s> remove -   Install the `pre-commit framework`_. </s> remove     extras_require={\n        \"dotenv\": [\"python-dotenv\"],\n        \"dev\": [\n            \"pytest\",\n            \"coverage\",\n            \"tox\",\n            \"sphinx\",\n            \"pallets-sphinx-themes\",\n            \"sphinxcontrib-log-cabinet\",\n            \"sphinx-issues\",\n        ],\n    },", "html_url": "https://github.com/pallets/flask/commit/eea31f29a50eeb30ec3c314bb2a6de4c931095c1", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   log request handling exceptions to that logger when not in debug\n <mask>   mode.  This makes it possible to receive mails on server errors\n <mask>   for example.\n <mask> \n <mask> Version 0.2\n <mask> -----------\n <mask>  </s> Added interactive Python docs, fixed part style. </s> remove             _request_ctx_stack.pop() </s> add             self.pop() </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "CHANGES"}
{"docstring_tokens": "replace keep keep keep keep keep", "code_tokens": " <mask> \\pagenumbering{arabic}\n <mask> \\definecolor{TitleColor}{rgb}{0,0,0}\n <mask> \\definecolor{InnerLinkColor}{rgb}{0,0,0}\n <mask> \n <mask> \\renewcommand{\\maketitle}{%\n <mask>   \\begin{titlepage}% </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}% </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \\renewcommand\\thepart{\\@Roman\\c@part}\n <mask> \\renewcommand\\part{%\n <mask>    \\if@noskipsec \\leavevmode \\fi\n <mask>    \\cleardoublepage\n <mask>    \\vspace*{6cm}%\n <mask>    \\@afterindentfalse\n <mask>    \\secdef\\@part\\@spart}\n <mask>  </s> remove    \\vspace*{8cm}% </s> add    \\vspace*{6cm}% </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \\renewcommand\\thepart{\\@Roman\\c@part}\n <mask> \\renewcommand\\part{%\n <mask>    \\if@noskipsec \\leavevmode \\fi\n <mask>    \\cleardoublepage\n <mask>    \\vspace*{8cm}%\n <mask>    \\@afterindentfalse\n <mask>    \\secdef\\@part\\@spart}\n <mask> \n <mask> \\def\\@part[#1]#2{%\n <mask>     \\ifnum \\c@secnumdepth >\\m@ne </s> add    \\pagestyle{empty} </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \\addcontentsline{toc}{part}{\\thepart\\hspace{1em}#1}%\n <mask>     \\else\n <mask>       \\addcontentsline{toc}{part}{#1}%\n <mask>     \\fi\n <mask>     {\\parindent \\z@ \\center\n <mask>      \\interlinepenalty \\@M\n <mask>      \\normalfont\n <mask>      \\ifnum \\c@secnumdepth >\\m@ne\n <mask>        \\rm\\Large \\partname~\\thepart\n <mask>        \\par\\nobreak </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}% </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \\nobreak\n <mask>     \\vskip 8ex\n <mask>     \\@afterheading}\n <mask> \\def\\@spart#1{%\n <mask>     {\\parindent \\z@ \\center\n <mask>      \\interlinepenalty \\@M\n <mask>      \\normalfont\n <mask>      \\huge \\bfseries #1\\par}%\n <mask>      \\nobreak\n <mask>      \\vskip 3ex </s> remove     {\\parindent \\z@ \\center </s> add     {\\parindent \\z@ %\\center </s> remove    \\vspace*{8cm}% </s> add    \\vspace*{6cm}% </s> add    \\pagestyle{empty}", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "docs/flaskstyle.sty"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Binds the request context.\"\"\"\n <mask>         _request_ctx_stack.push(self)\n <mask> \n <mask>     def __exit__(self, exc_type, exc_value, tb):\n <mask>         # do not pop the request stack if we are in debug mode and an\n <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.\n <mask>         if tb is None or not self.app.debug:\n <mask>             self.pop() </s> remove             _request_ctx_stack.pop() </s> add - added support for context binding that does not require the use of\n  the with statement for playing in the console.\n- the request context is now available within the with statement making\n  it possible to further push the request context or pop it.", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # do not pop the request stack if we are in debug mode and an\n <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.\n <mask>         if tb is None or not self.app.debug:\n <mask>             _request_ctx_stack.pop()\n <mask> \n <mask> \n <mask> def url_for(endpoint, **values):\n <mask>     \"\"\"Generates a URL to the given endpoint with the method provided.\n <mask>     The endpoint is relative to the active module if modules are in use. </s> add     def pop(self):\n        \"\"\"Pops the request context.\"\"\"\n        _request_ctx_stack.pop()\n\n    def __enter__(self):\n        self.push()\n        return self </s> add - added support for context binding that does not require the use of\n  the with statement for playing in the console.\n- the request context is now available within the with statement making\n  it possible to further push the request context or pop it.", "html_url": "https://github.com/pallets/flask/commit/ef0dc1800f7558abbefe070f361b97b9161b2452", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> intersphinx_mapping = {\n <mask>     \"python\": (\"https://docs.python.org/3/\", None),\n <mask>     \"werkzeug\": (\"https://werkzeug.palletsprojects.com/\", None),\n <mask>     \"click\": (\"https://click.palletsprojects.com/\", None),\n <mask>     \"jinja\": (\"http://jinja.pocoo.org/docs/\", None),\n <mask>     \"itsdangerous\": (\"https://itsdangerous.palletsprojects.com/\", None),\n <mask>     \"sqlalchemy\": (\"https://docs.sqlalchemy.org/\", None),\n <mask>     \"wtforms\": (\"https://wtforms.readthedocs.io/en/stable/\", None),\n <mask>     \"blinker\": (\"https://pythonhosted.org/blinker/\", None),\n <mask> } </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/ </s> add .. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/conf.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Flask depends on the `Jinja`_ template engine and the `Werkzeug`_ WSGI\n <mask> toolkit. The documentation for these libraries can be found at:\n <mask> \n <mask> - `Jinja documentation <http://jinja.pocoo.org/docs>`_\n <mask> - `Werkzeug documentation <https://werkzeug.palletsprojects.com/>`_\n <mask> \n <mask> .. _Jinja: https://www.palletsprojects.com/p/jinja/\n <mask> .. _Werkzeug: https://www.palletsprojects.com/p/werkzeug/\n <mask>  </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/ </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/ </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/index.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Generating HTML from within Python is not fun, and actually pretty\n <mask> cumbersome because you have to do the HTML escaping on your own to keep\n <mask> the application secure.  Because of that Flask configures the `Jinja2\n <mask> <http://jinja.pocoo.org/>`_ template engine for you automatically.\n <mask> \n <mask> To render a template you can use the :func:`~flask.render_template`\n <mask> method.  All you have to do is provide the name of the template and the\n <mask> variables you want to pass to the template engine as keyword arguments.\n <mask> Here's a simple example of how to render a template:: </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             /hello.html\n <mask> \n <mask> For templates you can use the full power of Jinja2 templates.  Head over\n <mask> to the official `Jinja2 Template Documentation\n <mask> <http://jinja.pocoo.org/docs/templates/>`_ for more information.\n <mask> \n <mask> Here is an example template:\n <mask> \n <mask> .. sourcecode:: html+jinja\n <mask>  </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This section only gives a very quick introduction into how Jinja2\n <mask> is integrated into Flask.  If you want information on the template\n <mask> engine's syntax itself, head over to the official `Jinja2 Template\n <mask> Documentation <http://jinja.pocoo.org/docs/templates/>`_ for\n <mask> more information.\n <mask> \n <mask> Jinja Setup\n <mask> -----------\n <mask>  </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> special variable available inside `Jinja for loops`_. It's used to\n <mask> display a line after each post except the last one, to visually separate\n <mask> them.\n <mask> \n <mask> .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for\n <mask> \n <mask> \n <mask> Create\n <mask> ------\n <mask>  </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/tutorial/blog.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> statement like ``if`` and ``for``. Unlike Python, blocks are denoted\n <mask> by start and end tags rather than indentation since static text within\n <mask> a block could change indentation.\n <mask> \n <mask> .. _Jinja: http://jinja.pocoo.org/docs/templates/\n <mask> .. _HTML: https://developer.mozilla.org/docs/Web/HTML\n <mask> \n <mask> \n <mask> The Base Layout\n <mask> --------------- </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "docs/tutorial/templates.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. |jQuery.ajax| replace:: ``jQuery.ajax``\n <mask> .. _jQuery.ajax: https://api.jquery.com/jQuery.ajax/\n <mask> \n <mask> .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/\n <mask> \n <mask> \n <mask> Install\n <mask> -------\n <mask>  </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/ </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/ </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/javascript/README.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> setup(\n <mask>     name=\"js_example\",\n <mask>     version=\"1.0.0\",\n <mask>     url=\"http://flask.pocoo.org/docs/patterns/jquery/\",\n <mask>     license=\"BSD\",\n <mask>     maintainer=\"Pallets team\",\n <mask>     maintainer_email=\"contact@palletsprojects.com\",\n <mask>     description=\"Demonstrates making Ajax requests to Flask.\",\n <mask>     long_description=readme, </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\", </s> add     url=\"https://flask.palletsprojects.com/tutorial/\", </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _Jinja for loops: http://jinja.pocoo.org/docs/templates/#for </s> add .. _Jinja for loops: https://jinja.palletsprojects.com/templates/#for </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\")", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/javascript/setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ======\n <mask> \n <mask> The basic blog app built in the Flask `tutorial`_.\n <mask> \n <mask> .. _tutorial: http://flask.pocoo.org/docs/tutorial/\n <mask> \n <mask> \n <mask> Install\n <mask> -------\n <mask>  </s> remove .. _Flask docs: http://flask.pocoo.org/docs/patterns/jquery/ </s> add .. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/ </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically.", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/tutorial/README.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> setup(\n <mask>     name=\"flaskr\",\n <mask>     version=\"1.0.0\",\n <mask>     url=\"http://flask.pocoo.org/docs/tutorial/\",\n <mask>     license=\"BSD\",\n <mask>     maintainer=\"Pallets team\",\n <mask>     maintainer_email=\"contact@palletsprojects.com\",\n <mask>     description=\"The basic blog app built in the Flask tutorial.\",\n <mask>     long_description=readme, </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/ </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_ </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically.", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "examples/tutorial/setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             \"  The template was looked up from an endpoint that \"\n <mask>             'belongs to the blueprint \"%s\".' % blueprint\n <mask>         )\n <mask>         info.append(\"  Maybe you did not place a template in the right folder?\")\n <mask>         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\")\n <mask> \n <mask>     app.logger.info(\"\\n\".join(info))\n <mask> \n <mask> \n <mask> def explain_ignored_app_run(): </s> Replace old pocoo links everywhere\n\npocco.org -> palletsprojects.com </s> remove             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text </s> add             assert \"See https://flask.palletsprojects.com/blueprints/#templates\" in text </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove <http://jinja.pocoo.org/docs/templates/>`_ for more information. </s> add <http://jinja.palletsprojects.com/templates/>`_ for more information. </s> remove Documentation <http://jinja.pocoo.org/docs/templates/>`_ for </s> add Documentation <https://jinja.palletsprojects.com/templates/>`_ for </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "src/flask/debughelpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert \"Error: the template could not be found\" in text\n <mask>             assert (\n <mask>                 \"looked up from an endpoint that belongs to \" 'the blueprint \"frontend\"'\n <mask>             ) in text\n <mask>             assert \"See http://flask.pocoo.org/docs/blueprints/#templates\" in text\n <mask> \n <mask>     with app.test_client() as c:\n <mask>         monkeypatch.setitem(app.config, \"EXPLAIN_TEMPLATE_LOADING\", True)\n <mask>         monkeypatch.setattr(\n <mask>             logging.getLogger(\"blueprintapp\"), \"handlers\", [_TestHandler()] </s> remove         info.append(\"  See http://flask.pocoo.org/docs/blueprints/#templates\") </s> add         info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\") </s> remove .. _Jinja: http://jinja.pocoo.org/docs/templates/ </s> add .. _Jinja: https://jinja.palletsprojects.com/templates/ </s> remove <http://jinja.pocoo.org/>`_ template engine for you automatically. </s> add <https://palletsprojects.com/p/jinja/>`_ template engine for you automatically. </s> remove .. _tutorial: http://flask.pocoo.org/docs/tutorial/ </s> add .. _tutorial: https://flask.palletsprojects.com/tutorial/ </s> remove     url=\"http://flask.pocoo.org/docs/tutorial/\", </s> remove - `Jinja documentation <http://jinja.pocoo.org/docs>`_ </s> add - `Jinja documentation <https://jinja.palletsprojects.com/>`_", "html_url": "https://github.com/pallets/flask/commit/ef434ea9985b756f13bed283dfa55828829e5e1f", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>    is for example very helpful if you try to generate JavaScript on the\n <mask>    fly.\n <mask> \n <mask>    Note that inside `script` tags no escaping must take place, so make\n <mask>    sure to disable escaping with ``|safe`` if you intend to use it inside\n <mask>    `script` tags:\n <mask> \n <mask>    .. sourcecode:: html+jinja\n <mask> \n <mask>        <script type=text/javascript>\n <mask>            doSomethingWith({{ user.username|tojson|safe }}); </s> Imply the |safe on tojson in templates and change escaping logic </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you. </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs)) </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>        <script type=text/javascript>\n <mask>            doSomethingWith({{ user.username|tojson|safe }});\n <mask>        </script>\n <mask> \n <mask>    That the ``|tojson`` filter escapes forward slashes properly for you.\n <mask> \n <mask> Controlling Autoescaping\n <mask> ------------------------\n <mask> \n <mask> Autoescaping is the concept of automatically escaping special characters\n <mask> of you.  Special characters in the sense of HTML (or XML, and thus XHTML) </s> Imply the |safe on tojson in templates and change escaping logic </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs)) </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             request=request,\n <mask>             session=session,\n <mask>             g=g\n <mask>         )\n <mask>         rv.filters['tojson'] = json.htmlsafe_dumps\n <mask>         return rv\n <mask> \n <mask>     def create_global_jinja_loader(self):\n <mask>         \"\"\"Creates the loader for the Jinja2 environment.  Can be used to\n <mask>         override just the loader and keeping the rest unchanged.  It's </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs)) </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you. </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags:", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         for func in funcs:\n <mask>             rv = func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>         # If this interpreter supports clearing the exception information\n <mask>         # we do that now.  This will only go into effect on Python 2.x,\n <mask>         # on 3.x it disappears automatically at the end of the exception\n <mask>         # stack.\n <mask>         if hasattr(sys, 'exc_clear'):\n <mask>             sys.exc_clear()\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=None):\n <mask>         \"\"\"Called when an application context is popped.  This works pretty\n <mask>         much the same as :meth:`do_teardown_request` but for the application\n <mask>         context.\n <mask>  </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> from werkzeug.http import http_date\n <mask> \n <mask> # Use the same json implementation as itsdangerous on which we\n <mask> # depend anyways.\n <mask> try: </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you. </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace replace replace", "code_tokens": " <mask> def htmlsafe_dumps(obj, **kwargs):\n <mask>     \"\"\"Works exactly like :func:`dumps` but is safe for use in ``<script>``\n <mask>     tags.  It accepts the same arguments and returns a JSON string.  Note that\n <mask>     this is available in templates through the ``|tojson`` filter but it will\n <mask>     have to be wrapped in ``|safe`` unless **true** XHTML is being used.\n <mask>     \"\"\"\n <mask>     rv = dumps(obj, **kwargs)\n <mask>     if _slash_escape:\n <mask>         rv = rv.replace('/', '\\\\/')\n <mask>     return rv.replace('<!', '<\\\\u0021') </s> Imply the |safe on tojson in templates and change escaping logic </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear() </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps </s> add         rv.filters['tojson'] = json.tojson_filter </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs)) </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove    That the ``|tojson`` filter escapes forward slashes properly for you.", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def htmlsafe_dump(obj, fp, **kwargs):\n <mask>     \"\"\"Like :func:`htmlsafe_dumps` but writes into a file object.\"\"\"\n <mask>     fp.write(htmlsafe_dumps(obj, **kwargs))\n <mask> \n <mask> \n <mask> def jsonify(*args, **kwargs):\n <mask>     \"\"\"Creates a :class:`~flask.Response` with the JSON representation of\n <mask>     the given arguments with an `application/json` mimetype.  The arguments </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear() </s> remove         rv.filters['tojson'] = json.htmlsafe_dumps </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags: </s> remove             rv = render('{{ \"</script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\/script>\"')\n            rv = render('{{ \"<\\0/script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\u0000\\\\/script>\"')\n            rv = render('{{ \"<!--<script>\"|tojson|safe }}')\n            self.assert_equal(rv, '\"<\\\\u0021--<script>\"')", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/json.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_template_escaping(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         render = flask.render_template_string\n <mask>         with app.test_request_context():\n <mask>             rv = render('{{ \"</script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\/script>\"')\n <mask>             rv = render('{{ \"<\\0/script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\u0000\\\\/script>\"')\n <mask>             rv = render('{{ \"<!--<script>\"|tojson|safe }}')\n <mask>             self.assert_equal(rv, '\"<\\\\u0021--<script>\"')\n <mask> \n <mask>     def test_json_customization(self):\n <mask>         class X(object):\n <mask>             def __init__(self, val):\n <mask>                 self.val = val </s> Imply the |safe on tojson in templates and change escaping logic </s> remove     rv = dumps(obj, **kwargs)\n    if _slash_escape:\n        rv = rv.replace('/', '\\\\/')\n    return rv.replace('<!', '<\\\\u0021') </s> add     rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv </s> remove     this is available in templates through the ``|tojson`` filter but it will\n    have to be wrapped in ``|safe`` unless **true** XHTML is being used. </s> add     this is available in templates through the ``|tojson`` filter which will\n    also mark the result as safe.  Due to how this function escapes certain\n    characters this is safe even if used outside of ``<script>`` tags.\n\n    .. versionchanged:: 0.10\n       This function's return value is now always safe for HTML usage, even\n       if outside of script tags or if used in XHTML. </s> remove         # If this interpreter supports clearing the exception information\n        # we do that now.  This will only go into effect on Python 2.x,\n        # on 3.x it disappears automatically at the end of the exception\n        # stack.\n        if hasattr(sys, 'exc_clear'):\n            sys.exc_clear() </s> remove     fp.write(htmlsafe_dumps(obj, **kwargs)) </s> add     fp.write(unicode(htmlsafe_dumps(obj, **kwargs))) </s> remove    sure to disable escaping with ``|safe`` if you intend to use it inside\n   `script` tags: </s> add    sure to disable escaping with ``|safe`` before Flask 0.10 if you intend\n   to use it inside `script` tags:", "html_url": "https://github.com/pallets/flask/commit/ef72b78042d7feffc864e7f2da3f62835fc63ee8", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   - \"3.5\"\n <mask> \n <mask> env:\n <mask>   - REQUIREMENTS=lowest\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=release-simplejson\n <mask>   - REQUIREMENTS=devel\n <mask>   - REQUIREMENTS=devel-simplejson\n <mask> \n <mask> matrix:\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=devel-simplejson </s> add   - REQUIREMENTS=release-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>   - REQUIREMENTS=lowest-simplejson\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=devel\n <mask>   - REQUIREMENTS=devel-simplejson\n <mask> \n <mask> matrix:\n <mask>   exclude:\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=devel-simplejson </s> add   - REQUIREMENTS=lowest-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   - REQUIREMENTS=lowest-simplejson\n <mask>   - REQUIREMENTS=release\n <mask>   - REQUIREMENTS=release-simplejson\n <mask>   - REQUIREMENTS=devel\n <mask> \n <mask> matrix:\n <mask>   exclude:\n <mask>     # Python 3 support currently does not work with lowest requirements\n </s> Tests with and without simplejson for every existing testenv (#1869) </s> add   - REQUIREMENTS=lowest-simplejson </s> add   - REQUIREMENTS=release-simplejson", "html_url": "https://github.com/pallets/flask/commit/f034d2e271403c7b3b8a1c2728b2320ed157a037", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter(self):\n <mask>         bp = flask.Blueprint('bp', __name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return s[::-1]\n <mask>         bp.add_app_template_filter(my_reverse)\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         bp = flask.Blueprint('bp', __name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter_with_name(self):\n <mask>         bp = flask.Blueprint('bp', __name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return s[::-1]\n <mask>         bp.add_app_template_filter(my_reverse, 'strrev')\n <mask>         app = flask.Flask(__name__)\n <mask>         app.register_blueprint(bp, url_prefix='/py')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         bp = flask.Blueprint('bp', __name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter()\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter(self):\n <mask>         app = flask.Flask(__name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app.add_template_filter(my_reverse)\n <mask>         self.assert_('my_reverse' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter('strrev')\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_add_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         app.add_template_filter(my_reverse, 'strrev')\n <mask>         self.assert_('strrev' in  app.jinja_env.filters.keys())\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         app = flask.Flask(__name__) </s> Add @template_test() decorator for creating custom jinja2 tests, like existing @template_filter() for filters.  Fixes #332 </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys()) </s> remove         self.assert_('strrev' in  app.jinja_env.filters.keys()) </s> add         self.assert_('strrev' in app.jinja_env.filters.keys()) </s> remove         self.assert_('my_reverse' in  app.jinja_env.filters.keys()) </s> add         self.assert_('my_reverse' in app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/f034d8d3451f590fca1badeac5da0230bed9b148", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return update_wrapper(new_f, f)\n <mask> \n <mask> \n <mask> class FlaskTestCase(unittest.TestCase):\n <mask>     pass\n <mask> \n <mask> \n <mask> class ContextTestCase(FlaskTestCase):\n <mask> \n <mask>     def test_context_binding(self): </s> Test that we're not leaking a request context in the testsuite, fixed a leak </s> remove         with catch_stderr() as err:\n            c.get('/')\n            out = err.getvalue()\n            assert 'WARNING in flask_tests [' in out\n            assert 'flask_tests.py' in out\n            assert 'the standard library is dead' in out\n            assert 'this is a debug statement' in out\n\n        with catch_stderr() as err:\n            try:\n                c.get('/exc')\n            except ZeroDivisionError:\n                pass\n            else:\n                assert False, 'debug log ate the exception' </s> add         with app.test_client() as c:\n            with catch_stderr() as err:\n                c.get('/')\n                out = err.getvalue()\n                assert 'WARNING in flask_tests [' in out\n                assert 'flask_tests.py' in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out\n\n            with catch_stderr() as err:\n                try:\n                    c.get('/exc')\n                except ZeroDivisionError:\n                    pass\n                else:\n                    assert False, 'debug log ate the exception'", "html_url": "https://github.com/pallets/flask/commit/f051939d8ba1c5ec585fd4db1f83237a66020c0a", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>         def exc():\n <mask>             1/0\n <mask>         c = app.test_client()\n <mask> \n <mask>         with catch_stderr() as err:\n <mask>             c.get('/')\n <mask>             out = err.getvalue()\n <mask>             assert 'WARNING in flask_tests [' in out\n <mask>             assert 'flask_tests.py' in out\n <mask>             assert 'the standard library is dead' in out\n <mask>             assert 'this is a debug statement' in out\n <mask> \n <mask>         with catch_stderr() as err:\n <mask>             try:\n <mask>                 c.get('/exc')\n <mask>             except ZeroDivisionError:\n <mask>                 pass\n <mask>             else:\n <mask>                 assert False, 'debug log ate the exception'\n <mask> \n </s> Test that we're not leaking a request context in the testsuite, fixed a leak </s> remove     pass\n </s> add     def ensure_clean_request_context(self):\n        # make sure we're not leaking a request context since we are\n        # testing flask internally in debug mode in a few cases\n        self.assertEqual(flask._request_ctx_stack.top, None)\n\n    def tearDown(self):\n        unittest.TestCase.tearDown(self)\n        self.ensure_clean_request_context()", "html_url": "https://github.com/pallets/flask/commit/f051939d8ba1c5ec585fd4db1f83237a66020c0a", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     make html\n <mask> \n <mask> Open ``_build/html/index.html`` in your browser to view the docs.\n <mask> \n <mask> Read more about `Sphinx <http://www.sphinx-doc.org>`_.\n <mask> \n <mask> \n <mask> make targets\n <mask> ~~~~~~~~~~~~\n <mask>  </s> remove .. _fabric: http://www.fabfile.org/ </s> add .. _fabric: https://www.fabfile.org/ </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_ </s> add `First Steps with Celery <https://celery.readthedocs.io/en/latest/getting-started/first-steps-with-celery.html>`_", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "CONTRIBUTING.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    .. attribute:: base_url\n <mask>    .. attribute:: url_root\n <mask> \n <mask>       Provides different ways to look at the current `IRI\n <mask>       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is\n <mask>       listening on the following application root::\n <mask> \n <mask>           http://www.example.com/myapplication\n <mask> \n <mask>       And a user requests the following URI:: </s> remove .. _Fabric: http://www.fabfile.org/ </s> add .. _Fabric: https://www.fabfile.org/ </s> remove .. _fabric: http://www.fabfile.org/ </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     configurations separately to the production server(s).  For some\n <mask>     details about how to do that, head over to the\n <mask>     :ref:`fabric-deployment` pattern.\n <mask> \n <mask> .. _fabric: http://www.fabfile.org/\n <mask> \n <mask> \n <mask> .. _instance-folders:\n <mask> \n <mask> Instance Folders </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_. </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove .. _Fabric: http://www.fabfile.org/ </s> add .. _Fabric: https://www.fabfile.org/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> \n <mask> .. _nginx: https://nginx.org/\n <mask> .. _lighttpd: https://www.lighttpd.net/\n <mask> .. _cherokee: http://cherokee-project.com/\n <mask> .. _uwsgi: http://projects.unbit.it/uwsgi/ </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/ </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove .. _fabric: http://www.fabfile.org/ </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _MongoKit: http://bytebucket.org/namlook/mongokit/ </s> add .. _MongoKit: https://github.com/namlook/mongokit </s> remove .. _Fabric: http://www.fabfile.org/ </s> add .. _Fabric: https://www.fabfile.org/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/uwsgi.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> 4``) binding to localhost port 4000 (``-b 127.0.0.1:4000``)::\n <mask> \n <mask>     $ gunicorn -w 4 -b 127.0.0.1:4000 myproject:app\n <mask> \n <mask> .. _Gunicorn: http://gunicorn.org/\n <mask> .. _eventlet: http://eventlet.net/\n <mask> .. _greenlet: https://greenlet.readthedocs.io/en/latest/\n <mask> \n <mask> uWSGI\n <mask> --------\n <mask>  </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove .. _uwsgi: http://projects.unbit.it/uwsgi/ </s> add .. _uwsgi: https://uwsgi-docs.readthedocs.io/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     $ uwsgi --http 127.0.0.1:5000 --module myproject:app\n <mask> \n <mask> For a more optimized setup, see :doc:`configuring uWSGI and NGINX <uwsgi>`.\n <mask> \n <mask> .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n <mask> .. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n <mask> \n <mask> Gevent\n <mask> -------\n <mask> \n <mask> `Gevent`_ is a coroutine-based Python networking library that uses </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/ </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/ </s> remove .. _Fabric: http://www.fabfile.org/ </s> add .. _Fabric: https://www.fabfile.org/ </s> remove .. _fabric: http://www.fabfile.org/ </s> add .. _fabric: https://www.fabfile.org/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/deploying/wsgi-standalone.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Many other features have been added, as well. A good guide to new features\n <mask> in HTML5 is Mark Pilgrim's soon-to-be-published book, `Dive Into HTML5`_.\n <mask> Not all of them are supported in browsers yet, however, so use caution.\n <mask> \n <mask> .. _Dive Into HTML5: http://diveintohtml5.info/\n <mask> \n <mask> What should be used?\n <mask> --------------------\n <mask> \n <mask> Currently, the answer is HTML5.  There are very few reasons to use XHTML </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_ </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/htmlfaq.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \techo.to the full path of the 'sphinx-build' executable. Alternatively you\n <mask> \techo.may add the Sphinx directory to PATH.\n <mask> \techo.\n <mask> \techo.If you don't have Sphinx installed, grab it from\n <mask> \techo.http://sphinx-doc.org/\n <mask> \texit /b 1\n <mask> )\n <mask> \n <mask> %SPHINXBUILD% -M %1 %SOURCEDIR% %BUILDDIR% %SPHINXOPTS%\n <mask> goto end </s> remove `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/make.bat"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Celery is a powerful task queue that can be used for simple background tasks\n <mask> as well as complex multi-stage programs and schedules. This guide will show you\n <mask> how to configure Celery using Flask, but assumes you've already read the\n <mask> `First Steps with Celery <http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html>`_\n <mask> guide in the Celery documentation.\n <mask> \n <mask> Install\n <mask> -------\n <mask>  </s> Use https for external links wherever possible </s> remove <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> add <https://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/celery.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> type ``fab deploy`` and see your application being deployed automatically\n <mask> to one or more remote servers.\n <mask> \n <mask> \n <mask> .. _Fabric: http://www.fabfile.org/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> remove Read more about `Sphinx <http://www.sphinx-doc.org>`_. </s> add Read more about `Sphinx <https://www.sphinx-doc.org>`_. </s> remove .. _fabric: http://www.fabfile.org/ </s> add .. _fabric: https://www.fabfile.org/ </s> remove .. _Gunicorn: http://gunicorn.org/\n.. _eventlet: http://eventlet.net/ </s> add .. _Gunicorn: https://gunicorn.org/\n.. _eventlet: https://eventlet.net/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/fabric.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Python primitives (numbers, strings, dicts and lists) look like which is\n <mask> widely supported and very easy to parse.  It became popular a few years\n <mask> ago and quickly replaced XML as transport format in web applications.\n <mask> \n <mask> .. _jQuery: http://jquery.com/\n <mask> \n <mask> Loading jQuery\n <mask> --------------\n <mask> \n <mask> In order to use jQuery, you have to download it first and place it in the </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/ </s> remove \techo.http://sphinx-doc.org/ </s> add \techo.https://www.sphinx-doc.org/", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [<User u'admin'>]\n <mask> >>> collection.User.find_one({'name': u'admin'})\n <mask> <User u'admin'>\n <mask> \n <mask> .. _MongoKit: http://bytebucket.org/namlook/mongokit/\n <mask> \n <mask> \n <mask> PyMongo Compatibility Layer\n <mask> ---------------------------\n <mask>  </s> remove .. _uwsgi: http://projects.unbit.it/uwsgi/ </s> add .. _uwsgi: https://uwsgi-docs.readthedocs.io/ </s> remove .. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router </s> add .. _uWSGI: https://uwsgi-docs.readthedocs.io/en/latest/\n.. _uWSGI HTTP Router: https://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/patterns/mongokit.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> text.  Not only these libraries, also the majority of web related Python\n <mask> libraries that deal with text.  If you don't know Unicode so far, you\n <mask> should probably read `The Absolute Minimum Every Software Developer\n <mask> Absolutely, Positively Must Know About Unicode and Character Sets\n <mask> <http://www.joelonsoftware.com/articles/Unicode.html>`_.  This part of the\n <mask> documentation just tries to cover the very basics so that you have a\n <mask> pleasant experience with Unicode related things.\n <mask> \n <mask> Automatic Conversion\n <mask> -------------------- </s> Use https for external links wherever possible </s> remove .. _Dive Into HTML5: http://diveintohtml5.info/ </s> add .. _Dive Into HTML5: http://diveintohtml5.info/table-of-contents.html </s> remove       <http://tools.ietf.org/html/rfc3987>`_.  Imagine your application is </s> add       <https://tools.ietf.org/html/rfc3987>`_.  Imagine your application is", "html_url": "https://github.com/pallets/flask/commit/f05625eb8239593daf755305e422b71d30c77054", "file_name": "docs/unicode.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _missing = object()\n <mask> \n <mask> \n <mask> def _get_data(req):\n <mask>     getter = getattr(req, 'get_data', None)\n <mask>     if getter is not None:\n <mask>         return getter()\n <mask>     return req.data\n <mask> \n <mask> \n <mask> class JSONMixin(object):\n <mask>     \"\"\"Mixin for both request and response classes to provide JSON parsing\n <mask>     capabilities.\n <mask> \n <mask>     .. versionadded:: 0.12\n </s> Alternative solution for lack of response caching </s> add     def _get_data_for_json(req, cache):\n        getter = getattr(req, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return req.data\n </s> remove             data = _get_data(self)\n </s> add             data = self._get_data_for_json(cache)", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         warn(DeprecationWarning('json is deprecated.  '\n <mask>                                 'Use get_json() instead.'), stacklevel=2)\n <mask>         return self.get_json()\n <mask> \n <mask>     def get_json(self, force=False, silent=False, cache=True):\n <mask>         \"\"\"Parses the incoming JSON request data and returns it.  By default\n <mask>         this function will return ``None`` if the mimetype is not\n <mask>         :mimetype:`application/json` but this can be overridden by the </s> remove def _get_data(req):\n    getter = getattr(req, 'get_data', None)\n    if getter is not None:\n        return getter()\n    return req.data </s> remove             data = _get_data(self) </s> add             data = self._get_data_for_json(cache)", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # that if the response charset was set explicitly then the data had\n <mask>         # been encoded correctly as well.\n <mask>         charset = self.mimetype_params.get('charset')\n <mask>         try:\n <mask>             data = _get_data(self)\n <mask>             if charset is not None:\n <mask>                 rv = json.loads(data, encoding=charset)\n <mask>             else:\n <mask>                 rv = json.loads(data)\n <mask>         except ValueError as e:\n </s> Alternative solution for lack of response caching </s> add     def _get_data_for_json(req, cache):\n        getter = getattr(req, 'get_data', None)\n        if getter is not None:\n            return getter(cache=cache)\n        return req.data\n </s> remove def _get_data(req):\n    getter = getattr(req, 'get_data', None)\n    if getter is not None:\n        return getter()\n    return req.data\n\n\n </s> add ", "html_url": "https://github.com/pallets/flask/commit/f0f458e0c5c4610cc210ef80a89b2b0870baa1b6", "file_name": "flask/wrappers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> `float`     like `int` but for floating point values\n <mask> `path`      like the default but also accepts slashes\n <mask> =========== ===========================================\n <mask> \n <mask> URL Building\n <mask> ````````````\n <mask> \n <mask> If it can match URLs, can it also generate them?  Of course you can.  To\n <mask> build a URL to a specific function you can use the :func:`~flask.url_for`\n <mask> function.  It accepts the name of the function as first argument and a </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`.", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> If it can match URLs, can it also generate them?  Of course you can.  To\n <mask> build a URL to a specific function you can use the :func:`~flask.url_for`\n <mask> function.  It accepts the name of the function as first argument and a\n <mask> number of keyword arguments, each corresponding to the variable part of\n <mask> the URL rule.  Here some examples:\n <mask> \n <mask> >>> from flask import Flask, url_for\n <mask> >>> app = Flask(__name__)\n <mask> >>> @app.route('/')\n <mask> ... def index(): pass </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`.", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> ...  print url_for('login')\n <mask> ...  print url_for('profile', username='John Doe')\n <mask> ... \n <mask> /\n <mask> /login\n <mask> /login?next=/\n <mask> /user/John%20Doe </s> add /login?next=/ </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`.", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> ...  print url_for('login', next='/')\n <mask> ... \n <mask> /\n <mask> /login\n <mask> /user/John%20Doe\n <mask> \n <mask> (This also uses the :meth:`~flask.Flask.test_request_context` method\n <mask> explained below.  It basically tells flask to think we are handling a </s> add ...  print url_for('login', next='/') </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples: </s> add     Variable arguments that are unknown to the target endpoint are appended\n    to the generated URL as query arguments.\n\n    For more information, head over to the :ref:`Quickstart <url-building>`.", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> def url_for(endpoint, **values):\n <mask>     \"\"\"Generates a URL to the given endpoint with the method provided.\n <mask> \n <mask>     :param endpoint: the endpoint of the URL (name of the function)\n <mask>     :param values: the variable arguments of the URL rule\n <mask>     \"\"\" </s> add the URL rule.  Unknown variable parts are appended to the URL as query\nparameter.  Here some examples:", "html_url": "https://github.com/pallets/flask/commit/f1603d33f266ab24eda604f76632fa604b91e3f9", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import pytest\n <mask> \n <mask> import os\n <mask> import datetime\n <mask> import flask\n <mask> from logging import StreamHandler\n <mask> from werkzeug.exceptions import BadRequest, NotFound\n <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_json_dump_to_file(self):\n        app = flask.Flask(__name__)\n\n        test_data = {'lol': 'wut'}\n\n        with app.app_context():\n            t_fh = open('test_json_dump_file', 'w')\n            flask.json.dump(test_data, t_fh)\n            t_fh.close()\n\n            t_fh = open('test_json_dump_file', 'r')\n            rv = flask.json.load(t_fh)\n            assert rv == test_data\n            t_fh.close()\n            os.remove('test_json_dump_file')\n </s> add     def test_jsonify_uuid_types(self):\n        \"\"\"Test jsonify with uuid.UUID types\"\"\"\n        test_uuid = uuid.UUID(bytes=b'\\xDE\\xAD\\xBE\\xEF'*4)\n\n        app = flask.Flask(__name__)\n        c = app.test_client()\n        url = '/uuid_test'\n        app.add_url_rule(url, 'uuid_test', lambda val=test_uuid: flask.jsonify(x=val))\n        rv = c.get(url)\n        assert rv.mimetype == 'application/json'\n        assert flask.json.loads(rv.data)['x'] == str(test_uuid)\n", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             assert rv == u'\"\\u2603\"'\n <mask> \n <mask>     def test_jsonify_basic_types(self):\n <mask>         \"\"\"Test jsonify with basic types.\"\"\"\n <mask>         # Should be able to use pytest parametrize on this, but I couldn't\n <mask>         # figure out the correct syntax\n <mask>         # https://pytest.org/latest/parametrize.html#pytest-mark-parametrize-parametrizing-test-functions\n <mask>         test_data = (0, 1, 23, 3.14, 's', \"longer string\", True, False,)\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_jsonify_uuid_types(self):\n        \"\"\"Test jsonify with uuid.UUID types\"\"\"\n        test_uuid = uuid.UUID(bytes=b'\\xDE\\xAD\\xBE\\xEF'*4)\n\n        app = flask.Flask(__name__)\n        c = app.test_client()\n        url = '/uuid_test'\n        app.add_url_rule(url, 'uuid_test', lambda val=test_uuid: flask.jsonify(x=val))\n        rv = c.get(url)\n        assert rv.mimetype == 'application/json'\n        assert flask.json.loads(rv.data)['x'] == str(test_uuid)\n </s> add import uuid", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     def test_json_attr(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.route('/add', methods=['POST'])\n <mask>         def add():\n <mask>             json = flask.request.get_json()\n <mask>             return text_type(json['a'] + json['b'])\n </s> Add tests for flask.json.dump() and test that jsonify correctly converts uuids. </s> add     def test_json_dump_to_file(self):\n        app = flask.Flask(__name__)\n\n        test_data = {'lol': 'wut'}\n\n        with app.app_context():\n            t_fh = open('test_json_dump_file', 'w')\n            flask.json.dump(test_data, t_fh)\n            t_fh.close()\n\n            t_fh = open('test_json_dump_file', 'r')\n            rv = flask.json.load(t_fh)\n            assert rv == test_data\n            t_fh.close()\n            os.remove('test_json_dump_file')\n </s> add import uuid", "html_url": "https://github.com/pallets/flask/commit/f16e477b2a7329d249b5793a0dc4986503a48371", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         rv = self.response_class()\n <mask>         rv.allow.update(methods)\n <mask>         return rv\n <mask> \n <mask>     def make_response(self, rv):\n <mask>         \"\"\"Converts the return value from a view function to a real\n <mask>         response object that is an instance of :attr:`response_class`.\n <mask>  </s> add         ctx = self.request_context(environ)\n        ctx.push()\n        error = None\n        try: </s> remove         if self.request.environ.get('flask._preserve_context') or \\\n           (tb is not None and self.app.preserve_context_on_exception):\n            self.preserved = True\n        else:\n            self.pop(exc_value)", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         :param start_response: a callable accepting a status code,\n <mask>                                a list of headers and an optional\n <mask>                                exception context to start the response\n <mask>         \"\"\"\n <mask>         with self.request_context(environ):\n <mask>             try:\n <mask>                 response = self.full_dispatch_request()\n <mask>             except Exception as e:\n <mask>                 response = self.make_response(self.handle_exception(e))\n <mask>             return response(environ, start_response) </s> add     def should_ignore_error(self, error):\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns `True` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False </s> remove         if self.request.environ.get('flask._preserve_context') or \\\n           (tb is not None and self.app.preserve_context_on_exception):\n            self.preserved = True\n        else:\n            self.pop(exc_value) </s> add         self.auto_pop(exc_value) </s> add - Changed how the teardown system is informed about exceptions.  This is now\n  more reliable in case something handles an exception halfway through\n  the error handling process.", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         # exception happened.  This will allow the debugger to still\n <mask>         # access the request object in the interactive shell.  Furthermore\n <mask>         # the context can be force kept alive for the test client.\n <mask>         # See flask.testing for how this works.\n <mask>         if self.request.environ.get('flask._preserve_context') or \\\n <mask>            (tb is not None and self.app.preserve_context_on_exception):\n <mask>             self.preserved = True\n <mask>         else:\n <mask>             self.pop(exc_value)\n <mask> \n <mask>     def __repr__(self):\n <mask>         return '<%s \\'%s\\' [%s] of %s>' % (\n <mask>             self.__class__.__name__,\n <mask>             self.request.url, </s> Changed teardown error handling to be more reliable. </s> add     def should_ignore_error(self, error):\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns `True` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False </s> add - Changed how the teardown system is informed about exceptions.  This is now\n  more reliable in case something handles an exception halfway through\n  the error handling process. </s> remove         with self.request_context(environ): </s> add         ctx = self.request_context(environ)\n        ctx.push()\n        error = None\n        try:", "html_url": "https://github.com/pallets/flask/commit/f1918093ac70d589a4d67af0d77140734c06c13d", "file_name": "flask/ctx.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace keep keep keep keep", "code_tokens": " <mask>     assert testapp.cli.name == testapp.name\n <mask> \n <mask> \n <mask> def test_find_best_app(test_apps):\n <mask>     \"\"\"Test of find_best_app.\"\"\"\n <mask>     class mod:\n <mask>         app = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.app\n <mask> \n <mask>     class mod:\n <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     assert find_best_app(mod) == mod.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(mod) == mod.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2') </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>         app = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.app\n <mask> \n <mask>     class mod:\n <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname') </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     assert find_best_app(mod) == mod.app </s> add     assert find_best_app(Module) == Module.app </s> remove     assert find_best_app(mod) == mod.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     \"\"\"Test of find_best_app.\"\"\"\n    class mod: </s> add     \"\"\"Test if `find_best_app` behaves as expected with different combinations of input.\"\"\"\n    class Module: </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2') </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module)", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask>         application = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.application\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.myapp\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>         myapp2 = Flask('appname2') </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     class mod:\n        myapp = Flask('appname')\n        myapp2 = Flask('appname2') </s> add     class Module:\n        pass\n    pytest.raises(NoAppException, find_best_app, Module) </s> remove     assert find_best_app(mod) == mod.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(mod) == mod.app </s> add     assert find_best_app(Module) == Module.app </s> remove     \"\"\"Test of find_best_app.\"\"\"\n    class mod: </s> add     \"\"\"Test if `find_best_app` behaves as expected with different combinations of input.\"\"\"\n    class Module:", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep keep", "code_tokens": " <mask>         myapp = Flask('appname')\n <mask>     assert find_best_app(mod) == mod.myapp\n <mask> \n <mask>     class mod:\n <mask>         myapp = Flask('appname')\n <mask>         myapp2 = Flask('appname2')\n <mask> \n <mask>     pytest.raises(NoAppException, find_best_app, mod)\n <mask> \n <mask>  </s> Enhance tests.test_cli.test_find_best_app (#1882)\n\nThis commit adds a test case for `test_find_best_app` where\r\nModule object does not contain Flask application.\r\nAlso cleans the function little bit to provides more meaningful comment. </s> remove     assert find_best_app(mod) == mod.myapp </s> add     assert find_best_app(Module) == Module.myapp </s> remove     assert find_best_app(mod) == mod.application </s> add     assert find_best_app(Module) == Module.application </s> remove     assert find_best_app(mod) == mod.app </s> add     assert find_best_app(Module) == Module.app", "html_url": "https://github.com/pallets/flask/commit/f19d3bd67e0d8213013cf06f47d951c8735515c8", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> \n <mask>       3. now you can run the minitwit.py file with your\n <mask>          python interpreter and the application will\n <mask>          greet you on http://localhost:5000/ </s> Added tests for minitwit.  Testing with Flask is awesome </s> remove             error = 'The two passwords to not match' </s> add             error = 'The two passwords do not match'", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "examples/minitwit/README"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             error = 'You have to enter a valid email address'\n <mask>         elif not request.form['password']:\n <mask>             error = 'You have to enter a password'\n <mask>         elif request.form['password'] != request.form['password2']:\n <mask>             error = 'The two passwords to not match'\n <mask>         elif get_user_id(request.form['username']) is not None:\n <mask>             error = 'The username is already taken'\n <mask>         else:\n <mask>             g.db.execute('''insert into user (\n <mask>                 username, email, pw_hash) values (?, ?, ?)''',\n </s> Added tests for minitwit.  Testing with Flask is awesome </s> add \t\n    ~ Is it tested?\n\n      You betcha.  Run the `minitwit_tests.py` file to\n      see the tests pass. </s> remove     @cached_property\n    def test(self):\n        \"\"\"A test client for this application\"\"\"\n </s> add     def test_client(self):\n        \"\"\"Creates a test client for this application\"\"\"", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         options.setdefault('use_reloader', self.debug)\n <mask>         options.setdefault('use_debugger', self.debug)\n <mask>         return run_simple(host, port, self, **options)\n <mask> \n <mask>     @cached_property\n <mask>     def test(self):\n <mask>         \"\"\"A test client for this application\"\"\"\n <mask>         from werkzeug import Client\n <mask>         return Client(self, self.response_class, use_cookies=True)\n <mask> \n <mask>     def open_resource(self, resource):\n <mask>         \"\"\"Opens a resource from the application's resource folder.  To see\n </s> Added tests for minitwit.  Testing with Flask is awesome </s> add \t\n    ~ Is it tested?\n\n      You betcha.  Run the `minitwit_tests.py` file to\n      see the tests pass. </s> remove             error = 'The two passwords to not match'\n </s> add             error = 'The two passwords do not match'", "html_url": "https://github.com/pallets/flask/commit/f2dc38cda61f76c64b97ab9f730accc986a4b188", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from sqlalchemy import create_engine\n <mask>     from sqlalchemy.orm import scoped_session, sessionmaker\n <mask>     from sqlalchemy.ext.declarative import declarative_base\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     db_session = scoped_session(sessionmaker(autocommit=False,\n <mask>                                              autoflush=False,\n <mask>                                              bind=engine)) \n <mask>     Base = declarative_base()\n <mask>     Base.query = db_session.query_property() </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     from sqlalchemy import create_engine, MetaData\n <mask>     from sqlalchemy.orm import scoped_session, sessionmaker\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     metadata = MetaData()\n <mask>     db_session = scoped_session(sessionmaker(autocommit=False,\n <mask>                                              autoflush=False,\n <mask>                                              bind=engine)) \n <mask>     def init_db(): </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> you basically only need the engine::\n <mask> \n <mask>     from sqlalchemy import create_engine, MetaData\n <mask> \n <mask>     engine = create_engine('sqlite:////tmp/test.db')\n <mask>     metadata = MetaData(bind=engine)\n <mask> \n <mask> Then you can either declare the tables in your code like in the examples\n <mask> above, or automatically load them::\n <mask>  </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True) </s> remove     engine = create_engine('sqlite:////tmp/test.db') </s> add     engine = create_engine('sqlite:////tmp/test.db', convert_unicode=True)", "html_url": "https://github.com/pallets/flask/commit/f345af8d9d33e6164747c865c29a72186a470c22", "file_name": "docs/patterns/sqlalchemy.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   JSON is handled by Flask or any Flask extension.\n <mask> - Removed deprecated internal ``flask.session`` module alias.  Use\n <mask>   ``flask.sessions`` instead to get the session module.  This is not to\n <mask>   be confused with ``flask.session`` the session proxy.\n <mask> \n <mask> Version 0.9\n <mask> -----------\n <mask>  </s> remove    The current session object (:class:`flask.session`) </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The current request object (:class:`flask.request`) </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context.", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>    .. versionadded:: 0.6\n <mask> \n <mask> .. data:: request\n <mask>    :noindex:\n <mask> \n <mask>    The current request object (:class:`flask.request`).  This variable is </s> remove    The current request object (:class:`flask.request`) </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> remove    The current session object (:class:`flask.session`) </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add     if reqctx is None:\n        return {}", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: request\n <mask>    :noindex:\n <mask> \n <mask>    The current request object (:class:`flask.request`)\n <mask> \n <mask> .. data:: session\n <mask>    :noindex:\n <mask> \n <mask>    The current session object (:class:`flask.session`) </s> remove    The current session object (:class:`flask.session`) </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42') </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: session\n <mask>    :noindex:\n <mask> \n <mask>    The current session object (:class:`flask.session`)\n <mask> \n <mask> .. data:: g\n <mask>    :noindex:\n <mask> \n <mask>    The request-bound object for global variables (:data:`flask.g`) </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> remove    The current request object (:class:`flask.request`) </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. data:: g\n <mask>    :noindex:\n <mask> \n <mask>    The request-bound object for global variables (:data:`flask.g`)\n <mask> \n <mask> .. function:: url_for\n <mask>    :noindex:\n <mask> \n <mask>    The :func:`flask.url_for` function. </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context. </s> remove    The current request object (:class:`flask.request`) </s> add    The current request object (:class:`flask.request`).  This variable is\n   unavailable if the template was rendered without an active request\n   context. </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "docs/templating.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             options['autoescape'] = self.select_jinja_autoescape\n <mask>         rv = Environment(self, **options)\n <mask>         rv.globals.update(\n <mask>             url_for=url_for,\n <mask>             get_flashed_messages=get_flashed_messages\n <mask>         )\n <mask>         rv.filters['tojson'] = json.htmlsafe_dumps\n <mask>         return rv\n <mask> \n <mask>     def create_global_jinja_loader(self): </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42') </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         :param context: the context as a dictionary that is updated in place\n <mask>                         to add extra variables.\n <mask>         \"\"\"\n <mask>         funcs = self.template_context_processors[None]\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.template_context_processors:\n <mask>             funcs = chain(funcs, self.template_context_processors[bp])\n <mask>         orig_ctx = context.copy()\n <mask>         for func in funcs:\n <mask>             context.update(func())\n <mask>         # make sure the original values win.  This makes it possible to\n <mask>         # easier add new variables in context processors without breaking </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> add     if reqctx is None:\n        return {} </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context.", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import posixpath\n <mask> from jinja2 import BaseLoader, Environment as BaseEnvironment, \\\n <mask>      TemplateNotFound\n <mask> \n <mask> from .globals import _request_ctx_stack\n <mask> from .signals import template_rendered\n <mask> from .module import blueprint_is_module\n <mask> \n <mask> \n <mask> def _default_template_ctx_processor(): </s> add     def test_request_less_rendering(self):\n        app = flask.Flask(__name__)\n        app.config['WORLD_NAME'] = 'Special World'\n        @app.context_processor\n        def context_processor():\n            return dict(foo=42)\n\n        with app.app_context():\n            rv = flask.render_template_string('Hello {{ config.WORLD_NAME }} '\n                                              '{{ foo }}')\n            self.assert_equal(rv, 'Hello Special World 42') </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     `session` and `g`.\n <mask>     \"\"\"\n <mask>     reqctx = _request_ctx_stack.top\n <mask>     return dict(\n <mask>         request=reqctx.request,\n <mask>         session=reqctx.session,\n <mask>         g=reqctx.g\n <mask>     )\n <mask>  </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `session` and `g`.\n <mask>     \"\"\"\n <mask>     reqctx = _request_ctx_stack.top\n <mask>     return dict(\n <mask>         config=reqctx.app.config,\n <mask>         request=reqctx.request,\n <mask>         session=reqctx.session,\n <mask>         g=reqctx.g\n <mask>     )\n <mask>  </s> add     if reqctx is None:\n        return {} </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                   the first one existing will be rendered\n <mask>     :param context: the variables that should be available in the\n <mask>                     context of the template.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     ctx.app.update_template_context(context)\n <mask>     return _render(ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n <mask>                    context, ctx.app)\n <mask> \n <mask>  </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add    The current session object (:class:`flask.session`).  This variable\n   is unavailable if the template was rendered without an active request\n   context.", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>                    rendered\n <mask>     :param context: the variables that should be available in the\n <mask>                     context of the template.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     ctx.app.update_template_context(context)\n <mask>     return _render(ctx.app.jinja_env.from_string(source),\n <mask>                    context, ctx.app) </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.template_context_processors:\n            funcs = chain(funcs, self.template_context_processors[bp]) </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add - Templates can now be rendered without request context.  The behavior is\n  slightly different as the ``request``, ``session`` and ``g`` objects\n  will not be available and blueprint's context processors are not\n  called.\n- The config object is now available to the template as a real global and\n  not through a context processor which makes it available even in imported\n  templates by default. </s> remove    The request-bound object for global variables (:data:`flask.g`) </s> add    The request-bound object for global variables (:data:`flask.g`).  This\n   variable is unavailable if the template was rendered without an active\n   request context. </s> add     if reqctx is None:\n        return {}", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/templating.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.data, '42')\n <mask> \n <mask>     def test_standard_context(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.secret_key = 'development key'\n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             flask.g.foo = 23 </s> remove from .globals import _request_ctx_stack </s> add from .globals import _request_ctx_stack, _app_ctx_stack </s> add         reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top </s> remove     ctx = _request_ctx_stack.top </s> add     ctx = _app_ctx_stack.top", "html_url": "https://github.com/pallets/flask/commit/f34c0281252bf1838e2ec24fe8b064b232a098ef", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> -   Python 3.12 compatibility.\n <mask> -   Require Werkzeug >= 2.3.6.\n <mask> -   Refactor how an app's root and instance paths are determined. :issue:`5160`\n <mask> \n <mask> \n <mask> Version 2.3.2 </s> remove [tool.setuptools.dynamic]\nversion = {attr = \"flask.__version__\"} </s> add [tool.flit.module]\nname = \"flask\"\n\n[tool.flit.sdist]\ninclude = [\n    \"docs/\",\n    \"examples/\",\n    \"requirements/\",\n    \"tests/\",\n    \"CHANGES.rst\",\n    \"CONTRIBUTING.rst\",\n    \"tox.ini\",\n]\nexclude = [\n    \"docs/_build/\",\n] </s> remove requires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\" </s> add requires = [\"flit_core<4\"]\nbuild-backend = \"flit_core.buildapi\"", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [project]\n <mask> name = \"Flask\"\n <mask> description = \"A simple framework for building complex web applications.\"\n <mask> readme = \"README.rst\"\n <mask> license = {text = \"BSD-3-Clause\"}\n <mask> maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n <mask> classifiers = [\n <mask>     \"Development Status :: 5 - Production/Stable\",\n <mask>     \"Environment :: Web Environment\",\n <mask>     \"Framework :: Flask\", </s> remove requires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\" </s> remove [tool.setuptools.dynamic]\nversion = {attr = \"flask.__version__\"} </s> add [tool.flit.module]\nname = \"flask\"\n\n[tool.flit.sdist]\ninclude = [\n    \"docs/\",\n    \"examples/\",\n    \"requirements/\",\n    \"tests/\",\n    \"CHANGES.rst\",\n    \"CONTRIBUTING.rst\",\n    \"tox.ini\",\n]\nexclude = [\n    \"docs/_build/\",\n] </s> add -   Use ``flit_core`` instead of ``setuptools`` as build backend.", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep keep replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> [project.scripts]\n <mask> flask = \"flask.cli:main\"\n <mask> \n <mask> [build-system]\n <mask> requires = [\"setuptools\"]\n <mask> build-backend = \"setuptools.build_meta\"\n <mask> \n <mask> [tool.setuptools.dynamic]\n <mask> version = {attr = \"flask.__version__\"}\n <mask> \n <mask> [tool.pytest.ini_options]\n <mask> testpaths = [\"tests\"]\n <mask> filterwarnings = [\n </s> switch to flit build backend </s> remove license = {text = \"BSD-3-Clause\"}\n </s> add license = {file = \"LICENSE.rst\"} </s> add -   Use ``flit_core`` instead of ``setuptools`` as build backend.", "html_url": "https://github.com/pallets/flask/commit/f38f3a745ab2f90084f495403ed28d4fc27e4b50", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> User's Guide\n <mask> ------------\n <mask> \n <mask> This part of the documentation is written text and should give you an idea\n <mask> how to work with Flask.  It's a series of step-by-step instructions for\n <mask> web development.\n <mask> \n <mask> .. toctree::\n <mask>    :maxdepth: 2\n <mask> \n <mask>    foreword </s> Copy edited and partially rewrote the foreword. </s> remove What does Micro Mean?\n--------------------- </s> add What does \"micro\" mean?\n----------------------- </s> remove questions about the intention of the project, what it aims at and when you </s> add questions about the purpose and goals of the project, and when you </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove For example Flask uses thread local objects internally so that you don't </s> add For example, Flask uses thread-local objects internally so that you don't </s> remove A Framework and An Example </s> add A Framework and an Example", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/contents.rst.inc"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace keep keep keep", "code_tokens": " <mask> ========\n <mask> \n <mask> Read this before you get started with Flask.  This hopefully answers some\n <mask> questions about the intention of the project, what it aims at and when you\n <mask> should or should not be using it.\n <mask> \n <mask> What does Micro Mean?\n <mask> ---------------------\n <mask> \n <mask> The micro in microframework for me means on the one hand being small in\n <mask> size and complexity but on the other hand also that the complexity of the </s> Copy edited and partially rewrote the foreword. </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove This part of the documentation is written text and should give you an idea\nhow to work with Flask.  It's a series of step-by-step instructions for\nweb development. </s> add This part of the documentation, which is mostly prose, begins with some\nbackground information about Flask, then focuses on step-by-step\ninstructions for web development with Flask. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove For example Flask uses thread local objects internally so that you don't </s> add For example, Flask uses thread-local objects internally so that you don't", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask> \n <mask> The micro in microframework for me means on the one hand being small in\n <mask> size and complexity but on the other hand also that the complexity of the\n <mask> applications that are written with these frameworks do not exceed a\n <mask> certain size.  A microframework like Flask sacrifices a few things in\n <mask> order to be approachable and to be as concise as possible.\n <mask> \n <mask> For example Flask uses thread local objects internally so that you don't\n <mask> have to pass objects around from function to function within a request in\n <mask> order to stay threadsafe.  While this is a really easy approach and saves </s> Copy edited and partially rewrote the foreword. </s> remove What does Micro Mean?\n--------------------- </s> add What does \"micro\" mean?\n----------------------- </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove A Framework and An Example </s> add A Framework and an Example </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> For example Flask uses thread local objects internally so that you don't\n <mask> have to pass objects around from function to function within a request in\n <mask> order to stay threadsafe.  While this is a really easy approach and saves\n <mask> you a lot of time, it also does not scale well to large applications.\n <mask> It's especially painful for more complex unittests and when you suddenly\n <mask> have to deal with code being executed outside of the context of a request\n <mask> (for example if you have cronjobs).\n <mask> \n <mask> Flask provides some tools to deal with the downsides of this approach but\n <mask> the core problem of this approach obviously stays.  It is also based on\n <mask> convention over configuration which means that a lot of things are\n <mask> preconfigured in Flask and will work well for smaller applications but not\n <mask> so much for larger ones (where and how it looks for templates, static\n <mask> files etc.)\n <mask> \n <mask> But don't worry if your application suddenly grows larger than it was\n <mask> initially and you're afraid Flask might not grow with it.  Even with\n <mask> larger frameworks you sooner or later will find out that you need\n <mask> something the framework just cannot do for you without modification.\n <mask> If you are ever in that situation, check out the :ref:`becomingbig`\n <mask> chapter.\n <mask> \n <mask> A Framework and An Example\n <mask> --------------------------\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a </s> Copy edited and partially rewrote the foreword. </s> remove For example Flask uses thread local objects internally so that you don't </s> add For example, Flask uses thread-local objects internally so that you don't </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask </s> remove Flask is not only a microframework, it is also an example.  Based on </s> add Flask is not only a microframework; it is also an example.  Based on </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like.", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask> A Framework and An Example\n <mask> --------------------------\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a\n <mask> framework.  Flask itself is just one way to implement a framework on top\n <mask> of existing libraries.  Unlike many other microframeworks Flask does not\n <mask> try to implement anything on its own, it reuses existing code.\n <mask> \n <mask> Flask is not only a microframework, it is also an example.  Based on\n <mask> Flask, there will be a series of blog posts that explain how to create a\n <mask> framework.  Flask itself is just one way to implement a framework on top\n <mask> of existing libraries.  Unlike many other microframeworks Flask does not\n <mask> try to implement anything on its own, it reuses existing code.\n <mask> \n <mask> Web Development is Dangerous\n <mask> ---------------------------- </s> remove A Framework and An Example </s> add A Framework and an Example </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove I'm not even joking.  Well, maybe a little.  If you write a web\napplication you are probably allowing users to register and leave their </s> add I'm not joking.  Well, maybe a little.  If you write a web\napplication, you are probably allowing users to register and leave their", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace", "code_tokens": " <mask> \n <mask> Web Development is Dangerous\n <mask> ----------------------------\n <mask> \n <mask> I'm not even joking.  Well, maybe a little.  If you write a web\n <mask> application you are probably allowing users to register and leave their\n <mask> data on your server.  The users are entrusting you with data.  And even if\n <mask> you are the only user that might leave data in your application, you still\n <mask> want that data to be stored in a secure manner. </s> Copy edited and partially rewrote the foreword. </s> remove Unfortunately there are many ways security of a web application can be </s> add Unfortunately, there are many ways the security of a web application can be </s> remove problems of modern web applications: cross site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure Flask (and the underlying\nJinja2 template engine) have you covered.  But there are many more ways to </s> add problems of modern web applications: cross-site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure, Flask and the underlying\nJinja2 template engine have you covered.  But there are many more ways to </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace keep", "code_tokens": " <mask> you are the only user that might leave data in your application, you still\n <mask> want that data to be stored in a secure manner.\n <mask> \n <mask> Unfortunately there are many ways security of a web application can be\n <mask> compromised.  Flask protects you against one of the most common security\n <mask> problems of modern web applications: cross site scripting (XSS).  Unless\n <mask> you deliberately mark insecure HTML as secure Flask (and the underlying\n <mask> Jinja2 template engine) have you covered.  But there are many more ways to\n <mask> cause security problems. </s> Copy edited and partially rewrote the foreword. </s> remove want that data to be stored in a secure manner. </s> add want that data to be stored securely. </s> remove I'm not even joking.  Well, maybe a little.  If you write a web\napplication you are probably allowing users to register and leave their </s> add I'm not joking.  Well, maybe a little.  If you write a web\napplication, you are probably allowing users to register and leave their </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications.", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask> cause security problems.\n <mask> \n <mask> Whenever something is dangerous where you have to watch out, the\n <mask> documentation will tell you so.  Some of the security concerns of web\n <mask> development are far more complex than one might think and often we all end\n <mask> up in situations where we think \"well, this is just far fetched, how could\n <mask> that possibly be exploited\" and then an intelligent guy comes along and\n <mask> figures a way out to exploit that application.  And don't think, your\n <mask> application is not important enough for hackers to take notice.  Depending\n <mask> on the kind of attack, chances are there are automated botnets out there\n <mask> trying to figure out how to fill your database with viagra advertisements.\n <mask> \n <mask> So always keep that in mind when doing web development.\n <mask> \n <mask> Target Audience </s> Copy edited and partially rewrote the foreword. </s> remove problems of modern web applications: cross site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure Flask (and the underlying\nJinja2 template engine) have you covered.  But there are many more ways to </s> add problems of modern web applications: cross-site scripting (XSS).  Unless\nyou deliberately mark insecure HTML as secure, Flask and the underlying\nJinja2 template engine have you covered.  But there are many more ways to </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove A Framework and An Example </s> add A Framework and an Example </s> remove Unfortunately there are many ways security of a web application can be </s> add Unfortunately, there are many ways the security of a web application can be", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Target Audience\n <mask> ---------------\n <mask> \n <mask> Is Flask for you?  If your application small-ish and does not depend on\n <mask> too complex database structures, Flask is the Framework for you.  It was\n <mask> designed from the ground up to be easy to use, based on established\n <mask> principles, good intentions and on top of two established libraries in\n <mask> widespread usage.  Recent versions of Flask scale nicely within reasonable\n <mask> bounds and if you grow larger, you won't have any troubles adjusting Flask\n <mask> for your new application size.\n <mask> \n <mask> If you suddenly discover that your application grows larger than\n <mask> originally intended, head over to the :ref:`becomingbig` section to see\n <mask> some possible solutions for larger applications. </s> remove It's especially painful for more complex unittests and when you suddenly\nhave to deal with code being executed outside of the context of a request\n(for example if you have cronjobs).\n\nFlask provides some tools to deal with the downsides of this approach but\nthe core problem of this approach obviously stays.  It is also based on\nconvention over configuration which means that a lot of things are\npreconfigured in Flask and will work well for smaller applications but not\nso much for larger ones (where and how it looks for templates, static\nfiles etc.)\n\nBut don't worry if your application suddenly grows larger than it was\ninitially and you're afraid Flask might not grow with it.  Even with\nlarger frameworks you sooner or later will find out that you need </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove Whenever something is dangerous where you have to watch out, the\ndocumentation will tell you so.  Some of the security concerns of web\ndevelopment are far more complex than one might think and often we all end\nup in situations where we think \"well, this is just far fetched, how could\nthat possibly be exploited\" and then an intelligent guy comes along and\nfigures a way out to exploit that application.  And don't think, your\napplication is not important enough for hackers to take notice.  Depending\non the kind of attack, chances are there are automated botnets out there\ntrying to figure out how to fill your database with viagra advertisements. </s> add The documentation will warn you about aspects of web development that\nrequire attention to security.  Some of these security concerns\nare far more complex than one might think, and we all sometimes underestimate\nthe likelihood that a vulnerability will be exploited, until a clever\nattacker figures out a way to exploit our applications.  And don't think\nthat your application is not important enough to attract an attacker.\nDepending on the kind of attack, chances are that automated bots are\nprobing for ways to fill your database with spam, links to malicious\nsoftware, and the like. </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications. </s> remove For example Flask uses thread local objects internally so that you don't </s> add For example, Flask uses thread-local objects internally so that you don't", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> If you suddenly discover that your application grows larger than\n <mask> originally intended, head over to the :ref:`becomingbig` section to see\n <mask> some possible solutions for larger applications.\n <mask> \n <mask> Satisfied?  Then head over to the :ref:`installation`. </s> remove Is Flask for you?  If your application small-ish and does not depend on\ntoo complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, based on established\nprinciples, good intentions and on top of two established libraries in\nwidespread usage.  Recent versions of Flask scale nicely within reasonable\nbounds and if you grow larger, you won't have any troubles adjusting Flask </s> add Is Flask for you?  If your application is small-ish and does not depend on\nvery complex database structures, Flask is the Framework for you.  It was\ndesigned from the ground up to be easy to use, and built on the firm\nfoundation of established principles, good intentions, and mature, widely\nused libraries.  Recent versions of Flask scale nicely within reasonable\nbounds, and if you grow larger, you won't have any trouble adjusting Flask </s> add It's especially painful for more complex unittests, and when you suddenly\nhave to deal with code being executed outside of the context of a request,\nsuch as in cron jobs.\n\nFlask provides some tools to deal with the downsides of this approach, but\nthe core problem remains.  Flask is also based on convention over\nconfiguration, which means that many things are preconfigured and will\nwork well for smaller applications but not so well for larger ones.  For\nexample, by convention, templates and static files are in subdirectories\nwithin the Python source tree of the application.\n\nBut don't worry if your application suddenly grows larger\nand you're afraid Flask might not grow with it.  Even with\nlarger frameworks, you'll eventually discover that you need </s> remove The micro in microframework for me means on the one hand being small in\nsize and complexity but on the other hand also that the complexity of the\napplications that are written with these frameworks do not exceed a\ncertain size.  A microframework like Flask sacrifices a few things in\norder to be approachable and to be as concise as possible. </s> add To me, the \"micro\" in microframework refers not only to the simplicity and\nsmall size of the framework, but also to the typically limited complexity\nand size of applications that are written with the framework.  To be\napproachable and concise, a microframework sacrifices a few features that\nmay be necessary in larger or more complex applications.", "html_url": "https://github.com/pallets/flask/commit/f3dd3da59e269cdf50839d9b0e86fa2849516483", "file_name": "docs/foreword.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>           - {name: '3.6', python: '3.6', os: ubuntu-latest, tox: py36}\n <mask>           - {name: 'PyPy', python: pypy3, os: ubuntu-latest, tox: pypy3}\n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask>       - uses: actions/setup-python@v2\n <mask>         with:\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add     typing </s> add include src/flask/py.typed", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": ".github/workflows/tests.yaml"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> graft docs\n <mask> prune docs/_build\n <mask> graft examples\n <mask> graft tests\n <mask> global-exclude *.pyc\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add     typing </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "MANIFEST.in"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> envlist =\n <mask>     py{39,38,37,36,py3}\n <mask>     style\n <mask>     docs\n <mask> skip_missing_interpreters = true\n <mask> \n <mask> [testenv]\n <mask> deps =\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add [testenv:typing]\ndeps = -r requirements/typing.txt\ncommands = mypy\n </s> add include src/flask/py.typed </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> skip_install = true\n <mask> commands = pre-commit run --all-files --show-diff-on-failure\n <mask> \n <mask> [testenv:docs]\n <mask> deps =\n <mask>     -r requirements/docs.txt\n <mask> \n <mask>     https://github.com/pallets/werkzeug/archive/master.tar.gz\n </s> Initial typing support\n\nThis enables type checking in CI and marks the project as typed. </s> add     typing </s> add include src/flask/py.typed </s> add           - {name: Typing, python: '3.9', os: ubuntu-latest, tox: typing}", "html_url": "https://github.com/pallets/flask/commit/f405c6f19e002ae13708cb33f6d48257cc1ea37a", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> - The :func:`flask.url_for` function now can generate anchors to the\n <mask>   generated links.\n <mask> - Logger now only returns the debug log setting if it was not set\n <mask>   explicitly.\n <mask> \n <mask> Version 0.8.1\n <mask> ------------- </s> Added support for _method to url_for() </s> remove        The `_anchor` parameter was added. </s> add        The `_anchor` and `_method` parameters were added. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external)", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     For more information, head over to the :ref:`Quickstart <url-building>`.\n <mask> \n <mask>     .. versionadded:: 0.9\n <mask>        The `_anchor` parameter was added.\n <mask> \n <mask>     :param endpoint: the endpoint of the URL (name of the function)\n <mask>     :param values: the variable arguments of the URL rule\n <mask>     :param _external: if set to `True`, an absolute URL is generated.\n <mask>     :param _anchor: if provided this is added as anchor to the URL. </s> Added support for _method to url_for() </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external) </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external)", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     :param _external: if set to `True`, an absolute URL is generated.\n <mask>     :param _anchor: if provided this is added as anchor to the URL.\n <mask>     \"\"\"\n <mask>     ctx = _request_ctx_stack.top\n <mask>     blueprint_name = request.blueprint\n <mask>     if not ctx.request._is_old_module:\n <mask>         if endpoint[:1] == '.': </s> Added support for _method to url_for() </s> remove        The `_anchor` parameter was added. </s> add        The `_anchor` and `_method` parameters were added. </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external) </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         elif endpoint.startswith('.'):\n <mask>             endpoint = endpoint[1:]\n <mask>     external = values.pop('_external', False)\n <mask>     anchor = values.pop('_anchor', None)\n <mask>     ctx.app.inject_url_defaults(endpoint, values)\n <mask>     rv = ctx.url_adapter.build(endpoint, values, method=method,\n <mask>                                force_external=external)\n <mask>     if anchor is not None:\n <mask>         rv += '#' + url_quote(anchor)\n <mask>     return rv </s> Added support for _method to url_for() </s> remove     rv = ctx.url_adapter.build(endpoint, values, force_external=external) </s> add     rv = ctx.url_adapter.build(endpoint, values, method=method,\n                               force_external=external) </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> remove        The `_anchor` parameter was added. </s> add        The `_anchor` and `_method` parameters were added. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             endpoint = endpoint[1:]\n <mask>     external = values.pop('_external', False)\n <mask>     anchor = values.pop('_anchor', None)\n <mask>     ctx.app.inject_url_defaults(endpoint, values)\n <mask>     rv = ctx.url_adapter.build(endpoint, values, force_external=external)\n <mask>     if anchor is not None:\n <mask>         rv += '#' + url_quote(anchor)\n <mask>     return rv\n <mask> \n <mask>  </s> Added support for _method to url_for() </s> add     method = values.pop('_method', None) </s> add     :param _method: if provided this explicitly specifies an HTTP method. </s> remove        The `_anchor` parameter was added. </s> add        The `_anchor` and `_method` parameters were added. </s> add - The :func:`flask.url_for` function now can also explicitly generate\n  URL rules specific to a given HTTP method.", "html_url": "https://github.com/pallets/flask/commit/f52e7a9dc944f425c2f2a77706bc2af98b23295c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep replace replace keep keep replace replace", "code_tokens": " <mask>    **Something that is untested is broken.**\n <mask> \n <mask> Not sure where that is coming from, and it's not entirely correct, but\n <mask> also not that far from the truth.  Untested applications make it hard to\n <mask> improve existing code and developers of untested applications tend to\n <mask> become pretty paranoid.  If an application has automated tests, you can\n <mask> safely change things, and you will instantly know if your change broke\n <mask> something. </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation. </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Even though it did not run any tests, we already know that our flaskr </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove All the other objects that are context bound can be used the same. </s> add All the other objects that are context bound can be used in the same\nway. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`,", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> become pretty paranoid.  If an application has automated tests, you can\n <mask> safely change things, and you will instantly know if your change broke\n <mask> something.\n <mask> \n <mask> Flask gives you a couple of ways to test applications.  It mainly does\n <mask> that by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\n <mask> code and handling the context locals for you.  You can then use that with\n <mask> your favourite testing solution.  In this documentation we will use the\n <mask> :mod:`unittest` package that comes preinstalled with each Python\n <mask> installation.\n <mask> \n <mask> The Application\n <mask> ---------------\n <mask> \n <mask> First we need an application to test for functionality.  For the testing </s> remove safely change things, and you will instantly know if your change broke\nsomething. </s> add safely make changes and instantly know if anything breaks. </s> remove Not sure where that is coming from, and it's not entirely correct, but\nalso not that far from the truth.  Untested applications make it hard to </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_. </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The Application\n <mask> ---------------\n <mask> \n <mask> First we need an application to test for functionality.  For the testing\n <mask> we will use the application from the :ref:`tutorial`.  If you don't have\n <mask> that application yet, get the sources from `the examples`_.\n <mask> \n <mask> .. _the examples:\n <mask>    http://github.com/mitsuhiko/flask/tree/master/examples/flaskr/\n <mask> \n <mask> The Testing Skeleton </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation. </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The Testing Skeleton\n <mask> --------------------\n <mask> \n <mask> In order to test that, we add a second module (\n <mask> `flaskr_tests.py`) and create a unittest skeleton there::\n <mask> \n <mask>     import os\n <mask>     import flaskr\n <mask>     import unittest\n <mask>     import tempfile </s> remove Even though it did not run any tests, we already know that our flaskr </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> remove Now we can also test that adding messages works.  Add a new test method </s> add We should also test that adding messages works.  Add a new test method", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     if __name__ == '__main__':\n <mask>         unittest.main()\n <mask> \n <mask> The code in the :meth:`~unittest.TestCase.setUp` method creates a new test\n <mask> client and initializes a new database.  That function is called before\n <mask> each individual test function.  To delete the database after the test, we\n <mask> close the file and remove it from the filesystem in the\n <mask> :meth:`~unittest.TestCase.tearDown` method.  What the test client does is\n <mask> give us a simple interface to the application.  We can trigger test\n <mask> requests to the application, and the client will also keep track of cookies\n <mask> for us.\n <mask> \n <mask> Because SQLite3 is filesystem-based we can easily use the tempfile module\n <mask> to create a temporary database and initialize it.  The\n <mask> :func:`~tempfile.mkstemp` function does two things for us: it returns a\n <mask> low-level file handle and a random file name, the latter we use as </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove If we now run that test suite, we should see the following output:: </s> add If we now run the test suite, we should see the following output:: </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`. </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in. </s> remove In order to test that, we add a second module (\n`flaskr_tests.py`) and create a unittest skeleton there:: </s> add In order to test the application, we add a second module \n(`flaskr_tests.py`) and create a unittest skeleton there:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> low-level file handle and a random file name, the latter we use as\n <mask> database name.  We just have to keep the `db_fd` around so that we can use\n <mask> the :func:`os.close` function to close the file.\n <mask> \n <mask> If we now run that test suite, we should see the following output::\n <mask> \n <mask>     $ python flaskr_tests.py\n <mask> \n <mask>     ----------------------------------------------------------------------\n <mask>     Ran 0 tests in 0.000s </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Even though it did not run any tests, we already know that our flaskr </s> add Even though it did not run any actual tests, we already know that our flaskr </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in. </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`. </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_. </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Ran 0 tests in 0.000s\n <mask> \n <mask>     OK\n <mask> \n <mask> Even though it did not run any tests, we already know that our flaskr\n <mask> application is syntactically valid, otherwise the import would have died\n <mask> with an exception.\n <mask> \n <mask> The First Test\n <mask> -------------- </s> remove If we now run that test suite, we should see the following output:: </s> add If we now run the test suite, we should see the following output:: </s> remove Of course you can submit forms with the test client as well, which we will\nuse now to log our user in. </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without </s> add If you were to use just the :meth:`~flask.Flask.test_client` without </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove Not sure where that is coming from, and it's not entirely correct, but\nalso not that far from the truth.  Untested applications make it hard to", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> The First Test\n <mask> --------------\n <mask> \n <mask> Now we can add the first test.  Let's check that the application shows\n <mask> \"No entries here so far\" if we access the root of the application (``/``).\n <mask> For that we modify our created test case class so that it looks like\n <mask> this::\n <mask> \n <mask>     class FlaskrTestCase(unittest.TestCase):\n <mask> \n <mask>         def setUp(self):\n <mask>             self.db_fd, flaskr.app.config['DATABASE'] = tempfile.mkstemp() </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation. </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`,", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         def test_empty_db(self):\n <mask>             rv = self.app.get('/')\n <mask>             assert 'No entries here so far' in rv.data\n <mask> \n <mask> Test functions begin with the word `test`.  Every function named like that\n <mask> will be picked up automatically.  By using `self.app.get` we can send an\n <mask> HTTP `GET` request to the application with the given path.  The return\n <mask> value will be a :class:`~flask.Flask.response_class` object.  We can now\n <mask> use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\n <mask> return value (as string) from the application.  In this case, we ensure\n <mask> that ``'No entries here so far'`` is part of the output.\n <mask> \n <mask> Run it again and you should see one passing test::\n <mask> \n <mask>     $ python flaskr_tests.py\n <mask>     . </s> remove If we now run that test suite, we should see the following output:: </s> add If we now run the test suite, we should see the following output:: </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`. </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     Ran 1 test in 0.034s\n <mask> \n <mask>     OK\n <mask> \n <mask> Of course you can submit forms with the test client as well, which we will\n <mask> use now to log our user in.\n <mask> \n <mask> Logging In and Out\n <mask> ------------------\n <mask> \n <mask> The majority of the functionality of our application is only available for\n <mask> the administrative user, so we need a way to log our test client in to the\n <mask> application and out of it again.  For that we fire some requests to the\n <mask> login and logout pages with the required form data (username and\n <mask> password).  Because the login and logout pages redirect, we tell the\n <mask> client to `follow_redirects`.\n <mask> \n <mask> Add the following two methods to your `FlaskrTestCase` class::\n <mask> \n <mask>    def login(self, username, password): </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove If we now run that test suite, we should see the following output:: </s> add If we now run the test suite, we should see the following output:: </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation. </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can easily test if logging in and out works and that it fails with </s> add Now we can easily test that logging in and out works and that it fails with", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    def logout(self):\n <mask>        return self.app.get('/logout', follow_redirects=True)\n <mask> \n <mask> Now we can easily test if logging in and out works and that it fails with\n <mask> invalid credentials.  Add this new test to the class::\n <mask> \n <mask>    def test_login_logout(self):\n <mask>        rv = self.login('admin', 'default')\n <mask>        assert 'You were logged in' in rv.data </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`. </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without </s> add If you were to use just the :meth:`~flask.Flask.test_client` without", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Test Adding Messages\n <mask> --------------------\n <mask> \n <mask> Now we can also test that adding messages works.  Add a new test method\n <mask> like this::\n <mask> \n <mask>     def test_messages(self):\n <mask>         self.login('admin', 'default')\n <mask>         rv = self.app.post('/add', data=dict( </s> fixing some wording issues on the testing page\n\nSigned-off-by: Armin Ronacher <armin.ronacher@active-4.com> </s> remove Now we can easily test if logging in and out works and that it fails with </s> add Now we can easily test that logging in and out works and that it fails with </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> add Now it's time to start testing the functionality of the application.  \nLet's check that the application shows \"No entries here so far\" if we \naccess the root of the application (``/``). To do this, we add a new\ntest method to our class, like this:: </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove functions.  Here's a full example that showcases this:: </s> add functions.  Here is a full example that demonstrates this approach::", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     OK\n <mask> \n <mask> For more complex tests with headers and status codes, check out the\n <mask> `MiniTwit Example`_ from the sources.  That one contains a larger test\n <mask> suite.\n <mask> \n <mask> \n <mask> .. _MiniTwit Example:\n <mask>    http://github.com/mitsuhiko/flask/tree/master/examples/minitwit/ </s> remove the administrative user, so we need a way to log our test client in to the\napplication and out of it again.  For that we fire some requests to the\nlogin and logout pages with the required form data (username and\npassword).  Because the login and logout pages redirect, we tell the\nclient to `follow_redirects`. </s> add the administrative user, so we need a way to log our test client in and out\nof the application.  To do this, we fire some requests to the login and logout \npages with the required form data (username and password).  And because the \nlogin and logout pages redirect, we tell the client to `follow_redirects`. </s> remove First we need an application to test for functionality.  For the testing\nwe will use the application from the :ref:`tutorial`.  If you don't have\nthat application yet, get the sources from `the examples`_. </s> add First, we need an application to test; we will use the application from \nthe :ref:`tutorial`.  If you don't have that application yet, get the \nsources from `the examples`_. </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us. </s> add client and initializes a new database.  This function is called before\neach individual test function is run.  To delete the database after the \ntest, we close the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  \n\nThis test client will give us a simple interface to the application.  We can \ntrigger test requests to the application, and the client will also keep track \nof cookies for us. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace", "code_tokens": " <mask> \n <mask> Other Testing Tricks\n <mask> --------------------\n <mask> \n <mask> Besides using the test client we used above, there is also the\n <mask> :meth:`~flask.Flask.test_request_context` method that in combination with\n <mask> the `with` statement can be used to activate a request context\n <mask> temporarily.  With that you can access the :class:`~flask.request`,\n <mask> :class:`~flask.g` and :class:`~flask.session` objects like in view\n <mask> functions.  Here's a full example that showcases this:: </s> remove All the other objects that are context bound can be used the same. </s> add All the other objects that are context bound can be used in the same\nway. </s> remove Sometimes it can be helpful to trigger a regular request but keep the </s> add Sometimes it is helpful to trigger a regular request but still keep the </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove Now we can add the first test.  Let's check that the application shows\n\"No entries here so far\" if we access the root of the application (``/``).\nFor that we modify our created test case class so that it looks like\nthis:: </s> remove client and initializes a new database.  That function is called before\neach individual test function.  To delete the database after the test, we\nclose the file and remove it from the filesystem in the\n:meth:`~unittest.TestCase.tearDown` method.  What the test client does is\ngive us a simple interface to the application.  We can trigger test\nrequests to the application, and the client will also keep track of cookies\nfor us.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with app.test_request_context('/?name=Peter'):\n <mask>         assert flask.request.path == '/'\n <mask>         assert flask.request.args['name'] == 'Peter'\n <mask> \n <mask> All the other objects that are context bound can be used the same.\n <mask> \n <mask> If you want to test your application with different configurations and\n <mask> there does not seem to be a good way to do that, consider switching to\n <mask> application factories (see :ref:`app-factories`).\n <mask>  </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove If you would just be using the :meth:`~flask.Flask.test_client` without </s> add If you were to use just the :meth:`~flask.Flask.test_client` without </s> remove is no longer available (because used outside of an actual request).\nKeep in mind however that :meth:`~flask.Flask.after_request` functions\nare already called at that point so your database connection and </s> add is no longer available (because you are trying to use it outside of the actual request).\nHowever, keep in mind that any :meth:`~flask.Flask.after_request` functions\nare already called at this point so your database connection and", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> --------------------------\n <mask> \n <mask> .. versionadded:: 0.4\n <mask> \n <mask> Sometimes it can be helpful to trigger a regular request but keep the\n <mask> context around for a little longer so that additional introspection can\n <mask> happen.  With Flask 0.4 this is possible by using the\n <mask> :meth:`~flask.Flask.test_client` with a `with` block::\n <mask> \n <mask>     app = flask.Flask(__name__) </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove Flask gives you a couple of ways to test applications.  It mainly does\nthat by exposing the Werkzeug test :class:`~werkzeug.test.Client` class to your\ncode and handling the context locals for you.  You can then use that with\nyour favourite testing solution.  In this documentation we will use the\n:mod:`unittest` package that comes preinstalled with each Python\ninstallation. </s> add Flask provides a way to test your application by exposing the Werkzeug \ntest :class:`~werkzeug.test.Client` and handling the context locals for you.\nYou can then use that with your favourite testing solution.  In this documentation\nwe will use the :mod:`unittest` package that comes pre-installed with Python. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output. </s> remove is no longer available (because used outside of an actual request).\nKeep in mind however that :meth:`~flask.Flask.after_request` functions\nare already called at that point so your database connection and </s> add is no longer available (because you are trying to use it outside of the actual request).\nHowever, keep in mind that any :meth:`~flask.Flask.after_request` functions\nare already called at this point so your database connection and", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep replace keep replace replace replace", "code_tokens": " <mask>         assert request.args['tequila'] == '42'\n <mask> \n <mask> If you would just be using the :meth:`~flask.Flask.test_client` without\n <mask> the `with` block, the `assert` would fail with an error because `request`\n <mask> is no longer available (because used outside of an actual request).\n <mask> Keep in mind however that :meth:`~flask.Flask.after_request` functions\n <mask> are already called at that point so your database connection and </s> remove Besides using the test client we used above, there is also the\n:meth:`~flask.Flask.test_request_context` method that in combination with\nthe `with` statement can be used to activate a request context\ntemporarily.  With that you can access the :class:`~flask.request`, </s> add Besides using the test client as shown above, there is also the\n:meth:`~flask.Flask.test_request_context` method that can be used\nin combination with the `with` statement to activate a request context\ntemporarily.  With this you can access the :class:`~flask.request`, </s> remove Test functions begin with the word `test`.  Every function named like that\nwill be picked up automatically.  By using `self.app.get` we can send an\nHTTP `GET` request to the application with the given path.  The return\nvalue will be a :class:`~flask.Flask.response_class` object.  We can now\nuse the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect the\nreturn value (as string) from the application.  In this case, we ensure\nthat ``'No entries here so far'`` is part of the output. </s> add Notice that our test functions begin with the word `test`; this allows \n:mod:`unittest` to automatically identify the method as a test to run. \n\nBy using `self.app.get` we can send an HTTP `GET` request to the application with \nthe given path.  The return value will be a :class:`~flask.Flask.response_class` object. \nWe can now use the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute to inspect\nthe return value (as string) from the application.  In this case, we ensure that \n``'No entries here so far'`` is part of the output.", "html_url": "https://github.com/pallets/flask/commit/f58c98904f83aeff934b66d87b4e42a06ceb840d", "file_name": "docs/testing.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flash('No file part')\n <mask>                 return redirect(request.url)\n <mask>             file = request.files['file']\n <mask>             # if user does not select file, browser also\n <mask>             # submit a empty part without filename\n <mask>             if file.filename == '':\n <mask>                 flash('No selected file')\n <mask>                 return redirect(request.url)\n <mask>             if file and allowed_file(file.filename):\n <mask>                 filename = secure_filename(file.filename) </s> remove The reason for this is that some file-like objects have a invalid or even </s> add The reason for this is that some file-like objects have an invalid or even </s> remove         #: To register a error handler, use the :meth:`errorhandler` </s> add         #: To register an error handler, use the :meth:`errorhandler`", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/patterns/fileuploads.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         is on its own line.\n <mask>         \"\"\"\n <mask> \n <mask> Module header:\n <mask>   The module header consists of an utf-8 encoding declaration (if non\n <mask>   ASCII letters are used, but it is recommended all the time) and a\n <mask>   standard docstring::\n <mask> \n <mask>     # -*- coding: utf-8 -*-\n <mask>     \"\"\" </s> remove # The unique identifier of the text. This can be a ISBN number </s> add # The unique identifier of the text. This can be an ISBN number </s> remove         #: To register a error handler, use the :meth:`errorhandler` </s> remove The reason for this is that some file-like objects have a invalid or even </s> add The reason for this is that some file-like objects have an invalid or even", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/styleguide.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # ETag still needs to be manually set\n <mask>     response = send_file(open(fname), attachment_filename=fname)\n <mask>     response.set_etag(...)\n <mask> \n <mask> The reason for this is that some file-like objects have a invalid or even\n <mask> misleading ``name`` attribute. Silently swallowing errors in such cases was not\n <mask> a satisfying solution.\n <mask> \n <mask> Additionally the default of falling back to ``application/octet-stream`` has\n <mask> been restricted. If Flask can't guess one or the user didn't provide one, the </s> remove   The module header consists of an utf-8 encoding declaration (if non </s> add   The module header consists of a utf-8 encoding declaration (if non", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> applications with Flask.  Because we want to make upgrading as easy as\n <mask> possible we tried to counter the problems arising from these changes by\n <mask> providing a script that can ease the transition.\n <mask> \n <mask> The script scans your whole application and generates an unified diff with\n <mask> changes it assumes are safe to apply.  However as this is an automated\n <mask> tool it won't be able to find all use cases and it might miss some.  We\n <mask> internally spread a lot of deprecation warnings all over the place to make\n <mask> it easy to find pieces of code that it was unable to upgrade.\n <mask>  </s> Fix typos/grammar in docs (#2201) </s> remove     output an unified diff with all the changes that are necessary to easily </s> add     output a unified diff with all the changes that are necessary to easily </s> remove         When a teardown function was called because of a exception it will </s> add         When a teardown function was called because of an exception it will </s> add # The unique identifier of the text. This can be an ISBN number", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: special key ``None`` points to a list of tuples where the first item\n <mask>         #: is the class for the instance check and the second the error handler\n <mask>         #: function.\n <mask>         #:\n <mask>         #: To register a error handler, use the :meth:`errorhandler`\n <mask>         #: decorator.\n <mask>         self.error_handler_spec = {None: self._error_handlers}\n <mask> \n <mask>         #: A list of functions that are called when :meth:`url_for` raises a\n <mask>         #: :exc:`~werkzeug.routing.BuildError`.  Each function registered here </s> remove         When a teardown function was called because of a exception it will </s> add         When a teardown function was called because of an exception it will", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         that they will fail.  If they do execute code that might fail they\n <mask>         will have to surround the execution of these code by try/except\n <mask>         statements and log occurring errors.\n <mask> \n <mask>         When a teardown function was called because of a exception it will\n <mask>         be passed an error object.\n <mask> \n <mask>         The return values of teardown functions are ignored.\n <mask> \n <mask>         .. admonition:: Debug Note </s> remove The script scans your whole application and generates an unified diff with </s> add The script scans your whole application and generates a unified diff with </s> remove         #: To register a error handler, use the :meth:`errorhandler` </s> add         #: To register an error handler, use the :meth:`errorhandler` </s> remove     output an unified diff with all the changes that are necessary to easily </s> add     output a unified diff with all the changes that are necessary to easily", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     flask-07-upgrade\n <mask>     ~~~~~~~~~~~~~~~~\n <mask> \n <mask>     This command line script scans a whole application tree and attempts to\n <mask>     output an unified diff with all the changes that are necessary to easily\n <mask>     upgrade the application to 0.7 and to not yield deprecation warnings.\n <mask> \n <mask>     This will also attempt to find `after_request` functions that don't modify\n <mask>     the response and appear to be better suited for `teardown_request`.\n <mask>  </s> remove         When a teardown function was called because of a exception it will </s> add         When a teardown function was called because of an exception it will", "html_url": "https://github.com/pallets/flask/commit/f5adb61b28f240effbba5a4686647c2af6e85b94", "file_name": "scripts/flask-07-upgrade.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import Map, Rule\n <mask> from werkzeug.exceptions import HTTPException, InternalServerError, NotFound\n <mask> \n <mask> from .helpers import _PackageBoundObject, url_for, get_flashed_messages, \\\n <mask>     _tojson_filter\n <mask> from .wrappers import Request, Response\n <mask> from .config import ConfigAttribute, Config\n <mask> from .ctx import _RequestContext\n <mask> from .globals import _request_ctx_stack, request\n <mask> from .session import Session, _NullSession </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint), </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint),", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                         Starting with Flask 0.6, `OPTIONS` is implicitly\n <mask>                         added and handled by the standard request handling.\n <mask>         \"\"\"\n <mask>         if endpoint is None:\n <mask>             assert view_func is not None, 'expected view func if endpoint ' \\\n <mask>                                           'is not provided.'\n <mask>             endpoint = view_func.__name__\n <mask>         options['endpoint'] = endpoint\n <mask>         methods = options.pop('methods', ('GET',))\n <mask>         provide_automatic_options = False\n <mask>         if 'OPTIONS' not in methods:\n <mask>             methods = tuple(methods) + ('OPTIONS',) </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint), </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options): </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> else:\n <mask>     _tojson_filter = json.dumps\n <mask> \n <mask> \n <mask> def jsonify(*args, **kwargs):\n <mask>     \"\"\"Creates a :class:`~flask.Response` with the JSON representation of\n <mask>     the given arguments with an `application/json` mimetype.  The arguments\n <mask>     to this function are the same as to the :class:`dict` constructor.\n <mask> \n <mask>     Example usage:: </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func)", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :copyright: (c) 2010 by Armin Ronacher.\n <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from .helpers import _PackageBoundObject\n <mask> \n <mask> \n <mask> def _register_module(module, static_path):\n <mask>     \"\"\"Internal helper function that returns a function for recording\n <mask>     that registers the `send_static_file` function for the module on </s> endpoint is optional for modules.  This fixes #86", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.add_url_rule(rule, f.__name__, f, **options)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint, view_func=None, **options):\n <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             the_rule = rule </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint), </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add     def test_default_endpoint_name(self):\n        app = flask.Flask(__name__)\n        mod = flask.Module(__name__, 'frontend')\n        def index():\n            return 'Awesome'\n        mod.add_url_rule('/', view_func=index)\n        app.register_module(mod)\n        rv = app.test_client().get('/')\n        assert rv.data == 'Awesome'\n        with app.test_request_context():\n            assert flask.url_for('frontend.index') == '/'", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             the_rule = rule\n <mask>             if state.url_prefix:\n <mask>                 the_rule = state.url_prefix + rule\n <mask>             the_endpoint = endpoint </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options): </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> remove             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint), </s> add             the_endpoint = endpoint\n            if the_endpoint is None:\n                the_endpoint = _endpoint_from_view_func(view_func)\n            state.app.add_url_rule(the_rule, '%s.%s' % (self.name,\n                                                        the_endpoint), </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func)", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def register_rule(state):\n <mask>             the_rule = rule\n <mask>             if state.url_prefix:\n <mask>                 the_rule = state.url_prefix + rule\n <mask>             state.app.add_url_rule(the_rule, '%s.%s' % (self.name, endpoint),\n <mask>                                    view_func, **options)\n <mask>         self._record(register_rule)\n <mask> \n <mask>     def before_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function </s> remove     def add_url_rule(self, rule, endpoint, view_func=None, **options): </s> add     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func)", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "flask/module.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         assert c.get('/admin/login').data == 'admin login'\n <mask>         assert c.get('/admin/logout').data == 'admin logout'\n <mask> \n <mask>     def test_request_processing(self):\n <mask>         catched = []\n <mask>         app = flask.Flask(__name__)\n <mask>         admin = flask.Module(__name__, 'admin', url_prefix='/admin') </s> remove             assert view_func is not None, 'expected view func if endpoint ' \\\n                                          'is not provided.'\n            endpoint = view_func.__name__ </s> add             endpoint = _endpoint_from_view_func(view_func) </s> add def _endpoint_from_view_func(view_func):\n    \"\"\"Internal helper that returns the default endpoint for a given\n    function.  This always is the function name.\n    \"\"\"\n    assert view_func is not None, 'expected view func if endpoint ' \\\n                                  'is not provided.'\n    return view_func.__name__ </s> add         .. versionchanged:: 0.6\n           The `endpoint` argument is now optional and will default to the\n           function name to consistent with the function of the same name\n           on the application object. </s> add from .helpers import _PackageBoundObject, _endpoint_from_view_func", "html_url": "https://github.com/pallets/flask/commit/f5b8c082847baa8a902cef22c43a5d50d7a55bdc", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>   mimetype parameter.\n <mask> - Don't modify the session on :func:`flask.get_flashed_messages` if there\n <mask>   are no messages in the session.\n <mask> - `before_request` handlers are now able to abort requests with errors.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask>  </s> remove         handler = self.error_handlers.get(500) </s> add         handler = self.error_handler_spec[None].get(500) </s> remove             app.error_handlers[404] = page_not_found </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove         explicitly by the user of this method. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> remove         handler = self.error_handlers.get(e.code) </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 return 'This page does not exist', 404\n <mask> \n <mask>         You can also register a function as error handler without using\n <mask>         the :meth:`errorhandler` decorator.  The following example is\n <mask>         equivalent to the one above::\n <mask> \n <mask>             def page_not_found(error): </s> remove             app.error_handlers[404] = page_not_found </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> remove             self.error_handlers[code] = f </s> add             self._register_error_handler(None, code_or_exception, f) </s> remove         handler = self.error_handlers.get(500) </s> add         handler = self.error_handler_spec[None].get(500) </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>                 return 'This page does not exist', 404\n <mask>             app.error_handlers[404] = page_not_found\n <mask> \n <mask>         :param code: the code as integer for the handler\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             self.error_handlers[code] = f\n <mask>             return f </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500 </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> remove         handler = self.error_handlers.get(e.code) </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         handler = self.error_handlers.get(500) </s> add         handler = self.error_handler_spec[None].get(500)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             self._register_error_handler(None, code_or_exception, f)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def template_filter(self, name=None):\n <mask>         \"\"\"A decorator that is used to register custom template filter.\n <mask>         You can specify a name for the filter, otherwise the function\n <mask>         name will be used. Example:: </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add         handler = self.error_handler_spec[None].get(500)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         exception as response.\n <mask> \n <mask>         .. versionadded: 0.3\n <mask>         \"\"\"\n <mask>         handler = self.error_handlers.get(e.code)\n <mask>         if handler is None:\n <mask>             return e\n <mask>         return handler(e)\n <mask> \n <mask>     def handle_exception(self, e): </s> remove             app.error_handlers[404] = page_not_found </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove             self.error_handlers[code] = f </s> add             self._register_error_handler(None, code_or_exception, f) </s> remove         except HTTPException, e:\n            rv = self.handle_http_exception(e) </s> add         except Exception, e:\n            rv = self.handle_user_exception(e) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500 </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> add     def test_user_error_handling(self):\n        class MyException(Exception):\n            pass\n\n        app = flask.Flask(__name__)\n        @app.errorhandler(MyException)\n        def handle_my_exception(e):\n            assert isinstance(e, MyException)\n            return '42'\n        @app.route('/')\n        def index():\n            raise MyException()\n\n        c = app.test_client()\n        assert c.get('/').data == '42'", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         exc_type, exc_value, tb = sys.exc_info()\n <mask> \n <mask>         got_request_exception.send(self, exception=e)\n <mask>         handler = self.error_handlers.get(500)\n <mask> \n <mask>         if self.propagate_exceptions:\n <mask>             # if we want to repropagate the exception, we can attempt to\n <mask>             # raise it with the whole traceback in case we can do that\n <mask>             # (the function was actually called from the except part) </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers. </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> remove             self.error_handlers[code] = f </s> add             self._register_error_handler(None, code_or_exception, f) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             request_started.send(self)\n <mask>             rv = self.preprocess_request()\n <mask>             if rv is None:\n <mask>                 rv = self.dispatch_request()\n <mask>         except HTTPException, e:\n <mask>             rv = self.handle_http_exception(e)\n <mask>         response = self.make_response(rv)\n <mask>         response = self.process_response(response)\n <mask>         request_finished.send(self, response=response)\n <mask>         return response\n <mask>  </s> remove         handler = self.error_handlers.get(e.code) </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         handler = self.error_handlers.get(500) </s> add         handler = self.error_handler_spec[None].get(500) </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> remove             self.error_handlers[code] = f </s> add             self._register_error_handler(None, code_or_exception, f)", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         self.static_url_path = static_url_path\n <mask>         self.deferred_functions = []\n <mask> \n <mask>     def _record(self, func):\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def _record_once(self, func): </s> add         explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint. </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def endpoint(self, endpoint):\n <mask>         \"\"\"Like :meth:`Flask.endpoint` but for a module.  This does not\n <mask>         prefix the endpoint with the module name, this has to be done\n <mask>         explicitly by the user of this method.\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             def register_endpoint(state):\n <mask>                 state.app.view_functions[endpoint] = f\n <mask>             self._record_once(register_endpoint) </s> remove             app.error_handlers[404] = page_not_found </s> add             app.error_handler_spec[None][404] = page_not_found\n\n        Setting error handlers via assignments to :attr:`error_handler_spec`\n        however is discouraged as it requires fidling with nested dictionaries\n        and the special case for arbitrary exception types.\n\n        The first `None` refers to the active blueprint.  If the error\n        handler should be application wide `None` shall be used.\n\n        .. versionadded:: 0.7\n           One can now additionally also register custom exception types\n           that do not necessarily have to be a subclass of the\n           :class:~`werkzeug.exceptions.HTTPException` class. </s> remove             self.error_handlers[code] = f </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> add         handler = self.error_handler_spec[None].get(500) </s> add - it is not possible to define user exception handlers.  That way you can\n  provide custom error messages from a central hub for certain errors that\n  might occur during request processing (for instance database connection\n  errors, timeouts from remote resources etc.).\n- Blueprints can provide blueprint specific error handlers.", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         assert rv.status_code == 500\n <mask>         assert 'internal server error' == rv.data\n <mask> \n <mask>     def test_teardown_on_pop(self):\n <mask>         buffer = []\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.teardown_request </s> add     def _register_error_handler(self, key, code_or_exception, f):\n        if isinstance(code_or_exception, HTTPException):\n            code_or_exception = code_or_exception.code\n        if isinstance(code_or_exception, (int, long)):\n            assert code_or_exception != 500 or key is None, \\\n                'It is currently not possible to register a 500 internal ' \\\n                'server error on a per-blueprint level.'\n            self.error_handler_spec.setdefault(key, {})[code_or_exception] = f\n        else:\n            self.error_handler_spec.setdefault(key, {}).setdefault(None, []) \\\n                .append((code_or_exception, f)) </s> add         handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code) </s> remove         except HTTPException, e:\n            rv = self.handle_http_exception(e) </s> add         except Exception, e:\n            rv = self.handle_user_exception(e) </s> add         You can also register handlers for arbitrary exceptions::\n\n            @app.errorhandler(DatabaseError)\n            def special_exception_handler(error):\n                return 'Database connection failed', 500", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     suite.addTest(unittest.makeSuite(BasicFunctionalityTestCase))\n <mask>     suite.addTest(unittest.makeSuite(TemplatingTestCase))\n <mask>     suite.addTest(unittest.makeSuite(ModuleTestCase))\n <mask>     suite.addTest(unittest.makeSuite(SendfileTestCase))\n <mask>     suite.addTest(unittest.makeSuite(LoggingTestCase))\n <mask>     suite.addTest(unittest.makeSuite(ConfigTestCase))\n <mask>     suite.addTest(unittest.makeSuite(SubdomainTestCase))\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase)) </s> add         self.view_functions = {}", "html_url": "https://github.com/pallets/flask/commit/f5ec9952decda8731a1f40ba788ba06d12c0229b", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   requests that do not pop the request stack for testing.\n <mask> - because the Python standard library caches loggers, the name of\n <mask>   the logger is configurable now to better support unittests.\n <mask> \n <mask> Version 0.3.1\n <mask> -------------\n <mask> \n </s> Added TESTING flag.  This fixes #58. </s> add ``TESTING``                     enable/disable testing mode </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> =============================== =========================================\n <mask> ``DEBUG``                       enable/disable debug mode\n <mask> ``SECRET_KEY``                  the secret key\n <mask> ``SESSION_COOKIE_NAME``         the name of the session cookie\n <mask> ``PERMANENT_SESSION_LIFETIME``  the lifetime of a permanent session as\n <mask>                                 :class:`datetime.timedelta` object.\n <mask> ``USE_X_SENDFILE``              enable/disable x-sendfile\n <mask> =============================== =========================================\n </s> Added TESTING flag.  This fixes #58. </s> add - added `TESTING` switch that can activate unittesting helpers. </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     #: This attribute can also be configured from the config with the `DEBUG`\n <mask>     #: configuration key.  Defaults to `False`.\n <mask>     debug = ConfigAttribute('DEBUG')\n <mask> \n <mask>     #: If a secret key is set, cryptographic components can use this to\n <mask>     #: sign cookies and other things.  Set this to a complex random value\n <mask>     #: when you want to use the secure cookie for instance.\n <mask>     #:\n </s> Added TESTING flag.  This fixes #58. </s> add ``TESTING``                     enable/disable testing mode </s> add - added `TESTING` switch that can activate unittesting helpers. </s> add         'TESTING':                              False,", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     default_config = ImmutableDict({\n <mask>         'DEBUG':                                False,\n <mask>         'SECRET_KEY':                           None,\n <mask>         'SESSION_COOKIE_NAME':                  'session',\n <mask>         'PERMANENT_SESSION_LIFETIME':           timedelta(days=31),\n <mask>         'USE_X_SENDFILE':                       False,\n </s> Added TESTING flag.  This fixes #58. </s> add     #: The testing flask.  Set this to `True` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate unittest helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: `TESTING` configuration key.  Defaults to `False`.\n    testing = ConfigAttribute('TESTING')\n </s> add ``TESTING``                     enable/disable testing mode </s> add - added `TESTING` switch that can activate unittesting helpers.", "html_url": "https://github.com/pallets/flask/commit/f5fb4576577cbedcedba9eb16d9fdace18c9292c", "file_name": "flask.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     for x, node in enumerate(from_imports):\n <mask>         values = node.value\n <mask>         if (values[0].value == 'flask') and (values[1].value == 'ext'):\n <mask>             # Case 1\n <mask>             if len(node.value) == 3:\n <mask>                 package = values[2].value\n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> add def test_no_change_to_import():\n    red = RedBaron(\"from flask import Flask\")\n    output = migrate.fix_tester(red)\n    assert output == \"from flask import Flask\" </s> remove def test__named_from_import():\n </s> add def test_named_from_import():", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/flaskext_migrate.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == \"import flask_foo as foobar\"\n <mask> \n <mask> \n <mask> def test__named_from_import():\n <mask>     red = RedBaron(\"from flask.ext.foo import bar as baz\")\n <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == \"from flask_foo import bar as baz\"\n <mask> \n <mask> \n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> add def test_no_change_to_import():\n    red = RedBaron(\"from flask import Flask\")\n    output = migrate.fix_tester(red)\n    assert output == \"from flask import Flask\" </s> add         if len(values) < 2:\n            continue", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/test_import_migration.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>                    \"flask.ext.foo.bar(var)\")\n <mask>     output = migrate.fix_tester(red)\n <mask>     assert output == (\"import flask_foo\\n\\n\"\n <mask>                       \"flask_foo.bar(var)\")\n </s> Add skip to fix unnoticed bug with good imports\n\nFixes logic so that imports that should not be changed are skipped, which was not happening correctly before. </s> remove def test__named_from_import():\n </s> add def test_named_from_import(): </s> add         if len(values) < 2:\n            continue", "html_url": "https://github.com/pallets/flask/commit/f6c45afb6ffa9fc1bd3d3637f7d38e423798dce9", "file_name": "scripts/test_import_migration.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def set_debug_value(ctx, value):\n <mask>     ctx.ensure_object(ScriptInfo).debug = value\n <mask> \n <mask> \n <mask> def set_app_value(ctx, value):\n <mask>     if value is not None:\n <mask>         if os.path.isfile(value):\n <mask>             value = prepare_exec_for_file(value)\n </s> Switch to newer click (2.0) </s> remove         'click>=0.6',\n </s> add         'click>=2.0',", "html_url": "https://github.com/pallets/flask/commit/f6d25bbc4f95112e9f5f85096d12a61ed43b38b8", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Add ``routes`` CLI command to output routes registered on the application.\n <mask>   (`#2259`_)\n <mask> \n <mask> .. _#1489: https://github.com/pallets/flask/pull/1489\n <mask> .. _#1898: https://github.com/pallets/flask/pull/1898\n <mask> .. _#1936: https://github.com/pallets/flask/pull/1936\n <mask> .. _#2017: https://github.com/pallets/flask/pull/2017\n <mask> .. _#2223: https://github.com/pallets/flask/pull/2223 </s> add .. _#2282: https://github.com/pallets/flask/pull/2282", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "CHANGES"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> import os\n <mask> import sys\n <mask> import pkgutil\n <mask> import posixpath\n <mask> import mimetypes </s> add </s> remove from warnings import warn </s> add import warnings </s> remove             socket.inet_pton(family, ip) </s> add             socket.inet_pton(family, value) </s> remove     import socket </s> add", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     :rtype: int\n <mask>     \"\"\"\n <mask>     return td.days * 60 * 60 * 24 + td.seconds\n <mask> \n <mask> def is_ip(ip):\n <mask>     \"\"\"Returns the if the string received is an IP or not.\n <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     import socket </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def is_ip(ip):\n <mask>     \"\"\"Returns the if the string received is an IP or not.\n <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not. </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     import socket </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     :param string: the string to check if it an IP or not\n <mask>     :param var_name: the name of the string that is being checked\n <mask> \n <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket\n <mask> \n <mask>     for family in (socket.AF_INET, socket.AF_INET6):\n <mask>         try: </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not. </s> remove     import socket </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove             socket.inet_pton(family, ip) </s> add             socket.inet_pton(family, value)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace", "code_tokens": " <mask>     :returns: True if string is an IP, False if not\n <mask>     :rtype: boolean\n <mask>     \"\"\"\n <mask>     import socket\n <mask> \n <mask>     for family in (socket.AF_INET, socket.AF_INET6):\n <mask>         try:\n <mask>             socket.inet_pton(family, ip) </s> remove     :returns: True if string is an IP, False if not\n    :rtype: boolean </s> add     :param value: value to check\n    :type value: str\n\n    :return: True if string is an IP address\n    :rtype: bool </s> remove     :param string: the string to check if it an IP or not\n    :param var_name: the name of the string that is being checked </s> add def is_ip(value):\n    \"\"\"Determine if the given string is an IP address. </s> remove def is_ip(ip):\n    \"\"\"Returns the if the string received is an IP or not. </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic.", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> import uuid\n <mask> import hashlib\n <mask> from warnings import warn\n <mask> from base64 import b64encode, b64decode\n <mask> from datetime import datetime\n <mask> from werkzeug.http import http_date, parse_date\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> from . import Markup, json </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove     import socket </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used. </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic.", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>         return isinstance(obj, self.null_session_class)\n <mask> \n <mask>     def get_cookie_domain(self, app):\n <mask>         \"\"\"Helpful helper method that returns the cookie domain that should\n <mask>         be used for the session cookie if session cookies are used.\n <mask>         \"\"\"\n <mask>         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n <mask>             return app.config['SESSION_COOKIE_DOMAIN']\n <mask>         if app.config['SERVER_NAME'] is not None:\n <mask>             # chop off the port which is usually not supported by browsers\n <mask>             rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n <mask> \n <mask>             # Google chrome does not like cookies set to .localhost, so\n <mask>             # we just go with no domain then.  Flask documents anyways that\n <mask>             # cross domain cookies need a fully qualified domain name\n <mask>             if rv == '.localhost':\n <mask>                 rv = None\n <mask> \n <mask>             # If we infer the cookie domain from the server name we need\n <mask>             # to check if we are in a subpath.  In that case we can't\n <mask>             # set a cross domain cookie.\n <mask>             if rv is not None:\n <mask>                 path = self.get_cookie_path(app)\n <mask>                 if path != '/':\n <mask>                     rv = rv.lstrip('.')\n <mask> \n <mask>             return rv\n <mask> \n <mask>     def get_cookie_path(self, app):\n <mask>         \"\"\"Returns the path for which the cookie should be valid.  The </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if domain is not None:\n            if is_ip(domain):\n                warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning) </s> add - Show warning when session cookie domain is a bare hostname or an IP\n  address, as these may not behave properly in some browsers, such as Chrome.\n  (`#2282`_)\n- Allow IP address as exact session cookie domain. (`#2282`_)\n- ``SESSION_COOKIE_DOMAIN`` is set if it is detected through ``SERVER_NAME``.\n  (`#2282`_)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             return self.session_class()\n <mask> \n <mask>     def save_session(self, app, session, response):\n <mask>         domain = self.get_cookie_domain(app)\n <mask>         if domain is not None:\n <mask>             if is_ip(domain):\n <mask>                 warnings.warn(\"IP introduced in SESSION_COOKIE_DOMAIN\", RuntimeWarning)\n <mask>         path = self.get_cookie_path(app)\n <mask> \n <mask>         # Delete case.  If there is no session we bail early.\n <mask>         # If the session was modified to be empty we remove the\n <mask>         # whole cookie. </s> refactor session cookie domain logic\ncache result of session cookie domain\nadd warnings for session cookie domain issues\nadd changelog </s> remove         if app.config['SESSION_COOKIE_DOMAIN'] is not None:\n            return app.config['SESSION_COOKIE_DOMAIN']\n        if app.config['SERVER_NAME'] is not None:\n            # chop off the port which is usually not supported by browsers\n            rv = '.' + app.config['SERVER_NAME'].rsplit(':', 1)[0]\n\n            # Google chrome does not like cookies set to .localhost, so\n            # we just go with no domain then.  Flask documents anyways that\n            # cross domain cookies need a fully qualified domain name\n            if rv == '.localhost':\n                rv = None\n\n            # If we infer the cookie domain from the server name we need\n            # to check if we are in a subpath.  In that case we can't\n            # set a cross domain cookie.\n            if rv is not None:\n                path = self.get_cookie_path(app)\n                if path != '/':\n                    rv = rv.lstrip('.')\n\n            return rv </s> add         rv = app.config['SESSION_COOKIE_DOMAIN']\n\n        # set explicitly, or cached from SERVER_NAME detection\n        # if False, return None\n        if rv is not None:\n            return rv if rv else None\n\n        rv = app.config['SERVER_NAME']\n\n        # server name not set, cache False to return none next time\n        if not rv:\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        # chop off the port which is usually not supported by browsers\n        # remove any leading '.' since we'll add that later\n        rv = rv.rsplit(':', 1)[0].lstrip('.')\n\n        if '.' not in rv:\n            # Chrome doesn't allow names without a '.'\n            # this should only come up with localhost\n            # hack around this by not setting the name, and show a warning\n            warnings.warn(\n                '\"{rv}\" is not a valid cookie domain, it must contain a \".\".'\n                ' Add an entry to your hosts file, for example'\n                ' \"{rv}.localdomain\", and use that instead.'.format(rv=rv)\n            )\n            app.config['SESSION_COOKIE_DOMAIN'] = False\n            return None\n\n        ip = is_ip(rv)\n\n        if ip:\n            warnings.warn(\n                'The session cookie domain is an IP address. This may not work'\n                ' as intended in some browsers. Add an entry to your hosts'\n                ' file, for example \"localhost.localdomain\", and use that'\n                ' instead.'\n            )\n\n        # if this is not an ip and app is mounted at the root, allow subdomain\n        # matching by adding a '.' prefix\n        if self.get_cookie_path(app) == '/' and not ip:\n            rv = '.' + rv\n\n        app.config['SESSION_COOKIE_DOMAIN'] = rv\n        return rv </s> remove         \"\"\"Helpful helper method that returns the cookie domain that should\n        be used for the session cookie if session cookies are used. </s> add         \"\"\"Returns the domain that should be set for the session cookie.\n        \n        Uses ``SESSION_COOKIE_DOMAIN`` if it is configured, otherwise\n        falls back to detecting the domain based on ``SERVER_NAME``.\n        \n        Once detected (or if not set at all), ``SESSION_COOKIE_DOMAIN`` is\n        updated to avoid re-running the logic. </s> add - Show warning when session cookie domain is a bare hostname or an IP\n  address, as these may not behave properly in some browsers, such as Chrome.\n  (`#2282`_)\n- Allow IP address as exact session cookie domain. (`#2282`_)\n- ``SESSION_COOKIE_DOMAIN`` is set if it is detected through ``SERVER_NAME``.\n  (`#2282`_)", "html_url": "https://github.com/pallets/flask/commit/f75ad9fca2e17c4777a3d7efc65f3ccab261e22c", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   debug mode.\n <mask> \n <mask> Version 0.12.1\n <mask> --------------\n <mask> \n <mask> Bugfix release, released on March 31st 2017 </s> remove             ('/a', '../b/c', ), </s> add             ('/a', '../b/c'), </s> remove             ('/a', 'b/../../c', ), </s> add             ('/a', 'b/../../c'), </s> remove             ('/a', 'b/../b/../../c', ), </s> add             ('/a', 'b/../b/../../c'), </s> add             (('/a/b/c', ''), '/a/b/c/'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :raises: :class:`~werkzeug.exceptions.NotFound` if one or more passed\n <mask>             paths fall out of its boundaries.\n <mask>     \"\"\"\n <mask>     for filename in pathnames:\n <mask>         if filename != '':\n <mask>             filename = posixpath.normpath(filename)\n <mask>  </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove         for sep in _os_alt_seps:\n            if sep in filename:\n                raise NotFound()\n        if os.path.isabs(filename) or \\\n           filename == '..' or \\\n           filename.startswith('../'): </s> add         if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            or filename == '..'\n            or filename.startswith('../')\n        ): </s> remove         directory = os.path.join(directory, filename)\n    return directory </s> add         parts.append(filename)\n\n    return posixpath.join(*parts)", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace keep replace replace keep", "code_tokens": " <mask>     for filename in pathnames:\n <mask>         if filename != '':\n <mask>             filename = posixpath.normpath(filename)\n <mask>         for sep in _os_alt_seps:\n <mask>             if sep in filename:\n <mask>                 raise NotFound()\n <mask>         if os.path.isabs(filename) or \\\n <mask>            filename == '..' or \\\n <mask>            filename.startswith('../'):\n <mask>             raise NotFound()\n <mask>         directory = os.path.join(directory, filename)\n <mask>     return directory\n <mask>  </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> add     parts = [directory] </s> add             ('/a', '../b/c'), </s> add             ('/a', 'b/../../c'), </s> add             ('/a', 'b/../b/../../c'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace keep replace keep keep", "code_tokens": " <mask>         passing = (\n <mask>             (('a/b/c', ), 'a/b/c'),\n <mask>             (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n <mask>             (('a', 'b', 'c', ), 'a/b/c'),\n <mask>             (('/a', 'b/c', ), '/a/b/c'),\n <mask>             (('a/b', 'X/../c'), 'a/b/c', ),\n <mask>             (('/a/b', 'c/X/..'), '/a/b/c', ),\n <mask>             # If last path is '' add a slash\n <mask>             (('/a/b/c', '', ), '/a/b/c/', ),\n <mask>             # Preserve dot slash\n <mask>             (('/a/b/c', './', ), '/a/b/c/.', ), </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ), </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             ('/a', '../b/c', ), </s> add             ('/a', '../b/c'), </s> remove             ('/a', 'b/../b/../../c', ), </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', 'b/../../c', ), </s> add             ('/a', 'b/../../c'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             (('/a/b', 'c/X/..'), '/a/b/c', ),\n <mask>             # If last path is '' add a slash\n <mask>             (('/a/b/c', '', ), '/a/b/c/', ),\n <mask>             # Preserve dot slash\n <mask>             (('/a/b/c', './', ), '/a/b/c/.', ),\n <mask>             (('a/b/c', 'X/..'), 'a/b/c/.', ),\n <mask>             # Base directory is always considered safe\n <mask>             (('../', 'a/b/c'), '../a/b/c'),\n <mask>             (('/..', ), '/..'),\n <mask>         )\n <mask>  </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             (('/a/b/c', '', ), '/a/b/c/', ), </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ), </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             ('/a', 'b/../b/../../c', ), </s> remove             ('/a', 'b/../../c', ), </s> remove             ('/a', '../b/c', ), </s> remove         directory = os.path.join(directory, filename)\n    return directory", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>         # Should raise werkzeug.exceptions.NotFound on unsafe joins.\n <mask>         failing = (\n <mask>             # path.isabs and ``..'' checks\n <mask>             ('/a', 'b', '/c'),\n <mask>             ('/a', '../b/c', ),\n <mask>             ('/a', '..', 'b/c'),\n <mask>             # Boundaries violations after path normalization\n <mask>             ('/a', 'b/../b/../../c', ),\n <mask>             ('/a', 'b', 'c/../..'),\n <mask>             ('/a', 'b/../../c', ),\n <mask>         ) </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             ('/a', 'b/../../c', ), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ), </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ), </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             (('/a/b/c', '', ), '/a/b/c/', ), </s> add             (('/a/b/c', ''), '/a/b/c/'),", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ('/a', '..', 'b/c'),\n <mask>             # Boundaries violations after path normalization\n <mask>             ('/a', 'b/../b/../../c', ),\n <mask>             ('/a', 'b', 'c/../..'),\n <mask>             ('/a', 'b/../../c', ),\n <mask>         )\n <mask> \n <mask>         for args in failing:\n <mask>             with pytest.raises(NotFound):\n <mask>                 print(flask.safe_join(*args)) </s> safe_join on Windows uses posixpath\n\nfixes #2033\ncloses #2059 </s> remove             ('/a', 'b/../b/../../c', ), </s> add             ('/a', 'b/../b/../../c'), </s> remove             ('/a', '../b/c', ), </s> add             ('/a', '../b/c'), </s> remove             (('/a/b/c', './', ), '/a/b/c/.', ),\n            (('a/b/c', 'X/..'), 'a/b/c/.', ), </s> add             (('/a/b/c', './'), '/a/b/c/.'),\n            (('a/b/c', 'X/..'), 'a/b/c/.'), </s> remove             (('a/b/c', ), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/', ), '/a/b/c'),\n            (('a', 'b', 'c', ), 'a/b/c'),\n            (('/a', 'b/c', ), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c', ),\n            (('/a/b', 'c/X/..'), '/a/b/c', ), </s> add             (('a/b/c',), 'a/b/c'),\n            (('/', 'a/', 'b/', 'c/'), '/a/b/c'),\n            (('a', 'b', 'c'), 'a/b/c'),\n            (('/a', 'b/c'), '/a/b/c'),\n            (('a/b', 'X/../c'), 'a/b/c'),\n            (('/a/b', 'c/X/..'), '/a/b/c'), </s> remove             (('/a/b/c', '', ), '/a/b/c/', ), </s> add             (('/a/b/c', ''), '/a/b/c/'), </s> add         parts.append(filename)\n\n    return posixpath.join(*parts)", "html_url": "https://github.com/pallets/flask/commit/f7c35bf0d51d1ae02709e39fe29110e12f64fb87", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace", "code_tokens": " <mask>       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n <mask>       # Try uploading to Test PyPI first, in case something fails.\n <mask>       - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n <mask>         with:\n <mask>           password: ${{ secrets.TEST_PYPI_TOKEN }}\n <mask>           repository_url: https://test.pypi.org/legacy/\n <mask>           packages_dir: artifact/\n <mask>       - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n <mask>         with:\n <mask>           password: ${{ secrets.PYPI_TOKEN }}\n </s> use oidc instead of token </s> add     permissions:\n      id-token: write", "html_url": "https://github.com/pallets/flask/commit/f7d9956c0f0e9a80b1d345adac191f6ebd0ffee4", "file_name": ".github/workflows/publish.yaml"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace", "code_tokens": " <mask> babel==2.8.0              # via sphinx\n <mask> certifi==2020.4.5.1       # via requests\n <mask> chardet==3.0.4            # via requests\n <mask> colorama==0.4.3           # via sphinx\n <mask> docutils==0.16            # via sphinx\n <mask> idna==2.9                 # via requests\n <mask> imagesize==1.2.0          # via sphinx\n <mask> importlib-metadata==1.7.0  # via pallets-sphinx-themes </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove pygments==2.6.1           # via sphinx </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove zipp==3.1.0               # via importlib-metadata", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> jinja2==2.11.2            # via sphinx\n <mask> markupsafe==1.1.1         # via jinja2\n <mask> packaging==20.4           # via -r requirements/docs.in, pallets-sphinx-themes, sphinx\n <mask> pallets-sphinx-themes==1.2.3  # via -r requirements/docs.in\n <mask> pygments==2.6.1           # via sphinx\n <mask> pyparsing==2.4.7          # via packaging\n <mask> pytz==2020.1              # via babel\n <mask> requests==2.23.0          # via sphinx\n <mask> six==1.15.0               # via packaging\n <mask> snowballstemmer==2.0.0    # via sphinx </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove colorama==0.4.3           # via sphinx </s> remove zipp==3.1.0               # via importlib-metadata", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> requests==2.23.0          # via sphinx\n <mask> six==1.15.0               # via packaging\n <mask> snowballstemmer==2.0.0    # via sphinx\n <mask> sphinx-issues==1.2.0      # via -r requirements/docs.in\n <mask> sphinx-tabs==1.1.13       # via -r requirements/docs.in\n <mask> sphinx==3.2.1             # via -r requirements/docs.in, pallets-sphinx-themes, sphinx-issues, sphinx-tabs, sphinxcontrib-log-cabinet\n <mask> sphinxcontrib-applehelp==1.0.2  # via sphinx\n <mask> sphinxcontrib-devhelp==1.0.2  # via sphinx\n <mask> sphinxcontrib-htmlhelp==1.0.3  # via sphinx\n <mask> sphinxcontrib-jsmath==1.0.1  # via sphinx </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove pygments==2.6.1           # via sphinx </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes </s> remove colorama==0.4.3           # via sphinx </s> remove zipp==3.1.0               # via importlib-metadata", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask> sphinxcontrib-log-cabinet==1.0.1  # via -r requirements/docs.in\n <mask> sphinxcontrib-qthelp==1.0.3  # via sphinx\n <mask> sphinxcontrib-serializinghtml==1.1.4  # via sphinx\n <mask> urllib3==1.25.9           # via requests\n <mask> zipp==3.1.0               # via importlib-metadata\n <mask> \n <mask> # The following packages are considered to be unsafe in a requirements file:\n <mask> # setuptools </s> Bump sphinx-tabs from 1.1.13 to 1.3.0 (#3822)\n\nBumps [sphinx-tabs](https://github.com/executablebooks/sphinx-tabs) from 1.1.13 to 1.3.0.\r\n- [Release notes](https://github.com/executablebooks/sphinx-tabs/releases)\r\n- [Changelog](https://github.com/executablebooks/sphinx-tabs/blob/master/CHANGELOG.md)\r\n- [Commits](https://github.com/executablebooks/sphinx-tabs/compare/v1.1.13...v1.3.0)\r\n\r\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com>\r\n\r\nCo-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com> </s> remove importlib-metadata==1.7.0  # via pallets-sphinx-themes </s> remove sphinx-tabs==1.1.13       # via -r requirements/docs.in </s> add sphinx-tabs==1.3.0        # via -r requirements/docs.in </s> remove pygments==2.6.1           # via sphinx </s> add pygments==2.6.1           # via sphinx, sphinx-tabs </s> remove colorama==0.4.3           # via sphinx", "html_url": "https://github.com/pallets/flask/commit/f7e33f240ee595349a46bf4eef95e1d9bdfee3da", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         .. versionadded:: 0.7\n <mask>         \"\"\"\n <mask>         if blueprint.name in self.blueprints:\n <mask>             assert self.blueprints[blueprint.name] is blueprint, \\\n <mask>                 'A blueprint\\'s name collision ocurred between %r and ' \\\n <mask>                 '%r.  Both share the same name \"%s\"' % \\\n <mask>                 (blueprint, self.blueprints[blueprint.name], blueprint.name) </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove     def __init__(self, blueprint, app, options): </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove     def register(self, app, options): </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False):", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 '%r.  Both share the same name \"%s\"' % \\\n <mask>                 (blueprint, self.blueprints[blueprint.name], blueprint.name)\n <mask>         else:\n <mask>             self.blueprints[blueprint.name] = blueprint\n <mask>         blueprint.register(self, options)\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"Connects a URL rule.  Works exactly like the :meth:`route`\n <mask>         decorator.  If a view_func is provided it will be registered with the\n <mask>         endpoint. </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule) </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove     def __init__(self, blueprint, app, options): </s> add     def __init__(self, blueprint, app, options, first_registration): </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False):", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> import os\n <mask> \n <mask> from .helpers import _PackageBoundObject, _endpoint_from_view_func\n <mask> \n <mask>  </s> remove         state = self.make_setup_state(app, options) </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint) </s> add             self._record_once(register_endpoint) </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Temporary holder object for registering a blueprint with the\n <mask>     application.\n <mask>     \"\"\"\n <mask> \n <mask>     def __init__(self, blueprint, app, options):\n <mask>         self.app = app\n <mask>         self.blueprint = blueprint\n <mask>         self.options = options\n <mask> \n <mask>         subdomain = self.options.get('subdomain') </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options) </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove     def register(self, app, options): </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove             self._record(register_endpoint) </s> add             self._record_once(register_endpoint)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         self.blueprint = blueprint\n <mask>         self.options = options\n <mask> \n <mask>         subdomain = self.options.get('subdomain')\n <mask>         if subdomain is None:\n <mask>             subdomain = self.blueprint.subdomain </s> remove     def __init__(self, blueprint, app, options): </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration) </s> remove             self._record(register_endpoint) </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _record(self, func):\n <mask>         self.deferred_functions.append(func)\n <mask> \n <mask>     def make_setup_state(self, app, options):\n <mask>         return BlueprintSetupState(self, app, options)\n <mask> \n <mask>     def register(self, app, options):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register a blueprint\n <mask>         on the application.  This can be overridden to customize the register\n <mask>         behavior.  Keyword arguments from </s> remove     def register(self, app, options): </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove     def __init__(self, blueprint, app, options): </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         state = self.make_setup_state(app, options) </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def make_setup_state(self, app, options):\n <mask>         return BlueprintSetupState(self, app, options)\n <mask> \n <mask>     def register(self, app, options):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register a blueprint\n <mask>         on the application.  This can be overridden to customize the register\n <mask>         behavior.  Keyword arguments from\n <mask>         :func:`~flask.Flask.register_blueprint` are directly forwarded to this\n <mask>         method in the `options` dictionary. </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options) </s> add     def _record_once(self, func):\n        def wrapper(state):\n            if state.first_registration:\n                func(state)\n        return self._record(update_wrapper(wrapper, func)) </s> remove         state = self.make_setup_state(app, options) </s> add         state = self.make_setup_state(app, options, first_registration) </s> remove     def __init__(self, blueprint, app, options): </s> add     def __init__(self, blueprint, app, options, first_registration): </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         behavior.  Keyword arguments from\n <mask>         :func:`~flask.Flask.register_blueprint` are directly forwarded to this\n <mask>         method in the `options` dictionary.\n <mask>         \"\"\"\n <mask>         state = self.make_setup_state(app, options)\n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(self.static_url_path + '/<path:filename>',\n <mask>                                view_func=self.send_static_file,\n <mask>                                endpoint='static')\n <mask>  </s> remove     def register(self, app, options): </s> add     def make_setup_state(self, app, options, first_registration=False):\n        return BlueprintSetupState(self, app, options, first_registration)\n\n    def register(self, app, options, first_registration=False): </s> remove     def make_setup_state(self, app, options):\n        return BlueprintSetupState(self, app, options) </s> remove         def register_rule(state):\n            state.add_url_rule(rule, endpoint, view_func, **options)\n        self._record(register_rule) </s> add         self._record(lambda s:\n            s.add_url_rule(rule, endpoint, view_func, **options)) </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n <mask>         \"\"\"Like :meth:`Flask.add_url_rule` but for a module.  The endpoint for\n <mask>         the :func:`url_for` function is prefixed with the name of the module.\n <mask>         \"\"\"\n <mask>         def register_rule(state):\n <mask>             state.add_url_rule(rule, endpoint, view_func, **options)\n <mask>         self._record(register_rule)\n <mask> \n <mask>     def endpoint(self, endpoint):\n <mask>         \"\"\"Like :meth:`Flask.endpoint` but for a module.  This does not\n <mask>         prefix the endpoint with the module name, this has to be done\n <mask>         explicitly by the user of this method. </s> remove         blueprint.register(self, options) </s> add             first_registration = True\n        blueprint.register(self, options, first_registration)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             def register_endpoint(state):\n <mask>                 state.app.view_functions[endpoint] = f\n <mask>             self._record(register_endpoint)\n <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def before_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function </s> remove             self._record(lambda s: s.app.errorhandler(code)(f)) </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.before_request` but for a module.  This function\n <mask>         is only executed before each request that is handled by a function of\n <mask>         that module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.before_request_funcs\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def before_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request`.  Such a function is executed </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint) </s> add             self._record_once(register_endpoint)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def before_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.before_request`.  Such a function is executed\n <mask>         before each request, even if outside of a module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.before_request_funcs\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def after_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  This function </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(lambda s: s.app.errorhandler(code)(f)) </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  This function\n <mask>         is only executed after each request that is handled by a function of\n <mask>         that module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.after_request_funcs\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def after_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  Such a function </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(lambda s: s.app.errorhandler(code)(f)) </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def after_app_request(self, f):\n <mask>         \"\"\"Like :meth:`Flask.after_request` but for a module.  Such a function\n <mask>         is executed after each request, even if outside of the module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.after_request_funcs\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  This </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(lambda s: s.app.errorhandler(code)(f)) </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f))", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  This\n <mask>         function is only executed for requests handled by a module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.template_context_processors\n <mask>             .setdefault(self.name, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def app_context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  Such a </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(register_endpoint) </s> add             self._record_once(register_endpoint)", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def app_context_processor(self, f):\n <mask>         \"\"\"Like :meth:`Flask.context_processor` but for a module.  Such a\n <mask>         function is executed each request, even if outside of the module.\n <mask>         \"\"\"\n <mask>         self._record(lambda s: s.app.template_context_processors\n <mask>             .setdefault(None, []).append(f))\n <mask>         return f\n <mask> \n <mask>     def app_errorhandler(self, code):\n <mask>         \"\"\"Like :meth:`Flask.errorhandler` but for a module.  This </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove             self._record(lambda s: s.app.errorhandler(code)(f)) </s> add             self._record_once(lambda s: s.app.errorhandler(code)(f)) </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>         \"\"\"Like :meth:`Flask.errorhandler` but for a module.  This\n <mask>         handler is used for all requests, even if outside of the module.\n <mask>         \"\"\"\n <mask>         def decorator(f):\n <mask>             self._record(lambda s: s.app.errorhandler(code)(f))\n <mask>             return f\n <mask>         return decorator </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove             self._record(register_endpoint) </s> add             self._record_once(register_endpoint) </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs </s> remove         self._record(lambda s: s.app.before_request_funcs </s> add         self._record_once(lambda s: s.app.before_request_funcs </s> remove         self._record(lambda s: s.app.template_context_processors </s> add         self._record_once(lambda s: s.app.template_context_processors </s> remove         self._record(lambda s: s.app.after_request_funcs </s> add         self._record_once(lambda s: s.app.after_request_funcs", "html_url": "https://github.com/pallets/flask/commit/f7e71b518f30923f494750e476f30d91c415723e", "file_name": "flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.http import parse_cache_control_header, parse_options_header\n <mask> from werkzeug.http import http_date\n <mask> from flask._compat import StringIO, text_type\n <mask> from flask.helpers import get_debug_flag, make_response\n <mask> try:\n <mask>     from pytz import timezone\n <mask> except ImportError:\n <mask>     has_pytz = False\n <mask> else:\n <mask>     has_pytz = True\n <mask> \n <mask> \n <mask> def has_encoding(name):\n <mask>     try:\n <mask>         import codecs </s> Re-revert to not using pytz\n\nWill spin a tzinfo subclass. </s> remove         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n        dt_aware = timezone(tzname).localize(dt_naive)\n        dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n        expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt_aware) == expected </s> add         tzinfo = datetime.timezone(datetime.timedelta(hours=tz[1]), name=tz[0])\n        dt = datetime.datetime(2017, 1, 1, 12, 34, 56, tzinfo=tzinfo)\n        gmt = datetime.timezone(datetime.timedelta(), name='GMT')\n        expected = dt.astimezone(gmt).strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n        assert flask.json.JSONEncoder().encode(dt) == expected </s> remove     @pytest.mark.skipif('not has_pytz')\n    @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n    def test_jsonify_aware_datetimes(self, tzname): </s> add     @pytest.mark.parametrize('tz', (('UTC', 0), ('PST', -8), ('KST', 9)))\n    def test_jsonify_aware_datetimes(self, tz):", "html_url": "https://github.com/pallets/flask/commit/f80376027571ba5190ab6cf1411dd1dd9bb9c65e", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             assert rv.mimetype == 'application/json'\n <mask>             assert flask.json.loads(rv.data)['x'] == http_date(d.timetuple())\n <mask> \n <mask>     @pytest.mark.skipif('not has_pytz')\n <mask>     @pytest.mark.parametrize('tzname', ('UTC', 'PST8PDT', 'Asia/Seoul'))\n <mask>     def test_jsonify_aware_datetimes(self, tzname):\n <mask>         \"\"\"Test if aware datetime.datetime objects are converted into GMT.\"\"\"\n <mask>         dt_naive = datetime.datetime(2017, 1, 1, 12, 34, 56)\n <mask>         dt_aware = timezone(tzname).localize(dt_naive)\n <mask>         dt_as_gmt = dt_aware.astimezone(timezone('GMT'))\n <mask>         expected = dt_as_gmt.strftime('\"%a, %d %b %Y %H:%M:%S %Z\"')\n <mask>         assert flask.json.JSONEncoder().encode(dt_aware) == expected\n <mask>  </s> Re-revert to not using pytz\n\nWill spin a tzinfo subclass. </s> remove try:\n    from pytz import timezone\nexcept ImportError:\n    has_pytz = False\nelse:\n    has_pytz = True", "html_url": "https://github.com/pallets/flask/commit/f80376027571ba5190ab6cf1411dd1dd9bb9c65e", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>         self.assert_equal(import_hooks, 1)\n <mask> \n <mask>     def test_flaskext_simple_import_normal(self):\n <mask>         from flask.ext.newext_simple import ext_id\n <mask>         self.assert_equal(ext_id, 'newext_simple')\n <mask> \n <mask>     def test_flaskext_simple_import_module(self):\n <mask>         from flask.ext import newext_simple\n <mask>         self.assert_equal(newext_simple.ext_id, 'newext_simple') </s> remove     def test_flaskext_package_import_normal(self): </s> add     def test_flaskext_new_package_import_normal(self): </s> remove     def test_flaskext_package_import_module(self): </s> add     def test_flaskext_new_package_import_module(self): </s> remove     def test_flaskext_package_import_submodule(self): </s> add     def test_flaskext_new_package_import_submodule(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace", "code_tokens": " <mask>         self.assert_equal(newext_simple.__name__, 'flask_newext_simple')\n <mask> \n <mask>     def test_flaskext_package_import_normal(self):\n <mask>         from flask.ext.newext_package import ext_id\n <mask>         self.assert_equal(ext_id, 'newext_package')\n <mask> \n <mask>     def test_flaskext_package_import_module(self): </s> remove     def test_flaskext_simple_import_module(self): </s> add     def test_flaskext_new_simple_import_module(self): </s> remove     def test_flaskext_package_import_submodule(self): </s> add     def test_flaskext_new_package_import_submodule(self): </s> remove     def test_flaskext_simple_import_normal(self): </s> add     def test_flaskext_new_simple_import_normal(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from flask.ext import newext_package\n <mask>         self.assert_equal(newext_package.ext_id, 'newext_package')\n <mask>         self.assert_equal(newext_package.__name__, 'flask_newext_package')\n <mask> \n <mask>     def test_flaskext_package_import_submodule(self):\n <mask>         from flask.ext.newext_package import submodule\n <mask>         self.assert_equal(submodule.__name__, 'flask_newext_package.submodule')\n <mask>         self.assert_equal(submodule.test_function(), 42)\n <mask> \n <mask>  </s> remove     def test_flaskext_package_import_module(self): </s> add     def test_flaskext_new_package_import_module(self): </s> remove     def test_flaskext_package_import_normal(self): </s> add     def test_flaskext_new_package_import_normal(self): </s> remove     def test_flaskext_simple_import_module(self): </s> add     def test_flaskext_new_simple_import_module(self): </s> remove     def test_flaskext_simple_import_normal(self): </s> add     def test_flaskext_new_simple_import_normal(self):", "html_url": "https://github.com/pallets/flask/commit/f80bfcaa28da98972002fb906c2559babe75801e", "file_name": "flask/testsuite/ext.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> that people can easily install the development version into their\n <mask> virtualenv without having to download the library by hand.\n <mask> \n <mask> Flask extensions must be licensed under a BSD, MIT or more liberal license\n <mask> to be able to be enlisted in the Flask Extension Registry.  Keep in mind\n <mask> that the Flask Extension Registry is a moderated place and libraries will\n <mask> be reviewed upfront if they behave as required.\n <mask> \n <mask> \"Hello Flaskext!\"\n <mask> ----------------- </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> What to use depends on what you have in mind.  For the SQLite 3 extension\n <mask> we will use the class-based approach because it will provide users with an\n <mask> object that handles opening and closing database connections.\n <mask> \n <mask> What's important about classes is that they encourage to be shared around\n <mask> on module level.  In that case, the object itself must not under any\n <mask> circumstances store any application specific state and must be shareable\n <mask> between different application.\n <mask> \n <mask> The Extension Code\n <mask> ------------------ </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind </s> add in order to be listed in the Flask Extension Registry.  Keep in mind </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> What's important about classes is that they encourage to be shared around\n <mask> on module level.  In that case, the object itself must not under any\n <mask> circumstances store any application specific state and must be shareable\n <mask> between different application.\n <mask> \n <mask> The Extension Code\n <mask> ------------------\n <mask> \n <mask> Here's the contents of the `flask_sqlite3.py` for copy/paste:: </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind </s> add in order to be listed in the Flask Extension Registry.  Keep in mind </s> add you did, it might be a very good idea to get some more input.  This not only\ngenerates useful feedback on what people might want from an extension, but\nalso avoids having multiple developers working in isolation on pretty much the\nsame problem.", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> development.  If you want to learn more, it's a very good idea to check\n <mask> out existing extensions on the `Flask Extension Registry`_.  If you feel\n <mask> lost there is still the `mailinglist`_ and the `IRC channel`_ to get some\n <mask> ideas for nice looking APIs.  Especially if you do something nobody before\n <mask> you did, it might be a very good idea to get some more input.  This not\n <mask> only to get an idea about what people might want to have from an\n <mask> extension, but also to avoid having multiple developers working on pretty\n <mask> much the same side by side.\n <mask> \n <mask> Remember: good API design is hard, so introduce your project on the\n <mask> mailinglist, and let other developers give you a helping hand with\n <mask> designing the API.\n <mask>  </s> Some grammar and typo fixes </s> remove What's important about classes is that they encourage to be shared around\non module level.  In that case, the object itself must not under any </s> add When designing your classes, it's important to make them easily reusable\nat the module level. This means the object itself must not under any </s> remove between different application. </s> add between different applications. </s> remove to be able to be enlisted in the Flask Extension Registry.  Keep in mind </s> add in order to be listed in the Flask Extension Registry.  Keep in mind", "html_url": "https://github.com/pallets/flask/commit/f80ea4fe5d3f194c567d3fd279e1e84050a12b10", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                                   jsonify responses will be pretty printed\n <mask>                                   if they are not requested by an\n <mask>                                   XMLHttpRequest object (controlled by\n <mask>                                   the ``X-Requested-With`` header)\n <mask> ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n <mask>                                   time it is requested and reloads it if\n <mask>                                   necessary. But disk I/O is costly and it may\n <mask>                                   be viable to disable this feature by setting\n <mask>                                   this key to ``False``. This option does not\n <mask>                                   affect debug mode.\n <mask> ``EXPLAIN_TEMPLATE_LOADING``      If this is enabled then every attempt to\n <mask>                                   load a template will write an info\n <mask>                                   message to the logger explaining the\n <mask>                                   attempts to locate the template.  This\n <mask>                                   can be useful to figure out why </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove         'TEMPLATES_AUTO_RELOAD':                True, </s> add         'TEMPLATES_AUTO_RELOAD':                None, </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD'] </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> remove     assert not app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "docs/config.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         'PREFERRED_URL_SCHEME':                 'http',\n <mask>         'JSON_AS_ASCII':                        True,\n <mask>         'JSON_SORT_KEYS':                       True,\n <mask>         'JSONIFY_PRETTYPRINT_REGULAR':          True,\n <mask>         'TEMPLATES_AUTO_RELOAD':                True,\n <mask>     })\n <mask> \n <mask>     #: The rule object to use for URL rules created.  This is used by\n <mask>     #: :meth:`add_url_rule`.  Defaults to :class:`werkzeug.routing.Rule`.\n <mask>     #: </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode.", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         options = dict(self.jinja_options)\n <mask>         if 'autoescape' not in options:\n <mask>             options['autoescape'] = self.select_jinja_autoescape\n <mask>         if 'auto_reload' not in options:\n <mask>             options['auto_reload'] = self.debug \\\n <mask>                 or self.config['TEMPLATES_AUTO_RELOAD']\n <mask>         rv = Environment(self, **options)\n <mask>         rv.globals.update(\n <mask>             url_for=url_for,\n <mask>             get_flashed_messages=get_flashed_messages,\n <mask>             config=self.config, </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode. </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove     assert not app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> add     # debug is False, config option is None </s> remove         'TEMPLATES_AUTO_RELOAD':                True, </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     assert rv.data == b'<h1>Jameson</h1>'\n <mask> \n <mask> def test_templates_auto_reload():\n <mask>     app = flask.Flask(__name__)\n <mask>     assert app.debug is False\n <mask>     assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n <mask>     assert app.jinja_env.auto_reload is False\n <mask>     # debug is False, config option is False </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove     assert app.config['TEMPLATES_AUTO_RELOAD']\n    assert app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is False </s> remove     assert not app.jinja_env.auto_reload </s> add     assert app.debug is False\n    assert app.jinja_env.auto_reload is False\n    # debug is False, config option is True\n    app = flask.Flask(__name__)\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.debug is False\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is None\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    assert app.config['TEMPLATES_AUTO_RELOAD'] is None\n    assert app.jinja_env.auto_reload is True\n    # debug is True, config option is False\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = False\n    assert app.jinja_env.auto_reload is False\n    # debug is True, config option is True\n    app = flask.Flask(__name__)\n    app.config['DEBUG'] = True\n    app.config['TEMPLATES_AUTO_RELOAD'] = True\n    assert app.jinja_env.auto_reload is True </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode. </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD'] </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> remove         'TEMPLATES_AUTO_RELOAD':                True, </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep replace replace keep keep replace keep keep", "code_tokens": " <mask>     app = flask.Flask(__name__)\n <mask>     assert app.config['TEMPLATES_AUTO_RELOAD']\n <mask>     assert app.jinja_env.auto_reload\n <mask>     app = flask.Flask(__name__)\n <mask>     app.config['TEMPLATES_AUTO_RELOAD'] = False\n <mask>     assert not app.jinja_env.auto_reload\n <mask> \n <mask> def test_template_loader_debugging(test_apps): </s> set TEMPLATE_AUTO_RELOAD default value to None </s> remove             options['auto_reload'] = self.debug \\\n                or self.config['TEMPLATES_AUTO_RELOAD'] </s> add             if self.config['TEMPLATES_AUTO_RELOAD'] is not None:\n                options['auto_reload'] = self.config['TEMPLATES_AUTO_RELOAD']\n            else:\n                options['auto_reload'] = self.debug </s> add     # debug is False, config option is None </s> remove ``TEMPLATES_AUTO_RELOAD``         Flask checks if template was modified each\n                                  time it is requested and reloads it if\n                                  necessary. But disk I/O is costly and it may\n                                  be viable to disable this feature by setting\n                                  this key to ``False``. This option does not\n                                  affect debug mode. </s> add ``TEMPLATES_AUTO_RELOAD``         If this is set to `True` every time a template\n                                  is requested Flask checks if the template was\n                                  modified and if yes, it will reload the\n                                  template. By default the value is ``None``\n                                  which means that Flask checks template\n                                  sources only in debug mode. </s> remove         'TEMPLATES_AUTO_RELOAD':                True, </s> add         'TEMPLATES_AUTO_RELOAD':                None,", "html_url": "https://github.com/pallets/flask/commit/f88765d504ce2fa9bc3926c76910b11510522892", "file_name": "tests/test_templating.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> Here you can see the full list of changes between each Flask release.\n <mask> \n <mask> Version 0.10.1\n <mask> --------------\n <mask> \n <mask> (bugfix release, released on June 14th 2013)\n <mask> \n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> add        blinker </s> remove             recorded.append('push')\n </s> add             recorded.append('pop')", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         recorded = []\n <mask>         def record_push(sender, **kwargs):\n <mask>             recorded.append('push')\n <mask>         def record_pop(sender, **kwargs):\n <mask>             recorded.append('push')\n <mask> \n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             return 'Hello'\n <mask> \n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> add        blinker </s> add Version 0.10.2\n--------------\n\n(bugfix release, release date to be announced)\n\n- Fixed broken `test_appcontext_signals()` test case.\n", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "flask/testsuite/signals.py"}
{"docstring_tokens": "keep keep keep add keep", "code_tokens": " <mask> envlist = py26, py27, pypy, py33\n <mask> \n <mask> [testenv]\n <mask> deps = -egit+git://github.com/mitsuhiko/werkzeug.git#egg=werkzeug\n <mask> commands = python run-tests.py []\n </s> Fix broken test_appcontext_signals test case\n\nThis fixes #781 and ensures that Flask is tested with blinker installed. </s> remove             recorded.append('push')\n </s> add             recorded.append('pop') </s> add Version 0.10.2\n--------------\n\n(bugfix release, release date to be announced)\n\n- Fixed broken `test_appcontext_signals()` test case.\n", "html_url": "https://github.com/pallets/flask/commit/f88cc2d2f9d14d97e33ddd2bbaa4b1885db06e1c", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         funcs = self.template_context_processors[None]\n <mask>         reqctx = _request_ctx_stack.top\n <mask>         if reqctx is not None:\n <mask>             bp = reqctx.request.blueprint\n <mask>             if bp is not None and bp in self.template_context_processors:\n <mask>                 funcs = chain(funcs, self.template_context_processors[bp])\n <mask>         orig_ctx = context.copy()\n <mask>         for func in funcs:\n <mask>             context.update(func())\n <mask>         # make sure the original values win.  This makes it possible to\n <mask>         # easier add new variables in context processors without breaking </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         bp = ctx.request.blueprint </s> remove         bp = _request_ctx_stack.top.request.blueprint </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             accessed in :meth:`~flask.Blueprint.record` callbacks.\n <mask> \n <mask>         .. versionadded:: 0.7\n <mask>         \"\"\"\n <mask>         first_registration = False\n <mask> \n <mask>         if blueprint.name in self.blueprints:\n <mask>             assert self.blueprints[blueprint.name] is blueprint, (\n <mask>                 \"A name collision occurred between blueprints\"\n <mask>                 f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n <mask>                 f\" Both share the same name {blueprint.name!r}.\"\n <mask>                 f\" Blueprints that are created on the fly need unique\"\n <mask>                 f\" names.\"\n <mask>             )\n <mask>         else:\n <mask>             self.blueprints[blueprint.name] = blueprint\n <mask>             first_registration = True\n <mask> \n <mask>         blueprint.register(self, options, first_registration)\n <mask> \n <mask>     def iter_blueprints(self):\n <mask>         \"\"\"Iterates over all blueprints by the order they were registered.\n <mask> \n <mask>         .. versionadded:: 0.11 </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> remove     def register(self, app, options, first_registration=False): </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c] </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> add         self._blueprints = [] </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask> \n <mask>         for name, c in (\n <mask>             (request.blueprint, code),\n <mask>             (None, code),\n <mask>             (request.blueprint, None),\n <mask>             (None, None),\n <mask>         ):\n <mask>             handler_map = self.error_handler_spec[name][c]\n <mask> \n <mask>             if not handler_map:\n <mask>                 continue </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove             for cls in exc_class.__mro__:\n                handler = handler_map.get(cls) </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             if not handler_map:\n <mask>                 continue\n <mask> \n <mask>             for cls in exc_class.__mro__:\n <mask>                 handler = handler_map.get(cls)\n <mask> \n <mask>                 if handler is not None:\n <mask>                     return handler\n <mask> \n <mask>     def handle_http_exception(self, e): </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove             if not handler_map:\n                continue </s> add                 if not handler_map:\n                    continue </s> remove                 if handler is not None:\n                    return handler </s> add                     if handler is not None:\n                        return handler </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c] </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp])", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             for cls in exc_class.__mro__:\n <mask>                 handler = handler_map.get(cls)\n <mask> \n <mask>                 if handler is not None:\n <mask>                     return handler\n <mask> \n <mask>     def handle_http_exception(self, e):\n <mask>         \"\"\"Handles an HTTP exception.  By default this will invoke the\n <mask>         registered error handlers and fall back to returning the\n <mask>         exception as response. </s> remove             for cls in exc_class.__mro__:\n                handler = handler_map.get(cls) </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> remove             if not handler_map:\n                continue </s> remove         for name, c in (\n            (request.blueprint, code),\n            (None, code),\n            (request.blueprint, None),\n            (None, None),\n        ):\n            handler_map = self.error_handler_spec[name][c] </s> add         for c in [code, None]:\n            for name in chain(self._request_blueprints(), [None]):\n                handler_map = self.error_handler_spec[name][c] </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         value is handled as if it was the return value from the view, and\n <mask>         further request handling is stopped.\n <mask>         \"\"\"\n <mask> \n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask> \n <mask>         funcs = self.url_value_preprocessors[None]\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args) </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         bp = ctx.request.blueprint", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask> \n <mask>         funcs = self.url_value_preprocessors[None]\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask> \n <mask>         funcs = self.before_request_funcs[None]\n <mask>         if bp is not None and bp in self.before_request_funcs:\n <mask>             funcs = chain(funcs, self.before_request_funcs[bp])\n <mask>         for func in funcs:\n <mask>             rv = func()\n <mask>             if rv is not None: </s> remove         bp = _request_ctx_stack.top.request.blueprint </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = ctx.request.blueprint", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep replace keep replace replace keep", "code_tokens": " <mask>         \"\"\"\n <mask>         ctx = _request_ctx_stack.top\n <mask>         bp = ctx.request.blueprint\n <mask>         funcs = ctx._after_request_functions\n <mask>         if bp is not None and bp in self.after_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n <mask>         if None in self.after_request_funcs: </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         if exc is _sentinel:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs[None])\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n <mask>         for func in funcs:\n <mask>             func(exc)\n <mask>         request_tearing_down.send(self, exc=exc)\n <mask> \n <mask>     def do_teardown_appcontext(self, exc=_sentinel): </s> remove         if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.url_value_preprocessors:\n                funcs = chain(funcs, self.url_value_preprocessors[bp]) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.after_request_funcs:\n                funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove             bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp]) </s> add             for bp in self._request_blueprints():\n                if bp in self.template_context_processors:\n                    funcs = chain(funcs, self.template_context_processors[bp]) </s> remove         bp = ctx.request.blueprint", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>         WSGI application. This calls :meth:`wsgi_app`, which can be\n <mask>         wrapped to apply middleware.\n <mask>         \"\"\"\n <mask>         return self.wsgi_app(environ, start_response) </s> remove     def register(self, app, options, first_registration=False): </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\")", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         #: blueprint.\n <mask>         self.url_prefix = url_prefix\n <mask> \n <mask>         #: A dictionary with URL defaults that is added to each and every\n <mask>         #: URL that was defined with the blueprint.\n <mask>         self.url_defaults = dict(self.blueprint.url_values_defaults)\n <mask>         self.url_defaults.update(self.options.get(\"url_defaults\", ())) </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> remove     def register(self, app, options, first_registration=False): </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> add         self._blueprints = [] </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration) </s> add         blueprint.register(self, options)", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if \"defaults\" in options:\n <mask>             defaults = dict(defaults, **options.pop(\"defaults\"))\n <mask>         self.app.add_url_rule(\n <mask>             rule,\n <mask>             f\"{self.blueprint.name}.{endpoint}\",\n <mask>             view_func,\n <mask>             defaults=defaults,\n <mask>             **options,\n <mask>         )\n <mask>  </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp])) </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp]) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         self.url_values_defaults = url_defaults\n <mask>         self.cli_group = cli_group\n <mask> \n <mask>     def _is_setup_finished(self):\n <mask>         return self.warn_on_modifications and self._got_registered_once\n <mask> \n <mask>     def record(self, func):\n <mask>         \"\"\"Registers a function that is called when the blueprint is </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> remove         if cli_resolved_group is None:\n            app.cli.commands.update(self.cli.commands)\n        elif cli_resolved_group is _sentinel:\n            self.cli.name = self.name\n            app.cli.add_command(self.cli)\n        else:\n            self.cli.name = cli_resolved_group\n            app.cli.add_command(self.cli) </s> add         if self.cli.commands:\n            if cli_resolved_group is None:\n                app.cli.commands.update(self.cli.commands)\n            elif cli_resolved_group is _sentinel:\n                self.cli.name = self.name\n                app.cli.add_command(self.cli)\n            else:\n                self.cli.name = cli_resolved_group\n                app.cli.add_command(self.cli)\n\n        for blueprint, bp_options in self._blueprints:\n            url_prefix = options.get(\"url_prefix\", \"\")\n            if \"url_prefix\" in bp_options:\n                url_prefix = (\n                    url_prefix.rstrip(\"/\") + \"/\" + bp_options[\"url_prefix\"].lstrip(\"/\")\n                )\n\n            bp_options[\"url_prefix\"] = url_prefix\n            bp_options[\"name_prefix\"] = options.get(\"name_prefix\", \"\") + self.name + \".\"\n            blueprint.register(app, bp_options) </s> add         self.name_prefix = self.options.get(\"name_prefix\", \"\") </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration) </s> add         blueprint.register(self, options) </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Subclasses can override this to return a subclass of the setup state.\n <mask>         \"\"\"\n <mask>         return BlueprintSetupState(self, app, options, first_registration)\n <mask> \n <mask>     def register(self, app, options, first_registration=False):\n <mask>         \"\"\"Called by :meth:`Flask.register_blueprint` to register all\n <mask>         views and callbacks registered on the blueprint with the\n <mask>         application. Creates a :class:`.BlueprintSetupState` and calls\n <mask>         each :meth:`record` callbackwith it.\n <mask>  </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> add     def _request_blueprints(self):\n        if _request_ctx_stack.top.request.blueprint is None:\n            return []\n        else:\n            return reversed(_request_ctx_stack.top.request.blueprint.split(\".\")) </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration) </s> add         blueprint.register(self, options)", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         :param first_registration: Whether this is the first time this\n <mask>             blueprint has been registered on the application.\n <mask>         \"\"\"\n <mask>         self._got_registered_once = True\n <mask>         state = self.make_setup_state(app, options, first_registration)\n <mask> \n <mask>         if self.has_static_folder:\n <mask>             state.add_url_rule(\n <mask>                 f\"{self.static_url_path}/<path:filename>\", </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove     def register(self, app, options, first_registration=False): </s> add     def register_blueprint(self, blueprint, **options):\n        \"\"\"Register a :class:`~flask.Blueprint` on this blueprint. Keyword\n        arguments passed to this method will override the defaults set\n        on the blueprint.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        self._blueprints.append((blueprint, options))\n\n    def register(self, app, options): </s> remove         first_registration = False\n\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, (\n                \"A name collision occurred between blueprints\"\n                f\" {blueprint!r} and {self.blueprints[blueprint.name]!r}.\"\n                f\" Both share the same name {blueprint.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            first_registration = True\n\n        blueprint.register(self, options, first_registration) </s> add         blueprint.register(self, options) </s> remove         bp = ctx.request.blueprint", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep replace replace replace keep keep replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>             deferred(state)\n <mask> \n <mask>         if not self.cli.commands:\n <mask>             return\n <mask> \n <mask>         cli_resolved_group = options.get(\"cli_group\", self.cli_group)\n <mask> \n <mask>         if cli_resolved_group is None:\n <mask>             app.cli.commands.update(self.cli.commands)\n <mask>         elif cli_resolved_group is _sentinel:\n <mask>             self.cli.name = self.name\n <mask>             app.cli.add_command(self.cli)\n <mask>         else:\n <mask>             self.cli.name = cli_resolved_group\n <mask>             app.cli.add_command(self.cli)\n <mask> \n <mask>     def add_url_rule(self, rule, endpoint=None, view_func=None, **options): </s> Nested blueprints\n\nThis allows blueprints to be nested within blueprints via a new\nBlueprint.register_blueprint method. This should provide a use case\nthat has been desired for the past ~10 years.\n\nThis works by setting the endpoint name to be the blueprint names,\nfrom parent to child delimeted by \".\" and then iterating over the\nblueprint names in reverse order in the app (from most specific to\nmost general). This means that the expectation of nesting a blueprint\nwithin a nested blueprint is met. </s> remove         bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add         for bp in self._request_blueprints():\n            if bp in self.teardown_request_funcs:\n                funcs = chain(funcs, reversed(self.teardown_request_funcs[bp])) </s> add                 for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls) </s> add         first_registration = False\n\n        if self.name in app.blueprints:\n            assert app.blueprints[self.name] is self, (\n                \"A name collision occurred between blueprints\"\n                f\" {self!r} and {app.blueprints[self.name]!r}.\"\n                f\" Both share the same name {self.name!r}.\"\n                f\" Blueprints that are created on the fly need unique\"\n                f\" names.\"\n            )\n        else:\n            app.blueprints[self.name] = self\n            first_registration = True </s> remove         if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp]) </s> add         for bp in self._request_blueprints():\n            if bp in self.before_request_funcs:\n                funcs = chain(funcs, self.before_request_funcs[bp])", "html_url": "https://github.com/pallets/flask/commit/f92e820b4bf357e9792d08ce398802715a63eafe", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    It's now also possible to use the ``in`` operator on it to see if an\n <mask>    attribute is defined and it yields all keys on iteration.\n <mask> \n <mask>    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same\n <mask>    way you would use them on a dictionary.\n <mask> \n <mask>    This is a proxy.  See :ref:`notes-on-proxies` for more information.\n <mask> \n <mask>  </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/api.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> .. versionadded:: 0.11\n <mask> \n <mask> .. currentmodule:: flask\n <mask> \n <mask> One of the nice new features in Flask 1.0 is the built-in integration of\n <mask> the `click <http://click.pocoo.org/>`_ command line interface.  This\n <mask> enables a wide range of new features for the Flask ecosystem and your own\n <mask> applications.\n <mask> \n <mask> Basic Usage </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the </s> add Starting with Flask 0.11 the recommended way to work with the shell is the", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> -----------------\n <mask> \n <mask> Even if you get mails, you probably also want to log warnings.  It's a\n <mask> good idea to keep as much information around that might be required to\n <mask> debug a problem.  By default as of Flask 1.0, errors are logged to your\n <mask> webserver's log automatically.  Warnings however are not.  Please note\n <mask> that Flask itself will not issue any warnings in the core system, so it's\n <mask> your responsibility to warn in the code if something seems odd.\n <mask> \n <mask> There are a couple of handlers provided by the logging system out of the </s> 1.0 -> 0.11 in the docs </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a </s> add Starting with Flask 0.11 there are multiple built-in ways to run a </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes </s> remove Flask 1.0 removed the ``debug_log_format`` attribute from Flask </s> add Flask 0.11 removed the ``debug_log_format`` attribute from Flask </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication.", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/errorhandling.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> Flask 0.8 introduced a redirect import system as a compatibility aid for app\n <mask> developers: Importing ``flask.ext.foo`` would try ``flask_foo`` and\n <mask> ``flaskext.foo`` in that order.\n <mask> \n <mask> As of Flask 1.0, most Flask extensions have transitioned to the new naming\n <mask> schema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is\n <mask> now deprecated -- you should use ``flask_foo``.\n <mask> \n <mask> \n <mask> .. _OAuth extension: http://pythonhosted.org/Flask-OAuth/\n <mask> .. _mailinglist: http://flask.pocoo.org/mailinglist/ </s> remove One of the nice new features in Flask 1.0 is the built-in integration of </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove in Flask 1.0.  Previously it was possible to use etags and mimetypes </s> add in Flask 0.11.  Previously it was possible to use etags and mimetypes", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ==================\n <mask> \n <mask> .. currentmodule:: flask\n <mask> \n <mask> Starting with Flask 1.0 there are multiple built-in ways to run a\n <mask> development server.  The best one is the :command:`flask` command line utility\n <mask> but you can also continue using the :meth:`Flask.run` method.\n <mask> \n <mask> Command Line\n <mask> ------------ </s> remove One of the nice new features in Flask 1.0 is the built-in integration of </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove Starting with Flask 1.0 the recommended way to work with the shell is the </s> add Starting with Flask 0.11 the recommended way to work with the shell is the </s> add Version 0.11\n------------\n\n0.11 is an odd release in the Flask release cycle because it was supposed\nto be the 1.0 release.  However because there was such a long lead time up\nto the release we decided to push out a 0.11 release first with some\nchanges removed to make the transition easier.  If you have been tracking\nthe master branch which was 1.0 you might see some unexpected changes.\n\nIn case you did track the master branch you will notice that `flask --app`\nis removed now.  You need to use the environment variable to specify an\napplication. </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/server.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Command Line Interface\n <mask> ----------------------\n <mask> \n <mask> Starting with Flask 1.0 the recommended way to work with the shell is the\n <mask> ``flask shell`` command which does a lot of this automatically for you.\n <mask> For instance the shell is automatically initialized with a loaded\n <mask> application context.\n <mask> \n <mask> For more information see :ref:`cli`. </s> remove Starting with Flask 1.0 there are multiple built-in ways to run a </s> remove    As of 1.0 you can use :meth:`pop` and :meth:`setdefault` in the same </s> add    As of 0.11 you can use :meth:`pop` and :meth:`setdefault` in the same </s> remove One of the nice new features in Flask 1.0 is the built-in integration of </s> add One of the nice new features in Flask 0.11 is the built-in integration of </s> remove As of Flask 1.0, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 1.0 but is </s> add As of Flask 0.11, most Flask extensions have transitioned to the new naming\nschema. The ``flask.ext.foo`` compatibility alias is still in Flask 0.11 but is", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/shell.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     $ easy_install -U Flask\n <mask> \n <mask> .. _upgrading-to-10:\n <mask> \n <mask> Version 1.0\n <mask> -----------\n <mask> \n <mask> Debugging\n <mask> `````````\n <mask> \n <mask> Flask 1.0 removed the ``debug_log_format`` attribute from Flask </s> remove Flask 1.0 removed the ``debug_log_format`` attribute from Flask </s> add Flask 0.11 removed the ``debug_log_format`` attribute from Flask", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Debugging\n <mask> `````````\n <mask> \n <mask> Flask 1.0 removed the ``debug_log_format`` attribute from Flask\n <mask> applications.  Instead the new ``LOGGER_HANDLER_POLICY`` configuration can\n <mask> be used to disable the default log handlers and custom log handlers can be\n <mask> set up.\n <mask> \n <mask> Error handling </s> remove debug a problem.  By default as of Flask 1.0, errors are logged to your </s> add debug a problem.  By default as of Flask 0.11, errors are logged to your", "html_url": "https://github.com/pallets/flask/commit/f9ea3fe026a684bb47a0f4794431dab30d0f601e", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     session.setdefault('_flashes', []).append((category, message))\n <mask> \n <mask> \n <mask> def get_flashed_messages(with_categories=False):\n <mask>     \"\"\"Pulls all flashed messages from the session and returns them.\n <mask>     Further calls in the same request to the function will return\n <mask>     the same messages.  By default just the messages are returned,\n <mask>     but when `with_categories` is set to `True`, the return value will\n <mask>     be a list of tuples in the form ``(category, message)`` instead.\n </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     :param category_filter: whitelist of categories to limit return values </s> add     .. versionchanged: 0.9\n        `category_filter` parameter added.\n </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes)", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     .. versionchanged:: 0.3\n <mask>        `with_categories` parameter added.\n <mask> \n <mask>     :param with_categories: set to `True` to also receive categories.\n <mask>     :param category_filter: whitelist of categories to limit return values\n <mask>     \"\"\"\n <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\ </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     :param category_filter: whitelist of categories to limit return values </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes) </s> remove def get_flashed_messages(with_categories=False): </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     .. versionchanged: 0.9\n <mask>         `category_filter` parameter added.\n <mask> \n <mask>     :param with_categories: set to `True` to also receive categories.\n <mask>     \"\"\"\n <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n <mask>             if '_flashes' in session else []\n <mask>     if category_filter: </s> Allow category filtering in get_flashed_messages to allow rending categories in separate html blocks </s> add     if category_filter:\n        flashes = filter(lambda f: f[0] in category_filter, flashes) </s> add     .. versionchanged: 0.9\n        `category_filter` parameter added. </s> remove def get_flashed_messages(with_categories=False): </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     flashes = _request_ctx_stack.top.flashes\n <mask>     if flashes is None:\n <mask>         _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n <mask>             if '_flashes' in session else []\n <mask>     if not with_categories:\n <mask>         return [x[1] for x in flashes]\n <mask>     return flashes\n <mask>  </s> remove def get_flashed_messages(with_categories=False): </s> add def get_flashed_messages(with_categories=False, category_filter=[]):", "html_url": "https://github.com/pallets/flask/commit/fa069f94dec3aeec4a81a00e7bbd8d95e400bf5f", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         try:\n <mask>             rv = info.load_app().cli.get_command(ctx, name)\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException: </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently. </s> remove         except NoAppException: </s> add         except Exception:\n            # Here we intentionally swallow all exceptions as we don't\n            # want the help page to break if the app does not exist.\n            # If someone attempts to use the command we try to create\n            # the app again and this will give us the error.", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.add_command(shell_command)\n <mask> \n <mask>     def get_command(self, ctx, name):\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         # Find the command in the application first, if we can find it.\n <mask>         # If the app is not available, we just ignore this silently.\n <mask>         try:\n <mask>             rv = info.load_app().cli.get_command(ctx, name)\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException: </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv </s> remove         except NoAppException: </s> add         except Exception:\n            # Here we intentionally swallow all exceptions as we don't\n            # want the help page to break if the app does not exist.\n            # If someone attempts to use the command we try to create\n            # the app again and this will give us the error.", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if rv is not None:\n <mask>                 return rv\n <mask>         except NoAppException:\n <mask>             pass\n <mask>         return click.Group.get_command(self, ctx, name)\n <mask> \n <mask>     def list_commands(self, ctx):\n <mask>         # The commands available is the list of both the application (if\n <mask>         # available) plus the builtin commands.\n <mask>         rv = set(click.Group.list_commands(self, ctx)) </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently. </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         rv = set(click.Group.list_commands(self, ctx))\n <mask>         info = ctx.ensure_object(ScriptInfo)\n <mask>         try:\n <mask>             rv.update(info.load_app().cli.list_commands(ctx))\n <mask>         except NoAppException:\n <mask>             pass\n <mask>         return sorted(rv)\n <mask> \n <mask>     def invoke_subcommand(self, ctx, cmd, cmd_name, args):\n <mask>         with_context = cmd.callback is None or \\ </s> remove         # Find the command in the application first, if we can find it.\n        # If the app is not available, we just ignore this silently. </s> add         # We load built-in commands first as these should always be the\n        # same no matter what the app does.  If the app does want to\n        # override this it needs to make a custom instance of this group\n        # and not attach the default commands.\n        #\n        # This also means that the script stays functional in case the\n        # application completely fails.\n        rv = click.Group.get_command(self, ctx, name)\n        if rv is not None:\n            return rv </s> remove         return click.Group.get_command(self, ctx, name)", "html_url": "https://github.com/pallets/flask/commit/fa6eded6f572dd4bc23b030f025156cdd1e63305", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import click\n <mask> \n <mask> from . import __version__\n <mask> from ._compat import iteritems, reraise\n <mask> from .globals import current_app\n <mask> from .helpers import get_debug_flag\n <mask> from ._compat import getargspec\n <mask> \n <mask>  </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         # This module is always executed as \"python -m flask.run\" and as such\n        # we need to ensure that we restore the actual command line so that\n        # the reloader can properly operate.\n        sys.argv = ['-m', this_module] + sys.argv[1:] </s> add         # Python rewrites \"python -m flask\" to the path to the file in argv.\n        # Restore the original command so that the reloader works.\n        sys.argv = ['-m', this_module] + args </s> remove         if sys.version_info >= (2, 7):\n            name = 'python -m ' + this_module.rsplit('.', 1)[0]\n        else:\n            name = 'python -m ' + this_module </s> add         this_module = 'flask'\n\n        if sys.version_info < (2, 7):\n            this_module += '.cli'\n\n        name = 'python -m ' + this_module </s> remove     this_module = __package__ + '.cli'", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask> def main(as_module=False):\n <mask>     this_module = __package__ + '.cli'\n <mask>     args = sys.argv[1:]\n <mask> \n <mask>     if as_module:\n <mask>         if sys.version_info >= (2, 7):\n <mask>             name = 'python -m ' + this_module.rsplit('.', 1)[0]\n <mask>         else:\n <mask>             name = 'python -m ' + this_module\n <mask> \n <mask>         # This module is always executed as \"python -m flask.run\" and as such\n <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate. </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         # This module is always executed as \"python -m flask.run\" and as such\n        # we need to ensure that we restore the actual command line so that\n        # the reloader can properly operate.\n        sys.argv = ['-m', this_module] + sys.argv[1:] </s> add         # Python rewrites \"python -m flask\" to the path to the file in argv.\n        # Restore the original command so that the reloader works.\n        sys.argv = ['-m', this_module] + args", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             name = 'python -m ' + this_module.rsplit('.', 1)[0]\n <mask>         else:\n <mask>             name = 'python -m ' + this_module\n <mask> \n <mask>         # This module is always executed as \"python -m flask.run\" and as such\n <mask>         # we need to ensure that we restore the actual command line so that\n <mask>         # the reloader can properly operate.\n <mask>         sys.argv = ['-m', this_module] + sys.argv[1:]\n <mask>     else:\n <mask>         name = None\n <mask> \n <mask>     cli.main(args=args, prog_name=name)\n <mask>  </s> be smarter about adding \".cli\" to reloader command\npython -m flask.cli raises an import warning on > 2.6\nit's only needed on 2.6, \"flask\" works otherwise\ncloses #2357 </s> remove         if sys.version_info >= (2, 7):\n            name = 'python -m ' + this_module.rsplit('.', 1)[0]\n        else:\n            name = 'python -m ' + this_module </s> add         this_module = 'flask'\n\n        if sys.version_info < (2, 7):\n            this_module += '.cli'\n\n        name = 'python -m ' + this_module </s> remove     this_module = __package__ + '.cli'", "html_url": "https://github.com/pallets/flask/commit/fa7e8d6073052adc5ba69702db4dec6571ef0bfd", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> import imp\n <mask> import os\n <mask> import sys\n <mask> \n <mask> from werkzeug import import_string\n <mask> \n <mask> \n <mask> class ConfigAttribute(object):\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> add         assert not app.config.from_pyfile('missing.cfg', silent=True) </s> remove             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add             assert not app.config.from_envvar('FOO_SETTINGS', silent=True)", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "flask/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             except RuntimeError, e:\n <mask>                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': 'flask_tests.py'}\n <mask>             assert app.config.from_envvar('FOO_SETTINGS')\n <mask>             self.common_object_test(app)\n <mask>         finally:\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> add         assert not app.config.from_pyfile('missing.cfg', silent=True) </s> add import errno", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             assert msg.endswith(\"missing.cfg'\")\n <mask>         else:\n <mask>             assert 0, 'expected config'\n <mask> \n <mask> \n <mask> class SubdomainTestCase(unittest.TestCase):\n <mask> \n <mask>     def test_basic_support(self):\n </s> Test passes.\nAdded test for silent flag; added import of errno so it passed. </s> remove             not app.config.from_envvar('FOO_SETTINGS', silent=True)\n </s> add             assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add import errno", "html_url": "https://github.com/pallets/flask/commit/fa9817778c83eb35b9c2c4332ccb7e5190d1ffa2", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>   which can be used by subclasses to alter the default\n <mask>   behaviour for `OPTIONS` responses.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask>  </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g) </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name)", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     :license: BSD, see LICENSE for more details.\n <mask> \"\"\"\n <mask> \n <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> def _lookup_object(name):\n <mask>     top = _request_ctx_stack.top\n <mask>     if top is None: </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name) </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g) </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g) </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from functools import partial\n <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> # context locals\n <mask> _request_ctx_stack = LocalStack()\n <mask> current_app = LocalProxy(partial(_lookup_object, 'app'))\n <mask> request = LocalProxy(partial(_lookup_object, 'request'))\n <mask> session = LocalProxy(partial(_lookup_object, 'session')) </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g) </s> add current_app = LocalProxy(partial(_lookup_object, 'app'))\nrequest = LocalProxy(partial(_lookup_object, 'request'))\nsession = LocalProxy(partial(_lookup_object, 'session'))\ng = LocalProxy(partial(_lookup_object, 'g')) </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g) </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace", "code_tokens": " <mask> from werkzeug import LocalStack, LocalProxy\n <mask> \n <mask> # context locals\n <mask> _request_ctx_stack = LocalStack()\n <mask> current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\n <mask> request = LocalProxy(lambda: _request_ctx_stack.top.request)\n <mask> session = LocalProxy(lambda: _request_ctx_stack.top.session)\n <mask> g = LocalProxy(lambda: _request_ctx_stack.top.g) </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name) </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g) </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "flask/globals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert index() == 'Hello World!'\n <mask>         ctx.pop()\n <mask>         try:\n <mask>             index()\n <mask>         except AttributeError:\n <mask>             pass\n <mask>         else:\n <mask>             assert 0, 'expected runtime error'\n <mask> \n <mask>     def test_test_client_context_binding(self): </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add     def test_request_locals(self):\n        self.assertEqual(repr(flask.g), '<LocalProxy unbound>')\n        self.assertFalse(flask.g) </s> add def _lookup_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('working outside of request context')\n    return getattr(top, name) </s> remove current_app = LocalProxy(lambda: _request_ctx_stack.top.app)\nrequest = LocalProxy(lambda: _request_ctx_stack.top.request)\nsession = LocalProxy(lambda: _request_ctx_stack.top.session)\ng = LocalProxy(lambda: _request_ctx_stack.top.g)", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             pass\n <mask>         else:\n <mask>             assert \"Expected ValueError\"\n <mask> \n <mask> \n <mask> class JSONTestCase(unittest.TestCase):\n <mask> \n <mask>     def test_jsonify(self):\n <mask>         d = dict(a=23, b=42, c=[1, 2, 3]) </s> Request local objects now fail properly with a RuntimeError.  This fixes #105 </s> add - Unbound locals now raise a proper :exc:`RuntimeError` instead\n  of an :exc:`AttributeError`.", "html_url": "https://github.com/pallets/flask/commit/faa1c71e455a99e9b098aa9bb4667c07a1bab6aa", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> request and get the information of the currently logged in user.  At the\n <mask> end of the request, the database connection is closed again.\n <mask> \n <mask> In Flask you can implement such things with the\n <mask> :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators in combination with the\n <mask> special :class:`~flask.g` object.\n <mask> \n <mask> \n <mask> .. _database-pattern:\n <mask>  </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators:: </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         #: To register a function here, use the :meth:`request_init` </s> add         #: To register a function here, use the :meth:`before_request` </s> remove         self.request_init_funcs = [] </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/patterns.rst"}
{"docstring_tokens": "keep replace keep keep keep replace", "code_tokens": " <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9.", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/patterns.rst"}
{"docstring_tokens": "keep keep replace replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> before each request and shut them down afterwards.\n <mask> \n <mask> Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators::\n <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask> Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n <mask> :meth:`~flask.Flask.request_shutdown` decorators::\n <mask> \n <mask>     @app.request_init\n <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     @app.request_shutdown </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     def before_request():\n <mask>         g.db = connect_db()\n <mask> \n <mask>     @app.request_shutdown\n <mask>     def after_request(response):\n <mask>         g.db.close()\n <mask>         return response\n <mask> \n <mask> Functions marked with :meth:`~flask.Flask.request_init` are called before\n <mask> a request and passed no arguments, functions marked with\n <mask> :meth:`~flask.Flask.request_shutdown` are called after a request and\n <mask> passed the response that will be sent to the client.  They have to return\n <mask> that response object or a different one.  In this case we just return it </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators:: </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions.", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return response\n <mask> \n <mask> Functions marked with :meth:`~flask.Flask.request_init` are called before\n <mask> a request and passed no arguments, functions marked with\n <mask> :meth:`~flask.Flask.request_shutdown` are called after a request and\n <mask> passed the response that will be sent to the client.  They have to return\n <mask> that response object or a different one.  In this case we just return it\n <mask> unchanged.\n <mask> \n <mask> We store our current database connection on the special :data:`~flask.g` </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators:: </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove     @app.request_shutdown </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove         before it's sent to the WSGI server. </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init` </s> add         #: To register a function here, use the :meth:`before_request`", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Step 5: The View Functions\n <mask> --------------------------\n <mask> \n <mask> Now that the database connections are working we can start writing the\n <mask> view functions.  We will need for of them:\n <mask> \n <mask> Show Entries\n <mask> ````````````\n <mask> \n <mask> This view shows all the entries stored in the database.  It listens on the </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove Flask allows us to do that with the :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators:: </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         #: To register a function here, use the :meth:`request_init` </s> add         #: To register a function here, use the :meth:`before_request` </s> remove         call every as :func:`request_init` decorated function. </s> remove         before it's sent to the WSGI server. </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         self.request_init_funcs = []", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "docs/tutorial.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             db.cursor().executescript(f.read())\n <mask>         db.commit()\n <mask> \n <mask> \n <mask> @app.request_init\n <mask> def before_request():\n <mask>     \"\"\"Make sure we are connected to the database each request.\"\"\"\n <mask>     g.db = connect_db()\n <mask> \n <mask>  </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9.", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Make sure we are connected to the database each request.\"\"\"\n <mask>     g.db = connect_db()\n <mask> \n <mask> \n <mask> @app.request_shutdown\n <mask> def after_request(response):\n <mask>     \"\"\"Closes the database again at the end of the request.\"\"\"\n <mask>     g.db.close()\n <mask>     return response\n <mask>  </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9.", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/flaskr/flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return 'http://www.gravatar.com/avatar/%s?d=identicon&s=%d' % \\\n <mask>         (md5(email.strip().lower().encode('utf-8')).hexdigest(), size)\n <mask> \n <mask> \n <mask> @app.request_init\n <mask> def before_request():\n <mask>     \"\"\"Make sure we are connected to the database each request and look\n <mask>     up the current user so that we know he's there.\n <mask>     \"\"\"\n <mask>     g.db = connect_db() </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> add Flask allows us to do that with the :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators:: </s> add :meth:`~flask.Flask.after_request` are called after a request and", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         g.user = query_db('select * from user where user_id = ?',\n <mask>                           [session['user_id']], one=True)\n <mask> \n <mask> \n <mask> @app.request_shutdown\n <mask> def after_request(response):\n <mask>     \"\"\"Closes the database again at the end of the request.\"\"\"\n <mask>     g.db.close()\n <mask>     return response\n <mask>  </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         #: To register a function here, use the :meth:`request_init` </s> remove         self.request_init_funcs = []", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "examples/minitwit/minitwit.py"}
{"docstring_tokens": "keep keep replace keep replace keep keep", "code_tokens": " <mask>         #: can for example be used to open database connections or\n <mask>         #: getting hold of the currently logged in user.\n <mask>         #: To register a function here, use the :meth:`request_init`\n <mask>         #: decorator.\n <mask>         self.request_init_funcs = []\n <mask> \n <mask>         #: a list of functions that are called at the end of the </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         #: To register a function here use the :meth:`request_shtdown` </s> add         #: To register a function here use the :meth:`after_request` </s> remove         self.request_shutdown_funcs = [] </s> add         self.after_request_funcs = [] </s> remove :meth:`~flask.Flask.request_init` and\n:meth:`~flask.Flask.request_shutdown` decorators in combination with the </s> add :meth:`~flask.Flask.before_request` and\n:meth:`~flask.Flask.after_request` decorators in combination with the </s> remove view functions.  We will need for of them: </s> add view functions.  We will need four of them: </s> remove @app.request_shutdown", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep", "code_tokens": " <mask>         #: a list of functions that are called at the end of the\n <mask>         #: request.  Tha function is passed the current response\n <mask>         #: object and modify it in place or replace it.\n <mask>         #: To register a function here use the :meth:`request_shtdown`\n <mask>         #: decorator.\n <mask>         self.request_shutdown_funcs = []\n <mask> \n <mask>         #: a list of functions that are called without arguments </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         self.request_init_funcs = [] </s> add         self.before_request_funcs = [] </s> remove         #: To register a function here, use the :meth:`request_init` </s> add         #: To register a function here, use the :meth:`before_request` </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove @app.request_shutdown </s> add @app.after_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep", "code_tokens": " <mask>             return f\n <mask>         return decorator\n <mask> \n <mask>     def request_init(self, f):\n <mask>         \"\"\"Registers a function to run before each request.\"\"\"\n <mask>         self.request_init_funcs.append(f)\n <mask>         return f </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> add     def after_request(self, f): </s> remove         self.request_shutdown_funcs.append(f) </s> add         self.after_request_funcs.append(f) </s> add @app.after_request </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before </s> remove @app.request_init </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Registers a function to run before each request.\"\"\"\n <mask>         self.request_init_funcs.append(f)\n <mask>         return f\n <mask> \n <mask>     def request_shutdown(self, f):\n <mask>         \"\"\"Register a function to be run after each request.\"\"\"\n <mask>         self.request_shutdown_funcs.append(f)\n <mask>         return f\n <mask> \n <mask>     def context_processor(self, f): </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         self.request_init_funcs.append(f) </s> add         self.before_request_funcs.append(f) </s> remove         self.request_shutdown_funcs.append(f) </s> remove     def request_init(self, f): </s> add     def before_request(self, f): </s> remove @app.request_shutdown </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     def preprocess_request(self):\n <mask>         \"\"\"Called before the actual request dispatching and will\n <mask>         call every as :func:`request_init` decorated function.\n <mask>         If any of these function returns a value it's handled as\n <mask>         if it was the return value from the view and further\n <mask>         request handling is stopped.\n <mask>         \"\"\"\n <mask>         for func in self.request_init_funcs:\n <mask>             rv = func()\n <mask>             if rv is not None:\n <mask>                 return rv\n <mask>  </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         for handler in self.request_shutdown_funcs: </s> add         for handler in self.after_request_funcs: </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init` </s> add         #: To register a function here, use the :meth:`before_request` </s> remove view functions.  We will need for of them: </s> add view functions.  We will need four of them: </s> remove Functions marked with :meth:`~flask.Flask.request_init` are called before </s> add Functions marked with :meth:`~flask.Flask.before_request` are called before", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 return rv\n <mask> \n <mask>     def process_response(self, response):\n <mask>         \"\"\"Can be overridden in order to modify the response object\n <mask>         before it's sent to the WSGI server.\n <mask> \n <mask>         :param response: a :attr:`response_class` object.\n <mask>         :return: a new response object or the same, has to be an\n <mask>                  instance of :attr:`response_class`.\n <mask>         \"\"\" </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove :meth:`~flask.Flask.request_shutdown` are called after a request and </s> add :meth:`~flask.Flask.after_request` are called after a request and </s> remove         #: To register a function here use the :meth:`request_shtdown`", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         session = _request_ctx_stack.top.session\n <mask>         if session is not None:\n <mask>             self.save_session(session, response)\n <mask>         for handler in self.request_shutdown_funcs:\n <mask>             response = handler(response)\n <mask>         return response\n <mask> \n <mask>     def wsgi_app(self, environ, start_response):\n <mask>         \"\"\"The actual WSGI application.  This is not implemented in </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove         call every as :func:`request_init` decorated function. </s> remove         before it's sent to the WSGI server. </s> add         before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions. </s> remove         #: To register a function here, use the :meth:`request_init`", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "flask.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>     def test_request_processing(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         evts = []\n <mask>         @app.request_init\n <mask>         def before_request():\n <mask>             evts.append('before')\n <mask>         @app.request_shutdown </s> request_init -> before_request and request_shutdown -> after_request\n\nThis fixes #9. </s> remove     @app.request_init </s> add     @app.before_request </s> remove     @app.request_shutdown </s> add     @app.after_request </s> remove     @app.request_shutdown </s> add     @app.after_request </s> remove     @app.request_init </s> add     @app.before_request </s> remove @app.request_init </s> add @app.before_request", "html_url": "https://github.com/pallets/flask/commit/fb2d2e446bdd806ea3de7b869c7371e2dae57a23", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> markupsafe==1.1.1\n <mask>     # via jinja2\n <mask> nodeenv==1.5.0\n <mask>     # via pre-commit\n <mask> packaging==20.8\n <mask>     # via\n <mask>     #   -r requirements/docs.in\n <mask>     #   pallets-sphinx-themes\n <mask>     #   pytest\n <mask>     #   sphinx </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8 </s> add packaging==20.9 </s> remove packaging==20.8 </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/dev.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> jinja2==2.11.2\n <mask>     # via sphinx\n <mask> markupsafe==1.1.1\n <mask>     # via jinja2\n <mask> packaging==20.8\n <mask>     # via\n <mask>     #   -r requirements/docs.in\n <mask>     #   pallets-sphinx-themes\n <mask>     #   sphinx\n <mask> pallets-sphinx-themes==1.2.3 </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8 </s> add packaging==20.9 </s> remove packaging==20.8 </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/docs.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> greenlet==1.0.0\n <mask>     # via -r requirements/tests.in\n <mask> iniconfig==1.1.1\n <mask>     # via pytest\n <mask> packaging==20.8\n <mask>     # via pytest\n <mask> pluggy==0.13.1\n <mask>     # via pytest\n <mask> py==1.9.0\n <mask>     # via pytest </s> Bump packaging from 20.8 to 20.9\n\nBumps [packaging](https://github.com/pypa/packaging) from 20.8 to 20.9.\n- [Release notes](https://github.com/pypa/packaging/releases)\n- [Changelog](https://github.com/pypa/packaging/blob/main/CHANGELOG.rst)\n- [Commits](https://github.com/pypa/packaging/compare/20.8...20.9)\n\nSigned-off-by: dependabot-preview[bot] <support@dependabot.com> </s> remove packaging==20.8 </s> add packaging==20.9 </s> remove packaging==20.8 </s> add packaging==20.9", "html_url": "https://github.com/pallets/flask/commit/fb5f04a8c71499391bab37aa4004ecc652724e0d", "file_name": "requirements/tests.txt"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - ``FLASK_APP`` can be set to an app factory, with arguments if needed, for\n <mask>   example ``FLASK_APP=myproject.app:create_app('dev')``. (`#2326`_)\n <mask> - ``View.provide_automatic_options = True`` is set on the view function from\n <mask>   ``View.as_view``, to be detected in ``app.add_url_rule``. (`#2316`_)\n <mask> - Error handling will try handlers registered for ``blueprint, code``,\n <mask>   ``app, code``, ``blueprint, exception``, ``app, exception``. (`#2314`_)\n <mask> - ``Cookie`` is added to the response's ``Vary`` header if the session is </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`. </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove         self.app_import_path = app_import_path </s> add         self.app_import_path = app_import_path or os.environ.get('FLASK_APP') </s> add                 raise NoAppException('Failed to find application in module ' </s> remove         if create_app is None:\n            if app_import_path is None:\n                app_import_path = find_default_import_path()\n            self.app_import_path = app_import_path\n        else:\n            app_import_path = None </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> add def prepare_import(path):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> .. _#2374: https://github.com/pallets/flask/pull/2374\n <mask> .. _#2373: https://github.com/pallets/flask/pull/2373\n <mask> .. _#2385: https://github.com/pallets/flask/issues/2385\n <mask> .. _#2412: https://github.com/pallets/flask/pull/2412\n <mask> \n <mask> Version 0.12.2\n <mask> --------------\n <mask>  </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             if isinstance(app, Flask):\n <mask>                 return app\n <mask>             else:\n <mask>                 raise RuntimeError('Failed to find application in module '\n <mask>                                    '\"{name}\"'.format(name=module))\n <mask>         except TypeError as e:\n <mask>             new_error = NoAppException(\n <mask>                 '{e}\\nThe app factory \"{factory}\" in module \"{module}\" could'\n <mask>                 ' not be called with the specified arguments (and a' </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module) </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> def prepare_exec_for_file(filename):\n <mask>     \"\"\"Given a filename this will try to calculate the python path, add it\n <mask>     to the search path and return the actual module name that is expected.\n <mask>     \"\"\"\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`. </s> remove         self.app_import_path = app_import_path </s> add         self.app_import_path = app_import_path or os.environ.get('FLASK_APP') </s> remove         __import__(module) </s> add         __import__(module_name) </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep replace replace", "code_tokens": " <mask>     to the search path and return the actual module name that is expected.\n <mask>     \"\"\"\n <mask>     module = []\n <mask> \n <mask>     # Chop off file extensions or package markers\n <mask>     if os.path.split(filename)[1] == '__init__.py':\n <mask>         filename = os.path.dirname(filename)\n <mask>     elif filename.endswith('.py'):\n <mask>         filename = filename[:-3]\n <mask>     else:\n <mask>         raise NoAppException('The file provided (%s) does exist but is not a '\n <mask>                              'valid Python file.  This means that it cannot '\n <mask>                              'be used as application.  Please change the '\n <mask>                              'extension to .py' % filename)\n <mask>     filename = os.path.realpath(filename)\n <mask> \n <mask>     dirpath = filename\n <mask>     while 1:\n <mask>         dirpath, extra = os.path.split(dirpath)\n <mask>         module.append(extra)\n <mask>         if not os.path.isfile(os.path.join(dirpath, '__init__.py')):\n <mask>             break\n <mask> \n <mask>     if sys.path[0] != dirpath:\n <mask>         sys.path.insert(0, dirpath) </s> remove     module = [] </s> add     path = os.path.realpath(path) </s> remove def prepare_exec_for_file(filename): </s> add def prepare_import(path): </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module) </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove     return '.'.join(module[::-1]) </s> add     return '.'.join(module_name[::-1])", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if sys.path[0] != dirpath:\n <mask>         sys.path.insert(0, dirpath)\n <mask> \n <mask>     return '.'.join(module[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, app_id, raise_if_not_found=True):\n <mask>     \"\"\"Attempts to locate the application.\"\"\"\n <mask>     __traceback_hide__ = True </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     if sys.path[0] != dirpath:\n        sys.path.insert(0, dirpath) </s> add     if sys.path[0] != path:\n        sys.path.insert(0, path) </s> remove def locate_app(script_info, app_id, raise_if_not_found=True): </s> add def locate_app(script_info, module_name, app_name, raise_if_not_found=True): </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            )", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     return '.'.join(module[::-1])\n <mask> \n <mask> \n <mask> def locate_app(script_info, app_id, raise_if_not_found=True):\n <mask>     \"\"\"Attempts to locate the application.\"\"\"\n <mask>     __traceback_hide__ = True\n <mask> \n <mask>     if ':' in app_id:\n <mask>         module, app_obj = app_id.split(':', 1)\n <mask>     else:\n <mask>         module = app_id\n <mask>         app_obj = None\n <mask> \n <mask>     try:\n <mask>         __import__(module)\n <mask>     except ImportError:\n <mask>         # Reraise the ImportError if it occurred within the imported module. </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         __import__(module) </s> add         __import__(module_name) </s> remove     return '.'.join(module[::-1]) </s> add     return '.'.join(module_name[::-1]) </s> remove     mod = sys.modules[module] </s> add     module = sys.modules[module_name]", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     try:\n <mask>         __import__(module)\n <mask>     except ImportError:\n <mask>         # Reraise the ImportError if it occurred within the imported module.\n <mask>         # Determine this by checking whether the trace has a depth > 1.\n <mask>         if sys.exc_info()[-1].tb_next:\n <mask>             stack_trace = traceback.format_exc()\n <mask>             raise NoAppException( </s> remove     if ':' in app_id:\n        module, app_obj = app_id.split(':', 1)\n    else:\n        module = app_id\n        app_obj = None </s> remove                 'There was an error trying to import the app ({module}):\\n'\n                '{stack_trace}'.format(\n                    module=module, stack_trace=stack_trace\n                ) </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc()) </s> remove     module = [] </s> remove                 raise RuntimeError('Failed to find application in module ' </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep keep keep replace replace replace replace keep", "code_tokens": " <mask>             stack_trace = traceback.format_exc()\n <mask>             raise NoAppException(\n <mask>                 'There was an error trying to import the app ({module}):\\n'\n <mask>                 '{stack_trace}'.format(\n <mask>                     module=module, stack_trace=stack_trace\n <mask>                 )\n <mask>             )\n <mask>         elif raise_if_not_found:\n <mask>             raise NoAppException(\n <mask>                 'The file/path provided ({module}) does not appear to exist.'\n <mask>                 ' Please verify the path is correct. If app is not on'\n <mask>                 ' PYTHONPATH, ensure the extension is .py.'.format(\n <mask>                     module=module)\n <mask>             ) </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             stack_trace = traceback.format_exc() </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                 raise RuntimeError('Failed to find application in module ' </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep keep keep", "code_tokens": " <mask>             )\n <mask>         else:\n <mask>             return\n <mask> \n <mask>     mod = sys.modules[module]\n <mask> \n <mask>     if app_obj is None:\n <mask>         return find_best_app(script_info, mod)\n <mask>     else:\n <mask>         return find_app_by_string(app_obj, script_info, mod)\n <mask> \n <mask>  </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app </s> add         return find_app_by_string(app_name, script_info, module) </s> remove                 'The file/path provided ({module}) does not appear to exist.'\n                ' Please verify the path is correct. If app is not on'\n                ' PYTHONPATH, ensure the extension is .py.'.format(\n                    module=module) </s> add                 'Could not import \"{name}\".\"'.format(name=module_name) </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> add         app = None </s> remove         self._loaded_app = rv\n        return rv </s> add         self._loaded_app = app\n        return app", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if app_obj is None:\n <mask>         return find_best_app(script_info, mod)\n <mask>     else:\n <mask>         return find_app_by_string(app_obj, script_info, mod)\n <mask> \n <mask> \n <mask> def find_default_import_path():\n <mask>     app = os.environ.get('FLASK_APP')\n <mask>     if app is None:\n <mask>         return\n <mask>     if os.path.isfile(app):\n <mask>         return prepare_exec_for_file(app)\n <mask>     return app\n <mask> \n <mask> \n <mask> def get_version(ctx, param, value):\n <mask>     if not value or ctx.resilient_parsing:\n <mask>         return </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod) </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     mod = sys.modules[module] </s> add     module = sys.modules[module_name] </s> add         app = None </s> remove         self._loaded_app = rv\n        return rv </s> add         self._loaded_app = app\n        return app </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> add             app._reconfigure_for_run_debug(debug)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>     def __init__(self, app_import_path=None, create_app=None):\n <mask>         if create_app is None:\n <mask>             if app_import_path is None:\n <mask>                 app_import_path = find_default_import_path()\n <mask>             self.app_import_path = app_import_path\n <mask>         else:\n <mask>             app_import_path = None\n <mask> \n <mask>         #: Optionally the import path for the Flask application.\n <mask>         self.app_import_path = app_import_path\n <mask>         #: Optionally a function that is passed the script info to create\n <mask>         #: the instance of the application.\n <mask>         self.create_app = create_app </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> add         app = None </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> remove                 rv = locate_app(self, self.app_import_path) </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add     if os.path.splitext(path)[1] == '.py':\n        path = os.path.splitext(path)[0]\n\n    if os.path.basename(path) == '__init__':\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, '__init__.py')): </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            )", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self.create_app, self)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = (self.app_import_path.split(':', 1) + [None])[:2] </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove                 rv = locate_app(self, self.app_import_path) </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> remove         self._loaded_app = rv\n        return rv </s> add         self._loaded_app = app\n        return app </s> add             app._reconfigure_for_run_debug(debug) </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod) </s> add     if app_name is None:\n        return find_best_app(script_info, module)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>             return self._loaded_app\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             rv = call_factory(self.create_app, self)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 rv = locate_app(self, self.app_import_path) </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> add         app = None </s> remove                 for module in ['wsgi.py', 'app.py']:\n                    import_path = prepare_exec_for_file(module)\n                    rv = locate_app(\n                        self, import_path, raise_if_not_found=False </s> add                 for path in ('wsgi.py', 'app.py'):\n                    import_name = prepare_import(path)\n                    app = locate_app(\n                        self, import_name, None, raise_if_not_found=False </s> remove         self._loaded_app = rv\n        return rv </s> add         self._loaded_app = app\n        return app </s> remove             rv._reconfigure_for_run_debug(debug) </s> add             app._reconfigure_for_run_debug(debug) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod) </s> add     if app_name is None:\n        return find_best_app(script_info, module)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep keep replace keep keep keep", "code_tokens": " <mask>             if self.app_import_path:\n <mask>                 rv = locate_app(self, self.app_import_path)\n <mask>             else:\n <mask>                 for module in ['wsgi.py', 'app.py']:\n <mask>                     import_path = prepare_exec_for_file(module)\n <mask>                     rv = locate_app(\n <mask>                         self, import_path, raise_if_not_found=False\n <mask>                     )\n <mask> \n <mask>                     if rv:\n <mask>                         break\n <mask> \n <mask>             if not rv: </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove                 rv = locate_app(self, self.app_import_path) </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> add             app._reconfigure_for_run_debug(debug) </s> remove         self._loaded_app = rv\n        return rv </s> add         self._loaded_app = app\n        return app", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                     if rv:\n <mask>                         break\n <mask> \n <mask>             if not rv:\n <mask>                 raise NoAppException(\n <mask>                     'Could not locate Flask application. You did not provide '\n <mask>                     'the FLASK_APP environment variable, and a wsgi.py or '\n <mask>                     'app.py module was not found in the current directory.\\n\\n'\n <mask>                     'For more information see '\n <mask>                     'http://flask.pocoo.org/docs/latest/quickstart/'\n <mask>                 )\n <mask> \n <mask>         debug = get_debug_flag()\n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug) </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove             rv._reconfigure_for_run_debug(debug) </s> add             app._reconfigure_for_run_debug(debug) </s> remove                 raise RuntimeError('Failed to find application in module ' </s> add                 raise NoAppException('Failed to find application in module ' </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')): </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep", "code_tokens": " <mask> \n <mask>         debug = get_debug_flag()\n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug)\n <mask> \n <mask>         self._loaded_app = rv\n <mask>         return rv\n <mask> \n <mask> \n <mask>         if debug is not None:\n <mask>             rv._reconfigure_for_run_debug(debug)\n <mask> \n <mask>         self._loaded_app = rv\n <mask>         return rv\n <mask>  </s> remove             rv = call_factory(self.create_app, self) </s> add             app = call_factory(self.create_app, self) </s> remove                 rv = locate_app(self, self.app_import_path) </s> add                 path, name = (self.app_import_path.split(':', 1) + [None])[:2]\n                import_name = prepare_import(path)\n                app = locate_app(self, import_name, name) </s> add         app = None </s> remove             if not rv:\n                raise NoAppException(\n                    'Could not locate Flask application. You did not provide '\n                    'the FLASK_APP environment variable, and a wsgi.py or '\n                    'app.py module was not found in the current directory.\\n\\n'\n                    'For more information see '\n                    'http://flask.pocoo.org/docs/latest/quickstart/'\n                ) </s> add         if not app:\n            raise NoAppException(\n                'Could not locate a Flask application. You did not provide '\n                'the \"FLASK_APP\" environment variable, and a \"wsgi.py\" or '\n                '\"app.py\" module was not found in the current directory.'\n            ) </s> remove                 for module in ['wsgi.py', 'app.py']:\n                    import_path = prepare_exec_for_file(module)\n                    rv = locate_app(\n                        self, import_path, raise_if_not_found=False </s> add                 for path in ('wsgi.py', 'app.py'):\n                    import_name = prepare_import(path)\n                    app = locate_app(\n                        self, import_name, None, raise_if_not_found=False", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "flask/cli.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def create_app():\n <mask>     return Flask('create_app')\n <mask> \n <mask> \n <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join(['create_app2', foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, bar, script_info): </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove def create_app3(foo, bar, script_info):\n    return Flask(\"_\".join(['create_app3', foo, bar])) </s> add def create_app3(foo, script_info):\n    return Flask('_'.join(['app3', foo, script_info.data['test']])) </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod) </s> add     if app_name is None:\n        return find_best_app(script_info, module) </s> remove     mod = sys.modules[module] </s> add     module = sys.modules[module_name]", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join(['create_app2', foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, bar, script_info):\n <mask>     return Flask(\"_\".join(['create_app3', foo, bar])) </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     return Flask(\"_\".join(['create_app2', foo, bar])) </s> add     return Flask('_'.join(['app2', foo, bar])) </s> remove     return Flask('create_app') </s> add     return Flask('app') </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     if app_obj is None:\n        return find_best_app(script_info, mod) </s> add     if app_name is None:\n        return find_best_app(script_info, module)", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # This file was part of Flask-CLI and was modified under the terms its license,\n <mask> # the Revised BSD License.\n <mask> # Copyright (C) 2015 CERN.\n <mask> #\n <mask> from __future__ import absolute_import, print_function\n <mask> import os\n <mask> import sys\n <mask> from functools import partial\n <mask> \n <mask> import click </s> remove from flask import Flask, current_app </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`. </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> add                 'While importing \"{name}\", an ImportError was raised:'\n                '\\n\\n{tb}'.format(name=module_name, tb=traceback.format_exc())", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace keep keep keep keep", "code_tokens": " <mask> import click\n <mask> import pytest\n <mask> from click.testing import CliRunner\n <mask> from flask import Flask, current_app\n <mask> \n <mask> from flask.cli import cli, AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n <mask>     find_best_app, locate_app, with_appcontext, prepare_exec_for_file, \\\n <mask>     find_default_import_path, get_version\n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def runner(): </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     return Flask('create_app') </s> add     return Flask('app') </s> remove def test_locate_app(test_apps):\n    \"\"\"Test of locate_app.\"\"\"\n    script_info = ScriptInfo()\n    assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n    ).name == \"create_app3_baz_qux\"\n    assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"notanpp.py\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp/app\")\n    pytest.raises(\n        RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app2('foo')\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app ()\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n    assert locate_app(\n        script_info, \"notanpp.py\", raise_if_not_found=False\n    ) is None\n\n\ndef test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n    \"\"\"Test of find_default_import_path.\"\"\"\n    monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n    assert find_default_import_path() == None\n    monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n    assert find_default_import_path() == 'notanapp'\n    tmpfile = tmpdir.join('testapp.py')\n    tmpfile.write('')\n    monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n    expect_rv = prepare_exec_for_file(str(tmpfile))\n    assert find_default_import_path() == expect_rv </s> add def test_locate_app_suppress_raise():\n    info = ScriptInfo()\n    app = locate_app(info, 'notanapp.py', None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\n            info, 'cliapp.importerrorapp', None, raise_if_not_found=False\n        ) </s> remove         if create_app is None:\n            if app_import_path is None:\n                app_import_path = find_default_import_path()\n            self.app_import_path = app_import_path\n        else:\n            app_import_path = None </s> remove def test_prepare_exec_for_file(test_apps):\n    \"\"\"Expect the correct path to be set and the correct module name to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect, where\n    the parent directory of given file is added to `sys.path`. </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs.", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace keep replace replace replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     pytest.raises(NoAppException, find_best_app, script_info, Module)\n <mask> \n <mask> \n <mask> def test_prepare_exec_for_file(test_apps):\n <mask>     \"\"\"Expect the correct path to be set and the correct module name to be returned.\n <mask> \n <mask>     :func:`prepare_exec_for_file` has a side effect, where\n <mask>     the parent directory of given file is added to `sys.path`.\n <mask>     \"\"\"\n <mask>     realpath = os.path.realpath('/tmp/share/test.py')\n <mask>     dirname = os.path.dirname(realpath)\n <mask>     assert prepare_exec_for_file('/tmp/share/test.py') == 'test'\n <mask>     assert dirname in sys.path\n <mask> \n <mask>     realpath = os.path.realpath('/tmp/share/__init__.py')\n <mask>     dirname = os.path.dirname(os.path.dirname(realpath))\n <mask>     assert prepare_exec_for_file('/tmp/share/__init__.py') == 'share'\n <mask>     assert dirname in sys.path\n <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         prepare_exec_for_file('/tmp/share/test.txt') </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove         prepare_exec_for_file('/tmp/share/test.txt') </s> remove def test_locate_app(test_apps):\n    \"\"\"Test of locate_app.\"\"\"\n    script_info = ScriptInfo()\n    assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n    assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n    ).name == \"create_app2_foo_bar\"\n    assert locate_app(\n        script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n    ).name == \"create_app3_baz_qux\"\n    assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"notanpp.py\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp/app\")\n    pytest.raises(\n        RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app2('foo')\")\n    pytest.raises(\n        NoAppException, locate_app,\n        script_info, \"cliapp.factory:create_app ()\")\n    pytest.raises(\n        NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n    assert locate_app(\n        script_info, \"notanpp.py\", raise_if_not_found=False\n    ) is None\n\n\ndef test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n    \"\"\"Test of find_default_import_path.\"\"\"\n    monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n    assert find_default_import_path() == None\n    monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n    assert find_default_import_path() == 'notanapp'\n    tmpfile = tmpdir.join('testapp.py')\n    tmpfile.write('')\n    monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n    expect_rv = prepare_exec_for_file(str(tmpfile))\n    assert find_default_import_path() == expect_rv </s> add def test_locate_app_suppress_raise():\n    info = ScriptInfo()\n    app = locate_app(info, 'notanapp.py', None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\n            info, 'cliapp.importerrorapp', None, raise_if_not_found=False\n        ) </s> add     path = os.path.realpath(path) </s> add - ``FLASK_APP`` can point to local packages that are not installed in dev mode,\n  although `pip install -e` should still be preferred. (`#2414`_) </s> remove     # Chop off file extensions or package markers\n    if os.path.split(filename)[1] == '__init__.py':\n        filename = os.path.dirname(filename)\n    elif filename.endswith('.py'):\n        filename = filename[:-3]\n    else:\n        raise NoAppException('The file provided (%s) does exist but is not a '\n                             'valid Python file.  This means that it cannot '\n                             'be used as application.  Please change the '\n                             'extension to .py' % filename)\n    filename = os.path.realpath(filename)\n\n    dirpath = filename\n    while 1:\n        dirpath, extra = os.path.split(dirpath)\n        module.append(extra)\n        if not os.path.isfile(os.path.join(dirpath, '__init__.py')):", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     with pytest.raises(NoAppException):\n <mask>         prepare_exec_for_file('/tmp/share/test.txt')\n <mask> \n <mask> \n <mask> def test_locate_app(test_apps):\n <mask>     \"\"\"Test of locate_app.\"\"\"\n <mask>     script_info = ScriptInfo()\n <mask>     assert locate_app(script_info, \"cliapp.app\").name == \"testapp\"\n <mask>     assert locate_app(script_info, \"cliapp.app:testapp\").name == \"testapp\"\n <mask>     assert locate_app(script_info, \"cliapp.factory\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app()\").name == \"create_app\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app2('foo', 'bar')\"\n <mask>     ).name == \"create_app2_foo_bar\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app2('foo', 'bar', )\"\n <mask>     ).name == \"create_app2_foo_bar\"\n <mask>     assert locate_app(\n <mask>         script_info, \"cliapp.factory:create_app3('baz', 'qux')\"\n <mask>     ).name == \"create_app3_baz_qux\"\n <mask>     assert locate_app(script_info, \"cliapp.multiapp:app1\").name == \"app1\"\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"notanpp.py\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"cliapp/app\")\n <mask>     pytest.raises(\n <mask>         RuntimeError, locate_app, script_info, \"cliapp.app:notanapp\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app,\n <mask>         script_info, \"cliapp.factory:create_app2('foo')\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app,\n <mask>         script_info, \"cliapp.factory:create_app ()\")\n <mask>     pytest.raises(\n <mask>         NoAppException, locate_app, script_info, \"cliapp.importerrorapp\")\n <mask>     assert locate_app(\n <mask>         script_info, \"notanpp.py\", raise_if_not_found=False\n <mask>     ) is None\n <mask> \n <mask> \n <mask> def test_find_default_import_path(test_apps, monkeypatch, tmpdir):\n <mask>     \"\"\"Test of find_default_import_path.\"\"\"\n <mask>     monkeypatch.delitem(os.environ, 'FLASK_APP', raising=False)\n <mask>     assert find_default_import_path() == None\n <mask>     monkeypatch.setitem(os.environ, 'FLASK_APP', 'notanapp')\n <mask>     assert find_default_import_path() == 'notanapp'\n <mask>     tmpfile = tmpdir.join('testapp.py')\n <mask>     tmpfile.write('')\n <mask>     monkeypatch.setitem(os.environ, 'FLASK_APP', str(tmpfile))\n <mask>     expect_rv = prepare_exec_for_file(str(tmpfile))\n <mask>     assert find_default_import_path() == expect_rv\n <mask> \n <mask> \n <mask> def test_get_version(test_apps, capsys):\n <mask>     \"\"\"Test of get_version.\"\"\" </s> allow local packages in FLASK_APP\ndon't require .py extension in FLASK_APP\nadd tests for nested package loading\nparametrize cli loading tests </s> remove     realpath = os.path.realpath('/tmp/share/test.py')\n    dirname = os.path.dirname(realpath)\n    assert prepare_exec_for_file('/tmp/share/test.py') == 'test'\n    assert dirname in sys.path\n\n    realpath = os.path.realpath('/tmp/share/__init__.py')\n    dirname = os.path.dirname(os.path.dirname(realpath))\n    assert prepare_exec_for_file('/tmp/share/__init__.py') == 'share'\n    assert dirname in sys.path </s> add     original_path = sys.path[:]\n\n    def reset_path():\n        sys.path[:] = original_path\n\n    request.addfinalizer(reset_path)\n\n    assert prepare_import(value) == result\n    assert sys.path[0] == path\n\n\n@pytest.mark.parametrize('iname,aname,result', (\n    ('cliapp.app', None, 'testapp'),\n    ('cliapp.app', 'testapp', 'testapp'),\n    ('cliapp.factory', None, 'app'),\n    ('cliapp.factory', 'create_app', 'app'),\n    ('cliapp.factory', 'create_app()', 'app'),\n    # no script_info\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\")', 'app2_foo_bar'),\n    # trailing comma space\n    ('cliapp.factory', 'create_app2(\"foo\", \"bar\", )', 'app2_foo_bar'),\n    # takes script_info\n    ('cliapp.factory', 'create_app3(\"foo\")', 'app3_foo_spam'),\n))\ndef test_locate_app(test_apps, iname, aname, result):\n    info = ScriptInfo()\n    info.data['test'] = 'spam'\n    assert locate_app(info, iname, aname).name == result\n\n\n@pytest.mark.parametrize('iname,aname', (\n    ('notanapp.py', None),\n    ('cliapp/app', None),\n    ('cliapp.app', 'notanapp'),\n    # not enough arguments\n    ('cliapp.factory', 'create_app2(\"foo\")'),\n    # nested import error\n    ('cliapp.importerrorapp', None),\n    # not a Python file\n    ('cliapp.message.txt', None),\n    # space before arg list\n    ('cliapp.factory', 'create_app ()'),\n))\ndef test_locate_app_raises(test_apps, iname, aname):\n    info = ScriptInfo() </s> add cwd = os.getcwd()\ntest_path = os.path.abspath(os.path.join(\n    os.path.dirname(__file__), 'test_apps'\n))\n\n\n@pytest.mark.parametrize('value,path,result', (\n    ('test', cwd, 'test'),\n    ('test.py', cwd, 'test'),\n    ('a/test', os.path.join(cwd, 'a'), 'test'),\n    ('test/__init__.py', cwd, 'test'),\n    ('test/__init__', cwd, 'test'),\n    # nested package\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', '__init__'),\n        test_path, 'cliapp.inner1'\n    ),\n    (\n        os.path.join(test_path, 'cliapp', 'inner1', 'inner2'),\n        test_path, 'cliapp.inner1.inner2'\n    ),\n    # dotted name\n    ('test.a.b', cwd, 'test.a.b'),\n    (os.path.join(test_path, 'cliapp.app'), test_path, 'cliapp.app'),\n    # not a Python file, will be caught during import\n    (\n        os.path.join(test_path, 'cliapp', 'message.txt'),\n        test_path, 'cliapp.message.txt'\n    ),\n))\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs. </s> remove         return find_app_by_string(app_obj, script_info, mod)\n\n\ndef find_default_import_path():\n    app = os.environ.get('FLASK_APP')\n    if app is None:\n        return\n    if os.path.isfile(app):\n        return prepare_exec_for_file(app)\n    return app </s> add         return find_app_by_string(app_name, script_info, module) </s> remove     mod = sys.modules[module] </s> add     module = sys.modules[module_name] </s> remove from flask.cli import cli, AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, locate_app, with_appcontext, prepare_exec_for_file, \\\n    find_default_import_path, get_version </s> add from flask import Flask, current_app\nfrom flask.cli import AppGroup, FlaskGroup, NoAppException, ScriptInfo, \\\n    find_best_app, get_version, locate_app, prepare_import, with_appcontext", "html_url": "https://github.com/pallets/flask/commit/fb845b90328278f4a557f898024a53800752fd53", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_('ConfigTestCase' not in app.config)\n <mask> \n <mask>     def test_config_from_file(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n <mask>         self.common_object_test(app)\n <mask> \n <mask>     def test_config_from_object(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_object(__name__) </s> remove                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out) </s> add                 self.assert_(os.path.basename(__file__.rsplit('.', 1)[0] + '.py') in out) </s> remove             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'} </s> add             os.environ = {'FOO_SETTINGS': __file__.rsplit('.', 1)[0] + '.py'}", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             else:\n <mask>                 self.assert_(0, 'expected exception')\n <mask>             self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n <mask>             self.assert_(app.config.from_envvar('FOO_SETTINGS'))\n <mask>             self.common_object_test(app)\n <mask>         finally:\n <mask>             os.environ = env\n <mask>  </s> remove         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py') </s> add         app.config.from_pyfile(__file__.rsplit('.', 1)[0] + '.py') </s> remove                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out) </s> add                 self.assert_(os.path.basename(__file__.rsplit('.', 1)[0] + '.py') in out)", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with catch_stderr() as err:\n <mask>                 c.get('/')\n <mask>                 out = err.getvalue()\n <mask>                 self.assert_('WARNING in helpers [' in out)\n <mask>                 self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n <mask>                 self.assert_('the standard library is dead' in out)\n <mask>                 self.assert_('this is a debug statement' in out)\n <mask> \n <mask>             with catch_stderr() as err:\n <mask>                 try: </s> Fixed a bug in the testsuite that caused problems when dots where in directory names </s> remove             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'} </s> add             os.environ = {'FOO_SETTINGS': __file__.rsplit('.', 1)[0] + '.py'}", "html_url": "https://github.com/pallets/flask/commit/fbd6776e68a12aa7bf7d646ca03d568cedc616f3", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS'])\n <mask>         rv = c.head('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert not rv.data  # head truncates\n <mask>         self.assert_equal(c.post('/more').data, 'POST')\n <mask>         self.assert_equal(c.get('/more').data, 'GET')\n <mask>         rv = c.delete('/more')\n <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS', 'POST']) </s> remove         assert not rv.data  # head truncates </s> add         self.assert_(not rv.data) # head truncates </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS'])\n <mask>         rv = c.head('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert not rv.data  # head truncates\n <mask>         self.assert_equal(c.post('/more').data, 'POST')\n <mask>         self.assert_equal(c.get('/more').data, 'GET')\n <mask>         rv = c.delete('/more')\n <mask>         self.assert_equal(rv.status_code, 405)\n <mask>         self.assert_equal(sorted(rv.allow), ['GET', 'HEAD', 'OPTIONS', 'POST'])\n </s> Changed assert to self.assert_ where it was still in place", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com/')\n <mask>         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n <mask>         assert 'httponly' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_session_using_server_name_and_port(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.update(\n <mask>             SECRET_KEY='foo', </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower() </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com:8080/')\n <mask>         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n <mask>         assert 'httponly' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_session_using_application_root(self):\n <mask>         class PrefixPathMiddleware(object):\n <mask>             def __init__(self, app, prefix):\n <mask>                 self.app = app </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower() </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower()) </s> remove         assert 'Response' in rv.data </s> remove         assert 'Response' in rv.data", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def index():\n <mask>             flask.session['testing'] = 42\n <mask>             return 'Hello World'\n <mask>         rv = app.test_client().get('/', 'http://example.com:8080/')\n <mask>         assert 'path=/bar' in rv.headers['set-cookie'].lower()\n <mask> \n <mask>     def test_missing_session(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         def expect_exception(f, *args, **kwargs):\n <mask>             try: </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove                 assert e.args and 'session is unavailable' in e.args[0] </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0]) </s> add             self.assert_(isinstance(e, MyException)) </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             try:\n <mask>                 f(*args, **kwargs)\n <mask>             except RuntimeError, e:\n <mask>                 assert e.args and 'session is unavailable' in e.args[0]\n <mask>             else:\n <mask>                 assert False, 'expected exception'\n <mask>         with app.test_request_context():\n <mask>             assert flask.session.get('missing_key') is None\n <mask>             expect_exception(flask.session.__setitem__, 'foo', 42) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove         assert flask._request_ctx_stack.top is None </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 assert e.args and 'session is unavailable' in e.args[0]\n <mask>             else:\n <mask>                 assert False, 'expected exception'\n <mask>         with app.test_request_context():\n <mask>             assert flask.session.get('missing_key') is None\n <mask>             expect_exception(flask.session.__setitem__, 'foo', 42)\n <mask>             expect_exception(flask.session.pop, 'foo')\n <mask> \n <mask>     def test_session_expiration(self):\n <mask>         permanent = True </s> add                 self.assert_(False, 'expected exception') </s> remove                 assert e.args and 'session is unavailable' in e.args[0] </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0]) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove         assert flask._request_ctx_stack.top is None </s> add         self.assert_(flask._request_ctx_stack.top is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return unicode(flask.session.permanent)\n <mask> \n <mask>         client = app.test_client()\n <mask>         rv = client.get('/')\n <mask>         assert 'set-cookie' in rv.headers\n <mask>         match = re.search(r'\\bexpires=([^;]+)', rv.headers['set-cookie'])\n <mask>         expires = parse_date(match.group())\n <mask>         expected = datetime.utcnow() + app.permanent_session_lifetime\n <mask>         self.assert_equal(expires.year, expected.year)\n <mask>         self.assert_equal(expires.month, expected.month) </s> remove         assert match is None </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove                 assert 'x-sendfile' in rv.headers </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         permanent = False\n <mask>         rv = app.test_client().get('/')\n <mask>         assert 'set-cookie' in rv.headers\n <mask>         match = re.search(r'\\bexpires=([^;]+)', rv.headers['set-cookie'])\n <mask>         assert match is None\n <mask> \n <mask>     def test_flashes(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.secret_key = 'testkey' </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.session.modified </s> add             self.assert_(flask.session.modified) </s> remove             assert not flask.session.modified </s> add             self.assert_(not flask.session.modified) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         app.secret_key = 'testkey'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert not flask.session.modified\n <mask>             flask.flash('Zap')\n <mask>             flask.session.modified = False\n <mask>             flask.flash('Zip')\n <mask>             assert flask.session.modified\n <mask>             self.assert_equal(list(flask.get_flashed_messages()), ['Zap', 'Zip'])\n <mask> \n <mask>     def test_extended_flashing(self):\n <mask>         app = flask.Flask(__name__) </s> add         self.assert_(match is None) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep replace replace keep replace keep", "code_tokens": " <mask>         def index():\n <mask>             assert 'before' in evts\n <mask>             assert 'after' not in evts\n <mask>             return 'request'\n <mask>         assert 'after' not in evts\n <mask>         rv = app.test_client().get('/').data </s> Changed assert to self.assert_ where it was still in place </s> remove         assert 'after' in evts </s> add         self.assert_('after' in evts) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'domain=.example.com' in rv.headers['set-cookie'].lower()\n        assert 'httponly' in rv.headers['set-cookie'].lower() </s> add         self.assert_('domain=.example.com' in rv.headers['set-cookie'].lower())\n        self.assert_('httponly' in rv.headers['set-cookie'].lower()) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower() </s> add         self.assert_('path=/bar' in rv.headers['set-cookie'].lower())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert 'after' not in evts\n <mask>             return 'request'\n <mask>         assert 'after' not in evts\n <mask>         rv = app.test_client().get('/').data\n <mask>         assert 'after' in evts\n <mask>         self.assert_equal(rv, 'request|after')\n <mask> \n <mask>     def test_teardown_request_handler(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'after' not in evts </s> add         self.assert_('after' not in evts) </s> remove             assert 'before' in evts\n            assert 'after' not in evts </s> add             self.assert_('before' in evts)\n            self.assert_('after' not in evts) </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def root():\n <mask>             return \"Response\"\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert 'Response' in rv.data\n <mask>         self.assert_equal(len(called), 1)\n <mask> \n <mask>     def test_teardown_request_handler_debug_mode(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> add         self.assert_(not rv.data) # head truncates </s> add         self.assert_(not rv.data) # head truncates", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def root():\n <mask>             return \"Response\"\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         assert 'Response' in rv.data\n <mask>         self.assert_equal(len(called), 1)\n <mask> \n <mask>     def test_teardown_request_handler_error(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove         assert not rv.data  # head truncates </s> add         self.assert_(not rv.data) # head truncates </s> remove         assert not rv.data  # head truncates </s> add         self.assert_(not rv.data) # head truncates", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def fails():\n <mask>             1/0\n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 500)\n <mask>         assert 'Internal Server Error' in rv.data\n <mask>         self.assert_equal(len(called), 2)\n <mask> \n <mask>     def test_before_after_request_order(self):\n <mask>         called = []\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'Internal Server Error' in rv.data </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app = flask.Flask(__name__)\n <mask>         @app.errorhandler(MyException)\n <mask>         def handle_my_exception(e):\n <mask>             assert isinstance(e, MyException)\n <mask>             return '42'\n <mask>         @app.route('/')\n <mask>         def index():\n <mask>             raise MyException()\n <mask>  </s> remove             assert False </s> add             self.assert_(False) </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         c = app.test_client()\n <mask>         try:\n <mask>             c.get('/fail')\n <mask>         except KeyError, e:\n <mask>             assert isinstance(e, BadRequest)\n <mask>         else:\n <mask>             self.fail('Expected exception')\n <mask> \n <mask>     def test_trapping_of_all_http_exceptions(self):\n <mask>         app = flask.Flask(__name__) </s> remove             assert 'init_jinja_globals' in str(log[0]['message']) </s> add             self.assert_('init_jinja_globals' in str(log[0]['message']))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         with app.test_client() as c:\n <mask>             try:\n <mask>                 c.post('/fail', data={'foo': 'index.txt'})\n <mask>             except DebugFilesKeyError, e:\n <mask>                 assert 'no file contents were transmitted' in str(e)\n <mask>                 assert 'This was submitted: \"index.txt\"' in str(e)\n <mask>             else:\n <mask>                 self.fail('Expected exception')\n <mask> \n <mask>     def test_teardown_on_pop(self):\n <mask>         buffer = [] </s> Changed assert to self.assert_ where it was still in place </s> remove             assert isinstance(e, BadRequest) </s> remove             assert msg.startswith('[Errno 2] Unable to load configuration '\n                                  'file (No such file or directory):')\n            assert msg.endswith(\"missing.cfg'\") </s> add             self.assert_(msg.startswith('[Errno 2] Unable to load configuration '\n                                        'file (No such file or directory):'))\n            self.assert_(msg.endswith(\"missing.cfg'\")) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         def hello():\n <mask>             pass\n <mask>         with app.test_request_context():\n <mask>             self.assert_equal(flask.url_for('hello', name='test x'), '/hello/test%20x')\n <mask>             assert flask.url_for('hello', name='test x', _external=True) \\\n <mask>                 == 'http://localhost/hello/test%20x'\n <mask> \n <mask>     def test_custom_converters(self):\n <mask>         from werkzeug.routing import BaseConverter\n <mask>         class ListConverter(BaseConverter):\n <mask>             def to_python(self, value): </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail' </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = app.test_client().get('/static/index.html')\n <mask>         self.assert_equal(rv.status_code, 200)\n <mask>         self.assert_equal(rv.data.strip(), '<h1>Hello World!</h1>')\n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('static', filename='index.html') \\\n <mask>                 == '/static/index.html'\n <mask> \n <mask>     def test_none_response(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         @app.route('/')\n <mask>         def test(): </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail' </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x' </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except ValueError, e:\n <mask>             self.assert_equal(str(e), 'View function did not return a response')\n <mask>             pass\n <mask>         else:\n <mask>             assert \"Expected ValueError\"\n <mask> \n <mask>     def test_request_locals(self):\n <mask>         self.assert_equal(repr(flask.g), '<LocalProxy unbound>')\n <mask>         self.assertFalse(flask.g)\n <mask>  </s> add             self.assert_(isinstance(e, ValueError)) </s> add             self.assert_(0, 'expected runtime error') </s> remove             assert isinstance(e, BadRequest) </s> add             self.assert_(isinstance(e, BadRequest))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         try:\n <mask>             with app.test_request_context('/', environ_overrides={'HTTP_HOST': 'localhost'}):\n <mask>                 pass\n <mask>         except Exception, e:\n <mask>             assert isinstance(e, ValueError)\n <mask>             self.assert_equal(str(e), \"the server name provided \" +\n <mask>                     \"('localhost.localdomain:5000') does not match the \" + \\\n <mask>                     \"server name from the WSGI environment ('localhost')\")\n <mask> \n <mask>         try: </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app.config['MAX_CONTENT_LENGTH'] = 64\n <mask>         @app.before_request\n <mask>         def always_first():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413) </s> remove             assert flask.session.modified </s> add             self.assert_(flask.session.modified) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert not flask.session.modified </s> add             self.assert_(not flask.session.modified) </s> remove         assert 'Exception on / [GET]' in err\n        assert 'Traceback (most recent call last):' in err\n        assert '1/0' in err\n        assert 'ZeroDivisionError:' in err", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert False\n <mask>         @app.route('/accept', methods=['POST'])\n <mask>         def accept_file():\n <mask>             flask.request.form['myfile']\n <mask>             assert False\n <mask>         @app.errorhandler(413)\n <mask>         def catcher(error):\n <mask>             return '42'\n <mask> \n <mask>         c = app.test_client() </s> remove             assert isinstance(e, BadRequest) </s> add             self.assert_(isinstance(e, BadRequest)) </s> remove             assert flask.session.modified </s> add             self.assert_(flask.session.modified) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask>         with app.test_request_context('/?name=World'):\n <mask>             self.assert_equal(index(), 'Hello World!')\n <mask>         with app.test_request_context('/meh'):\n <mask>             self.assert_equal(meh(), 'http://localhost/meh')\n <mask>         assert flask._request_ctx_stack.top is None\n <mask> \n <mask>     def test_context_test(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         assert not flask.request\n <mask>         assert not flask.has_request_context()\n <mask>         ctx = app.test_request_context()\n <mask>         ctx.push()\n <mask>         try:\n <mask>             assert flask.request </s> remove             assert flask.request\n            assert flask.has_request_context() </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove         assert app.logger is not logger1 </s> add         self.assert_(app.logger is not logger1)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         assert not flask.has_request_context()\n <mask>         ctx = app.test_request_context()\n <mask>         ctx.push()\n <mask>         try:\n <mask>             assert flask.request\n <mask>             assert flask.has_request_context()\n <mask>         finally:\n <mask>             ctx.pop()\n <mask> \n <mask>     def test_manual_context_binding(self):\n <mask>         app = flask.Flask(__name__) </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context()) </s> remove         assert flask._request_ctx_stack.top is None </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> add                     self.assert_(0, 'expected exception') </s> remove             assert flask.session.modified </s> add             self.assert_(flask.session.modified)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/basic.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), '/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('admin.static', filename='test.txt') \\\n <mask>                 == '/admin/static/test.txt'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             try:\n <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e: </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail' </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> add                 self.assert_(0, 'expected exception') </s> add                 self.assert_(0, 'expected exception') </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x' </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n <mask>                 self.assert_equal(e.name, 'missing.html')\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask> \n <mask>         with flask.Flask(__name__).test_request_context():\n <mask>             self.assert_equal(flask.render_template('nested/nested.txt'), 'I\\'m nested')\n <mask> \n <mask>     def test_safe_access(self): </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 f('/etc/passwd')\n <mask>             except NotFound:\n <mask>                 pass\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             try:\n <mask>                 f('../__init__.py')\n <mask>             except NotFound:\n <mask>                 pass\n <mask>             else: </s> add                     self.assert_(0, 'expected exception') </s> add                 self.assert_(0, 'expected exception') </s> add             self.assert_(0, 'expected runtime error') </s> add                 self.assert_(0, 'expected exception') </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     f('..\\\\__init__.py')\n <mask>                 except NotFound:\n <mask>                     pass\n <mask>                 else:\n <mask>                     assert 0, 'expected exception'\n <mask>             finally:\n <mask>                 os.path = old_path\n <mask> \n <mask>     @emits_module_deprecation_warning\n <mask>     def test_endpoint_decorator(self): </s> add                 self.assert_(0, 'expected exception') </s> add                 self.assert_(0, 'expected exception') </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> add                 self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         rv = c.get('/admin/static/css/test.css')\n <mask>         self.assert_equal(rv.data.strip(), '/* nested file */')\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert flask.url_for('admin.static', filename='test.txt') \\\n <mask>                 == '/admin/static/test.txt'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             try:\n <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n </s> Changed assert to self.assert_ where it was still in place", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 flask.render_template('missing.html')\n <mask>             except TemplateNotFound, e:\n <mask>                 self.assert_equal(e.name, 'missing.html')\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask> \n <mask>         with flask.Flask(__name__).test_request_context():\n <mask>             self.assert_equal(flask.render_template('nested/nested.txt'), 'I\\'m nested')\n <mask> \n <mask>     def test_templates_list(self): </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def common_object_test(self, app):\n <mask>         self.assert_equal(app.secret_key, 'devkey')\n <mask>         self.assert_equal(app.config['TEST_KEY'], 'foo')\n <mask>         assert 'ConfigTestCase' not in app.config\n <mask> \n <mask>     def test_config_from_file(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         app.config.from_pyfile(__file__.rsplit('.')[0] + '.py')\n <mask>         self.common_object_test(app) </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove         assert app.logger is logger1 </s> add         self.assert_(app.logger is logger1) </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove         assert app.logger is not logger1 </s> add         self.assert_(app.logger is not logger1) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None) </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace keep replace replace", "code_tokens": " <mask>                 app.config.from_envvar('FOO_SETTINGS')\n <mask>             except RuntimeError, e:\n <mask>                 assert \"'FOO_SETTINGS' is not set\" in str(e)\n <mask>             else:\n <mask>                 assert 0, 'expected exception'\n <mask>             assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove             assert msg.startswith('[Errno 2] Unable to load configuration '\n                                  'file (No such file or directory):')\n            assert msg.endswith(\"missing.cfg'\") </s> add             self.assert_(msg.startswith('[Errno 2] Unable to load configuration '\n                                        'file (No such file or directory):'))\n            self.assert_(msg.endswith(\"missing.cfg'\")) </s> remove                 assert e.args and 'session is unavailable' in e.args[0] </s> add                 self.assert_(e.args and 'session is unavailable' in e.args[0])", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 assert 0, 'expected exception'\n <mask>             assert not app.config.from_envvar('FOO_SETTINGS', silent=True)\n <mask> \n <mask>             os.environ = {'FOO_SETTINGS': __file__.rsplit('.')[0] + '.py'}\n <mask>             assert app.config.from_envvar('FOO_SETTINGS')\n <mask>             self.common_object_test(app)\n <mask>         finally:\n <mask>             os.environ = env\n <mask> \n <mask>     def test_config_missing(self): </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove             assert flask.request\n            assert flask.has_request_context() </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove         assert 'ConfigTestCase' not in app.config </s> add         self.assert_('ConfigTestCase' not in app.config) </s> remove             assert 0, 'expected config'\n        assert not app.config.from_pyfile('missing.cfg', silent=True) </s> add             self.assert_(0, 'expected config')\n        self.assert_(not app.config.from_pyfile('missing.cfg', silent=True))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace replace keep keep", "code_tokens": " <mask>         except IOError, e:\n <mask>             msg = str(e)\n <mask>             assert msg.startswith('[Errno 2] Unable to load configuration '\n <mask>                                   'file (No such file or directory):')\n <mask>             assert msg.endswith(\"missing.cfg'\")\n <mask>         else:\n <mask>             assert 0, 'expected config'\n <mask>         assert not app.config.from_pyfile('missing.cfg', silent=True)\n <mask> \n <mask>  </s> remove                 assert 0, 'expected exception'\n            assert not app.config.from_envvar('FOO_SETTINGS', silent=True) </s> add                 self.assert_(0, 'expected exception')\n            self.assert_(not app.config.from_envvar('FOO_SETTINGS', silent=True)) </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> remove                 assert 'no file contents were transmitted' in str(e)\n                assert 'This was submitted: \"index.txt\"' in str(e) </s> add                 self.assert_('no file contents were transmitted' in str(e))\n                self.assert_('This was submitted: \"index.txt\"' in str(e))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             c = app.test_client()\n <mask>             self.assert_equal(c.get('/').data, '42')\n <mask>             self.assert_equal(len(log), 1)\n <mask>             assert 'init_jinja_globals' in str(log[0]['message'])\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(DeprecationsTestCase)) </s> remove             assert isinstance(e, BadRequest) </s> add             self.assert_(isinstance(e, BadRequest))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/deprecations.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def test_send_file_regular(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             assert rv.direct_passthrough\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask>             with app.open_resource('static/index.html') as f:\n <mask>                 self.assert_equal(rv.data, f.read())\n <mask> \n <mask>     def test_send_file_xsendfile(self): </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' in rv.headers </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.render_template_string('{{ foo }}',\n                foo='<test>') == '<test>'\n            assert flask.render_template('mail.txt', foo='<test>') \\\n                == '<test> Mail' </s> add             self.assert_equal(flask.render_template_string('{{ foo }}',\n                              foo='<test>'), '<test>')\n            self.assert_equal(flask.render_template('mail.txt', foo='<test>'),\n                              '<test> Mail') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file('static/index.html')\n <mask>             assert rv.direct_passthrough\n <mask>             assert 'x-sendfile' in rv.headers\n <mask>             self.assert_equal(rv.headers['x-sendfile'],\n <mask>                 os.path.join(app.root_path, 'static/index.html'))\n <mask>             self.assert_equal(rv.mimetype, 'text/html')\n <mask> \n <mask>     def test_send_file_object(self): </s> remove                 assert 'x-sendfile' in rv.headers </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough </s> add             self.assert_(rv.direct_passthrough) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with app.test_request_context():\n <mask>                 f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>                 rv = flask.send_file(f)\n <mask>                 self.assert_equal(rv.mimetype, 'text/html')\n <mask>                 assert 'x-sendfile' in rv.headers\n <mask>                 self.assert_equal(rv.headers['x-sendfile'],\n <mask>                     os.path.join(app.root_path, 'static/index.html'))\n <mask>             # mimetypes + etag\n <mask>             self.assert_equal(len(captured), 2)\n <mask>  </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove             assert rv.direct_passthrough </s> add             self.assert_(rv.direct_passthrough) </s> remove         assert 'set-cookie' in rv.headers </s> add         self.assert_('set-cookie' in rv.headers) </s> remove         assert 'Internal Server Error' in rv.data </s> add         self.assert_('Internal Server Error' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         with catch_warnings() as captured:\n <mask>             with app.test_request_context():\n <mask>                 f = StringIO('Test')\n <mask>                 rv = flask.send_file(f)\n <mask>                 assert 'x-sendfile' not in rv.headers\n <mask>             # etags\n <mask>             self.assert_equal(len(captured), 1)\n <mask> \n <mask>     def test_attachment(self):\n <mask>         app = flask.Flask(__name__) </s> remove                 assert 'x-sendfile' in rv.headers </s> add                 self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers) </s> remove             assert rv.direct_passthrough </s> add             self.assert_(rv.direct_passthrough) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace", "code_tokens": " <mask>     def test_logger_cache(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         logger1 = app.logger\n <mask>         assert app.logger is logger1\n <mask>         self.assert_equal(logger1.name, __name__)\n <mask>         app.logger_name = __name__ + '/test_logger_cache'\n <mask>         assert app.logger is not logger1 </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e)) </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context()) </s> remove         assert flask._request_ctx_stack.top is None </s> add         self.assert_(flask._request_ctx_stack.top is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         with app.test_client() as c:\n <mask>             with catch_stderr() as err:\n <mask>                 c.get('/')\n <mask>                 out = err.getvalue()\n <mask>                 assert 'WARNING in helpers [' in out\n <mask>                 assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n <mask>                 assert 'the standard library is dead' in out\n <mask>                 assert 'this is a debug statement' in out\n <mask> \n <mask>             with catch_stderr() as err:\n <mask>                 try:\n <mask>                     c.get('/exc')\n <mask>                 except ZeroDivisionError: </s> Changed assert to self.assert_ where it was still in place </s> remove                     assert False, 'debug log ate the exception' </s> add                     self.assert_(False, 'debug log ate the exception') </s> remove                 assert 'no file contents were transmitted' in str(e)\n                assert 'This was submitted: \"index.txt\"' in str(e) </s> add                 self.assert_('no file contents were transmitted' in str(e))\n                self.assert_('This was submitted: \"index.txt\"' in str(e)) </s> remove                 assert 'x-sendfile' not in rv.headers </s> add                 self.assert_('x-sendfile' not in rv.headers) </s> remove         assert flask._request_ctx_stack.top is None </s> remove                 assert \"'FOO_SETTINGS' is not set\" in str(e) </s> add                 self.assert_(\"'FOO_SETTINGS' is not set\" in str(e))", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     c.get('/exc')\n <mask>                 except ZeroDivisionError:\n <mask>                     pass\n <mask>                 else:\n <mask>                     assert False, 'debug log ate the exception'\n <mask> \n <mask>     def test_exception_logging(self):\n <mask>         out = StringIO()\n <mask>         app = flask.Flask(__name__)\n <mask>         app.logger_name = 'flask_tests/test_exception_logging' </s> remove                 assert 'WARNING in helpers [' in out\n                assert os.path.basename(__file__.rsplit('.')[0] + '.py') in out\n                assert 'the standard library is dead' in out\n                assert 'this is a debug statement' in out </s> add                 self.assert_('WARNING in helpers [' in out)\n                self.assert_(os.path.basename(__file__.rsplit('.')[0] + '.py') in out)\n                self.assert_('the standard library is dead' in out)\n                self.assert_('this is a debug statement' in out) </s> add                     self.assert_(0, 'expected exception') </s> remove         assert app.logger is logger1 </s> add         self.assert_(app.logger is logger1) </s> remove         assert app.logger is not logger1 </s> add         self.assert_(app.logger is not logger1) </s> remove             assert flask.session.get('missing_key') is None </s> add             self.assert_(flask.session.get('missing_key') is None)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace keep", "code_tokens": " <mask> \n <mask>         rv = app.test_client().get('/')\n <mask>         self.assert_equal(rv.status_code, 500)\n <mask>         assert 'Internal Server Error' in rv.data\n <mask> \n <mask>         err = out.getvalue()\n <mask>         assert 'Exception on / [GET]' in err\n <mask>         assert 'Traceback (most recent call last):' in err\n <mask>         assert '1/0' in err\n <mask>         assert 'ZeroDivisionError:' in err\n <mask>  </s> remove         assert 'Internal Server Error' in rv.data </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove             assert not hasattr(flask.g, 'value')\n            assert 'Internal Server Error' in resp.data </s> add             self.assert_(not hasattr(flask.g, 'value'))\n            self.assert_('Internal Server Error' in resp.data) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data) </s> remove         assert 'Response' in rv.data </s> add         self.assert_('Response' in rv.data)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/helpers.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         flask.got_request_exception.connect(record, app)\n <mask>         try:\n <mask>             self.assert_equal(app.test_client().get('/').status_code, 500)\n <mask>             self.assert_equal(len(recorded), 1)\n <mask>             assert isinstance(recorded[0], ZeroDivisionError)\n <mask>         finally:\n <mask>             flask.got_request_exception.disconnect(record, app)\n <mask> \n <mask> \n <mask> def suite(): </s> remove             assert 'init_jinja_globals' in str(log[0]['message']) </s> add             self.assert_('init_jinja_globals' in str(log[0]['message'])) </s> remove             assert flask.request\n            assert flask.has_request_context() </s> add             self.assert_(flask.request)\n            self.assert_(flask.has_request_context()) </s> remove             assert app.config.from_envvar('FOO_SETTINGS') </s> add             self.assert_(app.config.from_envvar('FOO_SETTINGS')) </s> add                     self.assert_(0, 'expected exception')", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/signals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_no_escaping(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             assert flask.render_template_string('{{ foo }}',\n <mask>                 foo='<test>') == '<test>'\n <mask>             assert flask.render_template('mail.txt', foo='<test>') \\\n <mask>                 == '<test> Mail'\n <mask> \n <mask>     def test_macros(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             macro = flask.get_template_attribute('_macro.html', 'hello') </s> remove             assert flask.url_for('static', filename='index.html') \\\n                == '/static/index.html' </s> add             self.assert_equal(flask.url_for('static', filename='index.html'),\n                              '/static/index.html') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('admin.static', filename='test.txt') \\\n                == '/admin/static/test.txt' </s> add             self.assert_equal(flask.url_for('admin.static', filename='test.txt'),\n                              '/admin/static/test.txt') </s> remove             assert flask.url_for('hello', name='test x', _external=True) \\\n                == 'http://localhost/hello/test%20x' </s> add             self.assert_equal(flask.url_for('hello', name='test x', _external=True),\n                              'http://localhost/hello/test%20x') </s> add             self.assert_(rv.direct_passthrough) </s> remove             assert rv.direct_passthrough\n            assert 'x-sendfile' in rv.headers </s> add             self.assert_(rv.direct_passthrough)\n            self.assert_('x-sendfile' in rv.headers)", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter()\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         assert 'my_reverse' in  app.jinja_env.filters.keys()\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['my_reverse']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_name(self):\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'strrev' in  app.jinja_env.filters.keys() </s> add         self.assert_('strrev' in  app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         app = flask.Flask(__name__)\n <mask>         @app.template_filter('strrev')\n <mask>         def my_reverse(s):\n <mask>             return s[::-1]\n <mask>         assert 'strrev' in  app.jinja_env.filters.keys()\n <mask>         self.assert_equal(app.jinja_env.filters['strrev'], my_reverse)\n <mask>         self.assert_equal(app.jinja_env.filters['strrev']('abcd'), 'dcba')\n <mask> \n <mask>     def test_template_filter_with_template(self):\n <mask>         app = flask.Flask(__name__) </s> remove         assert 'my_reverse' in  app.jinja_env.filters.keys() </s> add         self.assert_('my_reverse' in  app.jinja_env.filters.keys())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/templating.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(resp.data, 'Hello World!')\n <mask>             self.assert_equal(resp.status_code, 200)\n <mask> \n <mask>             resp = c.get('/other')\n <mask>             assert not hasattr(flask.g, 'value')\n <mask>             assert 'Internal Server Error' in resp.data\n <mask>             self.assert_equal(resp.status_code, 500)\n <mask>             flask.g.value = 23\n <mask> \n <mask>         try:\n <mask>             flask.g.value </s> remove         assert 'Internal Server Error' in rv.data </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert 'Internal Server Error' in rv.data </s> add         self.assert_('Internal Server Error' in rv.data) </s> remove         assert flask._request_ctx_stack.top is None </s> add         self.assert_(flask._request_ctx_stack.top is None) </s> remove         assert 'path=/bar' in rv.headers['set-cookie'].lower() </s> remove         assert not flask.request\n        assert not flask.has_request_context() </s> add         self.assert_(not flask.request)\n        self.assert_(not flask.has_request_context())", "html_url": "https://github.com/pallets/flask/commit/fc2caa4b9c75a6ee8569495008efd1f37c27a8cb", "file_name": "flask/testsuite/testing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         for cls in self.default_tags:\n <mask>             self.register(cls)\n <mask> \n <mask>     def register(self, tag_class, force=False, index=-1):\n <mask>         \"\"\"Register a new tag with this serializer.\n <mask> \n <mask>         :param tag_class: tag class to register. Will be instantiated with this\n <mask>             serializer instance.\n <mask>         :param force: overwrite an existing tag. If false (default), a </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order. </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order. </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2)", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             serializer instance.\n <mask>         :param force: overwrite an existing tag. If false (default), a\n <mask>             :exc:`KeyError` is raised.\n <mask>         :param index: index to insert the new tag in the tag order. Useful when\n <mask>             the new tag is a special case of an existing tag. If -1 (default),\n <mask>             the tag is appended to the end of the order.\n <mask> \n <mask>         :raise KeyError: if the tag key is already registered and ``force`` is\n <mask>             not true.\n <mask>         \"\"\"\n <mask>         tag = tag_class(self) </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove     def register(self, tag_class, force=False, index=-1): </s> add     def register(self, tag_class, force=False, index=None): </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2)", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 raise KeyError(\"Tag '{0}' is already registered.\".format(key))\n <mask> \n <mask>             self.tags[key] = tag\n <mask> \n <mask>         if index == -1:\n <mask>             self.order.append(tag)\n <mask>         else:\n <mask>             self.order.insert(index, tag)\n <mask> \n <mask>     def tag(self, value): </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> add def test_tag_order():\n    class Tag1(JSONTag):\n        key = ' 1'\n\n    class Tag2(JSONTag):\n        key = ' 2'\n\n    s = TaggedJSONSerializer()\n\n    s.register(Tag1, index=-1)\n    assert isinstance(s.order[-2], Tag1)\n\n    s.register(Tag2, index=None)\n    assert isinstance(s.order[-1], Tag2) </s> remove     def register(self, tag_class, force=False, index=-1): </s> add     def register(self, tag_class, force=False, index=None): </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order. </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order.", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "flask/json/tag.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>     t = JSONTag(None)\n <mask>     pytest.raises(NotImplementedError, t.check, None)\n <mask>     pytest.raises(NotImplementedError, t.to_json, None)\n <mask>     pytest.raises(NotImplementedError, t.to_python, None) </s> Fix default index for TaggedJSONSerializer.register()\n\nChange the default value of ``index`` to ``None`` in ``register()`` so\nthat it is possible to insert a new tag as the penultimate item in the\norder list. </s> remove             the new tag is a special case of an existing tag. If -1 (default),\n            the tag is appended to the end of the order. </s> add             the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order. </s> remove     def register(self, tag_class, force=False, index=-1): </s> add     def register(self, tag_class, force=False, index=None):", "html_url": "https://github.com/pallets/flask/commit/fc6a1d9354124690e632323d46ee35c3b8c9c8d2", "file_name": "tests/test_json_tag.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> Unreleased\n <mask> \n <mask> \n <mask> Version 2.0.0\n <mask> -------------\n <mask> \n <mask> Released 2021-05-11\n <mask>  </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return path\n <mask> \n <mask> \n <mask> def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\":\n <mask>     \"\"\"Send a file from within a directory using :func:`send_file`.\n <mask> \n <mask>     .. code-block:: python\n <mask> \n <mask>         @app.route(\"/uploads/<path:name>\")\n </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename\n </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019`\n", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         ``directory``.\n <mask>     :param kwargs: Arguments to pass to :func:`send_file`.\n <mask> \n <mask>     .. versionadded:: 2.0\n <mask>         Moved the implementation to Werkzeug. This is now a wrapper to\n <mask>         pass some Flask-specific arguments.\n <mask> \n <mask>     .. versionadded:: 0.5\n <mask>     \"\"\" </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     if filename is not None:\n        warnings.warn(\n            \"The 'filename' parameter has been renamed to 'path'. The\"\n            \" old name will be removed in Flask 2.1.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        path = filename </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019` </s> remove def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\": </s> add def send_from_directory(\n    directory: str, path: str, filename: t.Optional[str] = None, **kwargs: t.Any\n) -> \"Response\":", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         pass some Flask-specific arguments.\n <mask> \n <mask>     .. versionadded:: 0.5\n <mask>     \"\"\"\n <mask>     return werkzeug.utils.send_from_directory(  # type: ignore\n <mask>         directory, path, **_prepare_send_file_kwargs(**kwargs)\n <mask>     )\n <mask>  </s> Re-add filename param for send_from_directory\n\nAdd a deprecation warning for the old name </s> add     .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter. </s> remove def send_from_directory(directory: str, path: str, **kwargs: t.Any) -> \"Response\": </s> add def send_from_directory(\n    directory: str, path: str, filename: t.Optional[str] = None, **kwargs: t.Any\n) -> \"Response\": </s> add -   Re-add the ``filename`` parameter in ``send_from_directory``. The\n    ``filename`` parameter has been renamed to ``path``, the old name\n    is deprecated. :pr:`4019`", "html_url": "https://github.com/pallets/flask/commit/fc82dd50e39700b14799df17578e2497b8f0248c", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep replace replace replace replace replace keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> Extension objects are not initially bound to an application. Using\n <mask> ``db.init_app``, the app gets configured for the extension. No\n <mask> application-specific state is stored on the extension object, so one extension\n <mask> object can be used for multiple apps. For more information about the design of\n <mask> extensions refer to :doc:`/extensiondev`.\n <mask> \n <mask> Your `model.py` might look like this when using `Flask-SQLAlchemy\n <mask> <http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n <mask> \n <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy() </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory. </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app) </s> add Using this design pattern, no application-specific state is stored on the\nextension object, so one extension object can be used for multiple apps. \nFor more information about the design of extensions refer to :doc:`/extensiondev`.", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Your `model.py` might look like this when using `Flask-SQLAlchemy\n <mask> <http://pythonhosted.org/Flask-SQLAlchemy/>`_::\n <mask> \n <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy()\n <mask> \n <mask>     # create some models\n <mask> \n <mask> Using Applications </s> remove     # create some models </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app) </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`. </s> remove Your `model.py` might look like this when using `Flask-SQLAlchemy\n<http://pythonhosted.org/Flask-SQLAlchemy/>`_:: </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent)::", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> But, rather, in model.py (or equivalent)::\n <mask> \n <mask>     db = SQLAlchemy()\n <mask> \n <mask> Using this design pattern, no application-specific state is stored on the\n <mask> extension object, so one extension object can be used for multiple apps. \n <mask> For more information about the design of extensions refer to :doc:`/extensiondev`. </s> remove Your `model.py` might look like this when using `Flask-SQLAlchemy\n<http://pythonhosted.org/Flask-SQLAlchemy/>`_:: </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent):: </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory. </s> add Using this design pattern, no application-specific state is stored on the\nextension object, so one extension object can be used for multiple apps. \nFor more information about the design of extensions refer to :doc:`/extensiondev`. </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`.", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     from flask.ext.sqlalchemy import SQLAlchemy\n <mask>     # no app object passed! Instead we use use db.init_app in the factory.\n <mask>     db = SQLAlchemy()\n <mask> \n <mask>     # create some models\n <mask> \n <mask> Using Applications\n <mask> ------------------\n <mask> \n <mask> So to use such an application you then have to create the application </s> remove     from flask.ext.sqlalchemy import SQLAlchemy\n    # no app object passed! Instead we use use db.init_app in the factory. </s> add It's preferable to create your extensions and app factories so that the\nextension object does not initially get bound to the application.\n\nUsing `Flask-SQLAlchemy <http://pythonhosted.org/Flask-SQLAlchemy/>`_, \nas an example, you should **not** do::\n    \n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        db = SQLAlchemy(app)\n\nBut, rather, in model.py (or equivalent):: </s> remove Extension objects are not initially bound to an application. Using\n``db.init_app``, the app gets configured for the extension. No\napplication-specific state is stored on the extension object, so one extension\nobject can be used for multiple apps. For more information about the design of\nextensions refer to :doc:`/extensiondev`. </s> add     \nand in your application.py (or equivalent)::\n\n    def create_app(config_filename):\n        app = Flask(__name__)\n        app.config.from_pyfile(config_filename)\n\n        from yourapplication.model import db\n        db.init_app(app)", "html_url": "https://github.com/pallets/flask/commit/fc85bf42ae8fcd6cc76c734d0871bb78ad2a8f06", "file_name": "docs/patterns/appfactories.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> -   JSON support no longer uses simplejson. To use another JSON module,\n <mask>     override ``app.json_encoder`` and ``json_decoder``. :issue:`3555`\n <mask> -   The ``encoding`` option to JSON functions is deprecated. :pr:`3562`\n <mask> -   Add :meth:`sessions.SessionInterface.get_cookie_name` to allow\n <mask>     setting the session cookie name dynamically. :pr:`3369`\n <mask> -   Add :meth:`Config.from_file` to load config using arbitrary file\n <mask>     loaders, such as ``toml.load`` or ``json.load``. </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        )", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> ``app`` or ``application``, then any application instance. If no instance is\n <mask> found, the command looks for a factory function named ``create_app`` or\n <mask> ``make_app`` that returns an instance.\n <mask> \n <mask> When calling an application factory, if the factory takes an argument named\n <mask> ``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\n <mask> keyword argument. If the application factory takes only one argument and no\n <mask> parentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\n <mask> is passed as a positional argument. If parentheses follow the factory name,\n <mask> their contents are parsed as Python literals and passes as arguments to the\n <mask> function. This means that strings must still be in quotes.\n <mask> \n <mask> \n <mask> Run the Development Server\n <mask> --------------------------\n <mask>  </s> deprecate passing script_info to factory </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments. </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     if \"script_info\" in arg_names: </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     def create_app(info): </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import traceback\n <mask> from functools import update_wrapper\n <mask> from operator import attrgetter\n <mask> from threading import Lock\n <mask> from threading import Thread </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        )", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace replace keep replace keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask>     arg_names = args_spec.args\n <mask>     arg_defaults = args_spec.defaults\n <mask> \n <mask>     if \"script_info\" in arg_names:\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments) </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None: </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove         def create_app(info): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments. </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     if \"script_info\" in arg_names:\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments)\n <mask>     elif not arguments and len(arg_names) == 1 and arg_defaults is None:\n <mask>         return app_factory(script_info)\n <mask> \n <mask>     return app_factory()\n <mask> \n <mask>  </s> deprecate passing script_info to factory </s> remove     if \"script_info\" in arg_names: </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments. </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly. </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes. </s> add If parentheses follow the factory name, their contents are parsed as\nPython literals and passed as arguments to the function. This means that\nstrings must still be in quotes. </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]])) </s> remove     def create_app(info): </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name):\n <mask>     \"\"\"Checks if the given string is a variable name or a function. If it is a\n <mask>     function, it checks for specified arguments and whether it takes a\n <mask>     ``script_info`` argument and calls the function with the appropriate\n <mask>     arguments.\n <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n <mask>     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n <mask>  </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes. </s> add -   Passing ``script_info`` to app factory functions is deprecated. This\n    was not portable outside the ``flask`` command. Use\n    ``click.get_current_context().obj`` if it's needed. :issue:`3552` </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     if \"script_info\" in arg_names: </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        )", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep", "code_tokens": " <mask> def create_app2(foo, bar):\n <mask>     return Flask(\"_\".join([\"app2\", foo, bar]))\n <mask> \n <mask> \n <mask> def create_app3(foo, script_info):\n <mask>     return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]]))\n <mask> \n <mask> \n <mask> def no_app():\n <mask>     pass </s> remove     def create_app(info): </s> add     def create_app(): </s> remove         def create_app(info): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_apps/cliapp/factory.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\") </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info): </s> add     def create_app(): </s> remove         def create_app(info): </s> add         def create_app(): </s> remove     def create_app(info): </s> add     def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\") </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info): </s> add     def create_app(): </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]])) </s> remove         def create_app(info): </s> add         def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def create_app(foo=None, script_info=None):\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\") </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info): </s> add     def create_app(): </s> remove def create_app3(foo, script_info):\n    return Flask(\"_\".join([\"app3\", foo, script_info.data[\"test\"]])) </s> remove         def create_app(info): </s> add         def create_app():", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         @staticmethod\n <mask>         def make_app():\n <mask>             return Flask(\"appname\")\n <mask> \n <mask>     assert isinstance(find_best_app(script_info, Module), Flask)\n <mask>     assert find_best_app(script_info, Module).name == \"appname\"\n <mask> \n <mask>     class Module:\n <mask>         myapp = Flask(\"appname1\")\n <mask> \n <mask>         @staticmethod </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # no script_info\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n <mask>         # trailing comma space\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n <mask>         # takes script_info\n <mask>         (\"cliapp.factory\", 'create_app3(\"foo\")', \"app3_foo_spam\"),\n <mask>         # strip whitespace\n <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"),\n <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result): </s> remove     info.data[\"test\"] = \"spam\" </s> remove     arg_names = args_spec.args\n    arg_defaults = args_spec.defaults </s> remove When calling an application factory, if the factory takes an argument named\n``script_info``, then the :class:`~cli.ScriptInfo` instance is passed as a\nkeyword argument. If the application factory takes only one argument and no\nparentheses follow the factory name, the :class:`~cli.ScriptInfo` instance\nis passed as a positional argument. If parentheses follow the factory name,\ntheir contents are parsed as Python literals and passes as arguments to the\nfunction. This means that strings must still be in quotes. </s> remove     if \"script_info\" in arg_names: </s> add     if \"script_info\" in args_spec.args:\n        warnings.warn(\n            \"The 'script_info' argument is deprecated and will not be\"\n            \" passed to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     elif not arguments and len(arg_names) == 1 and arg_defaults is None: </s> add     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n        warnings.warn(\n            \"Script info is deprecated and will not be passed as the\"\n            \" first argument to the app factory function in 2.1.\",\n            DeprecationWarning,\n        ) </s> remove     \"\"\"Checks if the given string is a variable name or a function. If it is a\n    function, it checks for specified arguments and whether it takes a\n    ``script_info`` argument and calls the function with the appropriate\n    arguments. </s> add     \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> def test_locate_app(test_apps, iname, aname, result):\n <mask>     info = ScriptInfo()\n <mask>     info.data[\"test\"] = \"spam\"\n <mask>     assert locate_app(info, iname, aname).name == result\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\n <mask>     \"iname,aname\", </s> remove         # takes script_info\n        (\"cliapp.factory\", 'create_app3(\"foo\")', \"app3_foo_spam\"), </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\")) </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     app = obj.load_app()\n <mask>     assert app.name == \"testapp\"\n <mask>     assert obj.load_app() is app\n <mask> \n <mask>     def create_app(info):\n <mask>         return Flask(\"createapp\")\n <mask> \n <mask>     obj = ScriptInfo(create_app=create_app)\n <mask>     app = obj.load_app()\n <mask>     assert app.name == \"createapp\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @with_appcontext\n <mask>     def testcmd():\n <mask>         click.echo(current_app.name)\n <mask> \n <mask>     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\"))\n <mask> \n <mask>     result = runner.invoke(testcmd, obj=obj)\n <mask>     assert result.exit_code == 0\n <mask>     assert result.output == \"testapp\\n\"\n <mask>  </s> deprecate passing script_info to factory </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\")) </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     info.data[\"test\"] = \"spam\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @subgroup.command(with_appcontext=True)\n <mask>     def test2():\n <mask>         click.echo(current_app.name)\n <mask> \n <mask>     obj = ScriptInfo(create_app=lambda info: Flask(\"testappgroup\"))\n <mask> \n <mask>     result = runner.invoke(cli, [\"test\"], obj=obj)\n <mask>     assert result.exit_code == 0\n <mask>     assert result.output == \"testappgroup\\n\"\n <mask>  </s> remove     obj = ScriptInfo(create_app=lambda info: Flask(\"testapp\")) </s> add     obj = ScriptInfo(create_app=lambda: Flask(\"testapp\")) </s> remove     def create_app(info): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"set_debug_flag\", (True, False))\n <mask> def test_flaskgroup_debug(runner, set_debug_flag):\n <mask>     \"\"\"Test FlaskGroup debug flag behavior.\"\"\"\n <mask> \n <mask>     def create_app(info):\n <mask>         app = Flask(\"flaskgroup\")\n <mask>         app.debug = True\n <mask>         return app\n <mask> \n <mask>     @click.group(cls=FlaskGroup, create_app=create_app, set_debug_flag=set_debug_flag) </s> remove     def create_app(info): </s> remove         def create_app(info): </s> remove         def create_app(info): </s> remove     def create_app(info): </s> remove     def create_app(info): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class TestRoutes:\n <mask>     @pytest.fixture\n <mask>     def invoke(self, runner):\n <mask>         def create_app(info):\n <mask>             app = Flask(__name__)\n <mask>             app.testing = True\n <mask> \n <mask>             @app.route(\"/get_post/<int:x>/<int:y>\", methods=[\"GET\", \"POST\"])\n <mask>             def yyy_get_post(x, y): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         return partial(runner.invoke, cli)\n <mask> \n <mask>     @pytest.fixture\n <mask>     def invoke_no_routes(self, runner):\n <mask>         def create_app(info):\n <mask>             app = Flask(__name__, static_folder=None)\n <mask>             app.testing = True\n <mask> \n <mask>             return app\n <mask>  </s> remove         def create_app(info): </s> add         def create_app(): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     def create_app(info): </s> add     def create_app(): </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     app = find_best_app(script_info, Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"script_info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\" </s> remove     assert isinstance(find_best_app(script_info, Module), Flask)\n    assert find_best_app(script_info, Module).name == \"appname\" </s> add     with pytest.deprecated_call(match=\"Script info\"):\n        app = find_best_app(script_info, Module)\n\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"", "html_url": "https://github.com/pallets/flask/commit/fcac7f11cf5fbdaa43c3a8c305b31cf0a43a70d3", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             self.name = name\n <mask>             self.__doc__ = doc\n <mask> \n <mask>         def _fail(self, *args, **kwargs):\n <mask>             raise RuntimeError(\n <mask>                 \"Signalling support is unavailable because the blinker\"\n <mask>                 \" library is not installed.\"\n <mask>             ) </s> remove                 \"signalling support is unavailable \"\n                \"because the blinker library is \"\n                \"not installed.\" </s> add                 \"Signalling support is unavailable because the blinker\"\n                \" library is not installed.\" </s> remove         send = lambda *a, **kw: None\n        connect = (\n            disconnect\n        ) = (\n            has_receivers_for\n        ) = receivers_for = temporarily_connected_to = connected_to = _fail </s> add -   Signaling support has a stub for the ``connect_via`` method when\n    the Blinker library is not installed. :pr:`3208`", "html_url": "https://github.com/pallets/flask/commit/fcf2eb4753d02caf258c5b1473fbb74721a3f489", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep replace replace replace keep keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>             raise RuntimeError(\n <mask>                 \"signalling support is unavailable \"\n <mask>                 \"because the blinker library is \"\n <mask>                 \"not installed.\"\n <mask>             )\n <mask> \n <mask>         send = lambda *a, **kw: None\n <mask>         connect = (\n <mask>             disconnect\n <mask>         ) = (\n <mask>             has_receivers_for\n <mask>         ) = receivers_for = temporarily_connected_to = connected_to = _fail\n <mask>         del _fail\n <mask> \n <mask> \n </s> FakeSignal should stub connect_via method </s> add         def send(self, *args, **kwargs):\n            pass\n </s> add -   Signaling support has a stub for the ``connect_via`` method when\n    the Blinker library is not installed. :pr:`3208`", "html_url": "https://github.com/pallets/flask/commit/fcf2eb4753d02caf258c5b1473fbb74721a3f489", "file_name": "flask/signals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Security Headers\n <mask> ----------------\n <mask> \n <mask> This section contains a list of headers supported by Flask.\n <mask> To configure HTTPS and handle the headers listed below we suggest the package `flask-talisman <https://github.com/GoogleCloudPlatform/flask-talisman>`_. \n <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> -------------------------------------\n <mask>  </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks. </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks. </s> add Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and man-in-the-middle (MITM) related attacks. </s> remove X-Frame-Options (Clickjacking protection) </s> add X-Frame-Options (Clickjacking Protection)", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> HTTP Strict Transport Security (HSTS)\n <mask> -------------------------------------\n <mask> \n <mask> Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask>     </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> HTTP Public Key Pinning (HPKP)\n <mask> ------------------------------\n <mask> \n <mask> This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask>  </s> remove X-Frame-Options (Clickjacking protection) </s> remove This section contains a list of headers supported by Flask. </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    Public-Key-Pins: pin-sha256=\"base64==\"; max-age=expireTime [; includeSubDomains][; report-uri=\"reportURI\"] \n <mask> \n <mask> See also `Public Key Pinning <https://developer.mozilla.org/en-US/docs/Web/HTTP/Public_Key_Pinning>`_.\n <mask> \n <mask> X-Frame-Options (Clickjacking protection)\n <mask> -----------------------------------------\n <mask> \n <mask> Prevents the client from clicking page elements outside of the website, avoiding hijacking or UI redress attacks.\n <mask> \n <mask> .. sourcecode:: none </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove This section contains a list of headers supported by Flask. </s> add This section contains a list of HTTP security headers supported by Flask.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Content Security Policy (CSP)\n <mask> -----------------------------\n <mask> \n <mask> Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.\n <mask> \n <mask> Example:\n <mask> \n <mask> .. sourcecode:: none\n <mask>     </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks. </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove X-Frame-Options (Clickjacking protection) </s> add X-Frame-Options (Clickjacking Protection) </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>    Content-Security-Policy: default-src https:; script-src 'nonce-{random}'; object-src 'none'\n <mask> \n <mask> See also `Content Security Policy <https://csp.withgoogle.com/docs/index.html>`_.\n <mask> \n <mask> Cookie options\n <mask> --------------\n <mask> \n <mask> While these headers are not directly security related, they have important options that may affect your flask application.\n <mask> \n <mask> - ``Secure`` limits your cookies to HTTPS traffic only. </s> remove While these headers are not directly security related, they have important options that may affect your flask application. </s> add While these headers are not directly security related, they have important options that may affect your Flask application. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks. </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Cookie options\n <mask> --------------\n <mask> \n <mask> While these headers are not directly security related, they have important options that may affect your flask application.\n <mask> \n <mask> - ``Secure`` limits your cookies to HTTPS traffic only.\n <mask> - ``HttpOnly`` protects the contents of your cookie from being visible to XSS.\n <mask> - ``SameSite`` ensures that cookies can only be requested from the same domain that created them but this feature is not yet fully supported across all browsers.  \n <mask>  </s> remove Cookie options </s> add Cookie Options </s> remove This section contains a list of headers supported by Flask. </s> add This section contains a list of HTTP security headers supported by Flask. </s> remove Redirects http requests to https on all urls, preventing Man-in-the-middle (MITM) attacks. </s> add Redirects HTTP requests to HTTPS on all URLs, preventing man-in-the-middle (MITM) attacks. </s> remove This enables your web server to authenticate with a client browser using a specific certificate key to prevent Man-in-the-middle (MITM) attacks. </s> add This enables your web server to authenticate with a client browser using a specific certificate key to prevent man-in-the-middle (MITM) attacks. </s> remove Enhances security and prevents common web vulnerabilities such as cross-site scripting (XSS) and Man-in-the-middle (MITM) related attacks.", "html_url": "https://github.com/pallets/flask/commit/fcfd03146011dbb2ab77868b2f56374d51b39d56", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             (None, code),\n <mask>             (request.blueprint, None),\n <mask>             (None, None),\n <mask>         ):\n <mask>             handler_map = self.error_handler_spec.setdefault(name, {}).get(c)\n <mask> \n <mask>             if not handler_map:\n <mask>                 continue\n <mask> \n <mask>             for cls in exc_class.__mro__: </s> remove         funcs = self.before_request_funcs.get(None, ()) </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ())) </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ())) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         funcs = self.url_default_functions.get(None, ())\n <mask>         if \".\" in endpoint:\n <mask>             bp = endpoint.rsplit(\".\", 1)[0]\n <mask>             funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n <mask>         for func in funcs:\n <mask>             func(endpoint, values) </s> remove         funcs = self.url_value_preprocessors.get(None, ()) </s> add         funcs = self.url_value_preprocessors[None]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask> \n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask> \n <mask>         funcs = self.url_value_preprocessors.get(None, ())\n <mask>         if bp is not None and bp in self.url_value_preprocessors:\n <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask>  </s> remove         funcs = self.before_request_funcs.get(None, ()) </s> add         funcs = self.before_request_funcs[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ())) </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ())) </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ()) </s> add         funcs = self.url_default_functions[None] </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c) </s> add             handler_map = self.error_handler_spec[name][c]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             funcs = chain(funcs, self.url_value_preprocessors[bp])\n <mask>         for func in funcs:\n <mask>             func(request.endpoint, request.view_args)\n <mask> \n <mask>         funcs = self.before_request_funcs.get(None, ())\n <mask>         if bp is not None and bp in self.before_request_funcs:\n <mask>             funcs = chain(funcs, self.before_request_funcs[bp])\n <mask>         for func in funcs:\n <mask>             rv = func()\n <mask>             if rv is not None: </s> remove         funcs = self.url_value_preprocessors.get(None, ()) </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = reversed(self.teardown_request_funcs.get(None, ())) </s> add         funcs = reversed(self.teardown_request_funcs[None]) </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ())) </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ()) </s> add         funcs = self.url_default_functions[None] </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c) </s> add             handler_map = self.error_handler_spec[name][c]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             Added the ``exc`` argument.\n <mask>         \"\"\"\n <mask>         if exc is _sentinel:\n <mask>             exc = sys.exc_info()[1]\n <mask>         funcs = reversed(self.teardown_request_funcs.get(None, ()))\n <mask>         bp = _request_ctx_stack.top.request.blueprint\n <mask>         if bp is not None and bp in self.teardown_request_funcs:\n <mask>             funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n <mask>         for func in funcs:\n <mask>             func(exc) </s> remove         funcs = self.url_value_preprocessors.get(None, ()) </s> add         funcs = self.url_value_preprocessors[None] </s> remove         funcs = self.before_request_funcs.get(None, ()) </s> add         funcs = self.before_request_funcs[None] </s> remove             funcs = chain(funcs, self.url_default_functions.get(bp, ())) </s> add             funcs = chain(funcs, self.url_default_functions[bp]) </s> remove         funcs = self.url_default_functions.get(None, ()) </s> remove             handler_map = self.error_handler_spec.setdefault(name, {}).get(c) </s> add             handler_map = self.error_handler_spec[name][c]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             Values of dict must be lists.\n <mask>             \"\"\"\n <mask>             for key, values in self_dict.items():\n <mask>                 key = self.name if key is None else f\"{self.name}.{key}\"\n <mask>                 app_dict.setdefault(key, []).extend(values)\n <mask> \n <mask>         def merge_dict_nested(self_dict, app_dict):\n <mask>             \"\"\"Merges self_dict into app_dict. Replaces None keys with self.name.\n <mask>             Values of dict must be dict.\n <mask>             \"\"\" </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         funcs = self.before_request_funcs.get(None, ()) </s> add         funcs = self.before_request_funcs[None] </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/blueprints.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: function.\n <mask>         #:\n <mask>         #: To register an error handler, use the :meth:`errorhandler`\n <mask>         #: decorator.\n <mask>         self.error_handler_spec = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that will be called at the\n <mask>         #: beginning of each request. The key of the dictionary is the name of\n <mask>         #: the blueprint this function is active for, or ``None`` for all\n <mask>         #: requests. To register a function, use the :meth:`before_request` </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.teardown_request_funcs = {} </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.after_request_funcs.setdefault(None, []).append(f) </s> add         self.after_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: beginning of each request. The key of the dictionary is the name of\n <mask>         #: the blueprint this function is active for, or ``None`` for all\n <mask>         #: requests. To register a function, use the :meth:`before_request`\n <mask>         #: decorator.\n <mask>         self.before_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that should be called after\n <mask>         #: each request.  The key of the dictionary is the name of the blueprint\n <mask>         #: this function is active for, ``None`` for all requests.  This can for\n <mask>         #: example be used to close database connections. To register a function </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {} </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.teardown_request_funcs = {} </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.before_request_funcs.setdefault(None, []).append(f) </s> add         self.before_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: each request.  The key of the dictionary is the name of the blueprint\n <mask>         #: this function is active for, ``None`` for all requests.  This can for\n <mask>         #: example be used to close database connections. To register a function\n <mask>         #: here, use the :meth:`after_request` decorator.\n <mask>         self.after_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that are called after\n <mask>         #: each request, even if an exception has occurred. The key of the\n <mask>         #: dictionary is the name of the blueprint this function is active for,\n <mask>         #: ``None`` for all requests. These functions are not allowed to modify </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {} </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.teardown_request_funcs = {} </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.after_request_funcs.setdefault(None, []).append(f) </s> add         self.after_request_funcs[None].append(f)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: teardown_request function. To register a function here, use the\n <mask>         #: :meth:`teardown_request` decorator.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.teardown_request_funcs = {}\n <mask> \n <mask>         #: A dictionary with list of functions that are called without argument\n <mask>         #: to populate the template context.  The key of the dictionary is the\n <mask>         #: name of the blueprint this function is active for, ``None`` for all\n <mask>         #: requests.  Each returns a dictionary that the template context is </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]} </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {} </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.url_default_functions = {} </s> add         self.url_default_functions = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: name of the blueprint this function is active for, ``None`` for all\n <mask>         #: requests.  Each returns a dictionary that the template context is\n <mask>         #: updated with.  To register a function here, use the\n <mask>         #: :meth:`context_processor` decorator.\n <mask>         self.template_context_processors = {None: [_default_template_ctx_processor]}\n <mask> \n <mask>         #: A dictionary with lists of functions that are called before the\n <mask>         #: :attr:`before_request_funcs` functions. The key of the dictionary is\n <mask>         #: the name of the blueprint this function is active for, or ``None``\n <mask>         #: for all requests. To register a function, use </s> remove         self.error_handler_spec = {} </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.url_default_functions = {}", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: for all requests. To register a function, use\n <mask>         #: :meth:`url_value_preprocessor`.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.url_value_preprocessors = {}\n <mask> \n <mask>         #: A dictionary with lists of functions that can be used as URL value\n <mask>         #: preprocessors.  The key ``None`` here is used for application wide\n <mask>         #: callbacks, otherwise the key is the name of the blueprint.\n <mask>         #: Each of these functions has the chance to modify the dictionary </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.template_context_processors = {None: [_default_template_ctx_processor]} </s> add         self.template_context_processors = defaultdict(\n            list, {None: [_default_template_ctx_processor]}\n        ) </s> remove         self.url_default_functions = {} </s> add         self.url_default_functions = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         #: provide a :meth:`url_defaults` function that adds the parameters\n <mask>         #: automatically again that were removed that way.\n <mask>         #:\n <mask>         #: .. versionadded:: 0.7\n <mask>         self.url_default_functions = {}\n <mask> \n <mask>     def _is_setup_finished(self):\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _method_route(self, method, rule, options): </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         funcs = self.url_default_functions.get(None, ()) </s> add         funcs = self.url_default_functions[None]", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         The function will be called without any arguments. If it returns a\n <mask>         non-None value, the value is handled as if it was the return value from\n <mask>         the view, and further request handling is stopped.\n <mask>         \"\"\"\n <mask>         self.before_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def after_request(self, f):\n <mask>         \"\"\"Register a function to be run after each request. </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.after_request_funcs.setdefault(None, []).append(f) </s> add         self.after_request_funcs[None].append(f) </s> remove         self.teardown_request_funcs.setdefault(None, []).append(f) </s> add         self.teardown_request_funcs[None].append(f) </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f) </s> add         self.url_value_preprocessors[None].append(f) </s> remove         self.url_default_functions.setdefault(None, []).append(f) </s> add         self.url_default_functions[None].append(f) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         As of Flask 0.7 this function might not be executed at the end of the\n <mask>         request in case an unhandled exception occurred.\n <mask>         \"\"\"\n <mask>         self.after_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def teardown_request(self, f):\n <mask>         \"\"\"Register a function to be run at the end of each request, </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.before_request_funcs.setdefault(None, []).append(f) </s> add         self.before_request_funcs[None].append(f) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {} </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>            immediately.  Instead it will keep it alive so that the interactive\n <mask>            debugger can still access it.  This behavior can be controlled\n <mask>            by the ``PRESERVE_CONTEXT_ON_EXCEPTION`` configuration variable.\n <mask>         \"\"\"\n <mask>         self.teardown_request_funcs.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def context_processor(self, f):\n <mask>         \"\"\"Registers a template context processor function.\"\"\" </s> remove         self.before_request_funcs.setdefault(None, []).append(f) </s> remove         self.teardown_request_funcs = {} </s> add         self.teardown_request_funcs = defaultdict(list) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         The function is passed the endpoint name and values dict. The return\n <mask>         value is ignored.\n <mask>         \"\"\"\n <mask>         self.url_value_preprocessors.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def url_defaults(self, f):\n <mask>         \"\"\"Callback function for URL defaults for all view functions of the </s> Utilise defaultdicts\n\nThis code originates from the Python 2.4 supporting version of Flask,\nwith defaultdicts being added in 2.5. Using defaultdict makes the\nintentional usage clearer, and slightly simplifies the code. </s> remove         self.url_default_functions.setdefault(None, []).append(f) </s> add         self.url_default_functions[None].append(f) </s> remove         self.url_value_preprocessors = {} </s> add         self.url_value_preprocessors = defaultdict(list) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Callback function for URL defaults for all view functions of the\n <mask>         application.  It's called with the endpoint and values and should\n <mask>         update the values passed in place.\n <mask>         \"\"\"\n <mask>         self.url_default_functions.setdefault(None, []).append(f)\n <mask>         return f\n <mask> \n <mask>     @setupmethod\n <mask>     def errorhandler(self, code_or_exception):\n <mask>         \"\"\"Register a function to handle errors by code or exception class. </s> remove         self.url_value_preprocessors.setdefault(None, []).append(f) </s> add         self.url_value_preprocessors[None].append(f) </s> remove         handlers = self.error_handler_spec.setdefault(key, {}).setdefault(code, {})\n        handlers[exc_class] = f </s> add         self.error_handler_spec[key][code][exc_class] = f </s> remove         self.before_request_funcs = {}", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 \" code. Use a subclass of HTTPException with that code\"\n <mask>                 \" instead.\"\n <mask>             )\n <mask> \n <mask>         handlers = self.error_handler_spec.setdefault(key, {}).setdefault(code, {})\n <mask>         handlers[exc_class] = f\n <mask> \n <mask>     @staticmethod\n <mask>     def _get_exc_class_and_code(exc_class_or_code):\n <mask>         \"\"\"Get the exception class being handled. For HTTP status codes\n <mask>         or ``HTTPException`` subclasses, return both the exception and </s> remove         self.after_request_funcs.setdefault(None, []).append(f) </s> add         self.after_request_funcs[None].append(f) </s> remove         self.after_request_funcs = {} </s> add         self.after_request_funcs = defaultdict(list) </s> remove         self.error_handler_spec = {} </s> add         self.error_handler_spec = defaultdict(lambda: defaultdict(dict)) </s> remove         self.before_request_funcs = {} </s> add         self.before_request_funcs = defaultdict(list)", "html_url": "https://github.com/pallets/flask/commit/fd62210f583e90764be6e8d9f295f37f33a65e48", "file_name": "src/flask/scaffold.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>   behaviour for `OPTIONS` responses.\n <mask> - Unbound locals now raise a proper :exc:`RuntimeError` instead\n <mask>   of an :exc:`AttributeError`.\n <mask> \n <mask> Version 0.6.1\n <mask> -------------\n <mask> \n <mask> Bugfix release, release date to be announced.\n <mask>  </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "CHANGES"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     requires support of the underlying webserver for `X-Sendfile`.\n <mask> \n <mask>     By default it will try to guess the mimetype for you, but you can\n <mask>     also explicitly provide one.  For extra security you probably want\n <mask>     to sent certain files as attachment (HTML for instance).\n <mask> \n <mask>     Please never pass filenames to this function from user sources without\n <mask>     checking them first.  Something like this is usually sufficient to\n <mask>     avoid security problems::\n <mask>  </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0 </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2) </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     .. versionadded:: 0.5\n <mask>        The `add_etags`, `cache_timeout` and `conditional` parameters were\n <mask>        added.  The default behaviour is now to attach etags.\n <mask> \n <mask>     :param filename_or_fp: the filename of the file to send.  This is\n <mask>                            relative to the :attr:`~Flask.root_path` if a\n <mask>                            relative path is specified.\n <mask>                            Alternatively a file object might be provided\n <mask>                            in which case `X-Sendfile` might not work and </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2) </s> remove     to sent certain files as attachment (HTML for instance). </s> add     to sent certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided. </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> add     \"\"\"Catch stderr in a StringIO\"\"\" </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         filename = filename_or_fp\n <mask>         file = None\n <mask>     else:\n <mask>         file = filename_or_fp\n <mask>         filename = getattr(file, 'name', None)\n <mask> \n <mask>         # XXX: this behaviour is now deprecated because it was unreliable.\n <mask>         # removed in Flask 1.0\n <mask>         if not attachment_filename and not mimetype \\ </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add         # XXX: this behaviour is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, basestring):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is not deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behaviour was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2) </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0 </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html') </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         from warnings import warn\n <mask>         file = filename_or_fp\n <mask>         filename = getattr(file, 'name', None)\n <mask>     if filename is not None:\n <mask>         if not os.path.isabs(filename):\n <mask>             filename = os.path.join(current_app.root_path, filename)\n <mask>     if mimetype is None and (filename or attachment_filename):\n <mask>         mimetype = mimetypes.guess_type(filename or attachment_filename)[0] </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> add     .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0 </s> add - Mimetype guessing and etag support based on file objects is now\n  deprecated for :func:`flask.send_file` because it was unreliable.\n  Pass filenames instead or attach your own etags and provide a\n  proper mimetype by hand. </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove     to sent certain files as attachment (HTML for instance). </s> add     to sent certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided. </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> @contextmanager\n <mask> def catch_stderr():\n <mask>     old_stderr = sys.stderr\n <mask>     sys.stderr = rv = StringIO()\n <mask>     try:\n <mask>         yield rv </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain' </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html') </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep replace replace replace replace replace replace replace keep", "code_tokens": " <mask>             assert rv.mimetype == 'text/html'\n <mask> \n <mask>     def test_send_file_object(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f)\n <mask>             with app.open_resource('static/index.html') as f:\n <mask>                 assert rv.data == f.read()\n <mask>             assert rv.mimetype == 'text/html'\n <mask> \n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f)\n <mask>             assert rv.mimetype == 'text/html'\n <mask>             assert 'x-sendfile' in rv.headers\n <mask>             assert rv.headers['x-sendfile'] == \\\n <mask>                 os.path.join(app.root_path, 'static/index.html')\n <mask>  </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain' </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> add     \"\"\"Catch stderr in a StringIO\"\"\"", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace keep keep replace replace replace replace keep keep", "code_tokens": " <mask>         app.use_x_sendfile = False\n <mask>         with app.test_request_context():\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f)\n <mask>             assert rv.data == 'Test'\n <mask>             assert rv.mimetype == 'application/octet-stream'\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f, mimetype='text/plain')\n <mask>             assert rv.data == 'Test'\n <mask>             assert rv.mimetype == 'text/plain'\n <mask> \n <mask>         app.use_x_sendfile = True\n <mask>         with app.test_request_context():\n <mask>             f = StringIO('Test')\n <mask>             rv = flask.send_file(f)\n <mask>             assert 'x-sendfile' not in rv.headers\n <mask> \n <mask>     def test_attachment(self): </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html') </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> add     \"\"\"Catch stderr in a StringIO\"\"\"", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert 'x-sendfile' not in rv.headers\n <mask> \n <mask>     def test_attachment(self):\n <mask>         app = flask.Flask(__name__)\n <mask>         with app.test_request_context():\n <mask>             f = open(os.path.join(app.root_path, 'static/index.html'))\n <mask>             rv = flask.send_file(f, as_attachment=True)\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>             assert value == 'attachment'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             assert options['filename'] == 'index.html'\n <mask>             rv = flask.send_file('static/index.html', as_attachment=True)\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition']) </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html') </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain' </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert options['filename'] == 'index.html'\n <mask> \n <mask>         with app.test_request_context():\n <mask>             rv = flask.send_file(StringIO('Test'), as_attachment=True,\n <mask>                                  attachment_filename='index.txt')\n <mask>             assert rv.mimetype == 'text/plain'\n <mask>             value, options = parse_options_header(rv.headers['Content-Disposition'])\n <mask>             assert value == 'attachment'\n <mask>             assert options['filename'] == 'index.txt'\n <mask>  </s> Deprecated send_file etag support and mimetype guessing for file-like objects.  This fixes #104 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f, as_attachment=True)\n            value, options = parse_options_header(rv.headers['Content-Disposition'])\n            assert value == 'attachment' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f, as_attachment=True)\n                value, options = parse_options_header(rv.headers['Content-Disposition'])\n                assert value == 'attachment'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove             f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'application/octet-stream'\n            f = StringIO('Test')\n            rv = flask.send_file(f, mimetype='text/plain')\n            assert rv.data == 'Test'\n            assert rv.mimetype == 'text/plain' </s> add             with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'application/octet-stream'\n            # etags\n            assert len(captured) == 1\n            with catch_warnings() as captured:\n                f = StringIO('Test')\n                rv = flask.send_file(f, mimetype='text/plain')\n                assert rv.data == 'Test'\n                assert rv.mimetype == 'text/plain'\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = StringIO('Test')\n            rv = flask.send_file(f)\n            assert 'x-sendfile' not in rv.headers </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = StringIO('Test')\n                rv = flask.send_file(f)\n                assert 'x-sendfile' not in rv.headers\n            # etags\n            assert len(captured) == 1 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            with app.open_resource('static/index.html') as f:\n                assert rv.data == f.read()\n            assert rv.mimetype == 'text/html' </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                with app.open_resource('static/index.html') as f:\n                    assert rv.data == f.read()\n                assert rv.mimetype == 'text/html'\n            # mimetypes + etag\n            assert len(captured) == 2 </s> remove         with app.test_request_context():\n            f = open(os.path.join(app.root_path, 'static/index.html'))\n            rv = flask.send_file(f)\n            assert rv.mimetype == 'text/html'\n            assert 'x-sendfile' in rv.headers\n            assert rv.headers['x-sendfile'] == \\\n                os.path.join(app.root_path, 'static/index.html') </s> add         with catch_warnings() as captured:\n            with app.test_request_context():\n                f = open(os.path.join(app.root_path, 'static/index.html'))\n                rv = flask.send_file(f)\n                assert rv.mimetype == 'text/html'\n                assert 'x-sendfile' in rv.headers\n                assert rv.headers['x-sendfile'] == \\\n                    os.path.join(app.root_path, 'static/index.html')\n            # mimetypes + etag\n            assert len(captured) == 2", "html_url": "https://github.com/pallets/flask/commit/fda14678c07d036ef3a1984a4e346e793cc5a63c", "file_name": "tests/flask_tests.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from markupsafe import escape\n <mask> from markupsafe import Markup\n <mask> from werkzeug.exceptions import abort as abort\n <mask> from werkzeug.utils import redirect as redirect\n <mask> \n <mask> from . import json as json\n <mask> from .app import Flask as Flask\n <mask> from .app import Request as Request\n <mask> from .app import Response as Response </s> add from .helpers import redirect as redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\") </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> from .helpers import get_flashed_messages as get_flashed_messages\n <mask> from .helpers import get_template_attribute as get_template_attribute\n <mask> from .helpers import make_response as make_response\n <mask> from .helpers import send_file as send_file\n <mask> from .helpers import send_from_directory as send_from_directory\n <mask> from .helpers import stream_with_context as stream_with_context\n <mask> from .helpers import url_for as url_for </s> remove from werkzeug.utils import redirect as redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import RoutingException\n <mask> from werkzeug.routing import Rule\n <mask> from werkzeug.wrappers import Response as BaseResponse\n <mask> \n <mask> from . import cli\n <mask> from . import json\n <mask> from .config import Config </s> add from werkzeug.utils import redirect as _wz_redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             ) from None\n <mask> \n <mask>         return asgiref_async_to_sync(func)\n <mask> \n <mask>     def make_response(self, rv: ResponseReturnValue) -> Response:\n <mask>         \"\"\"Convert the return value from a view function to an instance of\n <mask>         :attr:`response_class`.\n <mask> \n <mask>         :param rv: the return value from the view function. The view function\n <mask>             must return a response. Returning ``None``, or the view ending </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\") </s> remove from werkzeug.utils import redirect as redirect </s> add from .helpers import redirect as redirect", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/app.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> from werkzeug.routing import BuildError\n <mask> from werkzeug.urls import url_quote\n <mask> \n <mask> from .globals import _app_ctx_stack\n <mask> from .globals import _request_ctx_stack\n <mask> from .globals import current_app\n <mask> from .globals import request </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if t.TYPE_CHECKING:  # pragma: no cover\n <mask>     from .wrappers import Response\n <mask> \n <mask> \n <mask> def get_env() -> str:\n <mask>     \"\"\"Get the environment the app is running in, indicated by the </s> add def test_redirect_no_app():\n    response = flask.redirect(\"https://localhost\", 307)\n    assert response.location == \"https://localhost\"\n    assert response.status_code == 307\n\n\ndef test_redirect_with_app(app):\n    def redirect(location, code=302):\n        raise ValueError\n\n    app.redirect = redirect\n\n    with app.app_context(), pytest.raises(ValueError):\n        flask.redirect(\"other\")", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "src/flask/helpers.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         assert flask.url_for(\"myview\", _method=\"POST\") == \"/myview/create\"\n <mask> \n <mask> \n <mask> class TestNoImports:\n <mask>     \"\"\"Test Flasks are created without import.\n <mask> \n <mask>     Avoiding ``__import__`` helps create Flask instances where there are errors\n <mask>     at import time.  Those runtime errors will be apparent to the user soon\n <mask>     enough, but tools which build Flask instances meta-programmatically benefit </s> add -   Add an ``app.redirect`` method, which ``flask.redirect`` will call.\n    This makes it possible for an app to override how redirects work.\n    :issue:`4569` </s> remove from werkzeug.utils import redirect as redirect </s> add     from werkzeug.wrappers import Response as BaseResponse </s> add     def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        :param location: the url of the redirect\n        :param code: http return code\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return _wz_redirect(location, code=code, Response=self.response_class)", "html_url": "https://github.com/pallets/flask/commit/fdab801fbbd9de5adbdb3320ca4a1cb116c892f5", "file_name": "tests/test_helpers.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         app = flask.Flask(__name__, instance_path=here)\n <mask>         self.assert_equal(app.instance_path, here)\n <mask> \n <mask>     def test_uninstalled_module_paths(self):\n <mask>         from config_module_app import app\n <mask>         here = os.path.abspath(os.path.dirname(__file__))\n <mask>         self.assert_equal(app.instance_path, os.path.join(here, 'test_apps', 'instance'))\n <mask> \n <mask>     def test_uninstalled_package_paths(self): </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace replace", "code_tokens": " <mask> \n <mask>     def test_installed_module_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath('foo')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance')) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace replace replace replace replace keep", "code_tokens": " <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_installed_package_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath('foo')\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try: </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove             sys.modules['myapp'] = None\n\n    def test_prefix_installed_paths(self):\n        import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add             sys.prefix = real_prefix\n            sys.path.remove(installed_path)\n            if 'installed_package' in sys.modules:\n                del sys.modules['installed_package']\n\n    def test_prefix_package_paths(self):\n        here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance'))", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace keep replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_prefix_installed_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath(sys.prefix)\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__) </s> Update tests for new module helpers. </s> remove         import types\n        expected_prefix = os.path.abspath(sys.prefix)\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'MyApp.egg', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        egg_path = os.path.join(site_packages, 'SiteEgg.egg')\n        sys.path.append(site_packages)\n        sys.path.append(egg_path) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp')\n        mod = types.ModuleType('myapp')\n        mod.__path__ = [package_path]\n        mod.__file__ = os.path.join(package_path, '__init__.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        installed_path = os.path.join(expected_prefix, 'path')\n        sys.path.append(installed_path) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove         import types\n        expected_prefix = os.path.abspath('foo')\n        mod = types.ModuleType('myapp')\n        mod.__file__ = os.path.join(expected_prefix, 'lib', 'python2.5',\n                                    'site-packages', 'myapp.py')\n        sys.modules['myapp'] = mod </s> add         here = os.path.abspath(os.path.dirname(__file__))\n        expected_prefix = os.path.join(here, 'test_apps')\n        real_prefix, sys.prefix = sys.prefix, expected_prefix\n        site_packages = os.path.join(expected_prefix, 'lib', 'python2.5', 'site-packages')\n        sys.path.append(site_packages)", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep replace replace replace replace keep replace keep", "code_tokens": " <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n </s> Update tests for new module helpers.", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask>     def test_egg_installed_paths(self):\n <mask>         import types\n <mask>         expected_prefix = os.path.abspath(sys.prefix)\n <mask>         package_path = os.path.join(expected_prefix, 'lib', 'python2.5',\n <mask>                                     'site-packages', 'MyApp.egg', 'myapp')\n <mask>         mod = types.ModuleType('myapp')\n <mask>         mod.__path__ = [package_path]\n <mask>         mod.__file__ = os.path.join(package_path, '__init__.py')\n <mask>         sys.modules['myapp'] = mod\n <mask>         try:\n <mask>             mod.app = flask.Flask(mod.__name__)\n <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n </s> Update tests for new module helpers.", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.assert_equal(mod.app.instance_path,\n <mask>                              os.path.join(expected_prefix, 'var',\n <mask>                                           'myapp-instance'))\n <mask>         finally:\n <mask>             sys.modules['myapp'] = None\n <mask> \n <mask> \n <mask> def suite():\n <mask>     suite = unittest.TestSuite()\n <mask>     suite.addTest(unittest.makeSuite(ConfigTestCase)) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_app\n            self.assert_equal(site_app.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_app-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import site_package\n            self.assert_equal(site_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'site_package-instance')) </s> remove             mod.app = flask.Flask(mod.__name__)\n            self.assert_equal(mod.app.instance_path,\n                             os.path.join(expected_prefix, 'var',\n                                          'myapp-instance')) </s> add             import installed_package\n            self.assert_equal(installed_package.app.instance_path,\n                              os.path.join(expected_prefix, 'var',\n                                           'installed_package-instance')) </s> remove             sys.modules['myapp'] = None </s> add             sys.prefix = real_prefix\n            sys.path.remove(site_packages)\n            if 'site_package' in sys.modules:\n                del sys.modules['site_package'] </s> remove             sys.modules['myapp'] = None </s> add             sys.prefix = real_prefix\n            sys.path.remove(site_packages)\n            if 'site_app' in sys.modules:\n                del sys.modules['site_app']", "html_url": "https://github.com/pallets/flask/commit/fde6e364a497cd44d049df17c93d1fd05ec09f90", "file_name": "flask/testsuite/config.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \"\"\"\n <mask> \n <mask> from datetime import datetime\n <mask> from werkzeug.http import http_date, parse_date\n <mask> from werkzeug.datastructures import CallbackDict\n <mask> from .helpers import json </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep replace keep replace keep keep keep", "code_tokens": " <mask>             if isinstance(value, tuple):\n <mask>                 return {'##t': [_tag(x) for x in value]}\n <mask>             elif callable(getattr(value, '__html__', None)):\n <mask>                 return {'##m': unicode(value.__html__())}\n <mask>             elif isinstance(value, list):\n <mask>                 return [_tag(x) for x in value]\n <mask>             elif isinstance(value, datetime): </s> remove                 return {'##d': http_date(value)} </s> add                 return {' d': http_date(value)}", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 return {'##m': unicode(value.__html__())}\n <mask>             elif isinstance(value, list):\n <mask>                 return [_tag(x) for x in value]\n <mask>             elif isinstance(value, datetime):\n <mask>                 return {'##d': http_date(value)}\n <mask>             elif isinstance(value, dict):\n <mask>                 return dict((k, _tag(v)) for k, v in value.iteritems())\n <mask>             return value\n <mask>         return json.dumps(_tag(value), separators=(',', ':'))\n <mask>  </s> remove                 return {'##m': unicode(value.__html__())} </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##t': [_tag(x) for x in value]} </s> add                 return {' t': [_tag(x) for x in value]} </s> remove             elif the_key == '##d': </s> add             elif the_key == ' d': </s> remove             elif the_key == '##m': </s> add             elif the_key == ' m': </s> remove             if the_key == '##t': </s> add             if the_key == ' t': </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep", "code_tokens": " <mask>             if len(obj) != 1:\n <mask>                 return obj\n <mask>             the_key, the_value = obj.iteritems().next()\n <mask>             if the_key == '##t':\n <mask>                 return tuple(the_value)\n <mask>             elif the_key == '##m':\n <mask>                 return Markup(the_value)\n <mask>             elif the_key == '##d': </s> remove             elif the_key == '##d': </s> add             elif the_key == ' d': </s> remove                 return {'##m': unicode(value.__html__())} </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##t': [_tag(x) for x in value]} </s> add                 return {' t': [_tag(x) for x in value]} </s> remove                 return {'##d': http_date(value)} </s> add                 return {' d': http_date(value)} </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if the_key == '##t':\n <mask>                 return tuple(the_value)\n <mask>             elif the_key == '##m':\n <mask>                 return Markup(the_value)\n <mask>             elif the_key == '##d':\n <mask>                 return parse_date(the_value)\n <mask>             return obj\n <mask>         return json.loads(value, object_hook=object_hook)\n <mask> \n <mask>  </s> remove             elif the_key == '##m': </s> add             elif the_key == ' m': </s> remove             if the_key == '##t': </s> add             if the_key == ' t': </s> remove                 return {'##m': unicode(value.__html__())} </s> add                 return {' m': unicode(value.__html__())} </s> remove                 return {'##d': http_date(value)} </s> add                 return {' d': http_date(value)} </s> remove                 return {'##t': [_tag(x) for x in value]} </s> add                 return {' t': [_tag(x) for x in value]}", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     #: this type.\n <mask>     null_session_class = NullSession\n <mask> \n <mask>     def make_null_session(self, app):\n <mask>         \"\"\"Creates a null session which acts as a replacement object if the\n <mask>         real session support could not be loaded due to a configuration\n <mask>         error.  This mainly aids the user experience because the job of the </s> remove     session_class = SecureCookieSession </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> add     session_class = SecureCookieSession </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class SecureCookieSessionInterface(SessionInterface):\n <mask>     salt = 'cookie-session'\n <mask>     #: the hash function to use for the signature.  The default is sha1\n <mask>     digest_method = staticmethod(hashlib.sha1)\n <mask>     #: the name of the itsdangerous supported key derivation.  The default\n <mask>     #: is hmac.\n <mask>     key_derivation = 'hmac' </s> remove     session_class = SecureCookieSession </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> add     #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False </s> add     session_class = SecureCookieSession </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> remove         s = self.get_serializer(app) </s> add         s = self.get_signing_serializer(app) </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class SecureCookieSessionInterface(SessionInterface):\n <mask>     salt = 'cookie-session'\n <mask>     session_class = SecureCookieSession\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> add     session_class = SecureCookieSession </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> remove         s = self.get_serializer(app) </s> add         s = self.get_signing_serializer(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     #: JSON derived serializer with support for some extra Python types\n <mask>     #: such as datetime objects or tuples.\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_signing_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None\n <mask>         signer_kwargs = dict(\n <mask>             key_derivation=self.key_derivation, </s> remove     session_class = SecureCookieSession </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False </s> add     \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions. </s> remove         s = self.get_serializer(app) </s> add         s = self.get_signing_serializer(app)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace replace replace keep", "code_tokens": " <mask>     salt = 'cookie-session'\n <mask>     session_class = SecureCookieSession\n <mask>     serializer = session_json_serializer\n <mask> \n <mask>     def get_serializer(self, app):\n <mask>         if not app.secret_key:\n <mask>             return None\n <mask>         return URLSafeTimedSerializer(app.secret_key,\n <mask>                                       salt=self.salt,\n <mask>                                       serializer=self.serializer)\n <mask>  </s> add     session_class = SecureCookieSession </s> remove     session_class = SecureCookieSession </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples. </s> remove         s = self.get_serializer(app) </s> add         s = self.get_signing_serializer(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                       salt=self.salt,\n <mask>                                       serializer=self.serializer)\n <mask> \n <mask>     def open_session(self, app, request):\n <mask>         s = self.get_serializer(app)\n <mask>         if s is None:\n <mask>             return None\n <mask>         val = request.cookies.get(app.session_cookie_name)\n <mask>         if not val:\n <mask>             return self.session_class() </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> add     session_class = SecureCookieSession </s> remove         val = self.get_serializer(app).dumps(dict(session)) </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove     session_class = SecureCookieSession </s> add     #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(hashlib.sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = 'hmac'\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def save_session(self, app, session, response):\n <mask>         domain = self.get_cookie_domain(app)\n <mask>         path = self.get_cookie_path(app)\n <mask>         httponly = self.get_cookie_httponly(app)\n <mask>         secure = self.get_cookie_secure(app)\n <mask>         if not session:\n <mask>             if session.modified:\n <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return </s> add         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         val = self.get_serializer(app).dumps(dict(session)) </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove         s = self.get_serializer(app) </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return\n <mask>         expires = self.get_expiration_time(app, session)\n <mask>         val = self.get_signing_serializer(app).dumps(dict(session))\n <mask>         response.set_cookie(app.session_cookie_name, val,\n <mask>                             expires=expires, httponly=httponly, </s> remove         val = self.get_serializer(app).dumps(dict(session)) </s> add         val = self.get_signing_serializer(app).dumps(dict(session)) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         s = self.get_serializer(app) </s> remove     def get_serializer(self, app): </s> add     def get_signing_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>                 response.delete_cookie(app.session_cookie_name,\n <mask>                                        domain=domain, path=path)\n <mask>             return\n <mask>         expires = self.get_expiration_time(app, session)\n <mask>         val = self.get_serializer(app).dumps(dict(session))\n <mask>         response.set_cookie(app.session_cookie_name, val,\n <mask>                             expires=expires, httponly=httponly,\n <mask>                             domain=domain, path=path, secure=secure) </s> add         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app) </s> remove         s = self.get_serializer(app) </s> remove     def get_serializer(self, app): </s> remove         return URLSafeTimedSerializer(app.secret_key,\n                                      salt=self.salt,\n                                      serializer=self.serializer) </s> add         signer_kwargs = dict(\n            key_derivation=self.key_derivation,\n            digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                      serializer=self.serializer,\n                                      signer_kwargs=signer_kwargs) </s> add     session_class = SecureCookieSession", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "flask/sessions.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     platforms='any',\n <mask>     install_requires=[\n <mask>         'Werkzeug>=0.7',\n <mask>         'Jinja2>=2.4',\n <mask>         'itsdangerous>=0.16'\n <mask>     ],\n <mask>     classifiers=[\n <mask>         'Development Status :: 4 - Beta',\n <mask>         'Environment :: Web Environment',\n <mask>         'Intended Audience :: Developers', </s> add         val = self.get_signing_serializer(app).dumps(dict(session))", "html_url": "https://github.com/pallets/flask/commit/fe85970665ea3a38f9c6a8ef4756ff3a913850b6", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sqlite3.py\n <mask>         setup.py\n <mask>         LICENSE\n <mask> \n <mask> Here the contents of the most important files:\n <mask> \n <mask> flaskext/__init__.py\n <mask> ````````````````````\n <mask> \n <mask> The only purpose of this file is to mark the package as namespace package. </s> remove Here the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> add Here's the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> remove set.  This is used by Flask internally to figure out how to do name the </s> add set.  This is used by Flask internally to figure out how to name the", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> Initialization Functions\n <mask> ------------------------\n <mask> \n <mask> Here how the module would look like with initialization functions::\n <mask> \n <mask>     from __future__ import absolute_import\n <mask>     import sqlite3\n <mask>     from flask import g\n <mask>  </s> remove Here the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> add Here's the contents of the `flaskext/sqlite3.py` for copy/paste:: </s> remove set.  This is used by Flask internally to figure out how to do name the </s> add set.  This is used by Flask internally to figure out how to name the </s> remove the changes are the nice kind, the kind where you don't have th change </s> add the changes are the nice kind, the kind where you don't have to change", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/extensiondev.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Flask comes with a handy :func:`~flask.abort` function that aborts a\n <mask> request with an HTTP error code early.  It will also provide a plain black\n <mask> and white error page for you with a basic description, but nothing fancy.\n <mask> \n <mask> Depening on the error code it is less or more likely for the user to\n <mask> actually see such an error.\n <mask> \n <mask> Common Error Codes\n <mask> ------------------\n <mask>  </s> remove attacker now creates a page that sents a post request to that page with </s> add attacker now creates a page that sends a post request to that page with </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Here an example `_formhelpers.html` template with such a macro: </s> add Here's an example `_formhelpers.html` template with such a macro:", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/errorpages.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> is quite simple: it's on localhost port something and directly on the root\n <mask> of that server.  But what if you later decide to move your application to\n <mask> a different location?  For example to ``http://example.com/myapp``?  On\n <mask> the server side this never was a problem because we were using the handy\n <mask> :func:`~flask.url_for` function that did could answer that question for\n <mask> us, but if we are using jQuery we should better not hardcode the path to\n <mask> the application but make that dynamic, so how can we do that?\n <mask> \n <mask> A simple method would be to add a script tag to our page that sets a\n <mask> global variable to the prefix to the root of the application.  Something\n <mask> like this: </s> remove Here the HTML code needed for our little application (`index.html`). </s> add Here's the HTML code needed for our little application (`index.html`). </s> add Your index.html template either has to extend a `layout.html` template with </s> remove Depening on the error code it is less or more likely for the user to </s> add Depending on the error code it is less or more likely for the user to </s> remove is only allowing objects as toplevel elements when using </s> add is to only allow objects as toplevel elements when using </s> remove the changes are the nice kind, the kind where you don't have th change </s> add the changes are the nice kind, the kind where you don't have to change", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> --------\n <mask> \n <mask> You index.html template either has to extend a `layout.html` template with\n <mask> jQuery loaded and the `$SCRIPT_ROOT` variable set, or do that on the top.\n <mask> Here the HTML code needed for our little application (`index.html`).\n <mask> Notice that we also drop the script directly into the HTML here.  It is\n <mask> usually a better idea to have that in a separate script file:\n <mask> \n <mask> .. sourcecode:: html </s> remove Here an example `_formhelpers.html` template with such a macro: </s> add Here's an example `_formhelpers.html` template with such a macro:", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/jquery.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         def __call__(self, *args, **kwargs):\n <mask>             return self.view(*args, **kwargs)\n <mask> \n <mask> What's important here is is that `__module__` and `__name__` are properly\n <mask> set.  This is used by Flask internally to figure out how to do name the\n <mask> URL rules in case you don't provide a name for the rule yourself.\n <mask> \n <mask> Then you can define your central place to combine the views like this::\n <mask> \n <mask>     from flask import Flask </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/lazyloading.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> how easy this is.  WTForms does half the form generation for us already.\n <mask> To make it even nicer, we can write a macro that renders a field with\n <mask> label and a list of errors if there are any.\n <mask> \n <mask> Here an example `_formhelpers.html` template with such a macro:\n <mask> \n <mask> .. sourcecode:: html+jinja\n <mask> \n <mask>     {% macro render_field(field) %}\n <mask>       <dt>{{ field.label }} </s> add WTForm's field function that renders the field for us.  The keyword </s> remove Here the HTML code needed for our little application (`index.html`). </s> add Here's the HTML code needed for our little application (`index.html`). </s> add Depending on the error code it is less or more likely for the user to </s> remove You index.html template either has to extend a `layout.html` template with </s> add Your index.html template either has to extend a `layout.html` template with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/wtforms.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       </dd>\n <mask>     {% endmacro %}\n <mask> \n <mask> This macro accepts a couple of keyword arguments that are forwarded to\n <mask> WTForm's field function that renders the field for us.  They keyword\n <mask> arguments will be inserted as HTML attributes.  So for example you can\n <mask> call ``render_field(form.username, class='username')`` to add a class to\n <mask> the input element.  Note that WTForms returns standard Python unicode\n <mask> strings, so we have to tell Jinja2 that this data is already HTML escaped\n <mask> with the `|safe` filter. </s> remove Here an example `_formhelpers.html` template with such a macro: </s> add Here's an example `_formhelpers.html` template with such a macro: </s> remove You index.html template either has to extend a `layout.html` template with </s> add Your index.html template either has to extend a `layout.html` template with </s> remove Here the HTML code needed for our little application (`index.html`). </s> add Here's the HTML code needed for our little application (`index.html`). </s> add Depending on the error code it is less or more likely for the user to", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/patterns/wtforms.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> /login?next=/\n <mask> /user/John%20Doe\n <mask> \n <mask> (This also uses the :meth:`~flask.Flask.test_request_context` method\n <mask> explained below.  It basically tells flask to think we are handling a\n <mask> request even though we are not, we are in an interactive Python shell.\n <mask> Have a look at the explanation below. :ref:`context-locals`).\n <mask> \n <mask> Why would you want to build URLs instead of hardcoding them in your\n <mask> templates?  There are three good reasons for this: </s> add Depending on the error code it is less or more likely for the user to </s> remove attacker now creates a page that sents a post request to that page with </s> add attacker now creates a page that sends a post request to that page with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/quickstart.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> do stupid things without them knowing.\n <mask> \n <mask> Say you have a specific URL that, when you sent `POST` requests to will\n <mask> delete a user's profile (say `http://example.com/user/delete`).  If an\n <mask> attacker now creates a page that sents a post request to that page with\n <mask> some JavaScript he just has to trick some users to that page and their\n <mask> profiles will end up being deleted.\n <mask> \n <mask> Imagine you would run Facebook with millions of concurrent users and\n <mask> someone would send out links to images of little kittens.  When a user </s> remove Depening on the error code it is less or more likely for the user to </s> add Depending on the error code it is less or more likely for the user to </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove WTForm's field function that renders the field for us.  They keyword </s> add WTForm's field function that renders the field for us.  The keyword", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> Because it is a syntax error in JavaScript to have an object literal\n <mask> (``{...}``) toplevel an attacker could not just do a request to an\n <mask> external URL with the script tag to load up the data.  So what Flask does\n <mask> is only allowing objects as toplevel elements when using\n <mask> :func:`~flask.jsonify`.  Make sure to do the same when using an ordinary\n <mask> JSON generate function. </s> remove :func:`~flask.url_for` function that did could answer that question for\nus, but if we are using jQuery we should better not hardcode the path to </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to </s> add Depending on the error code it is less or more likely for the user to </s> remove set.  This is used by Flask internally to figure out how to do name the </s> add set.  This is used by Flask internally to figure out how to name the </s> remove You index.html template either has to extend a `layout.html` template with </s> add Your index.html template either has to extend a `layout.html` template with", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/security.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Upgrading to Newer Releases\n <mask> ===========================\n <mask> \n <mask> Flask itself is changing like any software is changing over time.  Most of\n <mask> the changes are the nice kind, the kind where you don't have th change\n <mask> anything in your code to profit from a new release.\n <mask> \n <mask> However every once in a while there are changes that do require some\n <mask> changes in your code or there are changes that make it possible for you to\n <mask> improve your own code quality by taking advantage of new features in </s> Fix some typos in the docs </s> remove set.  This is used by Flask internally to figure out how to do name the </s> add set.  This is used by Flask internally to figure out how to name the </s> add :func:`~flask.url_for` function that could answer that question for\nus, but if we are using jQuery we should not hardcode the path to </s> remove Depening on the error code it is less or more likely for the user to </s> add Depending on the error code it is less or more likely for the user to </s> remove explained below.  It basically tells flask to think we are handling a </s> add explained below.  It basically tells Flask to think we are handling a", "html_url": "https://github.com/pallets/flask/commit/ff2786d8afd6eba92ad75a22c2ad9275bd970f57", "file_name": "docs/upgrading.rst"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> -   When using ad-hoc certificates, check for the cryptography library\n <mask>     instead of PyOpenSSL. :pr:`3492`\n <mask> \n <mask> \n <mask> Version 1.1.2\n <mask> ------------- </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     args_spec = inspect.getfullargspec(app_factory) </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "CHANGES.rst"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> found, the command looks for a factory function named ``create_app`` or\n <mask> ``make_app`` that returns an instance.\n <mask> \n <mask> If parentheses follow the factory name, their contents are parsed as\n <mask> Python literals and passed as arguments to the function. This means that\n <mask> strings must still be in quotes.\n <mask> \n <mask> \n <mask> Run the Development Server\n <mask> --------------------------\n <mask>  </s> remove     args_spec = inspect.getfullargspec(app_factory) </s> remove def _called_with_wrong_args(factory): </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed </s> remove             \" first argument to the app factory function in 2.1.\",", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "docs/cli.rst"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     )\n <mask> \n <mask> \n <mask> def call_factory(script_info, app_factory, arguments=()):\n <mask>     \"\"\"Takes an app factory, a ``script_info` object and  optionally a tuple\n <mask>     of arguments. Checks for the existence of a script_info argument and calls\n <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask> \n <mask>     if \"script_info\" in args_spec.args:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\" </s> remove     if \"script_info\" in args_spec.args: </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None: </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove             \" first argument to the app factory function in 2.1.\", </s> add             \" single argument to the app factory function in 2.1.\", </s> remove         return app_factory(script_info) </s> add Python literals and passed as arguments and keyword arguments to the\nfunction. This means that strings must still be in quotes.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     the app_factory depending on that and the arguments provided.\n <mask>     \"\"\"\n <mask>     args_spec = inspect.getfullargspec(app_factory)\n <mask> \n <mask>     if \"script_info\" in args_spec.args:\n <mask>         warnings.warn(\n <mask>             \"The 'script_info' argument is deprecated and will not be\"\n <mask>             \" passed to the app factory function in 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         ) </s> remove     args_spec = inspect.getfullargspec(app_factory) </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None: </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove def call_factory(script_info, app_factory, arguments=()): </s> add def call_factory(script_info, app_factory, args=None, kwargs=None): </s> remove             \" first argument to the app factory function in 2.1.\", </s> add             \" single argument to the app factory function in 2.1.\", </s> remove         return app_factory(script_info)", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         )\n <mask>         return app_factory(*arguments, script_info=script_info)\n <mask>     elif arguments:\n <mask>         return app_factory(*arguments)\n <mask>     elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None:\n <mask>         warnings.warn(\n <mask>             \"Script info is deprecated and will not be passed as the\"\n <mask>             \" first argument to the app factory function in 2.1.\",\n <mask>             DeprecationWarning,\n <mask>         )\n <mask>         return app_factory(script_info)\n <mask>  </s> remove         return app_factory(script_info) </s> remove     if \"script_info\" in args_spec.args: </s> remove     args_spec = inspect.getfullargspec(app_factory) </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove     return app_factory() </s> add     return app_factory(*args, **kwargs)", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>             DeprecationWarning,\n <mask>         )\n <mask>         return app_factory(script_info)\n <mask> \n <mask>     return app_factory() </s> remove             \" first argument to the app factory function in 2.1.\", </s> add             \" single argument to the app factory function in 2.1.\", </s> remove def _called_with_wrong_args(factory): </s> add def _called_with_wrong_args(f): </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None: </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove     if \"script_info\" in args_spec.args: </s> add     if \"script_info\" in sig.parameters: </s> remove         # didn't reach the factory </s> add         # Didn't reach the function.", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace keep", "code_tokens": " <mask> \n <mask> def _called_with_wrong_args(factory):\n <mask>     \"\"\"Check whether calling a function raised a ``TypeError`` because\n <mask>     the call failed or because something in the factory raised the\n <mask>     error.\n <mask> \n <mask>     :param factory: the factory function that was called\n <mask>     :return: true if the call failed\n <mask>     \"\"\" </s> remove     return app_factory() </s> add     return app_factory(*args, **kwargs) </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully </s> remove         return app_factory(script_info)", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask>     tb = sys.exc_info()[2]\n <mask> \n <mask>     try:\n <mask>         while tb is not None:\n <mask>             if tb.tb_frame.f_code is factory.__code__:\n <mask>                 # in the factory, it was called successfully\n <mask>                 return False\n <mask> \n <mask>             tb = tb.tb_next\n <mask> \n <mask>         # didn't reach the factory\n <mask>         return True\n <mask>     finally:\n <mask>         # explicitly delete tb as it is circular referenced </s> remove         # explicitly delete tb as it is circular referenced </s> add         # Delete tb to break a circular reference. </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # didn't reach the factory\n <mask>         return True\n <mask>     finally:\n <mask>         # explicitly delete tb as it is circular referenced\n <mask>         # https://docs.python.org/2/library/sys.html#sys.exc_info\n <mask>         del tb\n <mask> \n <mask> \n <mask> def find_app_by_string(script_info, module, app_name): </s> remove         # didn't reach the factory </s> remove             if tb.tb_frame.f_code is factory.__code__:\n                # in the factory, it was called successfully </s> add             if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully. </s> remove     :param factory: the factory function that was called\n    :return: true if the call failed </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace keep", "code_tokens": " <mask>     \"\"\"\n <mask>     from . import Flask\n <mask> \n <mask>     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n <mask> \n <mask>     if not match:\n <mask>         raise NoAppException(\n <mask>             f\"{app_name!r} is not a valid variable name or function expression.\"\n <mask>         ) </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         app = None", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace replace keep keep keep", "code_tokens": " <mask>         )\n <mask> \n <mask>     name, args = match.groups()\n <mask> \n <mask>     try:\n <mask>         attr = getattr(module, name)\n <mask>     except AttributeError as e:\n <mask>         raise NoAppException(e.args[0])\n <mask> \n <mask>     if inspect.isfunction(attr):\n <mask>         if args: </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = () </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e: </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         raise NoAppException(\n <mask>             f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n <mask>         )\n <mask> \n <mask>     if inspect.isfunction(attr):\n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args, kwargs)\n <mask>         except TypeError: </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0]) </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e: </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = () </s> remove     name, args = match.groups() </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\" </s> add             f\"Failed to parse {app_name!r} as an attribute name or function call.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask>     if inspect.isfunction(attr):\n <mask>         if args:\n <mask>             try:\n <mask>                 args = ast.literal_eval(f\"({args},)\")\n <mask>             except (ValueError, SyntaxError):\n <mask>                 raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n <mask>         else:\n <mask>             args = ()\n <mask> \n <mask>         try:\n <mask>             app = call_factory(script_info, attr, args)\n <mask>         except TypeError as e: </s> use ast to parse FLASK_APP\n\nenables keyword arguments to factory functions </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0]) </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if not _called_with_wrong_args(attr):\n <mask>                 raise\n <mask> \n <mask>             raise NoAppException(\n <mask>                 f\"{e}\\nThe factory {app_name!r} in module\"\n <mask>                 f\" {module.__name__!r} could not be called with the\"\n <mask>                 \" specified arguments.\"\n <mask>             )\n <mask>     else:\n <mask>         app = attr </s> remove             app = call_factory(script_info, attr, args)\n        except TypeError as e: </s> add             app = call_factory(script_info, attr, args, kwargs)\n        except TypeError: </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         if args:\n            try:\n                args = ast.literal_eval(f\"({args},)\")\n            except (ValueError, SyntaxError):\n                raise NoAppException(f\"Could not parse the arguments in {app_name!r}.\")\n        else:\n            args = () </s> remove     except AttributeError as e:\n        raise NoAppException(e.args[0]) </s> add     except AttributeError:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\" </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None: </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ):", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if self._loaded_app is not None:\n <mask>             return self._loaded_app\n <mask> \n <mask>         app = None\n <mask> \n <mask>         if self.create_app is not None:\n <mask>             app = call_factory(self, self.create_app)\n <mask>         else:\n <mask>             if self.app_import_path:\n <mask>                 path, name = ( </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove         return app_factory(*arguments, script_info=script_info)\n    elif arguments:\n        return app_factory(*arguments)\n    elif not arguments and len(args_spec.args) == 1 and args_spec.defaults is None: </s> add         kwargs[\"script_info\"] = script_info\n\n    if (\n        not args\n        and len(sig.parameters) == 1\n        and next(iter(sig.parameters.values())).default is inspect.Parameter.empty\n    ): </s> remove     args_spec = inspect.getfullargspec(app_factory) </s> add     sig = inspect.signature(app_factory)\n    args = [] if args is None else args\n    kwargs = {} if kwargs is None else kwargs </s> remove             f\"{app_name!r} is not a valid variable name or function expression.\" </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "src/flask/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (\"cliapp.app\", \"testapp\", \"testapp\"),\n <mask>         (\"cliapp.factory\", None, \"app\"),\n <mask>         (\"cliapp.factory\", \"create_app\", \"app\"),\n <mask>         (\"cliapp.factory\", \"create_app()\", \"app\"),\n <mask>         # no script_info\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n <mask>         # trailing comma space\n <mask>         (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n <mask>         # strip whitespace\n <mask>         (\"cliapp.factory\", \" create_app () \", \"app\"), </s> add     if isinstance(expr, ast.Name):\n        name = expr.id\n        args = kwargs = None\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in expr.keywords}\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            )\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) </s> remove     match = re.match(r\"^ *([^ ()]+) *(?:\\((.*?) *,? *\\))? *$\", app_name)\n\n    if not match: </s> add     # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:", "html_url": "https://github.com/pallets/flask/commit/ff2f71379b719903e462ed6a83801b1736009000", "file_name": "tests/test_cli.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace", "code_tokens": " <mask> \n <mask> @pytest.fixture\n <mask> def app(request):\n <mask> \n <mask>     db_fd, temp_db_location = tempfile.mkstemp()\n <mask>     config = {\n <mask>         'DATABASE': temp_db_location, </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown) </s> remove         'DB_FD': db_fd </s> add     os.close(db_fd)\n    os.unlink(db_path)", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     db_fd, temp_db_location = tempfile.mkstemp()\n <mask>     config = {\n <mask>         'DATABASE': temp_db_location,\n <mask>         'TESTING': True,\n <mask>         'DB_FD': db_fd\n <mask>     }\n <mask> \n <mask>     app = create_app(config=config)\n <mask> \n <mask>     with app.app_context(): </s> remove         'DATABASE': temp_db_location, </s> remove def app(request):\n\n    db_fd, temp_db_location = tempfile.mkstemp() </s> add def app():\n    db_fd, db_path = tempfile.mkstemp() </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown) </s> add     os.close(db_fd)\n    os.unlink(db_path) </s> add @pytest.fixture\ndef client(app):\n    return app.test_client()", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         yield app\n <mask> \n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def client(app): </s> remove @pytest.fixture\ndef client(request, app):\n\n    client = app.test_client()\n\n    def teardown():\n        os.close(app.config['DB_FD'])\n        os.unlink(app.config['DATABASE'])\n    request.addfinalizer(teardown) </s> add @pytest.fixture\ndef client(app):\n    return app.test_client()", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>         init_db()\n <mask>         yield app\n <mask> \n <mask> \n <mask> @pytest.fixture\n <mask> def client(request, app):\n <mask> \n <mask>     client = app.test_client()\n <mask> \n <mask>     def teardown():\n <mask>         os.close(app.config['DB_FD'])\n <mask>         os.unlink(app.config['DATABASE'])\n <mask>     request.addfinalizer(teardown)\n <mask> \n <mask>     return client\n <mask> \n <mask> \n <mask> def login(client, username, password): </s> fix windows failure to remove temp file </s> add     os.close(db_fd)\n    os.unlink(db_path) </s> remove def app(request):\n\n    db_fd, temp_db_location = tempfile.mkstemp() </s> add def app():\n    db_fd, db_path = tempfile.mkstemp() </s> remove         'DATABASE': temp_db_location, </s> add         'DATABASE': db_path, </s> remove         'DB_FD': db_fd", "html_url": "https://github.com/pallets/flask/commit/ffca68fc86718b133668f341ddd8c2635d7e29ec", "file_name": "examples/flaskr/tests/test_flaskr.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> ^^^^^^\n <mask> - Bug in :meth:`Styler._copy` calling overridden methods in subclasses of :class:`Styler` (:issue:`52728`)\n <mask> -\n <mask> \n <mask> Other\n <mask> ^^^^^\n <mask> - Bug in :func:`assert_almost_equal` now throwing assertion error for two unequal sets (:issue:`51727`)\n <mask> - Bug in :func:`assert_frame_equal` checks category dtypes even when asked not to check index type (:issue:`52126`)\n <mask> - Bug in :meth:`DataFrame.reindex` with a ``fill_value`` that should be inferred with a :class:`ExtensionDtype` incorrectly inferring ``object`` dtype (:issue:`52586`)\n <mask> - Bug in :meth:`Series.map` when giving a callable to an empty series, the returned series had ``object`` dtype. It now keeps the original dtype (:issue:`52384`) </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         return super().std(axis, skipna, ddof, numeric_only, **kwargs) </s> add         result = cast(Series, super().std(axis, skipna, ddof, numeric_only, **kwargs))\n        return result.__finalize__(self, method=\"std\")", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ddof: int = 1,\n <mask>         numeric_only: bool = False,\n <mask>         **kwargs,\n <mask>     ):\n <mask>         return super().std(axis, skipna, ddof, numeric_only, **kwargs)\n <mask> \n <mask>     @doc(make_doc(\"skew\", ndim=2))\n <mask>     def skew(\n <mask>         self,\n <mask>         axis: Axis | None = 0,\n </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         marks=not_implemented_mark,\n </s> add  </s> add Metadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.std` (:issue:`28283`)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"sum\")),\n <mask>     ),\n <mask>     pytest.param(\n <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"std\")),\n <mask>         marks=not_implemented_mark,\n <mask>     ),\n <mask>     pytest.param(\n <mask>         (pd.DataFrame, frame_data, operator.methodcaller(\"mean\")),\n <mask>         marks=not_implemented_mark,\n <mask>     ),\n </s> Fix the metadata propagation in Dataframe.std (#52924)\n\n* Fix the metadata propagation both in Dataframe.std\r\n\r\n* Fix the typing problem by forcing propogation only on Series\r\n\r\n* From judge statement  to cast\r\n\r\n* Add whatsnew </s> remove         return super().std(axis, skipna, ddof, numeric_only, **kwargs)\n </s> add         result = cast(Series, super().std(axis, skipna, ddof, numeric_only, **kwargs))\n        return result.__finalize__(self, method=\"std\") </s> add Metadata\n^^^^^^^^\n- Fixed metadata propagation in :meth:`DataFrame.std` (:issue:`28283`)\n", "html_url": "https://github.com/pandas-dev/pandas/commit/000c3ed75ef63330b18f7751ac005f9a346a6d50", "file_name": "pandas/tests/generic/test_finalize.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> - ``DataFrame.to_csv()`` has dropped the ``engine`` parameter, as was deprecated in 0.17.1 (:issue:`11274`, :issue:`13419`)\n <mask> - ``DataFrame.to_dict()`` has dropped the ``outtype`` parameter in favor of ``orient`` (:issue:`13627`, :issue:`8486`)\n <mask> - ``pd.Categorical`` has dropped the ``levels`` attribute in favour of ``categories`` (:issue:`8376`)\n <mask> \n <mask> - Removal of the legacy time rules (offset aliases), deprecated since 0.17.0 (this has been alias since 0.8.0) (:issue:`13590`)\n <mask> \n <mask>   Previous Behavior: </s> remove     def _set_ordered(self, value):\n        \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n        warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n             FutureWarning, stacklevel=2)\n        self.set_ordered(value, inplace=True) </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered)", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "doc/source/whatsnew/v0.19.0.txt"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                           doc=_categories_doc)\n <mask> \n <mask>     _ordered = None\n <mask> \n <mask>     def _set_ordered(self, value):\n <mask>         \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n <mask>         warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n <mask>              FutureWarning, stacklevel=2)\n <mask>         self.set_ordered(value, inplace=True)\n <mask> \n <mask>     def set_ordered(self, value, inplace=False):\n <mask>         \"\"\"\n <mask>         Sets the ordered attribute to the boolean value\n <mask> \n <mask>         Parameters </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered) </s> add     ordered = property(fget=_get_ordered) </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`) </s> remove         # deperecated in v0.16.0\n        with tm.assert_produces_warning(FutureWarning):\n            cat.ordered = False\n            self.assertFalse(cat.ordered)\n        with tm.assert_produces_warning(FutureWarning): </s> add         # removed in 0.19.0\n        msg = \"can\\'t set attribute\"\n        with tm.assertRaisesRegexp(AttributeError, msg): </s> remove             self.assertTrue(cat.ordered) </s> add         with tm.assertRaisesRegexp(AttributeError, msg):\n            cat.ordered = False", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/core/categorical.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def _get_ordered(self):\n <mask>         \"\"\" Gets the ordered attribute \"\"\"\n <mask>         return self._ordered\n <mask> \n <mask>     ordered = property(fget=_get_ordered, fset=_set_ordered)\n <mask> \n <mask>     def set_categories(self, new_categories, ordered=None, rename=False,\n <mask>                        inplace=False):\n <mask>         \"\"\" Sets the categories to the specified new_categories.\n <mask>  </s> remove     def _set_ordered(self, value):\n        \"\"\" Sets the ordered attribute to the boolean value \"\"\"\n        warn(\"Setting 'ordered' directly is deprecated, use 'set_ordered'\",\n             FutureWarning, stacklevel=2)\n        self.set_ordered(value, inplace=True) </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`) </s> remove             self.assertTrue(cat.ordered) </s> add         with tm.assertRaisesRegexp(AttributeError, msg):\n            cat.ordered = False </s> remove         # deperecated in v0.16.0\n        with tm.assert_produces_warning(FutureWarning):\n            cat.ordered = False\n            self.assertFalse(cat.ordered)\n        with tm.assert_produces_warning(FutureWarning): </s> add         # removed in 0.19.0\n        msg = \"can\\'t set attribute\"\n        with tm.assertRaisesRegexp(AttributeError, msg):", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/core/categorical.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask>         cat2.set_ordered(False, inplace=True)\n <mask>         self.assertFalse(cat2.ordered)\n <mask> \n <mask>         # deperecated in v0.16.0\n <mask>         with tm.assert_produces_warning(FutureWarning):\n <mask>             cat.ordered = False\n <mask>             self.assertFalse(cat.ordered)\n <mask>         with tm.assert_produces_warning(FutureWarning):\n <mask>             cat.ordered = True\n <mask>             self.assertTrue(cat.ordered)\n <mask> \n <mask>     def test_set_categories(self):\n <mask>         cat = Categorical([\"a\", \"b\", \"c\", \"a\"], ordered=True) </s> remove     ordered = property(fget=_get_ordered, fset=_set_ordered) </s> add     ordered = property(fget=_get_ordered) </s> add - ``pd.Categorical`` has dropped setting of the ``ordered`` attribute directly in favor of the ``set_ordered`` method (:issue:`13671`)", "html_url": "https://github.com/pandas-dev/pandas/commit/006bd0b1c2f3ff183c1834a27305a1a3039011d8", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     def time_groupby_transform_series2(self):\n <mask>         self.df.groupby('id')['val'].transform(np.mean)\n <mask> \n <mask> class groupby_transform_cythonized(object):\n <mask>     goal_time = 0.2\n <mask> \n <mask>     def setup(self): </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "asv_bench/benchmarks/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Improved performance of sparse arithmetic with ``BlockIndex`` when the number of blocks are large, though recommended to use ``IntIndex`` in such cases (:issue:`13082`)\n <mask> - increased performance of ``DataFrame.quantile()`` as it now operates per-block (:issue:`11623`)\n <mask> \n <mask> \n <mask> \n <mask> \n <mask> \n <mask> .. _whatsnew_0182.bug_fixes:\n <mask> \n <mask> Bug Fixes </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True)) </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name) </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns]) </s> add     def _transform_fast(self, result, obj):\n        \"\"\"\n        Fast transform path for aggregations\n        \"\"\"\n        # if there were groups with no observations (Categorical only?)\n        # try casting data to original dtype\n        cast = (self.size().fillna(0) > 0).any() </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "doc/source/whatsnew/v0.18.2.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> - Regression in ``Series.quantile`` with nans (also shows up in ``.median()`` and ``.describe()``); furthermore now names the ``Series`` with the quantile (:issue:`13098`, :issue:`13146`)\n <mask> \n <mask> \n <mask> \n <mask> - Bug in ``Series.str.extractall()`` with ``str`` index raises ``ValueError``  (:issue:`13156`)\n <mask> \n <mask> \n <mask> - Bug in ``PeriodIndex`` and ``Period`` subtraction raises ``AttributeError`` (:issue:`13071`) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True)) </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "doc/source/whatsnew/v0.18.2.txt"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if isinstance(func, compat.string_types):\n <mask>             func = getattr(self, func)\n <mask> \n <mask>         ids, _, ngroup = self.grouper.group_info\n <mask>         mask = ids != -1\n <mask> \n <mask>         out = func().values[ids]\n <mask>         if not mask.all():\n <mask>             out = np.where(mask, out, np.nan)\n <mask> \n <mask>         obs = np.zeros(ngroup, dtype='bool')\n <mask>         obs[ids[mask]] = True\n <mask>         if not obs.all():\n <mask>             out = self._try_cast(out, self._selected_obj)\n <mask> \n <mask>         return Series(out, index=self.obj.index)\n <mask> \n <mask>     def filter(self, func, dropna=True, *args, **kwargs):  # noqa\n <mask>         \"\"\"\n <mask>         Return a copy of a Series excluding elements from groups that\n <mask>         do not satisfy the boolean criterion specified by func. </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         results = np.empty_like(obj.values, result.values.dtype)\n        for (name, group), (i, row) in zip(self, result.iterrows()):\n            indexer = self._get_index(name)\n            if len(indexer) > 0:\n                results[indexer] = np.tile(row.values, len(\n                    indexer)).reshape(len(indexer), -1) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected) </s> remove         expected = pd.Series(values, index=df.index) </s> add         expected = pd.Series(values, index=df.index, name='val') </s> remove         expected = Series([pd.Timestamp('2000-01-1')] * 2) </s> add         expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace replace replace", "code_tokens": " <mask>             return self._transform_general(func, *args, **kwargs)\n <mask> \n <mask>         results = np.empty_like(obj.values, result.values.dtype)\n <mask>         for (name, group), (i, row) in zip(self, result.iterrows()):\n <mask>             indexer = self._get_index(name)\n <mask>             if len(indexer) > 0:\n <mask>                 results[indexer] = np.tile(row.values, len(\n <mask>                     indexer)).reshape(len(indexer), -1)\n <mask> \n <mask>         counts = self.size().fillna(0).values\n <mask>         if any(counts == 0):\n <mask>             results = self._try_cast(results, obj[result.columns]) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True)) </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index) </s> add         cast = (self.size().fillna(0) > 0).any()\n        out = algos.take_1d(func().values, ids)\n        if cast:\n            out = self._try_cast(out, self.obj)\n        return Series(out, index=self.obj.index, name=self.obj.name)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         counts = self.size().fillna(0).values\n <mask>         if any(counts == 0):\n <mask>             results = self._try_cast(results, obj[result.columns])\n <mask> \n <mask>         return (DataFrame(results, columns=result.columns, index=obj.index)\n <mask>                 ._convert(datetime=True))\n <mask> \n <mask>     def _define_paths(self, func, *args, **kwargs):\n <mask>         if isinstance(func, compat.string_types):\n <mask>             fast_path = lambda group: getattr(group, func)(*args, **kwargs)\n <mask>             slow_path = lambda group: group.apply( </s> remove         counts = self.size().fillna(0).values\n        if any(counts == 0):\n            results = self._try_cast(results, obj[result.columns]) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/core/groupby.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         df = DataFrame({\"a\": [5, 15, 25]})\n <mask>         c = pd.cut(df.a, bins=[0, 10, 20, 30, 40])\n <mask> \n <mask>         result = df.a.groupby(c).transform(sum)\n <mask>         tm.assert_series_equal(result, df['a'], check_names=False)\n <mask>         self.assertTrue(result.name is None)\n <mask> \n <mask>         tm.assert_series_equal(\n <mask>             df.a.groupby(c).transform(lambda xs: np.sum(xs)), df['a'])\n <mask>         tm.assert_frame_equal(df.groupby(c).transform(sum), df[['a']])\n <mask>         tm.assert_frame_equal( </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index) </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         df = DataFrame({\"a\": [5, 15, 25, -5]})\n <mask>         c = pd.cut(df.a, bins=[-10, 0, 10, 20, 30, 40])\n <mask> \n <mask>         result = df.a.groupby(c).transform(sum)\n <mask>         tm.assert_series_equal(result, df['a'], check_names=False)\n <mask>         self.assertTrue(result.name is None)\n <mask> \n <mask>         tm.assert_series_equal(\n <mask>             df.a.groupby(c).transform(lambda xs: np.sum(xs)), df['a'])\n <mask>         tm.assert_frame_equal(df.groupby(c).transform(sum), df[['a']])\n <mask>         tm.assert_frame_equal( </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index) </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_categorical.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         grp = df.groupby('id')['val']\n <mask> \n <mask>         values = np.repeat(grp.mean().values,\n <mask>                            com._ensure_platform_int(grp.count().values))\n <mask>         expected = pd.Series(values, index=df.index)\n <mask>         result = grp.transform(np.mean)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>         result = grp.transform('mean')\n <mask>         assert_series_equal(result, expected) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> remove         mask = ids != -1\n\n        out = func().values[ids]\n        if not mask.all():\n            out = np.where(mask, out, np.nan)\n\n        obs = np.zeros(ngroup, dtype='bool')\n        obs[ids[mask]] = True\n        if not obs.all():\n            out = self._try_cast(out, self._selected_obj)\n\n        return Series(out, index=self.obj.index) </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         result = self.df.groupby('A')['C'].transform('mean')\n <mask>         expected = self.df.groupby('A')['C'].transform(np.mean)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>     def test_transform_length(self):\n <mask>         # GH 9697\n <mask>         df = pd.DataFrame({'col1': [1, 1, 2, 2], 'col2': [1, 2, 3, np.nan]})\n <mask>         expected = pd.Series([3.0] * 4)\n <mask>  </s> add         expected = pd.Series(values, index=df.index, name='val') </s> add class groupby_transform_dataframe(object):\n    # GH 12737\n    goal_time = 0.2\n\n    def setup(self):\n        self.df = pd.DataFrame({'group': np.repeat(np.arange(1000), 10),\n                                'B': np.nan,\n                                'C': np.nan})\n        self.df.ix[4::10, 'B':'C'] = 5\n\n    def time_groupby_transform_dataframe(self):\n        self.df.groupby('group').transform('first') </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a']) </s> remove         return (DataFrame(results, columns=result.columns, index=obj.index)\n                ._convert(datetime=True)) </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # 32-bit under 1.9-dev indexing issue\n <mask> \n <mask>         df = DataFrame({\"A\": range(2), \"B\": [pd.Timestamp('2000-01-1')] * 2})\n <mask>         result = df.groupby(\"A\")[\"B\"].transform(min)\n <mask>         expected = Series([pd.Timestamp('2000-01-1')] * 2)\n <mask>         assert_series_equal(result, expected)\n <mask> \n <mask>     def test_groupby_categorical_unequal_len(self):\n <mask>         # GH3011\n <mask>         series = Series([np.nan, np.nan, 1, 1, 2, 2, 3, 3, 4, 4]) </s> add     def test_series_fast_transform_date(self):\n        # GH 13191\n        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],\n                           'd': pd.date_range('2014-1-1', '2014-1-4')})\n        result = df.groupby('grouping')['d'].transform('first')\n        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),\n                 pd.Timestamp('2014-1-4')]\n        expected = pd.Series(dates, name='d')\n        assert_series_equal(result, expected) </s> add class groupby_transform_dataframe(object):\n    # GH 12737\n    goal_time = 0.2\n\n    def setup(self):\n        self.df = pd.DataFrame({'group': np.repeat(np.arange(1000), 10),\n                                'B': np.nan,\n                                'C': np.nan})\n        self.df.ix[4::10, 'B':'C'] = 5\n\n    def time_groupby_transform_dataframe(self):\n        self.df.groupby('group').transform('first') </s> add         # for each col, reshape to to size of original frame\n        # by take operation\n        ids, _, ngroup = self.grouper.group_info\n        output = []\n        for i, _ in enumerate(result.columns):\n            res = algos.take_1d(result.iloc[:, i].values, ids)\n            if cast:\n                res = self._try_cast(res, obj.iloc[:, i])\n            output.append(res)\n\n        return DataFrame._from_arrays(output, columns=result.columns,\n                                      index=obj.index) </s> remove         tm.assert_series_equal(result, df['a'], check_names=False)\n        self.assertTrue(result.name is None) </s> add         tm.assert_series_equal(result, df['a'])", "html_url": "https://github.com/pandas-dev/pandas/commit/009d1df85ec6e6f80cace1d949bb7cdc8d35df7c", "file_name": "pandas/tests/test_groupby.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>    Series.str.normalize\n <mask>    Series.str.pad\n <mask>    Series.str.repeat\n <mask>    Series.str.replace\n <mask>    Series.str.rfind\n <mask>    Series.str.rjust\n <mask>    Series.str.rpartition\n <mask>    Series.str.rstrip </s> ENH: Add StringMethods.partition and rpartition </s> add    Series.str.rpartition </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition``", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/api.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>    Series.str.replace\n <mask>    Series.str.rfind\n <mask>    Series.str.rjust\n <mask>    Series.str.rstrip\n <mask>    Series.str.slice\n <mask>    Series.str.slice_replace\n <mask>    Series.str.split\n <mask>    Series.str.startswith\n <mask>    Series.str.strip </s> ENH: Add StringMethods.partition and rpartition </s> add    Series.str.partition </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition``", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/api.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     :meth:`~Series.str.rstrip`,Equivalent to ``str.rstrip``\n <mask>     :meth:`~Series.str.lstrip`,Equivalent to ``str.lstrip``\n <mask>     :meth:`~Series.str.lower`,Equivalent to ``str.lower``\n <mask>     :meth:`~Series.str.upper`,Equivalent to ``str.upper``\n <mask>     :meth:`~Series.str.find`,Equivalent to ``str.find``\n <mask>     :meth:`~Series.str.rfind`,Equivalent to ``str.rfind``\n <mask>     :meth:`~Series.str.capitalize`,Equivalent to ``str.capitalize`` </s> ENH: Add StringMethods.partition and rpartition </s> add - Added ``StringMethods.partition()`` and ``rpartition()`` which behave as the same as standard ``str`` (:issue:`9773`) </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a')) </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/text.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Added ``StringMethods`` (.str accessor) to ``Index`` (:issue:`9068`)\n <mask> - Added ``StringMethods.normalize()`` which behaves the same as standard :func:`unicodedata.normalizes` (:issue:`10031`)\n <mask> \n <mask> - Allow clip, clip_lower, and clip_upper to accept array-like arguments as thresholds (:issue:`6966`). These methods now have an ``axis`` parameter which determines how the Series or DataFrame will be aligned with the threshold(s).\n <mask> \n <mask>   The ``.str`` accessor is now available for both ``Series`` and ``Index``.\n <mask> \n <mask>   .. ipython:: python\n <mask>  </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a')) </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add    Series.str.rpartition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "doc/source/whatsnew/v0.16.1.txt"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>             g = self.get(i)\n <mask> \n <mask>     def _wrap_result(self, result):\n <mask>         from pandas.core.series import Series\n <mask>         from pandas.core.frame import DataFrame\n <mask>         from pandas.core.index import Index\n <mask> \n <mask>         if not hasattr(result, 'ndim'): </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a')) </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/core/strings.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_series_equal(empty_str, empty.str.center(42))\n <mask>         tm.assert_series_equal(empty_list, empty.str.split('a'))\n <mask>         tm.assert_series_equal(empty_str, empty.str.slice(stop=1))\n <mask>         tm.assert_series_equal(empty_str, empty.str.slice(step=1))\n <mask>         tm.assert_series_equal(empty_str, empty.str.strip())\n <mask>         tm.assert_series_equal(empty_str, empty.str.lstrip()) </s> ENH: Add StringMethods.partition and rpartition </s> add     def test_empty_str_methods_to_frame(self):\n        empty_str = empty = Series(dtype=str)\n        empty_df = DataFrame([])\n        tm.assert_frame_equal(empty_df, empty.str.partition('a'))\n        tm.assert_frame_equal(empty_df, empty.str.rpartition('a')) </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/tests/test_strings.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_series_equal(empty_str, empty.str.normalize('NFC'))\n <mask> \n <mask>     def test_ismethods(self):\n <mask>         values = ['A', 'b', 'Xy', '4', '3A', '', 'TT', '55', '-', '  ']\n <mask>         str_s = Series(values)\n <mask>         alnum_e = [True, True, True, True, True, False, True, True, False, False] </s> ENH: Add StringMethods.partition and rpartition </s> add         # leave as it is to keep extract and get_dummies results\n        # can be merged to _wrap_result_expand in v0.17 </s> add         tm.assert_series_equal(empty_list, empty.str.partition('a', expand=False))\n        tm.assert_series_equal(empty_list, empty.str.rpartition('a', expand=False)) </s> add     :meth:`~Series.str.partition`,Equivalent to ``str.partition``\n    :meth:`~Series.str.rpartition`,Equivalent to ``str.rpartition`` </s> add    Series.str.rpartition </s> add    Series.str.partition", "html_url": "https://github.com/pandas-dev/pandas/commit/00c2408ac7837edd8d5d2098f8a95d666dd9857c", "file_name": "pandas/tests/test_strings.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This is a short introduction to pandas, geared mainly for new users.\n <mask> \n <mask> Customarily, we import as follows\n <mask> \n <mask> .. ipython:: python\n <mask> \n </s> DOC: cookbook updates - added idiom section </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/10min.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> This is a great *First Pull Request* (to add interesting links and/or put short code inline\n <mask> for existing links)\n <mask> \n <mask> .. _cookbook.selection:\n <mask> \n <mask> Selection\n <mask> ---------\n <mask> \n </s> DOC: cookbook updates - added idiom section </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> <http://stackoverflow.com/questions/14569223/timegrouper-pandas>`__\n <mask> \n <mask> `Resampling with custom periods\n <mask> <http://stackoverflow.com/questions/15408156/resampling-with-custom-periods>`__\n <mask> \n <mask> `Resample intraday frame without adding new days\n <mask> <http://stackoverflow.com/questions/14898574/resample-intrday-pandas-dataframe-without-add-new-days>`__\n </s> DOC: cookbook updates - added idiom section </s> add `appending to a csv\n<http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv>`__\n </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> `read_csv in action\n <mask> <http://wesmckinney.com/blog/?p=635>`__\n <mask> \n <mask> `Reading a csv chunk-by-chunk\n <mask> <http://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309>`__\n <mask> \n <mask> `Reading the first few lines of a frame\n <mask> <http://stackoverflow.com/questions/15008970/way-to-read-first-few-lines-for-pandas-dataframe>`__\n </s> DOC: cookbook updates - added idiom section </s> add Idioms\n------\n\n.. _cookbook.idioms:\n\nThese are some neat pandas ``idioms``\n\n`How to do if-then-else?\n<http://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else>`__\n\n`How to split a frame with a boolean criterion?\n<http://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion>`__\n\n`How to select from a frame with complex criteria?\n<http://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe>`__\n </s> add `Using TimeGrouper and another grouping to create subgroups, then apply a custom function\n<https://github.com/pydata/pandas/issues/3791>`__\n </s> add You can see more complex recipes in the :ref:`Cookbook<cookbook>`\r", "html_url": "https://github.com/pandas-dev/pandas/commit/010f7a4ab96b3eb149daad59c9c91ea462a7ee37", "file_name": "doc/source/cookbook.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> - :func:`read_html()` no longer ignores all-whitespace ``<tr>`` within ``<thead>`` when considering the ``skiprows`` and ``header`` arguments. Previously, users had to decrease their ``header`` and ``skiprows`` values on such tables to work around the issue. (:issue:`21641`)\n <mask> - :func:`read_excel()` will correctly show the deprecation warning for previously deprecated ``sheetname`` (:issue:`17994`)\n <mask> - :func:`read_csv()` and func:`read_table()` will throw ``UnicodeError`` and not coredump on badly encoded strings (:issue:`22748`)\n <mask> - :func:`read_csv()` will correctly parse timezone-aware datetimes (:issue:`22256`)\n <mask> - :func:`read_sas()` will parse numbers in sas7bdat-files that have width less than 8 bytes correctly. (:issue:`21616`)\n <mask> - :func:`read_sas()` will correctly parse sas7bdat files with many columns (:issue:`22628`)\n <mask> - :func:`read_sas()` will correctly parse sas7bdat files with data page types having also bit 7 set (so page type is 128 + 256 = 384) (:issue:`16615`)\n <mask> - Bug in :meth:`detect_client_encoding` where potential ``IOError`` goes unhandled when importing in a mod_wsgi process due to restricted access to stdout. (:issue:`21552`)\n <mask> - Bug in :func:`to_string()` that broke column alignment when ``index=False`` and width of first column's values is greater than the width of first column's header (:issue:`16839`, :issue:`13032`) </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "doc/source/whatsnew/v0.24.0.txt"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         int64_t *word_starts  # where we are in the stream\n <mask>         int64_t words_len\n <mask>         int64_t words_cap\n <mask> \n <mask>         char *pword_start        # pointer to stream start of current field\n <mask>         int64_t word_start       # position start of current field\n <mask> \n <mask>         int64_t *line_start      # position in words for start of line\n <mask>         int64_t *line_fields     # Number of fields in each line </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected) </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     int64_t i, cap, length; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/parsers.pyx"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     sz = sz ? sz : 1;\n <mask>     self->words = (char **)malloc(sz * sizeof(char *));\n <mask>     self->word_starts = (int64_t *)malloc(sz * sizeof(int64_t));\n <mask>     self->words_cap = sz;\n <mask>     self->words_len = 0;\n <mask> \n <mask>     // line pointers and metadata\n <mask>     self->line_start = (int64_t *)malloc(sz * sizeof(int64_t));\n <mask>  </s> remove         (char **)grow_buffer((void *)self->words, self->words_len, </s> add         (char **)grow_buffer((void *)self->words, length, </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected) </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add     int64_t max_words_cap;  // maximum word cap encountered </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`)", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     free(self);\n <mask> }\n <mask> \n <mask> static int make_stream_space(parser_t *self, size_t nbytes) {\n <mask>     int64_t i, cap;\n <mask>     int status;\n <mask>     void *orig_ptr, *newptr;\n <mask> \n <mask>     // Can we fit potentially nbytes tokens (+ null terminators) in the stream?\n <mask>  </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`)", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     */\n <mask> \n <mask>     cap = self->words_cap;\n <mask>     self->words =\n <mask>         (char **)grow_buffer((void *)self->words, length,\n <mask>                              (int64_t*)&self->words_cap, nbytes,\n <mask>                              sizeof(char *), &status); </s> remove         (char **)grow_buffer((void *)self->words, self->words_len, </s> add         (char **)grow_buffer((void *)self->words, length, </s> add     self->max_words_cap = sz; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected) </s> add     int64_t max_words_cap;  // maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     */\n <mask> \n <mask>     cap = self->words_cap;\n <mask>     self->words =\n <mask>         (char **)grow_buffer((void *)self->words, self->words_len,\n <mask>                              (int64_t*)&self->words_cap, nbytes,\n <mask>                              sizeof(char *), &status);\n <mask>     TRACE(\n <mask>         (\"make_stream_space: grow_buffer(self->self->words, %zu, %zu, %zu, \"\n <mask>          \"%d)\\n\", </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     self->max_words_cap = sz; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add     def test_read_chunksize_jagged_names(self):\n        # see gh-23509\n        data = \"\\n\".join([\"0\"] * 7 + [\",\".join([\"0\"] * 10)])\n        reader = self.read_csv(StringIO(data), names=range(10), chunksize=4)\n\n        expected = DataFrame()\n\n        for i in range(10):\n            if i == 0:\n                expected[i] = [0] * 8\n            else:\n                expected[i] = [np.nan] * 7 + [0]\n\n        result = pd.concat(reader)\n        tm.assert_frame_equal(result, expected) </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     int64_t max_words_cap;  // maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     int64_t i;\n <mask> \n <mask>     /* trim words, word_starts */\n <mask>     new_cap = _next_pow2(self->words_len) + 1;\n <mask>     if (new_cap < self->words_cap) {\n <mask>         TRACE((\"parser_trim_buffers: new_cap < self->words_cap\\n\")); </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     self->max_words_cap = sz; </s> remove         (char **)grow_buffer((void *)self->words, self->words_len, </s> add         (char **)grow_buffer((void *)self->words, length, </s> remove     int64_t i, cap; </s> add     int64_t i, cap, length; </s> add         int64_t max_words_cap    # maximum word cap encountered", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.c"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     int64_t words_len;\n <mask>     int64_t words_cap;\n <mask> \n <mask>     char *pword_start;      // pointer to stream start of current field\n <mask>     int64_t word_start;     // position start of current field\n <mask> \n <mask>     int64_t *line_start;    // position in words for start of line\n <mask>     int64_t *line_fields;   // Number of fields in each line </s> BUG: Don't over-optimize memory with jagged CSV (#23527)\n\nWith jagged CSV's, we risk being too quick\r\nto dump memory that we need to allocate\r\nbecause previous chunks would have\r\nindicated much larger rows than we can\r\nanticipate in subsequent chunks.\r\n\r\nCloses gh-23509. </s> add         int64_t max_words_cap    # maximum word cap encountered </s> remove     int64_t i, cap; </s> add     int64_t i, cap, length; </s> add     self->max_words_cap = sz; </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    } </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    }", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/_libs/src/parser/tokenizer.h"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         tm.assert_frame_equal(pd.concat(reader), df)\n <mask> \n <mask>     def test_read_text_list(self):\n <mask>         data = \"\"\"A,B,C\\nfoo,1,2,3\\nbar,4,5,6\"\"\"\n <mask>         as_list = [['A', 'B', 'C'], ['foo', '1', '2', '3'], ['bar',\n <mask>                                                              '4', '5', '6']] </s> add - Bug in :func:`read_csv()` in which memory management was prematurely optimized for the C engine when the data was being read in chunks (:issue:`23509`) </s> add     /**\n     * If we are reading in chunks, we need to be aware of the maximum number\n     * of words we have seen in previous chunks (self->max_words_cap), so\n     * that way, we can properly allocate when reading subsequent ones.\n     *\n     * Otherwise, we risk a buffer overflow if we mistakenly under-allocate\n     * just because a recent chunk did not have as many words.\n     */\n    if (self->words_len + nbytes < self->max_words_cap) {\n        length = self->max_words_cap - nbytes;\n    } else {\n        length = self->words_len;\n    } </s> add     /**\n     * Before we free up space and trim, we should\n     * save how many words we saw when parsing, if\n     * it exceeds the maximum number we saw before.\n     *\n     * This is important for when we read in chunks,\n     * so that we can inform subsequent chunk parsing\n     * as to how many words we could possibly see.\n     */\n    if (self->words_cap > self->max_words_cap) {\n        self->max_words_cap = self->words_cap;\n    }", "html_url": "https://github.com/pandas-dev/pandas/commit/011b79fbf73b45313b47c08b4be1fc07dcb99365", "file_name": "pandas/tests/io/parser/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     rxor,\n <mask> )\n <mask> \n <mask> if TYPE_CHECKING:\n <mask>     from pandas import DataFrame  # noqa:F401\n <mask> \n <mask> # -----------------------------------------------------------------------------\n <mask> # constants\n <mask> ARITHMETIC_BINOPS: Set[str] = {\n <mask>     \"add\", </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     # We assume that self.align(other, ...) has already been called\n <mask> \n <mask>     rvalues = right._values\n <mask>     if isinstance(rvalues, np.ndarray):\n <mask>         # TODO(EA2D): no need to special-case with 2D EAs\n <mask>         # We can operate block-wise\n <mask>         if axis == 0:\n <mask>             rvalues = rvalues.reshape(-1, 1)\n <mask>         else:\n <mask>             rvalues = rvalues.reshape(1, -1)\n <mask> \n <mask>         rvalues = np.broadcast_to(rvalues, left.shape)\n <mask> \n <mask>         array_op = get_array_op(func)\n <mask>         bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n <mask>         return type(left)(bm)\n <mask> \n <mask>     if axis == 0:\n <mask>         new_data = dispatch_to_series(left, right, func)\n <mask>     else:\n <mask>         new_data = dispatch_to_series(left, right, func, axis=\"columns\") </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\") </s> add         right = _maybe_align_series_as_frame(left, right, axis)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             right, join=\"outer\", axis=axis, level=level, copy=False\n <mask>         )\n <mask> \n <mask>     return left, right\n <mask> \n <mask> \n <mask> def _should_reindex_frame_op(\n <mask>     left: \"DataFrame\", right, op, axis, default_axis, fill_value, level </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             self, other, op, axis, default_axis, fill_value, level\n <mask>         ):\n <mask>             return _frame_arith_method_with_reindex(self, other, op)\n <mask> \n <mask>         # TODO: why are we passing flex=True instead of flex=not special?\n <mask>         #  15 tests fail if we pass flex=not special instead\n <mask>         self, other = _align_method_FRAME(self, other, axis, flex=True, level=level)\n <mask> \n <mask>         if isinstance(other, ABCDataFrame): </s> add         right = _maybe_align_series_as_frame(left, right, axis)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             # Another DataFrame\n <mask>             new_data = self._combine_frame(other, na_op, fill_value)\n <mask> \n <mask>         elif isinstance(other, ABCSeries):\n <mask>             if fill_value is not None:\n <mask>                 raise NotImplementedError(f\"fill_value {fill_value} not supported.\")\n <mask> \n <mask>             axis = self._get_axis_number(axis) if axis is not None else 1\n <mask>             new_data = _combine_series_frame(self, other, op, axis=axis)\n <mask>         else:\n <mask>             # in this case we always have `np.ndim(other) == 0`\n <mask>             if fill_value is not None: </s> add         if isinstance(other, ABCSeries) and fill_value is not None:\n            # TODO: We could allow this in cases where we end up going\n            #  through the DataFrame path\n            raise NotImplementedError(f\"fill_value {fill_value} not supported.\")", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/core/ops/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         expected = pd.Index(\n <mask>             [pd.Timedelta(days=2), pd.Timedelta(days=4), pd.Timestamp(\"2000-01-07\")]\n <mask>         )\n <mask>         expected = tm.box_expected(expected, box_with_array)\n <mask>         if box_with_array is pd.DataFrame:\n <mask>             expected = expected.astype(object)\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask>         msg = \"unsupported operand type|cannot subtract a datelike\"\n <mask>         with pytest.raises(TypeError, match=msg):\n <mask>             with tm.assert_produces_warning(PerformanceWarning): </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object) </s> add             \"true_divide'? cannot use operands|\" </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         expected = pd.Index(\n <mask>             [pd.Timedelta(0), pd.Timedelta(0), pd.Timestamp(\"2000-01-01\")]\n <mask>         )\n <mask>         expected = tm.box_expected(expected, box_with_array)\n <mask>         if box_with_array is pd.DataFrame:\n <mask>             expected = expected.astype(object)\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask> \n <mask> class TestTimedeltaArraylikeMulDivOps:\n <mask>     # Tests for timedelta64[ns] </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove         if box_with_array is pd.DataFrame:\n            expected = expected.astype(object) </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected) </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index </s> remove             \"true_divide cannot use operands|\" </s> add             \"true_divide'? cannot use operands|\" </s> remove             if fill_value is not None:\n                raise NotImplementedError(f\"fill_value {fill_value} not supported.\")", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         result = tdser / vector\n <mask>         tm.assert_equal(result, expected)\n <mask> \n <mask>         pattern = (\n <mask>             \"true_divide cannot use operands|\"\n <mask>             \"cannot perform __div__|\"\n <mask>             \"cannot perform __truediv__|\"\n <mask>             \"unsupported operand|\"\n <mask>             \"Cannot divide\"\n <mask>         ) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected) </s> remove     if isinstance(rvalues, np.ndarray):\n        # TODO(EA2D): no need to special-case with 2D EAs\n        # We can operate block-wise\n        if axis == 0:\n            rvalues = rvalues.reshape(-1, 1)\n        else:\n            rvalues = rvalues.reshape(1, -1)\n\n        rvalues = np.broadcast_to(rvalues, left.shape)\n\n        array_op = get_array_op(func)\n        bm = left._mgr.apply(array_op, right=rvalues.T, align_keys=[\"right\"])\n        return type(left)(bm)", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/arithmetic/test_timedelta64.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             np.array([1, 2, 3], dtype=np.int64),\n <mask>             range(1, 4),\n <mask>         ]:\n <mask> \n <mask>             tm.assert_series_equal(\n <mask>                 align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n <mask>             )\n <mask>             tm.assert_series_equal(\n <mask>                 align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns)\n <mask>             )\n <mask> \n <mask>         # length mismatch\n <mask>         msg = \"Unable to coerce to Series, length must be 3: given 2\"\n <mask>         for val in [[1, 2], (1, 2), np.array([1, 2]), range(1, 3)]: </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> add             tm.assert_frame_equal(align(df, val, \"columns\")[1], expected) </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected) </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> remove     from pandas import DataFrame  # noqa:F401 </s> add     from pandas import DataFrame, Series  # noqa:F401", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/frame/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>             expected = DataFrame(\n <mask>                 {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index\n <mask>             )\n <mask> \n <mask>         # length mismatch\n <mask>         msg = \"Unable to coerce to Series, length must be 3: given 2\"\n <mask>         for val in [[1, 2], (1, 2), np.array([1, 2]), range(1, 3)]: </s> BUG: flex op with DataFrame, Series and ea vs ndarray (#34277) </s> remove             tm.assert_series_equal(\n                align(df, val, \"index\")[1], Series([1, 2, 3], index=df.index)\n            )\n            tm.assert_series_equal(\n                align(df, val, \"columns\")[1], Series([1, 2, 3], index=df.columns) </s> add             expected = DataFrame({\"X\": val, \"Y\": val, \"Z\": val}, index=df.index)\n            tm.assert_frame_equal(align(df, val, \"index\")[1], expected)\n\n            expected = DataFrame(\n                {\"X\": [1, 1, 1], \"Y\": [2, 2, 2], \"Z\": [3, 3, 3]}, index=df.index </s> add     def test_df_flex_cmp_ea_dtype_with_ndarray_series(self):\n        ii = pd.IntervalIndex.from_breaks([1, 2, 3])\n        df = pd.DataFrame({\"A\": ii, \"B\": ii})\n\n        ser = pd.Series([0, 0])\n        res = df.eq(ser, axis=0)\n\n        expected = pd.DataFrame({\"A\": [False, False], \"B\": [False, False]})\n        tm.assert_frame_equal(res, expected)\n\n        ser2 = pd.Series([1, 2], index=[\"A\", \"B\"])\n        res2 = df.eq(ser2, axis=1)\n        tm.assert_frame_equal(res2, expected) </s> add </s> add     assert not isinstance(rvalues, np.ndarray)  # handled by align_series_as_frame </s> add </s> remove     from pandas import DataFrame  # noqa:F401 </s> add     from pandas import DataFrame, Series  # noqa:F401", "html_url": "https://github.com/pandas-dev/pandas/commit/014d8eabf0b8c3d0921ec2438d72514b34ea676b", "file_name": "pandas/tests/frame/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> Numeric\n <mask> ^^^^^^^\n <mask> \n <mask> -\n <mask> -\n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^ </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove     def test_quantile_empty(self): </s> remove Other\n^^^^^", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "doc/source/whatsnew/v1.0.0.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         if is_transposed:\n <mask>             data = data.T\n <mask> \n <mask>         result = data._data.quantile(\n <mask>             qs=q, axis=1, interpolation=interpolation, transposed=is_transposed\n <mask>         )\n <mask> \n <mask>         if result.ndim == 2: </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove     def test_quantile_empty(self): </s> add     def test_quantile_empty_no_rows(self):", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             [[pd.Timestamp(\"2012-01-02\"), pd.NaT]], index=[0.5], columns=[\"a\", \"b\"]\n <mask>         )\n <mask>         tm.assert_frame_equal(res, exp)\n <mask> \n <mask>     def test_quantile_empty(self):\n <mask> \n <mask>         # floats\n <mask>         df = DataFrame(columns=[\"a\", \"b\"], dtype=\"float64\")\n <mask> \n <mask>         res = df.quantile(0.5) </s> BUG: fix+test quantile with empty DataFrame, closes #23925 (#27436) </s> remove Other\n^^^^^", "html_url": "https://github.com/pandas-dev/pandas/commit/01babb590cb15ef5c6e9ad890ea580a5112e6999", "file_name": "pandas/tests/frame/test_quantile.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if prefix is None:\n <mask>             prefix = ''\n <mask> \n <mask>         result = result.addPrefix(prefix)\n <mask> \n <mask>         return result\n <mask> \n <mask>     def get_dummies(self, item):\n <mask>         \"\"\" </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item) </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index) </s> remove         dummies = dummies.addPrefix('FE_') </s> add         dummies = dummies.add_prefix('FE_') </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#') </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> remove             dummies = dummies.addPrefix('%s_' % effect) </s> add             dummies = dummies.add_prefix('%s_' % effect)", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             new_values = f(self.values)\n <mask>             return LongPanel(new_values, columns=self.items,\n <mask>                              index=self.index)\n <mask> \n <mask>     def addPrefix(self, prefix=None):\n <mask>         \"\"\"\n <mask>         Concatenate prefix string with panel items names.\n <mask> \n <mask>         Parameters\n <mask>         ----------\n <mask>         prefix : string\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         LongPanel\n <mask> \n <mask>         Note\n <mask>         ----\n <mask>         does *not* copy values matrix\n <mask>         \"\"\"\n <mask>         new_items = [_prefix_item(item, prefix) for item in self.items]\n <mask> \n <mask>         return LongPanel(self.values, columns=new_items,\n <mask>                          index=self.index)\n <mask> \n <mask> \n <mask> def _prep_ndarray(values, copy=True):\n <mask>     if not isinstance(values, np.ndarray):\n <mask>         values = np.asarray(values)\n <mask>         # NumPy strings are a pain, convert to object\n <mask>         if issubclass(values.dtype.type, basestring): </s> remove \ndef _prefix_item(item, prefix=None):\n    if prefix is None:\n        return item\n\n    template = '%s%s'\n    return template % (prefix, item) </s> remove         result = result.addPrefix(prefix) </s> remove             dummies = dummies.addPrefix('%s_' % effect) </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#')", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             values = values.copy()\n <mask>     assert(values.ndim == 3)\n <mask>     return values\n <mask> \n <mask> \n <mask> def _prefix_item(item, prefix=None):\n <mask>     if prefix is None:\n <mask>         return item\n <mask> \n <mask>     template = '%s%s'\n <mask>     return template % (prefix, item)\n <mask> \n <mask> def _homogenize_dict(frames, intersect=True, dtype=None):\n <mask>     \"\"\"\n <mask>     Conform set of DataFrame-like objects to either an intersection\n <mask>     of indices / columns or a union.\n <mask>  </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index) </s> add             dummies = dummies.add_prefix('%s_' % effect)", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.log('-- Excluding dummy for entity: %s' % to_exclude)\n <mask> \n <mask>             dummies = dummies.filter(dummies.items - [to_exclude])\n <mask> \n <mask>         dummies = dummies.addPrefix('FE_')\n <mask>         panel = panel.join(dummies)\n <mask> \n <mask>         return panel\n <mask> \n <mask>     def _add_categorical_dummies(self, panel, cat_mappings): </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> add         result = result.add_prefix(prefix) </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#') </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#')", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 dummies = dummies.filter(dummies.items - [mapped_name])\n <mask>                 dropped_dummy = True\n <mask> \n <mask>             dummies = _convertDummies(dummies, cat_mappings.get(effect))\n <mask>             dummies = dummies.addPrefix('%s_' % effect)\n <mask>             panel = panel.join(dummies)\n <mask> \n <mask>         return panel\n <mask> \n <mask>     @property </s> ENH: added add_prefix / add_suffix methods to DataFrame </s> remove         dummies = dummies.addPrefix('FE_') </s> add         dummies = dummies.add_prefix('FE_') </s> remove         result = result.addPrefix(prefix) </s> add         result = result.add_prefix(prefix) </s> remove     def test_addPrefix(self):\n        lp = self.panel.addPrefix('foo#') </s> add     def test_add_prefix(self):\n        lp = self.panel.add_prefix('foo#') </s> add     def test_add_prefix_suffix(self):\n        with_prefix = self.frame.add_prefix('foo#')\n        expected = ['foo#%s' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_prefix.columns, expected))\n\n        with_suffix = self.frame.add_suffix('#foo')\n        expected = ['%s#foo' % c for c in self.frame.columns]\n        self.assert_(np.array_equal(with_suffix.columns, expected)) </s> remove         lp = self.panel.addPrefix()\n        assert_panel_equal(lp.to_wide(), self.panel.to_wide())", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         renamed = self.frame.T.rename(index={'C' : 'foo', 'D' : 'bar'})\n <mask>         self.assert_(np.array_equal(renamed.index, ['A', 'B', 'foo', 'bar']))\n <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Time series related\n <mask> \n <mask>     def test_diff(self):\n <mask>         the_diff = self.tsframe.diff(1)\n <mask>  </s> remove             dummies = dummies.addPrefix('%s_' % effect) </s> add             dummies = dummies.add_prefix('%s_' % effect)", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/tests/test_frame.py"}
{"docstring_tokens": "keep replace replace keep keep replace replace replace keep keep keep", "code_tokens": " <mask> \n <mask>     def test_addPrefix(self):\n <mask>         lp = self.panel.addPrefix('foo#')\n <mask>         self.assertEqual(lp.items[0], 'foo#ItemA')\n <mask> \n <mask>         lp = self.panel.addPrefix()\n <mask>         assert_panel_equal(lp.to_wide(), self.panel.to_wide())\n <mask> \n <mask>     def test_pivot(self):\n <mask>         from pandas.core.reshape import _slow_pivot\n <mask>  </s> remove     def addPrefix(self, prefix=None):\n        \"\"\"\n        Concatenate prefix string with panel items names.\n\n        Parameters\n        ----------\n        prefix : string\n\n        Returns\n        -------\n        LongPanel\n\n        Note\n        ----\n        does *not* copy values matrix\n        \"\"\"\n        new_items = [_prefix_item(item, prefix) for item in self.items]\n\n        return LongPanel(self.values, columns=new_items,\n                         index=self.index)", "html_url": "https://github.com/pandas-dev/pandas/commit/01ea9cb140e824e8b3bf45cf03a882d92d4968fb", "file_name": "pandas/tests/test_panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Bug in :func:`assert_frame_equal` checks category dtypes even when asked not to check index type (:issue:`52126`)\n <mask> - Bug in :meth:`DataFrame.reindex` with a ``fill_value`` that should be inferred with a :class:`ExtensionDtype` incorrectly inferring ``object`` dtype (:issue:`52586`)\n <mask> - Bug in :meth:`Series.map` when giving a callable to an empty series, the returned series had ``object`` dtype. It now keeps the original dtype (:issue:`52384`)\n <mask> - Bug in :meth:`Series.memory_usage` when ``deep=True`` throw an error with Series of objects and the returned value is incorrect, as it does not take into account GC corrections (:issue:`51858`)\n <mask> -\n <mask> \n <mask> .. ***DO NOT USE THIS SECTION***\n <mask> \n <mask> -\n <mask> \n </s> BUG: Fix pandas._libs.json __name__ (#52903) </s> add     def test_ujson__name__(self):\n        # GH 52898\n        assert ujson.__name__ == \"pandas._libs.json\"\n </s> remove                                        .m_name = \"_libjson\",\n </s> add                                        .m_name = \"pandas._libs.json\",", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> static int module_clear(PyObject *m);\n <mask> static void module_free(void *module);\n <mask> \n <mask> static struct PyModuleDef moduledef = {.m_base = PyModuleDef_HEAD_INIT,\n <mask>                                        .m_name = \"_libjson\",\n <mask>                                        .m_methods = ujsonMethods,\n <mask>                                        .m_size = sizeof(modulestate),\n <mask>                                        .m_traverse = module_traverse,\n <mask>                                        .m_clear = module_clear,\n <mask>                                        .m_free = module_free};\n </s> BUG: Fix pandas._libs.json __name__ (#52903) </s> add     def test_ujson__name__(self):\n        # GH 52898\n        assert ujson.__name__ == \"pandas._libs.json\"\n </s> remove -\n </s> add - Fixed incorrect ``__name__`` attribute of ``pandas._libs.json`` (:issue:`52898`)", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "pandas/_libs/src/ujson/python/ujson.c"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         assert ujson.decode(ujson.encode(test_object)) == {\"a\": 1, \"b\": 2, \"d\": 4}\n <mask> \n <mask> \n <mask> class TestNumpyJSONTests:\n <mask>     @pytest.mark.parametrize(\"bool_input\", [True, False])\n <mask>     def test_bool(self, bool_input): </s> add                                        .m_name = \"pandas._libs.json\",", "html_url": "https://github.com/pandas-dev/pandas/commit/0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "file_name": "pandas/tests/io/json/test_ujson.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           packages:\n <mask>           - python-gtk2\n <mask>     - dist: trusty\n <mask>       env:\n <mask>         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true\n <mask>     - dist: trusty\n <mask>       env:\n <mask>         - JOB=\"3.7, NumPy dev\" ENV_FILE=\"ci/deps/travis-37-numpydev.yaml\" PATTERN=\"not slow and not network\" TEST_ARGS=\"-W error\" PANDAS_TESTING_MODE=\"deprecate\"\n <mask>       addons:\n <mask>         apt: </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   - echo \"script start\"\n <mask>   - source activate pandas-dev\n <mask>   - ci/run_build_docs.sh\n <mask>   - ci/run_tests.sh\n <mask>   - ci/code_checks.sh\n <mask> \n <mask> after_script:\n <mask>   - echo \"after_script start\"\n <mask>   - source activate pandas-dev && pushd /tmp && python -c \"import pandas; pandas.show_versions();\" && popd\n <mask>   - if [ -e test-data-single.xml ]; then </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0 </s> remove     - cpplint </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep replace replace replace replace keep keep keep", "code_tokens": " <mask>   - beautifulsoup4\n <mask>   - cython>=0.28.2\n <mask>   - dask\n <mask>   - fastparquet\n <mask>   - flake8>=3.5\n <mask>   - flake8-comprehensions\n <mask>   - flake8-rst>=0.6.0\n <mask>   - gcsfs\n <mask>   - geopandas\n <mask>   - html5lib\n <mask>   - ipython\n <mask>   - isort\n <mask>   - jinja2\n <mask>   - lxml\n <mask>   - matplotlib\n <mask>   - nomkl\n <mask>   - numexpr </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>   - pytz\n <mask>   - s3fs\n <mask>   - scikit-learn\n <mask>   - scipy\n <mask>   - seaborn\n <mask>   - sqlalchemy\n <mask>   - statsmodels\n <mask>   - xarray\n <mask>   - xlrd\n <mask>   - xlsxwriter </s> CI: Linting with azure instead of travis (#22854) </s> add   - asv </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml </s> remove     - cpplint </s> remove   - ci/code_checks.sh", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>   - hypothesis>=3.58.0\n <mask>   - pip:\n <mask>     - brotlipy\n <mask>     - coverage\n <mask>     - cpplint\n <mask>     - pandas-datareader\n <mask>     - python-dateutil </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0 </s> remove         - JOB=\"3.6, lint, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true LINT=true </s> add         - JOB=\"3.6, coverage\" ENV_FILE=\"ci/deps/travis-36.yaml\" PATTERN=\"not slow and not network\" PANDAS_TESTING_MODE=\"deprecate\" COVERAGE=true", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "ci/deps/travis-36.yaml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   - pytz\n <mask> \n <mask>   # development\n <mask>   - cython>=0.28.2\n <mask>   - flake8\n <mask>   - flake8-comprehensions\n <mask>   - flake8-rst>=0.6.0 </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0 </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "environment.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             ``'replace'``\n <mask>                 If table exists, drop it, recreate it, and insert data.\n <mask>             ``'append'``\n <mask>                 If table exists, insert data. Create if does not exist.\n <mask>         private_key : str, optional\n <mask>             Service account private key in JSON format. Can be file path\n <mask>             or string contents. This is useful for remote server\n <mask>             authentication (eg. Jupyter/IPython notebook on remote host).\n <mask>         auth_local_webserver : bool, default False\n <mask>             Use the `local webserver flow`_ instead of the `console flow`_\n <mask>             when getting user credentials.\n <mask> \n <mask>             .. _local webserver flow: </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host). </s> remove     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     major_axis : Index or array-like\n <mask>         axis=1\n <mask>     minor_axis : Index or array-like\n <mask>         axis=2\n <mask>     dtype : dtype, default None\n <mask>         Data type to force, otherwise infer\n <mask>     copy : boolean, default False\n <mask>         Copy data from inputs. Only affects DataFrame / 2d ndarray input\n <mask>     \"\"\"\n <mask> \n <mask>     @property </s> add     dtype : dtype, default None\n        Data type to force, otherwise infer", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     copy : boolean, default False\n <mask>         Copy data from inputs. Only affects DataFrame / 2d ndarray input\n <mask>     \"\"\"\n <mask> \n <mask>     @property\n <mask>     def _constructor(self): </s> remove     dtype : dtype, default None\n        Data type to force, otherwise infer </s> add         Returns\n        -------\n        same type as input", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/panel.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     -------\n <mask>     timedelta64 or numpy.array of timedelta64\n <mask>         Output type returned if parsing succeeded.\n <mask> \n <mask>     See also\n <mask>     --------\n <mask>     DataFrame.astype : Cast argument to a specified dtype.\n <mask>     to_datetime : Convert argument to datetime.\n <mask> \n <mask>     Examples </s> remove Returns\n-------\nsame type as input\n\nSee Also\n--------\npandas.Series.%(name)s\npandas.DataFrame.%(name)s </s> remove     lines : boolean, default False\n        Read the file as a json object per line. </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/tools/timedeltas.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _shared_docs = dict(**_shared_docs)\n <mask> _doc_template = \"\"\"\n <mask> \n <mask>         See Also\n <mask>         --------\n <mask>         Series.%(name)s\n <mask>         DataFrame.%(name)s </s> add         See Also\n        --------\n        Series.%(name)s\n        DataFrame.%(name)s </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance. </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     _shared_docs['cov'] = dedent(\"\"\"\n <mask>     Calculate the %(name)s sample covariance.\n <mask> \n <mask>     Parameters\n <mask>     ----------\n <mask>     other : Series, DataFrame, or ndarray, optional\n <mask>         if not supplied then will default to self and produce pairwise output\n <mask>     pairwise : bool, default None\n <mask>         If False then only matching columns between self and other will be used\n <mask>         and the output will be a DataFrame.\n <mask>         If True then all pairwise combinations will be calculated and the\n <mask>         output will be a MultiIndexed DataFrame in the case of DataFrame\n <mask>         inputs. In the case of missing elements, only complete pairwise\n <mask>         observations will be used.\n <mask>     ddof : int, default 1\n <mask>         Delta Degrees of Freedom.  The divisor used in calculations\n <mask>         is ``N - ddof``, where ``N`` represents the number of elements.\"\"\")\n <mask> \n <mask>     def cov(self, other=None, pairwise=None, ddof=1, **kwargs):\n <mask>         if other is None:\n <mask>             other = self._selected_obj\n <mask>             # only default unset </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndex DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        bias : bool, default False\n           Use a standard estimation bias correction </s> remove     _shared_docs['cov'] = dedent(\"\"\"\n    Calculate the %(name)s sample covariance. </s> add     _shared_docs['cov'] = \"\"\"\n        Calculate the %(name)s sample covariance.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep replace replace replace replace replace keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask> _bias_template = \"\"\"\n <mask> \n <mask> Parameters\n <mask> ----------\n <mask> bias : bool, default False\n <mask>     Use a standard estimation bias correction\n <mask> \"\"\"\n <mask> \n <mask> _pairwise_template = \"\"\"\n <mask> \n <mask> Parameters\n <mask> ----------\n <mask> other : Series, DataFrame, or ndarray, optional\n <mask>     if not supplied then will default to self and produce pairwise output\n <mask> pairwise : bool, default None\n <mask>     If False then only matching columns between self and other will be used and\n <mask>     the output will be a DataFrame.\n <mask>     If True then all pairwise combinations will be calculated and the output\n <mask>     will be a MultiIndex DataFrame in the case of DataFrame inputs.\n <mask>     In the case of missing elements, only complete pairwise observations will\n <mask>     be used.\n <mask> bias : bool, default False\n <mask>    Use a standard estimation bias correction\n <mask> \"\"\"\n <mask>  </s> remove     Parameters\n    ----------\n    other : Series, DataFrame, or ndarray, optional\n        if not supplied then will default to self and produce pairwise output\n    pairwise : bool, default None\n        If False then only matching columns between self and other will be used\n        and the output will be a DataFrame.\n        If True then all pairwise combinations will be calculated and the\n        output will be a MultiIndexed DataFrame in the case of DataFrame\n        inputs. In the case of missing elements, only complete pairwise\n        observations will be used.\n    ddof : int, default 1\n        Delta Degrees of Freedom.  The divisor used in calculations\n        is ``N - ddof``, where ``N`` represents the number of elements.\"\"\") </s> add         Parameters\n        ----------\n        other : Series, DataFrame, or ndarray, optional\n            If not supplied then will default to self and produce pairwise\n            output.\n        pairwise : bool, default None\n            If False then only matching columns between self and other will be\n            used and the output will be a DataFrame.\n            If True then all pairwise combinations will be calculated and the\n            output will be a MultiIndexed DataFrame in the case of DataFrame\n            inputs. In the case of missing elements, only complete pairwise\n            observations will be used.\n        ddof : int, default 1\n            Delta Degrees of Freedom.  The divisor used in calculations\n            is ``N - ddof``, where ``N`` represents the number of elements.\n    \"\"\" </s> remove     lines : boolean, default False\n        Read the file as a json object per line. </s> add     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/core/window.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         DataFrame.\n <mask>     reauth : boolean, default False\n <mask>         Force Google BigQuery to re-authenticate the user. This is useful\n <mask>         if multiple accounts are used.\n <mask>     private_key : str, optional\n <mask>         Service account private key in JSON format. Can be file path\n <mask>         or string contents. This is useful for remote server\n <mask>         authentication (eg. Jupyter/IPython notebook on remote host).\n <mask>     auth_local_webserver : boolean, default False\n <mask>         Use the `local webserver flow`_ instead of the `console flow`_\n <mask>         when getting user credentials.\n <mask> \n <mask>         .. _local webserver flow: </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host). </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> remove     lines : boolean, default False\n        Read the file as a json object per line.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         *New in version 0.8.0 of pandas-gbq*.\n <mask> \n <mask>         .. versionadded:: 0.24.0\n <mask>     verbose : None, deprecated\n <mask>         Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n <mask>         adjust verbosity instead\n <mask>         <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n <mask>     private_key : str, deprecated\n <mask>         Deprecated in pandas-gbq version 0.8.0. Use the ``credentials``\n <mask>         parameter and\n <mask>         :func:`google.oauth2.service_account.Credentials.from_service_account_info`\n <mask>         or </s> add     verbose : None, deprecated\n        Deprecated in pandas-gbq version 0.4.0. Use the `logging module to\n        adjust verbosity instead\n        <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__. </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host). </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host).", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         Service account private key in JSON format. Can be file path\n <mask>         or string contents. This is useful for remote server\n <mask>         authentication (eg. Jupyter/IPython notebook on remote host).\n <mask> \n <mask>     Returns\n <mask>     -------\n <mask>     df: DataFrame\n <mask>         DataFrame representing results of query.\n <mask>  </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host). </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host). </s> remove \nParameters\n----------\nother : Series, DataFrame, or ndarray, optional\n    if not supplied then will default to self and produce pairwise output\npairwise : bool, default None\n    If False then only matching columns between self and other will be used and\n    the output will be a DataFrame.\n    If True then all pairwise combinations will be calculated and the output\n    will be a MultiIndex DataFrame in the case of DataFrame inputs.\n    In the case of missing elements, only complete pairwise observations will\n    be used.\nbias : bool, default False\n   Use a standard estimation bias correction </s> add         Returns\n        -------\n        same type as input </s> remove     encoding : str, default is 'utf-8'\n        The encoding to use to decode py3 bytes. </s> add     lines : boolean, default False\n        Read the file as a json object per line.", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/gbq.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep replace replace", "code_tokens": " <mask>         The timestamp unit to detect if converting dates. The default behaviour\n <mask>         is to try and detect the correct precision, but if this is not desired\n <mask>         then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,\n <mask>         milliseconds, microseconds or nanoseconds respectively.\n <mask>     lines : boolean, default False\n <mask>         Read the file as a json object per line.\n <mask> \n <mask>         .. versionadded:: 0.19.0\n <mask> \n <mask>     encoding : str, default is 'utf-8'\n <mask>         The encoding to use to decode py3 bytes. </s> remove     private_key : str, optional\n        Service account private key in JSON format. Can be file path\n        or string contents. This is useful for remote server\n        authentication (eg. Jupyter/IPython notebook on remote host). </s> remove         private_key : str, optional\n            Service account private key in JSON format. Can be file path\n            or string contents. This is useful for remote server\n            authentication (eg. Jupyter/IPython notebook on remote host).", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "pandas/io/json/json.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> python-dateutil>=2.5.0\n <mask> pytz\n <mask> cython>=0.28.2\n <mask> flake8\n <mask> flake8-comprehensions\n <mask> flake8-rst>=0.6.0 </s> remove   - flake8>=3.5\n  - flake8-comprehensions\n  - flake8-rst>=0.6.0 </s> remove   - ipython\n  - isort\n  - jinja2\n  - lxml </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0])) </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg)", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "requirements-dev.txt"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask> statsmodels\n <mask> xarray\n <mask> xlrd\n <mask> xlsxwriter\n <mask> xlwt </s> CI: Linting with azure instead of travis (#22854) </s> remove   - seaborn </s> CI: Linting with azure instead of travis (#22854) </s> remove   - seaborn </s> add </s> remove   - ci/code_checks.sh </s> add </s> add </s> add", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "requirements-dev.txt"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     with open(conda_fname) as conda_fd:\n <mask>         deps = yaml.safe_load(conda_fd)['dependencies']\n <mask> \n <mask>     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps)))\n <mask> \n <mask>     if compare:\n <mask>         with open(pip_fname) as pip_fd:\n <mask>             return pip_content != pip_fd.read()\n <mask>     else: </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0])) </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg)", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     argparser.add_argument('--compare',\n <mask>                            action='store_true',\n <mask>                            help='compare whether the two files are equivalent')\n <mask>     args = argparser.parse_args()\n <mask> \n <mask>     repo_path = os.path.dirname(os.path.abspath(os.path.dirname(__file__)))\n <mask>     res = main(os.path.join(repo_path, 'environment.yml'),\n <mask>                os.path.join(repo_path, 'requirements-dev.txt'), </s> remove         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n                         '`{}` after `environment.yml` is modified.\\n'.format(\n                             sys.argv[0])) </s> add         msg = ('`requirements-dev.txt` has to be generated with `{}` after '\n               '`environment.yml` is modified.\\n'.format(sys.argv[0]))\n        if args.azure:\n            msg = ('##vso[task.logissue type=error;'\n                   'sourcepath=requirements-dev.txt]{}'.format(msg))\n        sys.stderr.write(msg) </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps))) </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps)", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep", "code_tokens": " <mask>     res = main(os.path.join(repo_path, 'environment.yml'),\n <mask>                os.path.join(repo_path, 'requirements-dev.txt'),\n <mask>                compare=args.compare)\n <mask>     if res:\n <mask>         sys.stderr.write('`requirements-dev.txt` has to be generated with '\n <mask>                          '`{}` after `environment.yml` is modified.\\n'.format(\n <mask>                              sys.argv[0]))\n <mask>     sys.exit(res) </s> remove     pip_content = '\\n'.join(filter(None, map(conda_package_to_pip, deps))) </s> add     pip_deps = []\n    for dep in deps:\n        if isinstance(dep, str):\n            conda_dep = conda_package_to_pip(dep)\n            if conda_dep:\n                pip_deps.append(conda_dep)\n        elif isinstance(dep, dict) and len(dep) == 1 and 'pip' in dep:\n            pip_deps += dep['pip']\n        else:\n            raise ValueError('Unexpected dependency {}'.format(dep))\n\n    pip_content = '\\n'.join(pip_deps)", "html_url": "https://github.com/pandas-dev/pandas/commit/022f458ee858721d366c27dd88940d69383ab960", "file_name": "scripts/generate_pip_deps_from_conda.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n <mask> \n <mask>         final = []\n <mask>         for result, block in zip(results, kept_blocks):\n <mask> \n <mask>             result = type(obj)(result, index=obj.index, columns=block.columns)\n <mask>             final.append(result)\n <mask> \n <mask>         exclude = exclude or []\n <mask>         columns = [c for c in self._selected_obj.columns if c not in exclude]\n <mask>         if not columns and not len(final) and exclude:\n <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif not len(final):\n <mask>             return obj.astype(\"float64\")\n <mask>  </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns: </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\")", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep", "code_tokens": " <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif not len(final):\n <mask>             return obj.astype(\"float64\")\n <mask> \n <mask>         df = concat(final, axis=1).reindex(columns=columns, copy=False)\n <mask> \n <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location </s> add     def _insert_on_column(self, result: \"DataFrame\", obj: \"DataFrame\"): </s> remove         if not columns and not len(final) and exclude: </s> add         if not columns and not len(results) and exclude: </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns: </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return df\n <mask> \n <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location\n <mask>         from pandas import Series\n <mask> \n <mask>         if self.on is not None and not self._on.equals(obj.index): </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False) </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> add     from pandas import DataFrame, Series\n    from pandas.core.internals import Block  # noqa:F401 </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         # if we have an 'on' column we want to put it back into\n <mask>         # the results in the same location\n <mask>         if self.on is not None and not self._on.equals(obj.index):\n <mask>             name = self._on.name\n <mask>             extra_col = Series(self._on, index=obj.index, name=name)\n <mask>             if name in result.columns:\n <mask>                 # TODO: sure we want to overwrite results?\n <mask>                 result[name] = extra_col </s> remove             if name not in df.columns and name not in df.index.names:\n                new_loc = len(df.columns)\n                df.insert(new_loc, name, extra_col)\n            elif name in df.columns: </s> add             if name in result.columns: </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False) </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> add     def _insert_on_column(self, result: \"DataFrame\", obj: \"DataFrame\"): </s> remove                 df[name] = extra_col\n        return df </s> add                 result[name] = extra_col\n            elif name in result.index.names:\n                pass\n            elif name in self._selected_obj.columns:\n                # insert in the same location as we had in _selected_obj\n                old_cols = self._selected_obj.columns\n                new_cols = result.columns\n                old_loc = old_cols.get_loc(name)\n                overlap = new_cols.intersection(old_cols[:old_loc])\n                new_loc = len(overlap)\n                result.insert(new_loc, name, extra_col)\n            else:\n                # insert at the end\n                result[name] = extra_col", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep replace replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask>             extra_col = Series(self._on, index=obj.index, name=name)\n <mask>             if name not in df.columns and name not in df.index.names:\n <mask>                 new_loc = len(df.columns)\n <mask>                 df.insert(new_loc, name, extra_col)\n <mask>             elif name in df.columns:\n <mask>                 # TODO: sure we want to overwrite results?\n <mask>                 df[name] = extra_col\n <mask>         return df\n <mask> \n <mask>     def _center_window(self, result, window) -> np.ndarray:\n <mask>         \"\"\" </s> remove         df = concat(final, axis=1).reindex(columns=columns, copy=False) </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or [] </s> remove         if not columns and not len(final) and exclude: </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # This isn't quite blockwise, since `blocks` is actually a collection\n <mask>         #  of homogenenous DataFrames.\n <mask>         blocks, obj = self._create_blocks(self._selected_obj)\n <mask> \n <mask>         skipped: List[int] = []\n <mask>         res_blocks: List[\"Block\"] = []\n <mask>         for i, blk in enumerate(mgr.blocks):\n <mask>             try: </s> remove         results: List[ArrayLike] = []\n        for i, b in enumerate(blocks): </s> add         res_blocks: List[\"Block\"] = []\n        for i, blk in enumerate(mgr.blocks): </s> add                 nbs = blk.apply(hfunc) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep keep", "code_tokens": " <mask>         blocks, obj = self._create_blocks(self._selected_obj)\n <mask> \n <mask>         skipped: List[int] = []\n <mask>         results: List[ArrayLike] = []\n <mask>         for i, b in enumerate(blocks):\n <mask>             try:\n <mask>                 values = self._prep_values(b.values)\n <mask> \n <mask>             except (TypeError, NotImplementedError):\n <mask>                 skipped.append(i) </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove             result = homogeneous_func(values)\n            results.append(result) </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\") </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or [] </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             except (TypeError, NotImplementedError):\n <mask>                 skipped.append(i)\n <mask>                 continue\n <mask> \n <mask>             result = homogeneous_func(values)\n <mask>             results.append(result)\n <mask> \n <mask>         return self._wrap_results(results, obj, skipped)\n <mask> \n <mask>     def _apply(\n <mask>         self, </s> remove         return self._wrap_results(results, obj, skipped) </s> add         new_cols = mgr.reset_dropped_locs(res_blocks, skipped)\n        new_mgr = type(mgr).from_blocks(res_blocks, [new_cols, obj.index])\n        out = obj._constructor(new_mgr)\n        self._insert_on_column(out, obj)\n        return out </s> remove         results: List[ArrayLike] = []\n        for i, b in enumerate(blocks): </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or []", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             result = homogeneous_func(values)\n <mask>             results.append(result)\n <mask> \n <mask>         return self._wrap_results(results, obj, skipped)\n <mask> \n <mask>     def _apply(\n <mask>         self,\n <mask>         func: Callable,\n <mask>         center: bool, </s> remove             result = homogeneous_func(values)\n            results.append(result) </s> add             res_blocks.extend(nbs)\n\n        if not len(res_blocks) and skipped:\n            raise DataError(\"No numeric types to aggregate\")\n        elif not len(res_blocks):\n            return obj.astype(\"float64\") </s> add         mgr = obj._mgr\n\n        def hfunc(bvalues: ArrayLike) -> ArrayLike:\n            # TODO(EA2D): getattr unnecessary with 2D EAs\n            values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n            res_values = homogeneous_func(values)\n            return getattr(res_values, \"T\", res_values) </s> remove         kept_blocks = [blk for i, blk in enumerate(orig_blocks) if i not in skipped]\n\n        final = []\n        for result, block in zip(results, kept_blocks):\n\n            result = type(obj)(result, index=obj.index, columns=block.columns)\n            final.append(result)\n\n        exclude = exclude or [] </s> add         df = concat(results, axis=1).reindex(columns=columns, copy=False)\n        self._insert_on_column(df, obj)\n        return df </s> remove         if not columns and not len(final) and exclude: </s> add         if not columns and not len(results) and exclude:", "html_url": "https://github.com/pandas-dev/pandas/commit/02b0a86da5a972375384cbc67c4d833b692caaba", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.mean`, :meth:`DataFrame.mean` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`36703`, :issue:`44008`)\n <mask> - Bug in :meth:`DataFrame.corrwith` raising ``NotImplementedError`` for pyarrow-backed dtypes (:issue:`52314`)\n <mask> - Bug in :meth:`DataFrame.size` and :meth:`Series.size` returning 64-bit integer instead of int (:issue:`52897`)\n <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.median` and :meth:`DataFrame.median` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`34671`)\n <mask> \n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^ </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series.", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Bug in :meth:`DataFrame.corrwith` raising ``NotImplementedError`` for pyarrow-backed dtypes (:issue:`52314`)\n <mask> - Bug in :meth:`DataFrame.size` and :meth:`Series.size` returning 64-bit integer instead of int (:issue:`52897`)\n <mask> - Bug in :meth:`Series.corr` and :meth:`Series.cov` raising ``AttributeError`` for masked dtypes (:issue:`51422`)\n <mask> - Bug in :meth:`Series.median` and :meth:`DataFrame.median` with object-dtype values containing strings that can be converted to numbers (e.g. \"2\") returning incorrect numeric results; these now raise ``TypeError`` (:issue:`34671`)\n <mask> -\n <mask> \n <mask> \n <mask> Conversion\n <mask> ^^^^^^^^^^\n <mask> - Bug in :func:`DataFrame.style.to_latex` and :func:`DataFrame.style.to_html` if the DataFrame contains integers with more digits than can be represented by floating point double precision (:issue:`52272`) </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`) </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series.", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "doc/source/whatsnew/v2.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def any(  # type: ignore[override]\n <mask>         self,\n <mask>         *,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> Series:\n <mask>         # error: Incompatible return value type (got \"Union[Series, bool]\",\n <mask>         # expected \"Series\") </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @doc(make_doc(\"all\", ndim=2))\n <mask>     def all(\n <mask>         self,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> Series:\n <mask>         # error: Incompatible return value type (got \"Union[Series, bool]\",\n <mask>         # expected \"Series\") </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None, </s> remove         bool_only=None, </s> remove         bool_only=None, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     * 1 / 'columns' : reduce the columns, return a Series whose index is the\n <mask>       original index.\n <mask>     * None : reduce all axes, return a scalar.\n <mask> \n <mask> bool_only : bool, default None\n <mask>     Include only boolean columns. If None, will attempt to use everything,\n <mask>     then use only boolean data. Not implemented for Series.\n <mask> skipna : bool, default True\n <mask>     Exclude NA/null values. If the entire row/column is NA and skipna is\n <mask>     True, then the result will be {empty_value}, as for an empty row/column.\n <mask>     If skipna is False, then NA are treated as True, because these are not\n <mask>     equal to zero. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/generic.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def any(  # type: ignore[override]\n <mask>         self,\n <mask>         *,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> bool:\n <mask>         nv.validate_logical_func((), kwargs, fname=\"any\")\n <mask>         validate_bool_kwarg(skipna, \"skipna\", none_allowed=False) </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @Appender(make_doc(\"all\", ndim=1))\n <mask>     def all(\n <mask>         self,\n <mask>         axis: Axis = 0,\n <mask>         bool_only=None,\n <mask>         skipna: bool = True,\n <mask>         **kwargs,\n <mask>     ) -> bool:\n <mask>         nv.validate_logical_func((), kwargs, fname=\"all\")\n <mask>         validate_bool_kwarg(skipna, \"skipna\", none_allowed=False) </s> BUG: Change default of bool_only to False (#53283) </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove         bool_only=None, </s> add         bool_only: bool = False, </s> remove bool_only : bool, default None\n    Include only boolean columns. If None, will attempt to use everything,\n    then use only boolean data. Not implemented for Series. </s> add bool_only : bool, default False\n    Include only boolean columns. Not implemented for Series. </s> add - Bug in :meth:`Series.any`, :meth:`Series.all`, :meth:`DataFrame.any`, and :meth:`DataFrame.all` had the default value of ``bool_only`` set to ``None`` instead of ``False``; this change should have no impact on users (:issue:`53258`)", "html_url": "https://github.com/pandas-dev/pandas/commit/030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace keep keep keep keep", "code_tokens": " <mask> changes in this branch specific to one bug or feature so it is clear\n <mask> what the branch brings to *pandas*. You can have many shiny-new-features\n <mask> and switch in between them using the git checkout command.\n <mask> \n <mask> To update this branch, you need to retrieve the changes from the master branch::\n <mask> \n <mask>     git fetch upstream\n <mask>     git rebase upstream/master\n <mask> \n <mask> This will replay your commits on top of the latest pandas git master.  If this\n <mask> leads to merge conflicts, you must resolve these before submitting your pull\n <mask> request.  If you have uncommitted changes, you will need to ``stash`` them prior </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating. </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f </s> add </s> remove     git push -f origin shiny-new-feature </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by:: </s> add the code. \n\n.. _contributing.update-pr:", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     git fetch upstream\n <mask>     git rebase upstream/master\n <mask> \n <mask> This will replay your commits on top of the latest pandas git master.  If this\n <mask> leads to merge conflicts, you must resolve these before submitting your pull\n <mask> request.  If you have uncommitted changes, you will need to ``stash`` them prior\n <mask> to updating.  This will effectively store your changes and they can be reapplied\n <mask> after updating.\n <mask> \n <mask> .. _contributing.documentation:\n <mask> \n <mask> Contributing to the documentation\n <mask> ================================= </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git fetch upstream\n    git rebase upstream/master </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by:: </s> add the code. \n\n.. _contributing.update-pr: </s> remove     git push -f origin shiny-new-feature </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove To update this branch, you need to retrieve the changes from the master branch:: </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> Now you can commit your changes in your local repository::\n <mask> \n <mask>     git commit -m\n <mask> \n <mask> Combining commits\n <mask> -----------------\n <mask> \n <mask> If you have multiple commits, you may want to combine them into one commit, often\n <mask> referred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\n <mask> when submitting a pull request as it maintains a more compact commit history.  To rebase\n <mask> your commits::\n <mask> \n <mask>     git rebase -i HEAD~#\n <mask> \n <mask> Where # is the number of commits you want to combine.  Then you can pick the relevant\n <mask> commit message and discard others.\n <mask> \n <mask> To squash to the master branch do::\n <mask> \n <mask>     git rebase -i master\n <mask> \n <mask> Use the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\n <mask> or ``f`` to ``fixup``, meaning to merge the commit messages.\n <mask> \n <mask> Then you will need to push the branch (see below) forcefully to replace the current\n <mask> commits with the new ones::\n <mask> \n <mask>     git push origin shiny-new-feature -f\n <mask> \n <mask> \n <mask> Pushing your changes\n <mask> --------------------\n <mask> \n <mask> When you want your changes to appear publicly on your GitHub page, push your\n <mask> forked feature branch's commits:: </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git push -f origin shiny-new-feature </s> add Updating your pull request\n--------------------------\n\nBased on the review you get on your pull request, you will probably need to make\nsome changes to the code. In that case, you can make them in your branch, \nadd a new commit to that branch, push it to GitHub, and the pull request will be\nautomatically updated.  Pushing them to GitHub again is done by::\n\n    git push origin shiny-new-feature </s> remove To update this branch, you need to retrieve the changes from the master branch:: </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating. </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove     git fetch upstream\n    git rebase upstream/master </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove the code. If you need to make more changes, you can make them in\nyour branch, push them to GitHub, and the pull request will be automatically\nupdated.  Pushing them to GitHub again is done by:: </s> add the code. \n\n.. _contributing.update-pr:", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep keep", "code_tokens": " <mask> #. Write a description of your changes in the ``Preview Discussion`` tab\n <mask> #. Click ``Send Pull Request``.\n <mask> \n <mask> This request then goes to the repository maintainers, and they will review\n <mask> the code. If you need to make more changes, you can make them in\n <mask> your branch, push them to GitHub, and the pull request will be automatically\n <mask> updated.  Pushing them to GitHub again is done by::\n <mask> \n <mask>     git push -f origin shiny-new-feature\n <mask> \n <mask> This will automatically update your pull request with the latest code and restart the </s> DOC: update contributing guide regarding updating a pull request (merge master) (#19990) </s> remove     git fetch upstream\n    git rebase upstream/master </s> add     git checkout master\n    git pull upstream master --ff-only </s> remove This will replay your commits on top of the latest pandas git master.  If this\nleads to merge conflicts, you must resolve these before submitting your pull\nrequest.  If you have uncommitted changes, you will need to ``stash`` them prior\nto updating.  This will effectively store your changes and they can be reapplied\nafter updating. </s> add When you want to update the feature branch with changes in master after\nyou created the branch, check the section on\n:ref:`updating a PR <contributing.update-pr>`. </s> remove To update this branch, you need to retrieve the changes from the master branch:: </s> add When creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:: </s> remove Combining commits\n-----------------\n\nIf you have multiple commits, you may want to combine them into one commit, often\nreferred to as \"squashing\" or \"rebasing\".  This is a common request by package maintainers\nwhen submitting a pull request as it maintains a more compact commit history.  To rebase\nyour commits::\n\n    git rebase -i HEAD~#\n\nWhere # is the number of commits you want to combine.  Then you can pick the relevant\ncommit message and discard others.\n\nTo squash to the master branch do::\n\n    git rebase -i master\n\nUse the ``s`` option on a commit to ``squash``, meaning to keep the commit messages,\nor ``f`` to ``fixup``, meaning to merge the commit messages.\n\nThen you will need to push the branch (see below) forcefully to replace the current\ncommits with the new ones::\n\n    git push origin shiny-new-feature -f", "html_url": "https://github.com/pandas-dev/pandas/commit/0368927fd26e261e87125479a96e59da8985f5f5", "file_name": "doc/source/contributing.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     min_fname_arg_count = 0\n <mask>     max_length = len(compat_args) + min_fname_arg_count\n <mask>     actual_length = len(args) + min_fname_arg_count\n <mask>     msg = (\n <mask>         r\"{fname}\\(\\) takes at most {max_length} \"\n <mask>         r\"argument \\({actual_length} given\\)\".format(\n <mask>             fname=_fname, max_length=max_length, actual_length=actual_length\n <mask>         )\n <mask>     )\n <mask> \n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         validate_args(_fname, args, min_fname_arg_count, compat_args)\n <mask>  </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg) </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name) </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         title_line = \"{side} {title}{adj} {side}\".format(\n            side=char * side_len, title=title, adj=adj\n        ) </s> add         title_line = f\"{char * side_len} {title}{adj} {char * side_len}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     min_fname_arg_count = 2\n <mask>     max_length = len(compat_args) + min_fname_arg_count\n <mask>     actual_length = len(args) + min_fname_arg_count\n <mask>     msg = (\n <mask>         r\"{fname}\\(\\) takes at most {max_length} \"\n <mask>         r\"arguments \\({actual_length} given\\)\".format(\n <mask>             fname=_fname, max_length=max_length, actual_length=actual_length\n <mask>         )\n <mask>     )\n <mask> \n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         validate_args(_fname, args, min_fname_arg_count, compat_args)\n <mask>  </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg) </s> remove         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name) </s> add         msg = f\"'{obj_name}' has no attribute '{invalid_attr_name}'\" </s> remove         title_line = \"{side} {title}{adj} {side}\".format(\n            side=char * side_len, title=title, adj=adj\n        ) </s> add         title_line = f\"{char * side_len} {title}{adj} {char * side_len}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"i\", range(1, 3))\n <mask> def test_not_all_defaults(i):\n <mask>     bad_arg = \"foo\"\n <mask>     msg = (\n <mask>         \"the '{arg}' parameter is not supported \"\n <mask>         r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n <mask>     )\n <mask> \n <mask>     compat_args = {\"foo\": 2, \"bar\": -1, \"baz\": 3}\n <mask>     arg_vals = (1, -1, 3)\n <mask>  </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname) </s> add         fr\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove                 \"sourcepath=requirements-dev.txt]{}\".format(msg) </s> add                 f\"sourcepath=requirements-dev.txt]{msg}\" </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_args.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> @pytest.mark.parametrize(\"i\", range(1, 3))\n <mask> def test_not_all_none(i):\n <mask>     bad_arg = \"foo\"\n <mask>     msg = (\n <mask>         r\"the '{arg}' parameter is not supported \"\n <mask>         r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)\n <mask>     )\n <mask> \n <mask>     compat_args = {\"foo\": 1, \"bar\": \"s\", \"baz\": None}\n <mask> \n <mask>     kwarg_keys = (\"foo\", \"bar\", \"baz\") </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname) </s> add         f\"the '{bad_arg}' parameter is not supported \"\n        fr\"in the pandas implementation of {_fname}\\(\\)\" </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove                 \"sourcepath=requirements-dev.txt]{}\".format(msg) </s> add                 f\"sourcepath=requirements-dev.txt]{msg}\" </s> remove         msg = \"'{arg}' is not a valid function for 'Window' object\".format(arg=arg) </s> add         msg = f\"'{arg}' is not a valid function for 'Window' object\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tests/util/test_validate_kwargs.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     def __repr__(self) -> str:\n <mask>         info = \"\"\n <mask>         if self.year is not None:\n <mask>             info += \"year={year}, \".format(year=self.year)\n <mask>         info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day)\n <mask> \n <mask>         if self.offset is not None:\n <mask>             info += \"offset={offset}\".format(offset=self.offset)\n <mask>  </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info) </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> add         url += f\"{self.source_file_name}#L{self.source_file_def_line}\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name) </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.offset is not None:\n <mask>             info += \"offset={offset}\".format(offset=self.offset)\n <mask> \n <mask>         if self.observance is not None:\n <mask>             info += \"observance={obs}\".format(obs=self.observance)\n <mask> \n <mask>         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n <mask>         return repr\n <mask> \n <mask>     def dates(self, start_date, end_date, return_name=False): </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info) </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             info += \"offset={offset}\".format(offset=self.offset) </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day) </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name) </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         if self.observance is not None:\n <mask>             info += \"observance={obs}\".format(obs=self.observance)\n <mask> \n <mask>         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info)\n <mask>         return repr\n <mask> \n <mask>     def dates(self, start_date, end_date, return_name=False):\n <mask>         \"\"\"\n <mask>         Calculate holidays observed between start date and end date </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name) </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day) </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             DatetimeIndex of holidays\n <mask>         \"\"\"\n <mask>         if self.rules is None:\n <mask>             raise Exception(\n <mask>                 \"Holiday Calendar {name} does not have any \"\n <mask>                 \"rules specified\".format(name=self.name)\n <mask>             )\n <mask> \n <mask>         if start is None:\n <mask>             start = AbstractHolidayCalendar.start_date\n <mask>  </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info) </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove             info += \"year={year}, \".format(year=self.year)\n        info += \"month={mon}, day={day}, \".format(mon=self.month, day=self.day) </s> add             info += f\"year={self.year}, \"\n        info += f\"month={self.month}, day={self.day}, \"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "pandas/tseries/holiday.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     files = [\n <mask>         x\n <mask>         for x in root.xpath(\"//a/text()\")\n <mask>         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists()\n <mask>     ]\n <mask> \n <mask>     N = len(files)\n <mask> \n <mask>     for i, filename in enumerate(files, 1): </s> remove         print(\n            \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n        ) </s> add         print(f\"Downloaded {link} to {out} [{i}/{N}]\") </s> remove             full_directive = \".. {}\".format(directive)", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/download_wheels.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     for i, filename in enumerate(files, 1):\n <mask>         out = str(dest.joinpath(filename))\n <mask>         link = urllib.request.urljoin(base, filename)\n <mask>         urllib.request.urlretrieve(link, out)\n <mask>         print(\n <mask>             \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n <mask>         )\n <mask> \n <mask> \n <mask> def main(args=None):\n <mask>     args = parse_args(args)\n <mask>     fetch(args.version) </s> remove         if x.startswith(\"pandas-{}\".format(version)) and not dest.joinpath(x).exists() </s> add         if x.startswith(f\"pandas-{version}\") and not dest.joinpath(x).exists() </s> remove             full_directive = \".. {}\".format(directive) </s> add             full_directive = f\".. {directive}\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/download_wheels.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     def test_raises_for_invalid_attribute_name(self, invalid_name):\n <mask>         name_components = invalid_name.split(\".\")\n <mask>         obj_name, invalid_attr_name = name_components[-2], name_components[-1]\n <mask>         msg = \"'{}' has no attribute '{}'\".format(obj_name, invalid_attr_name)\n <mask>         with pytest.raises(AttributeError, match=msg):\n <mask>             validate_docstrings.Docstring(invalid_name)\n <mask> \n <mask>     @pytest.mark.parametrize(\n <mask>         \"name\", [\"pandas.Series.str.isdecimal\", \"pandas.Series.str.islower\"] </s> remove         msg = 'No module can be imported from \"{}\"'.format(invalid_name) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname)", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/tests/test_validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property\n <mask>     def github_url(self):\n <mask>         url = \"https://github.com/pandas-dev/pandas/blob/master/\"\n <mask>         url += \"{}#L{}\".format(self.source_file_name, self.source_file_def_line)\n <mask>         return url\n <mask> \n <mask>     @property\n <mask>     def start_blank_lines(self):\n <mask>         i = None </s> remove             info += \"offset={offset}\".format(offset=self.offset) </s> add             info += f\"offset={self.offset}\" </s> remove         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n            full_line=full_line, title_line=title_line\n        )", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def parameter_desc(self, param):\n <mask>         desc = self.doc_parameters[param][1]\n <mask>         # Find and strip out any sphinx directives\n <mask>         for directive in DIRECTIVES:\n <mask>             full_directive = \".. {}\".format(directive)\n <mask>             if full_directive in desc:\n <mask>                 # Only retain any description before the directive\n <mask>                 desc = desc[: desc.index(full_directive)]\n <mask>         return desc\n <mask>  </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0]) </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"])) </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\") </s> remove         print(\n            \"Downloaded {link} to {out} [{i}/{N}]\".format(link=link, out=out, i=i, N=N)\n        )", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep keep keep replace", "code_tokens": " <mask>                     \"EX03\",\n <mask>                     error_code=err.error_code,\n <mask>                     error_message=err.message,\n <mask>                     times_happening=\" ({} times)\".format(err.count)\n <mask>                     if err.count > 1\n <mask>                     else \"\",\n <mask>                 )\n <mask>             )\n <mask>         examples_source_code = \"\".join(doc.examples_source_code)\n <mask>         for wrong_import in (\"numpy\", \"pandas\"):\n <mask>             if \"import {}\".format(wrong_import) in examples_source_code: </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove             full_directive = \".. {}\".format(directive)", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # functions from introspecting Series and DataFrame\n <mask>     api_item_names = set(list(zip(*api_items))[0])\n <mask>     for class_ in (pandas.Series, pandas.DataFrame):\n <mask>         for member in inspect.getmembers(class_):\n <mask>             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0])\n <mask>             if not member[0].startswith(\"_\") and func_name not in api_item_names:\n <mask>                 if prefix and not func_name.startswith(prefix):\n <mask>                     continue\n <mask>                 doc_info = validate_one(func_name)\n <mask>                 if ignore_deprecated and doc_info[\"deprecated\"]: </s> remove         repr = \"Holiday: {name} ({info})\".format(name=self.name, info=info) </s> add         repr = f\"Holiday: {self.name} ({info})\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"])) </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace replace keep keep keep keep", "code_tokens": " <mask>         full_line = char * width\n <mask>         side_len = (width - len(title) - 2) // 2\n <mask>         adj = \"\" if len(title) % 2 == 0 else \" \"\n <mask>         title_line = \"{side} {title}{adj} {side}\".format(\n <mask>             side=char * side_len, title=title, adj=adj\n <mask>         )\n <mask> \n <mask>         return \"\\n{full_line}\\n{title_line}\\n{full_line}\\n\\n\".format(\n <mask>             full_line=full_line, title_line=title_line\n <mask>         )\n <mask> \n <mask>     exit_status = 0\n <mask>     if func_name is None:\n <mask>         result = validate_all(prefix, ignore_deprecated) </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"arguments \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"arguments \\({actual_length} given\\)\" </s> remove         r\"{fname}\\(\\) takes at most {max_length} \"\n        r\"argument \\({actual_length} given\\)\".format(\n            fname=_fname, max_length=max_length, actual_length=actual_length\n        ) </s> add         fr\"{_fname}\\(\\) takes at most {max_length} \"\n        fr\"argument \\({actual_length} given\\)\" </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\"", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep replace replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         result = validate_one(func_name)\n <mask>         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n <mask>         sys.stderr.write(\"{}\\n\".format(result[\"docstring\"]))\n <mask>         sys.stderr.write(header(\"Validation\"))\n <mask>         if result[\"errors\"]:\n <mask>             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"])))\n <mask>             for err_code, err_desc in result[\"errors\"]:\n <mask>                 # Failing examples are printed at the end\n <mask>                 if err_code == \"EX02\":\n <mask>                     sys.stderr.write(\"\\tExamples do not pass tests\\n\") </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(err_desc)) </s> add                 sys.stderr.write(f\"\\t{err_desc}\\n\") </s> add             sys.stderr.write(f\"{len(result['warnings'])} Warnings found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc)) </s> add                 sys.stderr.write(f\"\\t{wrn_desc}\\n\") </s> remove             func_name = \"pandas.{}.{}\".format(class_.__name__, member[0]) </s> add             func_name = f\"pandas.{class_.__name__}.{member[0]}\" </s> remove             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name)) </s> add             sys.stderr.write(f'Docstring for \"{func_name}\" correct. :)\\n')", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask>                 if err_code == \"EX02\":\n <mask>                     sys.stderr.write(\"\\tExamples do not pass tests\\n\")\n <mask>                     continue\n <mask>                 sys.stderr.write(\"\\t{}\\n\".format(err_desc))\n <mask>         if result[\"warnings\"]:\n <mask>             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"]))) </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"]))) </s> add             sys.stderr.write(f\"{len(result['errors'])} Errors found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc)) </s> add                 sys.stderr.write(f\"\\t{wrn_desc}\\n\") </s> remove             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name)) </s> add             sys.stderr.write(f'Docstring for \"{func_name}\" correct. :)\\n') </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"])) </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>         if result[\"warnings\"]:\n <mask>             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"])))\n <mask>             for wrn_code, wrn_desc in result[\"warnings\"]:\n <mask>                 sys.stderr.write(\"\\t{}\\n\".format(wrn_desc))\n <mask> \n <mask>         if not result[\"errors\"]:\n <mask>             sys.stderr.write('Docstring for \"{}\" correct. :)\\n'.format(func_name))\n <mask> \n <mask>         if result[\"examples_errors\"]:\n <mask>             sys.stderr.write(header(\"Doctests\")) </s> CLN: replacing '.format' with f-strings in various files (#30706) </s> remove             sys.stderr.write(\"{} Warnings found:\\n\".format(len(result[\"warnings\"]))) </s> add             sys.stderr.write(f\"{len(result['warnings'])} Warnings found:\\n\") </s> remove                 sys.stderr.write(\"\\t{}\\n\".format(err_desc)) </s> add                 sys.stderr.write(f\"\\t{err_desc}\\n\") </s> remove             sys.stderr.write(\"{} Errors found:\\n\".format(len(result[\"errors\"]))) </s> add             sys.stderr.write(f\"{len(result['errors'])} Errors found:\\n\") </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"])) </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\") </s> remove                     times_happening=\" ({} times)\".format(err.count)\n                    if err.count > 1\n                    else \"\", </s> add                     times_happening=f\" ({err.count} times)\" if err.count > 1 else \"\",", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default=\"default\",\n <mask>         choices=format_opts,\n <mask>         help=\"format of the output when validating \"\n <mask>         \"multiple docstrings (ignored when validating one).\"\n <mask>         \"It can be {}\".format(str(format_opts)[1:-1]),\n <mask>     )\n <mask>     argparser.add_argument(\n <mask>         \"--prefix\",\n <mask>         default=None,\n <mask>         help=\"pattern for the \" </s> remove         r\"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname) </s> remove         \"the '{arg}' parameter is not supported \"\n        r\"in the pandas implementation of {func}\\(\\)\".format(arg=bad_arg, func=_fname) </s> remove             \"`requirements-dev.txt` has to be generated with `{}` after \"\n            \"`environment.yml` is modified.\\n\".format(sys.argv[0]) </s> add             f\"`requirements-dev.txt` has to be generated with `{sys.argv[0]}` after \"\n            \"`environment.yml` is modified.\\n\" </s> remove                 \"Holiday Calendar {name} does not have any \"\n                \"rules specified\".format(name=self.name) </s> add                 f\"Holiday Calendar {self.name} does not have any rules specified\" </s> remove         sys.stderr.write(header(\"Docstring ({})\".format(func_name)))\n        sys.stderr.write(\"{}\\n\".format(result[\"docstring\"])) </s> add         sys.stderr.write(header(f\"Docstring ({func_name})\"))\n        sys.stderr.write(f\"{result['docstring']}\\n\")", "html_url": "https://github.com/pandas-dev/pandas/commit/036dc8863e20632c6497cc69e341be41ad0be172", "file_name": "scripts/validate_docstrings.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def _filter_data(self):\n <mask>         \"\"\"\n <mask> \n <mask>         \"\"\"\n <mask>         data, cat_mapping = self._convert_x()\n <mask>         x_names = data.keys()\n <mask> \n <mask>         if isinstance(data, LongPanel):\n <mask>             data = data.toWide()\n <mask> \n <mask>         elif not isinstance(data, WidePanel): </s> add             cat_mapping = {} </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data) </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items </s> remove         for key, value in self._x_orig.iteritems():", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         data = self._x_orig\n <mask> \n <mask>         if isinstance(data, LongPanel):\n <mask>             data = data.toWide()\n <mask> \n <mask>         else:\n <mask>             data, cat_mapping = self._convert_x(data)\n <mask> \n <mask>             if not isinstance(data, WidePanel): </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys() </s> add         data = self._x_orig </s> remove         elif not isinstance(data, WidePanel):\n            data = WidePanel.fromDict(data) </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items </s> remove     def _convert_x(self): </s> add     def _convert_x(self, x):", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         weights = data_long['__weights__'] if self._weights else None\n <mask> \n <mask>         return x, x_filt, y, weights, weights_filt, cat_mapping\n <mask> \n <mask>     def _convert_x(self):\n <mask> \n <mask>         # Converts non-numeric data in x to floats. x_converted is the\n <mask>         # DataMatrix with converted values, and x_conversion is a dict that\n <mask>         # provides the reverse mapping.  For example, if 'A' was converted to 0\n <mask>         # for x named 'variety', then x_conversion['variety'][0] is 'A'. </s> remove         for key, value in self._x_orig.iteritems(): </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # provides the reverse mapping.  For example, if 'A' was converted to 0\n <mask>         # for x named 'variety', then x_conversion['variety'][0] is 'A'.\n <mask>         x_converted = {}\n <mask>         x_conversion = {}\n <mask>         for key, value in self._x_orig.iteritems():\n <mask>             df = value\n <mask>             if _is_numeric(df):\n <mask>                 x_converted[key] = df\n <mask>             else:\n <mask>                 values = df.values </s> remove     def _convert_x(self): </s> add     def _convert_x(self, x): </s> add         else:\r\n            data, cat_mapping = self._convert_x(data)\r\n\r\n            if not isinstance(data, WidePanel):\r\n                data = WidePanel.fromDict(data)\r\n\r\n        x_names = data.items </s> remove         data, cat_mapping = self._convert_x()\n        x_names = data.keys()", "html_url": "https://github.com/pandas-dev/pandas/commit/03c74e4492da468a7b118575c1a0291392d6e64b", "file_name": "pandas/stats/plm.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     weekofyear,\"The week ordinal of the year\"\n <mask>     week,\"The week ordinal of the year\"\n <mask>     dayofweek,\"The number of the day of the week with Monday=0, Sunday=6\"\n <mask>     weekday,\"The number of the day of the week with Monday=0, Sunday=6\"\n <mask>     isocalendar,\"The ISO 8601 year, week and day of the date\"\n <mask>     quarter,\"Quarter of the date: Jan-Mar = 1, Apr-Jun = 2, etc.\"\n <mask>     days_in_month,\"The number of days in the month of the datetime\"\n <mask>     is_month_start,\"Logical indicating if first day of month (defined by frequency)\"\n <mask>     is_month_end,\"Logical indicating if last day of month (defined by frequency)\"\n <mask>     is_quarter_start,\"Logical indicating if first day of quarter (defined by frequency)\" </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     @property </s> add </s> remove     @property </s> add </s> remove         >>> ser.dt.isocalendar </s> add         >>> ser.dt.isocalendar() </s> remove         >>> idx.isocalendar </s> add         >>> idx.isocalendar() </s> remove         >>> ser.dt.isocalendar.week </s> add         >>> ser.dt.isocalendar().week", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/user_guide/timeseries.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. ipython:: python\n <mask> \n <mask>    idx = pd.date_range(start='2019-12-29', freq='D', periods=4)\n <mask>    idx.to_series().dt.isocalendar\n <mask> \n <mask> .. _timeseries.offsets:\n <mask> \n <mask> DateOffset objects\n <mask> ------------------ </s> remove         >>> idx.isocalendar </s> add         >>> idx.isocalendar() </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"] </s> add     _other_ops = [\"date\", \"time\", \"timetz\"] </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/user_guide/timeseries.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> - Positional slicing on a :class:`IntervalIndex` now supports slices with ``step > 1`` (:issue:`31658`)\n <mask> - :class:`Series.str` now has a `fullmatch` method that matches a regular expression against the entire string in each row of the series, similar to `re.fullmatch` (:issue:`32806`).\n <mask> - :meth:`DataFrame.sample` will now also allow array-like and BitGenerator objects to be passed to ``random_state`` as seeds (:issue:`32503`)\n <mask> - :meth:`MultiIndex.union` will now raise `RuntimeWarning` if the object inside are unsortable, pass `sort=False` to suppress this warning (:issue:`33015`)\n <mask> - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`).\n <mask> - The :meth:`DataFrame.to_feather` method now supports additional keyword\n <mask>   arguments (e.g. to set the compression) that are added in pyarrow 0.17\n <mask>   (:issue:`33422`).\n <mask> - :meth:`DataFrame.to_csv`, :meth:`DataFrame.to_pickle`,\n <mask>   and :meth:`DataFrame.to_json` now support passing a dict of </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\" </s> remove    idx.to_series().dt.isocalendar </s> add    idx.to_series().dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "doc/source/whatsnew/v1.1.0.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"daysinmonth\",\n <mask>         \"microsecond\",\n <mask>         \"nanosecond\",\n <mask>     ]\n <mask>     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"]\n <mask>     _datetimelike_ops = _field_ops + _object_ops + _bool_ops + _other_ops\n <mask>     _datetimelike_methods = [\n <mask>         \"to_period\",\n <mask>         \"tz_localize\",\n <mask>         \"tz_convert\", </s> remove         >>> idx.isocalendar", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             timestamps = self.asi8\n <mask> \n <mask>         return tslib.ints_to_pydatetime(timestamps, box=\"date\")\n <mask> \n <mask>     @property\n <mask>     def isocalendar(self):\n <mask>         \"\"\"\n <mask>         Returns a DataFrame with the year, week, and day calculated according to\n <mask>         the ISO 8601 standard.\n <mask>  </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\" </s> remove         return self._get_values().isocalendar.set_index(self._parent.index) </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         Examples\n <mask>         --------\n <mask>         >>> idx = pd.date_range(start='2019-12-29', freq='D', periods=4)\n <mask>         >>> idx.isocalendar\n <mask>            year  week  day\n <mask>         0  2019    52    7\n <mask>         1  2020     1    1\n <mask>         2  2020     1    2\n <mask>         3  2020     1    3 </s> remove         >>> idx.isocalendar.week </s> add         >>> idx.isocalendar().week </s> remove         >>> ser.dt.isocalendar.week </s> add         >>> ser.dt.isocalendar().week </s> remove    idx.to_series().dt.isocalendar </s> add    idx.to_series().dt.isocalendar() </s> remove         return self._get_values().isocalendar.set_index(self._parent.index) </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\"", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         0  2019    52    7\n <mask>         1  2020     1    1\n <mask>         2  2020     1    2\n <mask>         3  2020     1    3\n <mask>         >>> idx.isocalendar.week\n <mask>         0    52\n <mask>         1     1\n <mask>         2     1\n <mask>         3     1\n <mask>         Name: week, dtype: UInt32 </s> CLN: Change isocalendar to be a method (#33533)\n\nFor consistency with `Timestamp.isocalendar`, this should rather be a\r\nmethod.\r\n\r\nFollowup of #33220, see the discussions following the merge </s> remove         >>> idx.isocalendar </s> add         >>> idx.isocalendar() </s> remove         >>> ser.dt.isocalendar.week </s> add         >>> ser.dt.isocalendar().week </s> remove         >>> ser.dt.isocalendar </s> add         >>> ser.dt.isocalendar() </s> remove     @property </s> add </s> remove     @property </s> add", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/arrays/datetimes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @property\n <mask>     def freq(self):\n <mask>         return self._get_values().inferred_freq\n <mask> \n <mask>     @property\n <mask>     def isocalendar(self):\n <mask>         \"\"\"\n <mask>         Returns a DataFrame with the year, week, and day calculated according to\n <mask>         the ISO 8601 standard.\n <mask>  </s> remove - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` accessor that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> add - :class:`Series.dt` and :class:`DatatimeIndex` now have an `isocalendar` method that returns a :class:`DataFrame` with year, week, and day calculated according to the ISO 8601 calendar (:issue:`33206`). </s> remove     isocalendar,\"The ISO 8601 year, week and day of the date\" </s> remove         return self._get_values().isocalendar.set_index(self._parent.index) </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> add         >>> ser.dt.isocalendar().week", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         --------\n <mask>         >>> ser = pd.to_datetime(pd.Series([\"2010-01-01\", pd.NaT]))\n <mask>         >>> ser.dt.isocalendar\n <mask>            year  week  day\n <mask>         0  2009    53     5\n <mask>         1  <NA>  <NA>  <NA>\n <mask>         >>> ser.dt.isocalendar.week\n <mask>         0      53\n <mask>         1    <NA>\n <mask>         Name: week, dtype: UInt32\n <mask>         \"\"\" </s> remove         >>> idx.isocalendar.week", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         0      53\n <mask>         1    <NA>\n <mask>         Name: week, dtype: UInt32\n <mask>         \"\"\"\n <mask>         return self._get_values().isocalendar.set_index(self._parent.index)\n <mask> \n <mask> \n <mask> @delegate_names(\n <mask>     delegate=TimedeltaArray, accessors=TimedeltaArray._datetimelike_ops, typ=\"property\"\n <mask> ) </s> remove         >>> idx.isocalendar.week </s> add         >>> idx.isocalendar().week </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/core/indexes/accessors.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             \"floor\",\n <mask>             \"ceil\",\n <mask>             \"day_name\",\n <mask>             \"month_name\",\n <mask>         ]\n <mask>         ok_for_td = TimedeltaIndex._datetimelike_ops\n <mask>         ok_for_td_methods = [\n <mask>             \"components\", </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"] </s> add     _other_ops = [\"date\", \"time\", \"timetz\"] </s> remove         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar </s> add         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar() </s> remove    idx.to_series().dt.isocalendar </s> add    idx.to_series().dt.isocalendar() </s> remove         >>> idx.isocalendar", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/tests/series/test_datetime_values.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             [[\"2010-01-01\", pd.NaT], [[2009, 53, 5], [np.NaN, np.NaN, np.NaN]]],\n <mask>         ],\n <mask>     )\n <mask>     def test_isocalendar(self, input_series, expected_output):\n <mask>         result = pd.to_datetime(pd.Series(input_series)).dt.isocalendar\n <mask>         expected_frame = pd.DataFrame(\n <mask>             expected_output, columns=[\"year\", \"week\", \"day\"], dtype=\"UInt32\"\n <mask>         )\n <mask>         tm.assert_frame_equal(result, expected_frame) </s> remove         return self._get_values().isocalendar.set_index(self._parent.index) </s> add         return self._get_values().isocalendar().set_index(self._parent.index) </s> remove     _other_ops = [\"date\", \"time\", \"timetz\", \"isocalendar\"] </s> remove    idx.to_series().dt.isocalendar </s> add    idx.to_series().dt.isocalendar()", "html_url": "https://github.com/pandas-dev/pandas/commit/041dc4456f6936cd742b2f28440b7b64fb33d3e3", "file_name": "pandas/tests/series/test_datetime_values.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Reindexing and alignment\n <mask> \n <mask>     def align(self, other, join='outer', axis=None, level=None, copy=True):\n <mask>         \"\"\"\n <mask>         Align two DataFrame object on their index and columns with the\n <mask>         specified join method for each axis Index\n <mask> \n <mask>         Parameters </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             Align on index (0), columns (1), or both (None)\n <mask>         level : int or name\n <mask>             Broadcast across a level, matching Index values on the\n <mask>             passed MultiIndex level\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         (left, right) : (DataFrame, type of other)\n <mask>             Aligned objects </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True): </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None): </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns)) </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all())", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         else:  # pragma: no cover\n <mask>             raise TypeError('unsupported type: %s' % type(other))\n <mask> \n <mask>     def _align_frame(self, other, join='outer', axis=None, level=None,\n <mask>                      copy=True):\n <mask>         # defaults\n <mask>         join_index, join_columns = None, None\n <mask>         ilidx, iridx = None, None\n <mask>         clidx, cridx = None, None\n <mask>  </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns)) </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True): </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         left = self._reindex_with_indexers(join_index, ilidx,\n <mask>                                            join_columns, clidx, copy)\n <mask>         right = other._reindex_with_indexers(join_index, iridx,\n <mask>                                              join_columns, cridx, copy)\n <mask>         return left, right\n <mask> \n <mask>     def _align_series(self, other, join='outer', axis=None, level=None,\n <mask>                       copy=True):\n <mask>         fdata = self._data\n <mask>         if axis == 0:\n <mask>             join_index = self.index\n <mask>             lidx, ridx = None, None </s> remove                      copy=True): </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns)) </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             fdata = fdata.copy()\n <mask> \n <mask>         left_result = DataFrame(fdata)\n <mask>         right_result = other if ridx is None else other.reindex(join_index)\n <mask>         return left_result, right_result\n <mask> \n <mask>     def reindex(self, index=None, columns=None, method=None, level=None,\n <mask>                 copy=True):\n <mask>         \"\"\"Conform DataFrame to new index with optional filling logic, placing\n <mask>         NA/NaN in locations having no value in the previous index. A new object </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True): </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns)) </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         except Exception:\n <mask>             mapped = lib.map_infer(self.values, func)\n <mask>             return Series(mapped, index=self.index, name=self.name)\n <mask> \n <mask>     def align(self, other, join='outer', level=None, copy=True):\n <mask>         \"\"\"\n <mask>         Align two Series object with the specified join method\n <mask> \n <mask>         Parameters\n <mask>         ---------- </s> remove     def align(self, other, join='outer', axis=None, level=None, copy=True): </s> add     def align(self, other, join='outer', axis=None, level=None, copy=True,\n              fill_value=None): </s> remove                       copy=True): </s> remove                      copy=True):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             Always return new objects. If copy=False and no reindexing is\n <mask>             required, the same object will be returned (for better performance)\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         (left, right) : (Series, Series)\n <mask>             Aligned Series </s> Added fill_value argument to Series/DataFrame.align </s> add         copy : boolean, default True\n            Always returns new objects. If copy=False and no reindexing is\n            required then original objects are returned.\n        fill_value : object, default None\n            Fills na's if not None </s> remove         return left, right </s> remove         return left, right", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                                                  return_indexers=True)\n <mask> \n <mask>         left = self._reindex_indexer(join_index, lidx, copy)\n <mask>         right = other._reindex_indexer(join_index, ridx, copy)\n <mask>         return left, right\n <mask> \n <mask>     def _reindex_indexer(self, new_index, indexer, copy):\n <mask>         if indexer is not None:\n <mask>             new_values = com.take_1d(self.values, indexer)\n <mask>         else: </s> remove         return left, right </s> remove                       copy=True): </s> remove                      copy=True): </s> remove         af, bf = self.frame.align(other, axis=0)\n        self.assert_(bf.columns.equals(other.columns)) </s> add         af, bf = self.frame.align(other, axis=0, fill_value=-1)\n        self.assert_(bf.columns.equals(other.columns))        \n        #test fill value\n        join_idx = self.frame.index.join(other.index)\n        diff_a = self.frame.index.diff(join_idx)\n        diff_b = other.index.diff(join_idx)\n        diff_a_vals = af.reindex(diff_a).values\n        diff_b_vals = bf.reindex(diff_b).values\n        self.assert_((diff_a_vals == -1).all()) </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/core/series.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         self.assert_(af._data is self.frame._data)\n <mask> \n <mask>         # axis = 0\n <mask>         other = self.frame.ix[:-5, :3]\n <mask>         af, bf = self.frame.align(other, axis=0)\n <mask>         self.assert_(bf.columns.equals(other.columns))\n <mask> \n <mask>         af, bf = self.frame.align(other, join='right', axis=0)\n <mask>         self.assert_(bf.columns.equals(other.columns))\n <mask>         self.assert_(bf.index.equals(other.index))\n <mask>         self.assert_(af.index.equals(other.index)) </s> remove                      copy=True): </s> remove                       copy=True): </s> remove     def align(self, other, join='outer', level=None, copy=True): </s> add     def align(self, other, join='outer', level=None, copy=True,\n              fill_value=None):", "html_url": "https://github.com/pandas-dev/pandas/commit/0430ff75e9fe25518771a3ddda4062f3c62c9743", "file_name": "pandas/tests/test_frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             try:\n <mask>                 result = libreduction.compute_reduction(\n <mask>                     values, self.f, axis=self.axis, dummy=dummy, labels=labels\n <mask>                 )\n <mask>                 return self.obj._constructor_sliced(result, index=labels)\n <mask>             except Exception:\n <mask>                 pass\n <mask> \n <mask>         # compute the result using the series generator\n <mask>         self.apply_series_generator()\n <mask> \n </s> BUG: Fix TypeError raised in libreduction (#28643) </s> add             else:\n                return self.obj._constructor_sliced(result, index=labels) </s> remove     msg = (\n        r'\\(\"unsupported operand type\\(s\\) for \\+: '\n        \"'Timestamp' and 'float'\\\"\"\n        r\", 'occurred at index 0'\\)\"\n    )\n </s> add     msg = r'\\(\"unsupported operand type\\(s\\) for \\+: ' \"'Timestamp' and 'float'\\\", 0\"", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/core/apply.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                     raise\n <mask>             except ZeroDivisionError:\n <mask>                 # reached via numexpr; fall back to python implementation\n <mask>                 pass\n <mask> \n <mask>         # compute the result using the series generator\n <mask>         self.apply_series_generator()\n <mask> \n <mask>         # wrap results </s> add             except ValueError as err:\n                if \"Function does not reduce\" not in str(err):\n                    # catch only ValueError raised intentionally in libreduction\n                    raise\n            except TypeError:\n                # e.g. test_apply_ignore_failures we just ignore\n                if not self.ignore_failures:\n                    raise\n            except ZeroDivisionError:\n                # reached via numexpr; fall back to python implementation", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/core/apply.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     assert_frame_equal(result, expected)\n <mask> \n <mask>     # won't work with axis = 1\n <mask>     grouped = df.groupby({\"A\": 0, \"C\": 0, \"D\": 1, \"E\": 1}, axis=1)\n <mask>     msg = (\n <mask>         r'\\(\"unsupported operand type\\(s\\) for \\+: '\n <mask>         \"'Timestamp' and 'float'\\\"\"\n <mask>         r\", 'occurred at index 0'\\)\"\n <mask>     )\n <mask>     with pytest.raises(TypeError, match=msg):\n <mask>         grouped.agg(lambda x: x.sum(0, numeric_only=False))\n <mask> \n <mask> \n <mask> def test_omit_nuisance_python_multiple(three_group):\n </s> BUG: Fix TypeError raised in libreduction (#28643) </s> remove                 return self.obj._constructor_sliced(result, index=labels)\n            except Exception:\n </s> add             except ValueError as err:\n                if \"Function does not reduce\" not in str(err):\n                    # catch only ValueError raised intentionally in libreduction\n                    raise\n            except TypeError:\n                # e.g. test_apply_ignore_failures we just ignore\n                if not self.ignore_failures:\n                    raise\n            except ZeroDivisionError:\n                # reached via numexpr; fall back to python implementation </s> add             else:\n                return self.obj._constructor_sliced(result, index=labels)", "html_url": "https://github.com/pandas-dev/pandas/commit/0436570f05c3b6e7bbb7c7d8fc8fa2f28a0420a8", "file_name": "pandas/tests/groupby/test_groupby.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     sum_x,\n <mask>                     neg_ct,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask>         else:\n <mask>             for j in range(start[i - 1], s):\n <mask>                 val = values[j]\n <mask>                 nobs, sum_x, neg_ct, compensation_remove = remove_mean( </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/mean_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     sum_x,\n <mask>                     neg_ct,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask> \n <mask>         if nobs >= min_periods and nobs > 0:\n <mask>             result = sum_x / nobs\n <mask>             if num_consecutive_same_value >= nobs: </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/mean_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     mean_x,\n <mask>                     ssqdm_x,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask>         else:\n <mask>             for j in range(start[i - 1], s):\n <mask>                 val = values[j]\n <mask>                 nobs, mean_x, ssqdm_x, compensation_remove = remove_var( </s> remove                     prev_value, </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value, </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> remove                     prev_value, </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/var_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     mean_x,\n <mask>                     ssqdm_x,\n <mask>                     compensation_add,\n <mask>                     num_consecutive_same_value,\n <mask>                     prev_value,\n <mask>                 )\n <mask> \n <mask>         if nobs >= min_periods and nobs > ddof:\n <mask>             if nobs == 1 or num_consecutive_same_value >= nobs:\n <mask>                 result = 0.0 </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues] </s> add                     prev_value,  # pyright: ignore[reportGeneralTypeIssues]", "html_url": "https://github.com/pandas-dev/pandas/commit/047da251c83c513617e437fec82133fbf690cb77", "file_name": "pandas/core/_numba/kernels/var_.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # ----------------------------------------------------------------\n <mask> # Common arguments\n <mask> # ----------------------------------------------------------------\n <mask> @pytest.fixture(params=[0, 1, \"index\", \"columns\"], ids=lambda x: f\"axis {repr(x)}\")\n <mask> def axis(request):\n <mask>     \"\"\"\n <mask>     Fixture for returning the axis numbers of a DataFrame.\n <mask>     \"\"\"\n <mask>     return request.param </s> remove         new_mgr = mgr.apply(hfunc, ignore_failures=True) </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/conftest.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> from pandas.core.indexes.api import (\n <mask>     Index,\n <mask>     MultiIndex,\n <mask> )\n <mask> from pandas.core.reshape.concat import concat\n <mask> from pandas.core.util.numba_ import (\n <mask>     NUMBA_FUNC_CACHE,\n <mask>     maybe_use_numba,\n <mask> ) </s> add         def hfunc2d(values: ArrayLike) -> ArrayLike:\n            values = self._prep_values(values)\n            return homogeneous_func(values)\n\n        if isinstance(mgr, ArrayManager) and self.axis == 1:\n            new_mgr = mgr.apply_2d(hfunc2d, ignore_failures=True)\n        else:\n            new_mgr = mgr.apply(hfunc, ignore_failures=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             values = self._prep_values(getattr(bvalues, \"T\", bvalues))\n <mask>             res_values = homogeneous_func(values)\n <mask>             return getattr(res_values, \"T\", res_values)\n <mask> \n <mask>         new_mgr = mgr.apply(hfunc, ignore_failures=True)\n <mask>         out = obj._constructor(new_mgr)\n <mask> \n <mask>         if out.shape[1] == 0 and obj.shape[1] > 0:\n <mask>             raise DataError(\"No numeric types to aggregate\")\n <mask>         elif out.shape[1] == 0: </s> add from pandas.core.internals import ArrayManager", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/core/window/rolling.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     tm.assert_frame_equal(result, expected)\n <mask> \n <mask> \n <mask> def test_rolling_window_as_string():\n <mask>     # see gh-22590\n <mask>     date_today = datetime.now()\n <mask>     days = date_range(date_today, date_today + timedelta(365), freq=\"D\")\n <mask> \n <mask>     npr = np.random.RandomState(seed=421) </s> remove     expected = Series(\n        expData, index=days.rename(\"DateCol\")._with_freq(None), name=\"metric\"\n    ) </s> add     index = days.rename(\"DateCol\")\n    if not using_array_manager:\n        # INFO(ArrayManager) preserves the frequence of the index\n        index = index._with_freq(None)\n    expected = Series(expData, index=index, name=\"metric\")", "html_url": "https://github.com/pandas-dev/pandas/commit/04a0b86a9f7b80d91a8cf5f09953459096b2137e", "file_name": "pandas/tests/window/test_rolling.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace keep keep", "code_tokens": " <mask>    s3\n <mask>    s3.str.replace(\"^.a|dog\", \"XX-XX \", case=False, regex=True)\n <mask> \n <mask> .. warning::\n <mask> \n <mask>     Some caution must be taken when dealing with regular expressions! The current behavior\n <mask>     is to treat single character patterns as literal strings, even when ``regex`` is set\n <mask>     to ``True``. This behavior is deprecated and will be removed in a future version so\n <mask>     that the ``regex`` keyword is always respected.\n <mask> \n <mask> .. versionchanged:: 1.2.0 </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None]) </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "doc/source/user_guide/text.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     is to treat single character patterns as literal strings, even when ``regex`` is set\n <mask>     to ``True``. This behavior is deprecated and will be removed in a future version so\n <mask>     that the ``regex`` keyword is always respected.\n <mask> \n <mask> .. versionchanged:: 1.2.0\n <mask> \n <mask> If you want literal replacement of a string (equivalent to :meth:`str.replace`), you\n <mask> can set the optional ``regex`` parameter to ``False``, rather than escaping each\n <mask> character. In this case both ``pat`` and ``repl`` must be strings:\n <mask>  </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected. </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None]) </s> add @pytest.mark.parametrize(\"regex\", [True, False])", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "doc/source/user_guide/text.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         repl: str | Callable,\n <mask>         n: int = -1,\n <mask>         case: bool | None = None,\n <mask>         flags: int = 0,\n <mask>         regex: bool | None = None,\n <mask>     ):\n <mask>         r\"\"\"\n <mask>         Replace each occurrence of pattern/regex in the Series/Index.\n <mask> \n <mask>         Equivalent to :meth:`str.replace` or :func:`re.sub`, depending on </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove         result = ser.str.replace(pat, repl, n=2) </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype) </s> add         expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         flags : int, default 0 (no flags)\n <mask>             Regex module flags, e.g. re.IGNORECASE. Cannot be set if `pat` is a compiled\n <mask>             regex.\n <mask>         regex : bool, default True\n <mask>             Determines if the passed-in pattern is a regular expression:\n <mask> \n <mask>             - If True, assumes the passed-in pattern is a regular expression.\n <mask>             - If False, treats the pattern as a literal string\n <mask>             - Cannot be set to False if `pat` is a compiled regex or `repl` is </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected. </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level()) </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             - If False, treats the pattern as a literal string\n <mask>             - Cannot be set to False if `pat` is a compiled regex or `repl` is\n <mask>               a callable.\n <mask> \n <mask>             .. versionadded:: 0.23.0\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         Series or Index of object\n <mask>             A copy of the object with all matching occurrences of `pat` replaced by\n <mask>             `repl`. </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         regex : bool, default True </s> add         regex : bool, default False </s> add - Change the default argument of ``regex`` for :meth:`Series.str.replace` from ``True`` to ``False``. Additionally, a single character ``pat`` with ``regex=True`` is now treated as a regular expression instead of a string literal. (:issue:`36695`, :issue:`24804`) </s> remove     Some caution must be taken when dealing with regular expressions! The current behavior\n    is to treat single character patterns as literal strings, even when ``regex`` is set\n    to ``True``. This behavior is deprecated and will be removed in a future version so\n    that the ``regex`` keyword is always respected. </s> add .. versionchanged:: 2.0\n\nSingle character pattern with ``regex=True`` will also be treated as regular expressions:\n\n.. ipython:: python </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level()) </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         1    bar\n <mask>         2    NaN\n <mask>         dtype: object\n <mask>         \"\"\"\n <mask>         if regex is None:\n <mask>             if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n <mask>                 # warn only in cases where regex behavior would differ from literal\n <mask>                 msg = (\n <mask>                     \"The default value of regex will change from True to False \"\n <mask>                     \"in a future version.\"\n <mask>                 )\n <mask>                 if len(pat) == 1:\n <mask>                     msg += (\n <mask>                         \" In addition, single character regular expressions will \"\n <mask>                         \"*not* be treated as literal strings when regex=True.\"\n <mask>                     )\n <mask>                 warnings.warn(msg, FutureWarning, stacklevel=find_stack_level())\n <mask> \n <mask>         # Check whether repl is valid (GH 13438, GH 15055)\n <mask>         if not (isinstance(repl, str) or callable(repl)):\n <mask>             raise TypeError(\"repl must be a string or callable\")\n <mask> \n <mask>         is_compiled_re = is_re(pat) </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype): </s> add def test_replace_regex(any_string_dtype): </s> remove         regex : bool, default True </s> add         regex : bool, default False", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             )\n <mask>         elif callable(repl):\n <mask>             raise ValueError(\"Cannot use a callable replacement when regex=False\")\n <mask> \n <mask>         # The current behavior is to treat single character patterns as literal strings,\n <mask>         # even when ``regex`` is set to ``True``.\n <mask>         if isinstance(pat, str) and len(pat) == 1:\n <mask>             regex = False\n <mask> \n <mask>         if regex is None:\n <mask>             regex = True\n <mask> \n <mask>         if case is None:\n <mask>             case = True\n <mask> \n <mask>         result = self._data.array._str_replace(\n <mask>             pat, repl, n=n, case=case, flags=flags, regex=regex </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level()) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None]) </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> add    s4 = pd.Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=\"string\")\n   s4\n   s4.str.replace(\".\", \"a\", regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/core/strings/accessor.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     pat = re.compile(r\"(?<=\\w),(?=\\w)\", flags=re.UNICODE)\n <mask>     with tm.maybe_produces_warning(\n <mask>         PerformanceWarning, any_string_dtype == \"string[pyarrow]\"\n <mask>     ):\n <mask>         result = ser.str.replace(pat, \", \")\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> def test_replace_compiled_regex_raises(any_string_dtype):\n <mask>     # case and flags provided to str.replace will have no effect </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     msg = \"case and flags cannot be set when pat is a compiled regex\"\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", flags=re.IGNORECASE)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=True)\n <mask>  </s> remove         ser.str.replace(pat, \"\", case=True) </s> add         ser.str.replace(pat, \"\", case=True, regex=True) </s> remove         result = ser.str.replace(pat, \", \") </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove         result = ser.str.replace(pat, repl, n=2) </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove             values.str.replace(\"a\", repl) </s> add             values.str.replace(\"a\", repl, regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=False)\n <mask> \n <mask>     with pytest.raises(ValueError, match=msg):\n <mask>         ser.str.replace(pat, \"\", case=True)\n <mask> \n <mask> \n <mask> def test_replace_compiled_regex_callable(any_string_dtype):\n <mask>     # test with callable\n <mask>     ser = Series([\"fooBAD__barBAD\", np.nan], dtype=any_string_dtype) </s> remove         ser.str.replace(pat, \"\", case=False) </s> add         ser.str.replace(pat, \"\", case=False, regex=True) </s> remove         ser.str.replace(pat, \"\", flags=re.IGNORECASE) </s> add         ser.str.replace(pat, \"\", flags=re.IGNORECASE, regex=True) </s> remove             values.str.replace(\"a\", repl) </s> remove         result = ser.str.replace(pat, repl, n=2) </s> add         result = ser.str.replace(pat, repl, n=2, regex=True) </s> remove         result = ser.str.replace(pat, \", \") </s> add         result = ser.str.replace(pat, \", \", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype): </s> add def test_replace_regex(any_string_dtype):", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     pat = re.compile(\"[a-z][A-Z]{2}\")\n <mask>     with tm.maybe_produces_warning(\n <mask>         PerformanceWarning, any_string_dtype == \"string[pyarrow]\"\n <mask>     ):\n <mask>         result = ser.str.replace(pat, repl, n=2)\n <mask>     expected = Series([\"foObaD__baRbaD\", np.nan], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize( </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\")", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep replace keep keep replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask> \n <mask> def test_replace_regex_default_warning(any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask>     s = Series([\"a\", \"b\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     msg = (\n <mask>         \"The default value of regex will change from True to False in a \"\n <mask>         \"future version\\\\.$\"\n <mask>     )\n <mask> \n <mask>     with tm.assert_produces_warning(\n <mask>         FutureWarning,\n <mask>         match=msg,\n <mask>         raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n <mask>     ):\n <mask>         result = s.str.replace(\"^.$\", \"a\")\n <mask>     expected = Series([\"a\", \"a\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected) </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> remove         result = s.str.replace(\".\", \"a\", regex=regex)\n\n    expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype) </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> add     # https://github.com/pandas-dev/pandas/pull/24809, enforced in 2.0\n    # GH 24804", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     expected = Series([\"a\", \"a\", \"ac\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\"regex\", [True, False, None])\n <mask> def test_replace_regex_single_character(regex, any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask> \n <mask>     # The current behavior is to treat single character patterns as literal strings,\n <mask>     # even when ``regex`` is set to ``True``. </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove     # https://github.com/pandas-dev/pandas/pull/24809\n\n    # The current behavior is to treat single character patterns as literal strings,\n    # even when ``regex`` is set to ``True``. </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove def test_replace_regex_default_warning(any_string_dtype): </s> add def test_replace_regex(any_string_dtype): </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace keep keep replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> @pytest.mark.parametrize(\"regex\", [True, False, None])\n <mask> def test_replace_regex_single_character(regex, any_string_dtype):\n <mask>     # https://github.com/pandas-dev/pandas/pull/24809\n <mask> \n <mask>     # The current behavior is to treat single character patterns as literal strings,\n <mask>     # even when ``regex`` is set to ``True``.\n <mask> \n <mask>     s = Series([\"a.b\", \".\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n <mask> \n <mask>     if regex is None:\n <mask>         msg = re.escape(\n <mask>             \"The default value of regex will change from True to False in a future \"\n <mask>             \"version. In addition, single character regular expressions will *not* \"\n <mask>             \"be treated as literal strings when regex=True.\"\n <mask>         )\n <mask>         with tm.assert_produces_warning(\n <mask>             FutureWarning,\n <mask>             match=msg,\n <mask>         ):\n <mask>             result = s.str.replace(\".\", \"a\", regex=regex) </s> DEPR: Change str.replace(regex) from True to False & single behavior (#49486)\n\n* DEPR: Change str.replace(regex) from True to False & single behavior\r\n\r\n* Add versionnchanged </s> remove @pytest.mark.parametrize(\"regex\", [True, False, None]) </s> add @pytest.mark.parametrize(\"regex\", [True, False]) </s> remove     msg = (\n        \"The default value of regex will change from True to False in a \"\n        \"future version\\\\.$\"\n    )\n\n    with tm.assert_produces_warning(\n        FutureWarning,\n        match=msg,\n        raise_on_extra_warnings=any_string_dtype != \"string[pyarrow]\",\n    ):\n        result = s.str.replace(\"^.$\", \"a\") </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True) </s> remove         if regex is None:\n            if isinstance(pat, str) and any(c in pat for c in \".+*|^$?[](){}\\\\\"):\n                # warn only in cases where regex behavior would differ from literal\n                msg = (\n                    \"The default value of regex will change from True to False \"\n                    \"in a future version.\"\n                )\n                if len(pat) == 1:\n                    msg += (\n                        \" In addition, single character regular expressions will \"\n                        \"*not* be treated as literal strings when regex=True.\"\n                    )\n                warnings.warn(msg, FutureWarning, stacklevel=find_stack_level()) </s> remove         # The current behavior is to treat single character patterns as literal strings,\n        # even when ``regex`` is set to ``True``.\n        if isinstance(pat, str) and len(pat) == 1:\n            regex = False\n\n        if regex is None:\n            regex = True </s> remove def test_replace_regex_default_warning(any_string_dtype): </s> add def test_replace_regex(any_string_dtype):", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             match=msg,\n <mask>         ):\n <mask>             result = s.str.replace(\".\", \"a\", regex=regex)\n <mask>     else:\n <mask>         result = s.str.replace(\".\", \"a\", regex=regex)\n <mask> \n <mask>     expected = Series([\"aab\", \"a\", \"b\", np.nan, \"\"], dtype=any_string_dtype)\n <mask>     tm.assert_series_equal(result, expected)\n <mask> \n <mask> \n <mask> # --------------------------------------------------------------------------------------\n <mask> # str.match </s> remove     if regex is None:\n        msg = re.escape(\n            \"The default value of regex will change from True to False in a future \"\n            \"version. In addition, single character regular expressions will *not* \"\n            \"be treated as literal strings when regex=True.\"\n        )\n        with tm.assert_produces_warning(\n            FutureWarning,\n            match=msg,\n        ):\n            result = s.str.replace(\".\", \"a\", regex=regex) </s> add     result = s.str.replace(\".\", \"a\", regex=regex)\n    if regex:\n        expected = Series([\"aaa\", \"a\", \"a\", np.nan, \"\"], dtype=any_string_dtype) </s> add     result = s.str.replace(\"^.$\", \"a\", regex=True)", "html_url": "https://github.com/pandas-dev/pandas/commit/050a1a2e22bf383a3acef9dbbb5a0c3dbc6948b0", "file_name": "pandas/tests/strings/test_find_replace.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     #----------------------------------------------------------------------\n <mask>     # Plotting\n <mask> \n <mask>     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n <mask>              figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds):\n <mask>         \"\"\"\n <mask>         Make line plot of DataFrame's series with the index on the x-axis using\n <mask>         matplotlib / pylab.\n <mask> \n <mask>         Parameters </s> remove         plt.draw_if_interactive() </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best') </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize) </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         sharey : boolean, default False\n <mask>             In case subplots=True, share y axis\n <mask>         use_index : boolean, default True\n <mask>             Use index as ticks for x axis\n <mask>         kwds : keywords\n <mask>             Options to pass to Axis.plot\n <mask> \n <mask>         Notes\n <mask>         -----\n <mask>         This method doesn't make much sense for cross-sections, </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize) </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds): </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 fig = plt.figure(figsize=figsize)\n <mask>                 ax = fig.add_subplot(111)\n <mask>             else:\n <mask>                 fig = ax.get_figure()\n <mask> \n <mask>         if kind == 'line':\n <mask>             if use_index:\n <mask>                 x = self.index </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col) </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize) </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best') </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep replace replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     ax.plot(x, y, label=str(col), **kwds)\n <mask> \n <mask>                 ax.grid(grid)\n <mask>         elif kind == 'bar':\n <mask>             N = len(self)\n <mask>             M = len(self.columns)\n <mask>             xinds = np.arange(N) + 0.25\n <mask>             colors = ['red', 'green', 'blue', 'yellow', 'black']\n <mask>             rects = []\n <mask>             labels = []\n <mask>             for i, col in enumerate(_try_sort(self.columns)):\n <mask>                 empty = self[col].count() == 0\n <mask>                 y = self[col].values if not empty else np.zeros(x.shape)\n <mask>                 if subplots:\n <mask>                     ax = axes[i]\n <mask>                     ax.bar(xinds, y, 0.5,\n <mask>                            bottom=np.zeros(N), linewidth=1, **kwds)\n <mask>                     ax.set_title(col)\n <mask>                 else:\n <mask>                     rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n <mask>                     labels.append(col)\n <mask> \n <mask>             if N < 10:\n <mask>                 fontsize = 12\n <mask>             else:\n <mask>                 fontsize = 10\n <mask> \n <mask>             ax.set_xticks(xinds + 0.25)\n <mask>             ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n <mask> \n <mask>         # try to make things prettier\n <mask>         try: </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         plt.draw_if_interactive() </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> add                 axes = [ax] </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best') </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep replace replace replace keep replace", "code_tokens": " <mask>             pass\n <mask> \n <mask>         if legend and not subplots:\n <mask>             if kind == 'line':\n <mask>                 ax.legend(loc='best')\n <mask>             else:\n <mask>                 ax.legend([r[0] for r in rects],labels,loc='best') </s> remove         plt.draw_if_interactive() </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize) </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add                 axes = [ax] </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col)", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 ax.legend(loc='best')\n <mask>             else:\n <mask>                 ax.legend([r[0] for r in rects],labels,loc='best')\n <mask> \n <mask>         plt.draw_if_interactive()\n <mask> \n <mask>     def hist(self, grid=True, **kwds):\n <mask>         \"\"\"\n <mask>         Draw Histogram the DataFrame's series using matplotlib / pylab.\n <mask>  </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds): </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best') </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col) </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> remove         elif kind == 'bar':\n            N = len(self)\n            M = len(self.columns)\n            xinds = np.arange(N) + 0.25\n            colors = ['red', 'green', 'blue', 'yellow', 'black']\n            rects = []\n            labels = []\n            for i, col in enumerate(_try_sort(self.columns)):\n                empty = self[col].count() == 0\n                y = self[col].values if not empty else np.zeros(x.shape)\n                if subplots:\n                    ax = axes[i]\n                    ax.bar(xinds, y, 0.5,\n                           bottom=np.zeros(N), linewidth=1, **kwds)\n                    ax.set_title(col)\n                else:\n                    rects.append(ax.bar(xinds+i*0.5/M,y,0.5/M,bottom=np.zeros(N),color=colors[i % len(colors)], **kwds))\n                    labels.append(col) </s> remove             if N < 10:\n                fontsize = 12\n            else:\n                fontsize = 10\n\n            ax.set_xticks(xinds + 0.25)\n            ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize) </s> add             if legend and not subplots:\n                ax.legend(loc='best')\n        elif kind == 'bar':\n            self._bar_plot(axes, subplots=subplots, grid=grid, rot=rot,\n                           legend=legend) </s> add     def test_plot_bar(self):\n        df = DataFrame(np.random.randn(6, 4),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=['one', 'two', 'three', 'four'])\n\n        _check_plot_works(df.plot, kind='bar')\n        _check_plot_works(df.plot, kind='bar', legend=False)\n        _check_plot_works(df.plot, kind='bar', subplots=True)\n\n        df = DataFrame(np.random.randn(6, 15),\n                       index=['a', 'b', 'c', 'd', 'e', 'f'],\n                       columns=range(15))\n        _check_plot_works(df.plot, kind='bar')", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         _check_plot_works(df.plot, subplots=True)\n <mask>         _check_plot_works(df.plot, subplots=True, use_index=False)\n <mask> \n <mask>     def test_hist(self):\n <mask>         df = DataFrame(np.random.randn(100, 4))\n <mask>         _check_plot_works(df.hist)\n <mask>         _check_plot_works(df.hist, grid=False)\n <mask> \n <mask>     def test_plot_int_columns(self): </s> remove         if legend and not subplots:\n            if kind == 'line':\n                ax.legend(loc='best') </s> add         plt.draw_if_interactive()\n\n    def _bar_plot(self, axes, subplots=False, use_index=True, grid=True,\n                  rot=30, legend=True, **kwds):\n        N, K = self.shape\n        xinds = np.arange(N) + 0.25\n        colors = 'rgbyk'\n        rects = []\n        labels = []\n\n        if not subplots:\n            ax = axes[0]\n\n        for i, col in enumerate(_try_sort(self.columns)):\n            empty = self[col].count() == 0\n            y = self[col].values if not empty else np.zeros(len(self))\n            if subplots:\n                ax = axes[i]\n                ax.bar(xinds, y, 0.5,\n                       bottom=np.zeros(N), linewidth=1, **kwds)\n                ax.set_title(col) </s> add         if N < 10:\n            fontsize = 12\n        else:\n            fontsize = 10\n\n        ax.set_xticks(xinds + 0.25)\n        ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)\n\n        if legend and not subplots:\n            fig = ax.get_figure()\n            fig.legend([r[0] for r in rects], labels, loc='upper center',\n                       fancybox=True, ncol=6, mode='expand')\n\n        import matplotlib.pyplot as plt\n        plt.subplots_adjust(top=0.8) </s> remove     def plot(self, kind='line', subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None, **kwds): </s> add     def plot(self, subplots=False, sharex=True, sharey=False, use_index=True,\n             figsize=None, grid=True, legend=True, rot=30, ax=None,\n             kind='line', **kwds): </s> remove                 ax.legend([r[0] for r in rects],labels,loc='best') </s> add                 rects.append(ax.bar(xinds + i * 0.5/K, y, 0.5/K,\n                                    bottom=np.zeros(N),\n                                    color=colors[i % len(colors)], **kwds))\n                labels.append(col)", "html_url": "https://github.com/pandas-dev/pandas/commit/0518b54bfc2bf6ae4a657183b65c714f4187609c", "file_name": "pandas/tests/test_graphics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     @property  # NB: override with cache_readonly in immutable subclasses\n <mask>     def hasnans(self):\n <mask>         \"\"\" return if I have any nans; enables various perf speedups \"\"\"\n <mask>         return self._isnan.any()\n <mask> \n <mask>     def _maybe_mask_results(self, result, fill_value=None, convert=None):\n <mask>         \"\"\"\n <mask>         Parameters\n <mask>         ---------- </s> remove             return self._isnan.any() </s> add             return bool(self._isnan.any()) </s> add         return bool(isna(self).any()) </s> add - :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`).", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/core/arrays/datetimelike.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @cache_readonly\n <mask>     def hasnans(self):\n <mask>         \"\"\" return if I have any nans; enables various perf speedups \"\"\"\n <mask>         if self._can_hold_na:\n <mask>             return self._isnan.any()\n <mask>         else:\n <mask>             return False\n <mask> \n <mask>     def isna(self):\n <mask>         \"\"\" </s> remove         return self._isnan.any() </s> add         return bool(self._isnan.any()) </s> remove         return isna(self).any() </s> add         return bool(isna(self).any()) </s> add - :meth:`Index.hasnans` and :meth:`Series.hasnans` now always return a python boolean. Previously, a python or a numpy boolean could be returned, depending on circumstances (:issue:`23294`).", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/core/indexes/base.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # We test against `idx_unique`, so first we make sure it's unique\n <mask>         # and doesn't contain nans.\n <mask>         assert idx_unique.is_unique is True\n <mask>         try:\n <mask>             assert not idx_unique.hasnans\n <mask>         except NotImplementedError:\n <mask>             pass\n <mask> \n <mask>         for dropna in [False, True]:\n <mask>             result = idx._get_unique_index(dropna=dropna) </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove         assert not index.hasnans </s> add         assert index.hasnans is False </s> remove         assert index.hasnans </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 # cases in indices doesn't include NaN\n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert not idx.hasnans\n <mask> \n <mask>                 idx = index.copy()\n <mask>                 values = np.asarray(idx.values)\n <mask> \n <mask>                 if len(index) == 0: </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans </s> add     assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 expected[1] = True\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert idx.hasnans\n <mask> \n <mask>     def test_fillna(self):\n <mask>         # GH 11343\n <mask>         for name, index in self.indices.items():\n <mask>             if len(index) == 0: </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove         assert index.hasnans </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 expected = np.array([False] * len(idx), dtype=bool)\n <mask>                 expected[1] = True\n <mask>                 tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>                 assert idx.hasnans\n <mask> \n <mask>     def test_nulls(self):\n <mask>         # this is really a smoke test for the methods\n <mask>         # as these are adequately tested for function elsewhere\n <mask>  </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove             assert not idx_unique.hasnans </s> add             assert idx_unique.hasnans is False </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/common.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.DatetimeIndex(['2011-01-01', '2011-01-02'], tz=tz)\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.DatetimeIndex(['2011-01-01', 'NaT'], tz=tz)\n <mask>         assert idx._can_hold_na </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/datetimes/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.DatetimeIndex(['2011-01-01', 'NaT'], tz=tz)\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     def test_equals(self):\n <mask>         # GH 13107 </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/datetimes/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         tm.assert_index_equal(result, expected)\n <mask> \n <mask>     def test_with_nans(self, closed):\n <mask>         index = self.create_index(closed=closed)\n <mask>         assert not index.hasnans\n <mask> \n <mask>         result = index.isna()\n <mask>         expected = np.repeat(False, len(index))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask>  </s> remove         assert index.hasnans </s> add         assert index.hasnans is True </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/interval/test_interval.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         expected = np.repeat(True, len(index))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask> \n <mask>         index = self.create_index_with_nan(closed=closed)\n <mask>         assert index.hasnans\n <mask> \n <mask>         result = index.isna()\n <mask>         expected = np.array([False, True] + [False] * (len(index) - 2))\n <mask>         tm.assert_numpy_array_equal(result, expected)\n <mask>  </s> remove         assert not index.hasnans </s> add         assert index.hasnans is False </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/interval/test_interval.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>             expected = np.array([False] * len(idx), dtype=bool)\n <mask>             expected[1] = True\n <mask>             tm.assert_numpy_array_equal(idx._isnan, expected)\n <mask>             assert idx.hasnans\n <mask> \n <mask> \n <mask> def test_dropna():\n <mask>     # GH 6194\n <mask>     idx = pd.MultiIndex.from_arrays([[1, np.nan, 3, np.nan, 5], </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove         assert index.hasnans </s> add         assert index.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     # cases in indices doesn't include NaN\n <mask>     expected = np.array([False] * len(index), dtype=bool)\n <mask>     tm.assert_numpy_array_equal(index._isnan, expected)\n <mask>     assert not index.hasnans\n <mask> \n <mask>     index = idx.copy()\n <mask>     values = index.values\n <mask>     values[1] = np.nan\n <mask>  </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove     assert index.hasnans </s> add     assert index.hasnans is True </s> remove         assert index.hasnans </s> add         assert index.hasnans is True </s> remove         assert not index.hasnans </s> add         assert index.hasnans is False </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     expected = np.array([False] * len(index), dtype=bool)\n <mask>     expected[1] = True\n <mask>     tm.assert_numpy_array_equal(index._isnan, expected)\n <mask>     assert index.hasnans\n <mask> \n <mask> \n <mask> def test_nan_stays_float():\n <mask> \n <mask>     # GH 7031 </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove         assert index.hasnans </s> add         assert index.hasnans is True </s> remove         assert not index.hasnans </s> add         assert index.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/multi/test_missing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.PeriodIndex(['2011-01-01', '2011-01-02'], freq='D')\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.PeriodIndex(['2011-01-01', 'NaT'], freq='D')\n <mask>         assert idx._can_hold_na </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/period/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.PeriodIndex(['2011-01-01', 'NaT'], freq='D')\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     @pytest.mark.parametrize('freq', ['D', 'M'])\n <mask>     def test_equals(self, freq): </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove     assert not idx.hasnans </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/period/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.TimedeltaIndex(['1 days', '2 days'])\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, False]))\n <mask>         assert not idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([], dtype=np.intp))\n <mask> \n <mask>         idx = pd.TimedeltaIndex(['1 days', 'NaT'])\n <mask>         assert idx._can_hold_na </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove     assert not idx.hasnans </s> add     assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/timedeltas/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         idx = pd.TimedeltaIndex(['1 days', 'NaT'])\n <mask>         assert idx._can_hold_na\n <mask> \n <mask>         tm.assert_numpy_array_equal(idx._isnan, np.array([False, True]))\n <mask>         assert idx.hasnans\n <mask>         tm.assert_numpy_array_equal(idx._nan_idxs,\n <mask>                                     np.array([1], dtype=np.intp))\n <mask> \n <mask>     def test_equals(self):\n <mask>         # GH 13107 </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/indexes/timedeltas/test_ops.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace", "code_tokens": " <mask> \n <mask> def test_hasnans_unchached_for_series():\n <mask>     # GH#19700\n <mask>     idx = pd.Index([0, 1])\n <mask>     assert not idx.hasnans\n <mask>     assert 'hasnans' in idx._cache\n <mask>     ser = idx.to_series()\n <mask>     assert not ser.hasnans </s> remove     assert ser.hasnans </s> add     assert ser.hasnans is True </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove             assert idx.hasnans </s> add             assert idx.hasnans is True </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove         assert idx.hasnans </s> add         assert idx.hasnans is True", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/series/test_internals.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask>     ser = idx.to_series()\n <mask>     assert not ser.hasnans\n <mask>     assert not hasattr(ser, '_cache')\n <mask>     ser.iloc[-1] = np.nan\n <mask>     assert ser.hasnans\n <mask>     assert pd.Series.hasnans.__doc__ == pd.Index.hasnans.__doc__ </s> remove     assert not ser.hasnans </s> add     assert ser.hasnans is False </s> remove     assert not idx.hasnans </s> add     assert idx.hasnans is False </s> remove     assert not index.hasnans </s> add     assert index.hasnans is False </s> remove                 assert not idx.hasnans </s> add                 assert idx.hasnans is False </s> remove                 assert idx.hasnans </s> add                 assert idx.hasnans is True </s> remove         assert not idx.hasnans </s> add         assert idx.hasnans is False", "html_url": "https://github.com/pandas-dev/pandas/commit/051f4a2cf70f25649bae680d290cbf3ed77363ab", "file_name": "pandas/tests/series/test_internals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def time_tz(self, tz, freq):\n <mask>         self.ts.tz\n <mask> \n <mask>     def time_offset(self, tz, freq):\n <mask>         self.ts.offset\n <mask> \n <mask>     def time_dayofweek(self, tz, freq):\n <mask>         self.ts.dayofweek\n <mask> \n <mask>     def time_weekday_name(self, tz, freq):\n <mask>         self.ts.weekday_name </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             nat_series_dtype_timestamp / 1.0 </s> remove             nat_series_dtype_timestamp / 1 </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> add                 assert_series_equal(result, expected)", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "asv_bench/benchmarks/timestamp.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask>     exp = klass([Timestamp('2000-01-31 00:15:00', tz='US/Central'),\n <mask>                  Timestamp('2000-02-29', tz='US/Central')], name='a')\n <mask>     assert_func(result, exp)\n <mask>     assert_func(result2, exp)\n <mask> \n <mask>     # array of offsets - valid for Series only\n <mask>     if klass is Series:\n <mask>         with tm.assert_produces_warning(PerformanceWarning):\n <mask>             s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n <mask>             result = s + Series([pd.offsets.DateOffset(years=1),\n <mask>                                  pd.offsets.MonthEnd()])\n <mask>             exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n <mask>                          ])\n <mask>             assert_func(result, exp)\n <mask> \n <mask>             # same offset\n <mask>             result = s + Series([pd.offsets.DateOffset(years=1),\n <mask>                                  pd.offsets.DateOffset(years=1)])\n <mask>             exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n <mask>             assert_func(result, exp)\n <mask> \n <mask>     s = klass([Timestamp('2000-01-05 00:15:00'),\n <mask>                Timestamp('2000-01-31 00:23:00'),\n <mask>                Timestamp('2000-01-01'),\n <mask>                Timestamp('2000-03-31'),\n <mask>                Timestamp('2000-02-29'),\n <mask>                Timestamp('2000-12-31'),\n <mask>                Timestamp('2000-05-15'),\n <mask>                Timestamp('2001-06-15')])\n <mask> \n <mask>     # DateOffset relativedelta fastpath\n <mask>     relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n <mask>                        ('hours', 5), ('minutes', 10), ('seconds', 2),\n <mask>                        ('microseconds', 5)]\n <mask>     for i, kwd in enumerate(relative_kwargs):\n <mask>         op = pd.DateOffset(**dict([kwd]))\n <mask>         assert_func(klass([x + op for x in s]), s + op)\n <mask>         assert_func(klass([x - op for x in s]), s - op)\n <mask>         op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n <mask>         assert_func(klass([x + op for x in s]), s + op)\n <mask>         assert_func(klass([x - op for x in s]), s - op)\n <mask> \n <mask>     # assert these are equal on a piecewise basis\n <mask>     offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n <mask>                'YearEnd', ('YearEnd', {'month': 5}),\n <mask>                'MonthBegin', 'MonthEnd',\n <mask>                'SemiMonthEnd', 'SemiMonthBegin',\n <mask>                'Week', ('Week', {'weekday': 3}),\n <mask>                'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n <mask>                'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n <mask>                'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n <mask>                'BusinessHour', 'BYearBegin', 'BYearEnd',\n <mask>                'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n <mask>                ('FY5253Quarter', {'qtr_with_extra_week': 1,\n <mask>                                   'startingMonth': 1,\n <mask>                                   'weekday': 2,\n <mask>                                   'variation': 'nearest'}),\n <mask>                ('FY5253', {'weekday': 0,\n <mask>                            'startingMonth': 2,\n <mask>                            'variation':\n <mask>                            'nearest'}),\n <mask>                ('WeekOfMonth', {'weekday': 2,\n <mask>                                 'week': 2}),\n <mask>                'Easter', ('DateOffset', {'day': 4}),\n <mask>                ('DateOffset', {'month': 5})]\n <mask> \n <mask>     with warnings.catch_warnings(record=True):\n <mask>         for normalize in (True, False):\n <mask>             for do in offsets:\n <mask>                 if isinstance(do, tuple):\n <mask>                     do, kwargs = do\n <mask>                 else:\n <mask>                     do = do\n <mask>                     kwargs = {}\n <mask> \n <mask>                     for n in [0, 5]:\n <mask>                         if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n <mask>                                    'FY5253Quarter', 'FY5253'] and n == 0):\n <mask>                             continue\n <mask>                     op = getattr(pd.offsets, do)(n,\n <mask>                                                  normalize=normalize,\n <mask>                                                  **kwargs)\n <mask>                     assert_func(klass([x + op for x in s]), s + op)\n <mask>                     assert_func(klass([x - op for x in s]), s - op)\n <mask>                     assert_func(klass([op + x for x in s]), op + s) </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp) </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             nat_series_dtype_timestamp / 1.0 </s> add             dt64_series / one </s> remove             nat_series_dtype_timestamp / 1 </s> add             one / dt64_series </s> add             dt64_series * one </s> add             one * dt64_series", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/indexes/datetimes/test_arithmetic.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             td1 ** scalar_td\n <mask> \n <mask>     @pytest.mark.parametrize('scalar_td', [\n <mask>         timedelta(minutes=5, seconds=4),\n <mask>         pytest.param(Timedelta('5m4s'),\n <mask>                      marks=pytest.mark.xfail(reason=\"Timedelta.__floordiv__ \"\n <mask>                                                     \"bug GH#18846\")),\n <mask>         Timedelta('5m4s').to_timedelta64()])\n <mask>     def test_timedelta_rfloordiv(self, scalar_td):\n <mask>         # GH#18831\n <mask>         td1 = Series([timedelta(minutes=5, seconds=3)] * 3)\n <mask>         td1.iloc[2] = np.nan </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             nat_series_dtype_timestamp / 1.0 </s> remove     def time_offset(self, tz, freq):\n        self.ts.offset", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>                             nat_series_dtype_timestamp)\n <mask> \n <mask>         # multiplication\n <mask>         with pytest.raises(TypeError):\n <mask>             dt64_series * one\n <mask>         with pytest.raises(TypeError):\n <mask>             one * dt64_series\n <mask>  </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1 </s> add             dt64_series * one </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0 </s> remove             nat_series_dtype_timestamp / 1.0 </s> remove             nat_series_dtype_timestamp / 1 </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp) </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace", "code_tokens": " <mask>                             nat_series_dtype_timestamp)\n <mask> \n <mask>         # multiplication\n <mask>         with pytest.raises(TypeError):\n <mask>             datetime_series * 1\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp * 1\n <mask>         with pytest.raises(TypeError):\n <mask>             datetime_series * 1.0\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp * 1.0 </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> remove             nat_series_dtype_timestamp / 1.0 </s> remove             nat_series_dtype_timestamp / 1 </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask>         # division\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp / 1.0\n <mask>         with pytest.raises(TypeError):\n <mask>             nat_series_dtype_timestamp / 1\n <mask> \n <mask>     def test_dt64series_arith_overflow(self):\n <mask>         # GH#12534, fixed by #19024 </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0 </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1 </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series): </s> add                 assert_series_equal(result, expected) </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>                 expected = s1.apply(\n <mask>                     lambda x: Timedelta(np.timedelta64(m, unit)) / x)\n <mask>                 result = np.timedelta64(m, unit) / s1\n <mask> \n <mask>         # astype\n <mask>         s = Series(date_range('20130101', periods=3))\n <mask>         result = s.astype(object) </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s) </s> remove             nat_series_dtype_timestamp / 1.0 </s> remove             nat_series_dtype_timestamp / 1 </s> remove             datetime_series * 1.0\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1.0 </s> remove     def test_series_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = Series(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([2, 3, 4], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + 1\n            assert_series_equal(res, exp)\n\n            res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n            exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_series_equal(res, exp)\n            res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n            assert_series_equal(res, exp)\n\n            s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                           pd.Timedelta('3 days')], dtype=dtype)\n            exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                             pd.Timedelta('6 days')])\n            assert_series_equal(pd.Timedelta('3 days') + s, exp)\n            assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n        s = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    def test_frame_radd_more(self):\n        data = [[1, 2, 3],\n                [1.1, 2.2, 3.3],\n                [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n                 pd.NaT],\n                ['x', 'y', 1]]\n\n        for d in data:\n            for dtype in [None, object]:\n                s = DataFrame(d, dtype=dtype)\n                with pytest.raises(TypeError):\n                    'foo_' + s\n\n        for dtype in [None, object]:\n            res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n            assert_frame_equal(res, exp)\n\n            res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n            exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n            assert_frame_equal(res, exp)\n            res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n            assert_frame_equal(res, exp) </s> add     def test_series_radd_str(self):\n        ser = pd.Series(['x', np.nan, 'x'])\n        assert_series_equal('a' + ser, pd.Series(['ax', np.nan, 'ax']))\n        assert_series_equal(ser + 'a', pd.Series(['xa', np.nan, 'xa']))\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_more(self, dtype):\n        res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([2, 3, 4], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + 1\n        assert_series_equal(res, exp)\n\n        res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n        exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_series_equal(res, exp)\n        res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n        assert_series_equal(res, exp)\n\n        s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n                       pd.Timedelta('3 days')], dtype=dtype)\n        exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n                         pd.Timedelta('6 days')])\n        assert_series_equal(pd.Timedelta('3 days') + s, exp)\n        assert_series_equal(s + pd.Timedelta('3 days'), exp)\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_series_radd_str_invalid(self, dtype, data):\n        ser = Series(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + ser\n\n    @pytest.mark.parametrize('data', [\n        [1, 2, 3],\n        [1.1, 2.2, 3.3],\n        [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'), pd.NaT],\n        ['x', 'y', 1]])\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_str_invalid(self, dtype, data):\n        df = DataFrame(data, dtype=dtype)\n        with pytest.raises(TypeError):\n            'foo_' + df\n\n    @pytest.mark.parametrize('dtype', [None, object])\n    def test_frame_radd_more(self, dtype):\n        res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n        assert_frame_equal(res, exp)\n\n        res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n        exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n        assert_frame_equal(res, exp)\n        res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n        assert_frame_equal(res, exp)\n\n    def test_frame_radd_str(self): </s> remove             datetime_series * 1\n        with pytest.raises(TypeError):\n            nat_series_dtype_timestamp * 1", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         with pytest.raises(TypeError):\n <mask>             self.ts + datetime.now()\n <mask> \n <mask>     def test_series_radd_more(self):\n <mask>         data = [[1, 2, 3],\n <mask>                 [1.1, 2.2, 3.3],\n <mask>                 [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n <mask>                  pd.NaT],\n <mask>                 ['x', 'y', 1]]\n <mask> \n <mask>         for d in data:\n <mask>             for dtype in [None, object]:\n <mask>                 s = Series(d, dtype=dtype)\n <mask>                 with pytest.raises(TypeError):\n <mask>                     'foo_' + s\n <mask> \n <mask>         for dtype in [None, object]:\n <mask>             res = 1 + pd.Series([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.Series([2, 3, 4], dtype=dtype)\n <mask>             assert_series_equal(res, exp)\n <mask>             res = pd.Series([1, 2, 3], dtype=dtype) + 1\n <mask>             assert_series_equal(res, exp)\n <mask> \n <mask>             res = np.nan + pd.Series([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.Series([np.nan, np.nan, np.nan], dtype=dtype)\n <mask>             assert_series_equal(res, exp)\n <mask>             res = pd.Series([1, 2, 3], dtype=dtype) + np.nan\n <mask>             assert_series_equal(res, exp)\n <mask> \n <mask>             s = pd.Series([pd.Timedelta('1 days'), pd.Timedelta('2 days'),\n <mask>                            pd.Timedelta('3 days')], dtype=dtype)\n <mask>             exp = pd.Series([pd.Timedelta('4 days'), pd.Timedelta('5 days'),\n <mask>                              pd.Timedelta('6 days')])\n <mask>             assert_series_equal(pd.Timedelta('3 days') + s, exp)\n <mask>             assert_series_equal(s + pd.Timedelta('3 days'), exp)\n <mask> \n <mask>         s = pd.Series(['x', np.nan, 'x'])\n <mask>         assert_series_equal('a' + s, pd.Series(['ax', np.nan, 'ax']))\n <mask>         assert_series_equal(s + 'a', pd.Series(['xa', np.nan, 'xa']))\n <mask> \n <mask>     def test_frame_radd_more(self):\n <mask>         data = [[1, 2, 3],\n <mask>                 [1.1, 2.2, 3.3],\n <mask>                 [pd.Timestamp('2011-01-01'), pd.Timestamp('2011-01-02'),\n <mask>                  pd.NaT],\n <mask>                 ['x', 'y', 1]]\n <mask> \n <mask>         for d in data:\n <mask>             for dtype in [None, object]:\n <mask>                 s = DataFrame(d, dtype=dtype)\n <mask>                 with pytest.raises(TypeError):\n <mask>                     'foo_' + s\n <mask> \n <mask>         for dtype in [None, object]:\n <mask>             res = 1 + pd.DataFrame([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.DataFrame([2, 3, 4], dtype=dtype)\n <mask>             assert_frame_equal(res, exp)\n <mask>             res = pd.DataFrame([1, 2, 3], dtype=dtype) + 1\n <mask>             assert_frame_equal(res, exp)\n <mask> \n <mask>             res = np.nan + pd.DataFrame([1, 2, 3], dtype=dtype)\n <mask>             exp = pd.DataFrame([np.nan, np.nan, np.nan], dtype=dtype)\n <mask>             assert_frame_equal(res, exp)\n <mask>             res = pd.DataFrame([1, 2, 3], dtype=dtype) + np.nan\n <mask>             assert_frame_equal(res, exp)\n <mask> \n <mask>         df = pd.DataFrame(['x', np.nan, 'x'])\n <mask>         assert_frame_equal('a' + df, pd.DataFrame(['ax', np.nan, 'ax']))\n <mask>         assert_frame_equal(df + 'a', pd.DataFrame(['xa', np.nan, 'xa']))\n <mask> \n <mask>     def test_operators_frame(self): </s> Followup Cleanup DTI test_arithmetic, ASV (#19149) </s> remove \n    # array of offsets - valid for Series only\n    if klass is Series:\n        with tm.assert_produces_warning(PerformanceWarning):\n            s = klass([Timestamp('2000-1-1'), Timestamp('2000-2-1')])\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.MonthEnd()])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2000-2-29')\n                         ])\n            assert_func(result, exp)\n\n            # same offset\n            result = s + Series([pd.offsets.DateOffset(years=1),\n                                 pd.offsets.DateOffset(years=1)])\n            exp = klass([Timestamp('2001-1-1'), Timestamp('2001-2-1')])\n            assert_func(result, exp)\n\n    s = klass([Timestamp('2000-01-05 00:15:00'),\n               Timestamp('2000-01-31 00:23:00'),\n               Timestamp('2000-01-01'),\n               Timestamp('2000-03-31'),\n               Timestamp('2000-02-29'),\n               Timestamp('2000-12-31'),\n               Timestamp('2000-05-15'),\n               Timestamp('2001-06-15')])\n\n    # DateOffset relativedelta fastpath\n    relative_kwargs = [('years', 2), ('months', 5), ('days', 3),\n                       ('hours', 5), ('minutes', 10), ('seconds', 2),\n                       ('microseconds', 5)]\n    for i, kwd in enumerate(relative_kwargs):\n        op = pd.DateOffset(**dict([kwd]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n        op = pd.DateOffset(**dict(relative_kwargs[:i + 1]))\n        assert_func(klass([x + op for x in s]), s + op)\n        assert_func(klass([x - op for x in s]), s - op)\n\n    # assert these are equal on a piecewise basis\n    offsets = ['YearBegin', ('YearBegin', {'month': 5}),\n               'YearEnd', ('YearEnd', {'month': 5}),\n               'MonthBegin', 'MonthEnd',\n               'SemiMonthEnd', 'SemiMonthBegin',\n               'Week', ('Week', {'weekday': 3}),\n               'BusinessDay', 'BDay', 'QuarterEnd', 'QuarterBegin',\n               'CustomBusinessDay', 'CDay', 'CBMonthEnd',\n               'CBMonthBegin', 'BMonthBegin', 'BMonthEnd',\n               'BusinessHour', 'BYearBegin', 'BYearEnd',\n               'BQuarterBegin', ('LastWeekOfMonth', {'weekday': 2}),\n               ('FY5253Quarter', {'qtr_with_extra_week': 1,\n                                  'startingMonth': 1,\n                                  'weekday': 2,\n                                  'variation': 'nearest'}),\n               ('FY5253', {'weekday': 0,\n                           'startingMonth': 2,\n                           'variation':\n                           'nearest'}),\n               ('WeekOfMonth', {'weekday': 2,\n                                'week': 2}),\n               'Easter', ('DateOffset', {'day': 4}),\n               ('DateOffset', {'month': 5})]\n\n    with warnings.catch_warnings(record=True):\n        for normalize in (True, False):\n            for do in offsets:\n                if isinstance(do, tuple):\n                    do, kwargs = do\n                else:\n                    do = do\n                    kwargs = {}\n\n                    for n in [0, 5]:\n                        if (do in ['WeekOfMonth', 'LastWeekOfMonth',\n                                   'FY5253Quarter', 'FY5253'] and n == 0):\n                            continue\n                    op = getattr(pd.offsets, do)(n,\n                                                 normalize=normalize,\n                                                 **kwargs)\n                    assert_func(klass([x + op for x in s]), s + op)\n                    assert_func(klass([x - op for x in s]), s - op)\n                    assert_func(klass([op + x for x in s]), op + s) </s> add </s> add         Timedelta('5m4s'), </s> remove             nat_series_dtype_timestamp / 1.0 </s> add             dt64_series / one </s> add                 assert_series_equal(result, expected) </s> remove             nat_series_dtype_timestamp / 1 </s> add             one / dt64_series </s> add     @pytest.mark.parametrize('dt64_series', [\n        Series([Timestamp('19900315'), Timestamp('19900315')]),\n        Series([NaT, Timestamp('19900315')]),\n        Series([NaT, NaT], dtype='datetime64[ns]')])\n    @pytest.mark.parametrize('one', [1, 1.0, np.array(1)])\n    def test_dt64_mul_div_numeric_invalid(self, one, dt64_series):", "html_url": "https://github.com/pandas-dev/pandas/commit/055bfa6a2a4ef81d6a0c41c6f870dbe0ec5296d3", "file_name": "pandas/tests/series/test_operators.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     # ndarray-like stats methods\n <mask> \n <mask>     def count(self, axis=0, level=None, numeric_only=False):\n <mask>         \"\"\"\n <mask>         Return Series with number of non-NA/null observations over requested\n <mask>         axis. Works with non-floating point data as well (detects NaN and None)\n <mask> \n <mask>         Parameters\n <mask>         ----------\n <mask>         axis : {0 or 'index', 1 or 'columns'}, default 0\n <mask>             0 or 'index' for row-wise, 1 or 'columns' for column-wise\n <mask>         level : int or level name, default None\n <mask>             If the axis is a MultiIndex (hierarchical), count along a\n <mask>             particular level, collapsing into a DataFrame\n <mask>         numeric_only : boolean, default False\n <mask>             Include only float, int, boolean data\n <mask> \n <mask>         Returns </s> remove             Include only float, int, boolean data", "html_url": "https://github.com/pandas-dev/pandas/commit/0596cb18fa9705651b0486310792debb2e4df430", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         level : int or level name, default None\n <mask>             If the axis is a MultiIndex (hierarchical), count along a\n <mask>             particular level, collapsing into a DataFrame\n <mask>         numeric_only : boolean, default False\n <mask>             Include only float, int, boolean data\n <mask> \n <mask>         Returns\n <mask>         -------\n <mask>         count : Series (or DataFrame if level specified)\n <mask>         \"\"\"\n <mask>         axis = self._get_axis_number(axis)\n <mask>         if level is not None:\n <mask>             return self._count_level(level, axis=axis, </s> remove             0 or 'index' for row-wise, 1 or 'columns' for column-wise\n        level : int or level name, default None\n            If the axis is a MultiIndex (hierarchical), count along a\n            particular level, collapsing into a DataFrame </s> add             If 0 or 'index' counts are generated for each column.\n            If 1 or 'columns' counts are generated for each **row**.\n        level : int or str, optional\n            If the axis is a `MultiIndex` (hierarchical), count along a\n            particular `level`, collapsing into a `DataFrame`.\n            A `str` specifies the level name. </s> remove         Return Series with number of non-NA/null observations over requested\n        axis. Works with non-floating point data as well (detects NaN and None) </s> add         Count non-NA cells for each column or row.\n\n        The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n        on `pandas.options.mode.use_inf_as_na`) are considered NA.", "html_url": "https://github.com/pandas-dev/pandas/commit/0596cb18fa9705651b0486310792debb2e4df430", "file_name": "pandas/core/frame.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> # Note: don't use this config for your own repositories. Instead, see\n <mask> # \"Version control integration\" in README.md.\n <mask> exclude: ^(blib2to3/|profiling/|tests/data/)\n <mask> repos:\n <mask> -   repo: local\n <mask>     hooks:\n <mask>     - id: black\n <mask>       name: black\n <mask>       language: system\n <mask>       entry: black\n <mask>       types: [python]\n <mask>     - id: flake8\n <mask>       name: flake8\n <mask>       language: system\n <mask>       entry: flake8\n <mask>       types: [python]\n <mask>     - id: mypy\n <mask>       name: mypy\n <mask>       language: system\n <mask>       entry: mypy\n <mask>       types: [python]\n <mask>       exclude: ^docs/conf.py </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy </s> remove         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\" </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\"", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "replace keep replace keep keep keep keep keep", "code_tokens": " <mask> dist: xenial\n <mask> language: python\n <mask> cache: pip\n <mask> env:\n <mask> - TEST_CMD=\"coverage run tests/test_black.py\"\n <mask> install:\n <mask> - pip install coverage coveralls flake8 flake8-bugbear mypy\n <mask> - pip install -e '.[d]' </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy </s> add - pip install coverage coveralls pre-commit </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\"", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> cache: pip\n <mask> env:\n <mask> - TEST_CMD=\"coverage run tests/test_black.py\"\n <mask> install:\n <mask> - pip install coverage coveralls flake8 flake8-bugbear mypy\n <mask> - pip install -e '.[d]'\n <mask> script:\n <mask> - $TEST_CMD\n <mask> after_success:\n <mask> - coveralls </s> remove cache: pip </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\" </s> add         - TEST_CMD=\"pre-commit run --all-files\" </s> remove     - name: \"mypy\"\n      python: 3.6\n      env:\n        - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n    - name: \"black\"\n      python: 3.7\n      env:\n        - TEST_CMD=\"black --check --verbose .\"\n    - name: \"flake8\" </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace replace keep keep replace keep keep", "code_tokens": " <mask>   include:\n <mask>     - name: \"mypy\"\n <mask>       python: 3.6\n <mask>       env:\n <mask>         - TEST_CMD=\"mypy black.py blackd.py tests/test_black.py\"\n <mask>     - name: \"black\"\n <mask>       python: 3.7\n <mask>       env:\n <mask>         - TEST_CMD=\"black --check --verbose .\"\n <mask>     - name: \"flake8\"\n <mask>       python: 3.7\n <mask>       env:\n <mask>         - TEST_CMD=\"flake8 black.py blackd.py tests/test_black.py\"\n <mask>     - name: \"3.6\"\n <mask>       python: 3.6 </s> Run pre-commit on Travis CI (#1081) </s> remove - pip install coverage coveralls flake8 flake8-bugbear mypy </s> add - pip install coverage coveralls pre-commit </s> remove     - id: black\n      name: black\n      language: system\n      entry: black\n      types: [python]\n    - id: flake8\n      name: flake8\n      language: system\n      entry: flake8\n      types: [python]\n    - id: mypy\n      name: mypy\n      language: system\n      entry: mypy\n      types: [python]\n      exclude: ^docs/conf.py </s> add       - id: black\n        name: black\n        language: system\n        entry: black\n        require_serial: true\n        types: [python]\n\n  - repo: https://gitlab.com/pycqa/flake8\n    rev: 3.7.8\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-bugbear]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.740\n    hooks:\n      - id: mypy\n        exclude: ^docs/conf.py </s> remove cache: pip </s> add cache:\n  pip: true\n  directories:\n    - $HOME/.cache/pre-commit </s> remove dist: xenial </s> add </s> remove -   repo: local </s> add   - repo: local", "html_url": "https://github.com/psf/black/commit/000147c007787fc26e8ccb4fb9843a6f9d80affb", "file_name": ".travis.yml"}
{"docstring_tokens": "replace keep keep keep keep keep", "code_tokens": " <mask> name: Build wheels and publish to PyPI\n <mask> \n <mask> on:\n <mask>   release:\n <mask>     types: [published]\n <mask>   pull_request: </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> add   push:\n    branches:\n      - main </s> remove build = \"cp3*-*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp-*\", \"cp312-*\"] </s> add build = \"cp3*\"\nskip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp*\", \"cp312-*\"] </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\" </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\" </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add     if: github.event_name == 'release' </s> remove     name: mypyc wheels (${{ matrix.name }}) </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     types: [published]\n <mask>   pull_request:\n <mask> \n <mask> permissions:\n <mask>   contents: read\n <mask> \n <mask> jobs: </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove name: Build wheels and publish to PyPI </s> add name: Build and publish </s> add     if: github.event_name == 'release' </s> remove         include:\n          - os: ubuntu-latest\n            name: linux-x86_64\n          - os: windows-2019\n            name: windows-amd64\n          - os: macos-11\n            name: macos-x86_64\n            macos_arch: \"x86_64\"\n          - os: macos-11\n            name: macos-arm64\n            macos_arch: \"arm64\"\n          - os: macos-11\n            name: macos-universal2\n            macos_arch: \"universal2\" </s> remove     name: mypyc wheels (${{ matrix.name }})", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     name: sdist + pure wheel\n <mask>     runs-on: ubuntu-latest\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask> \n <mask>       - name: Set up latest Python\n <mask>         uses: actions/setup-python@v4 </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\" </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove name: Build wheels and publish to PyPI </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep replace keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>   mypyc:\n <mask>     name: mypyc wheels (${{ matrix.name }})\n <mask>     runs-on: ${{ matrix.os }}\n <mask>     strategy:\n <mask>       fail-fast: false\n <mask>       matrix:\n <mask>         include:\n <mask>           - os: ubuntu-latest\n <mask>             name: linux-x86_64\n <mask>           - os: windows-2019\n <mask>             name: windows-amd64\n <mask>           - os: macos-11\n <mask>             name: macos-x86_64\n <mask>             macos_arch: \"x86_64\"\n <mask>           - os: macos-11\n <mask>             name: macos-arm64\n <mask>             macos_arch: \"arm64\"\n <mask>           - os: macos-11\n <mask>             name: macos-universal2\n <mask>             macos_arch: \"universal2\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask>  </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\" </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }} </s> add     if: github.event_name == 'release' </s> remove name: Build wheels and publish to PyPI </s> add name: Build and publish </s> add     if: github.event_name == 'release' </s> add   push:\n    branches:\n      - main", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             macos_arch: \"universal2\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v4\n <mask> \n <mask>       - name: Build wheels via cibuildwheel\n <mask>         uses: pypa/cibuildwheel@v2.15.0\n <mask>         env:\n <mask>           CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\"\n <mask> \n <mask>       - name: Upload wheels as workflow artifacts\n <mask>         uses: actions/upload-artifact@v3\n <mask>         with:\n <mask>           name: ${{ matrix.name }}-mypyc-wheels </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove     name: mypyc wheels (${{ matrix.name }}) </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix </s> remove name: Build wheels and publish to PyPI", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     name: Update stable branch\n <mask>     needs: [main, mypyc]\n <mask>     runs-on: ubuntu-latest\n <mask>     permissions:\n <mask>       contents: write\n <mask> \n <mask>     steps: </s> mypyc build improvements (#3881)\n\nBuild in separate jobs. This makes it clearer if e.g. a single Python\r\nversion is failing. It also potentially gets you more parallelism.\r\n\r\nBuild everything on push to master.\r\n\r\nOnly build Linux 3.8 and 3.11 wheels on PRs. </s> add   push:\n    branches:\n      - main </s> add     name: mypyc wheels ${{ matrix.only }}\n    needs: generate_wheels_matrix </s> add     if: github.event_name == 'release' </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove name: Build wheels and publish to PyPI </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\" </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }}", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": ".github/workflows/pypi_upload.yml"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> # So these are the environments we target:\n <mask> # - Python: CPython 3.8+ only\n <mask> # - Architecture (64-bit only): amd64 / x86_64, universal2, and arm64\n <mask> # - OS: Linux (no musl), Windows, and macOS\n <mask> build = \"cp3*-*\"\n <mask> skip = [\"*-manylinux_i686\", \"*-musllinux_*\", \"*-win32\", \"pp-*\", \"cp312-*\"]\n <mask> # This is the bare minimum needed to run the test suite. Pulling in the full\n <mask> # test_requirements.txt would download a bunch of other packages not necessary\n <mask> # here and would slow down the testing step a fair bit.\n <mask> test-requires = [\"pytest>=6.1.1\"]\n <mask> test-command = 'pytest {project} -k \"not incompatible_with_mypyc\"' </s> add         include: ${{ fromJson(needs.generate_wheels_matrix.outputs.include) }} </s> remove \n      - name: Build wheels via cibuildwheel\n        uses: pypa/cibuildwheel@v2.15.0\n        env:\n          CIBW_ARCHS_MACOS: \"${{ matrix.macos_arch }}\" </s> add       - uses: pypa/cibuildwheel@v2.15.0\n        with:\n          only: ${{ matrix.only }}", "html_url": "https://github.com/psf/black/commit/004fb79706a02c9a06abd5c416b033340f99e558", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> from asyncio.base_events import BaseEventLoop\n <mask> from concurrent.futures import Executor, ProcessPoolExecutor\n <mask> from enum import Enum, Flag\n <mask> from functools import partial, wraps\n <mask> import keyword\n <mask> import logging\n <mask> from multiprocessing import Manager\n <mask> import os\n <mask> from pathlib import Path\n <mask> import re </s> add from io import BytesIO, TextIOWrapper", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     if src.suffix == \".pyi\":\n <mask>         mode |= FileMode.PYI\n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast, mode=mode\n <mask>         )\n <mask>     except NothingChanged: </s> Preserve line endings when formatting a file in place (#288) </s> remove     src = sys.stdin.read() </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read() </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name)) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach()", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES:\n <mask>         with open(src, \"w\", encoding=src_buffer.encoding) as f:\n <mask>             f.write(dst_contents)\n <mask>     elif write_back == write_back.DIFF:\n <mask>         src_name = f\"{src}  (original)\"\n <mask>         dst_name = f\"{src}  (formatted)\"\n <mask>         diff_contents = diff(src_contents, dst_contents, src_name, dst_name) </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdout.write(dst) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name)) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove             sys.stdout.write(diff_contents) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read()) </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         diff_contents = diff(src_contents, dst_contents, src_name, dst_name)\n <mask>         if lock:\n <mask>             lock.acquire()\n <mask>         try:\n <mask>             sys.stdout.write(diff_contents)\n <mask>         finally:\n <mask>             if lock:\n <mask>                 lock.release()\n <mask>     return True\n <mask>  </s> Preserve line endings when formatting a file in place (#288) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove             sys.stdout.write(dst) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove     src = sys.stdin.read() </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name)) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to\n <mask>     :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     src = sys.stdin.read()\n <mask>     dst = src\n <mask>     try:\n <mask>         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)\n <mask>         return True\n <mask>  </s> Preserve line endings when formatting a file in place (#288) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read()) </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read() </s> remove             sys.stdout.write(diff_contents) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>         return False\n <mask> \n <mask>     finally:\n <mask>         if write_back == WriteBack.YES:\n <mask>             sys.stdout.write(dst)\n <mask>         elif write_back == WriteBack.DIFF:\n <mask>             src_name = \"<stdin>  (original)\"\n <mask>             dst_name = \"<stdin>  (formatted)\"\n <mask>             sys.stdout.write(diff(src, dst, src_name, dst_name))\n <mask> \n <mask>  </s> Preserve line endings when formatting a file in place (#288) </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove             sys.stdout.write(diff_contents) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read() </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> GRAMMARS = [\n <mask>     pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>     pygram.python_grammar_no_print_statement,\n <mask>     pygram.python_grammar, </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read())", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def lib2to3_parse(src_txt: str) -> Node:\n <mask>     \"\"\"Given a string with source, return the lib2to3 Node.\"\"\"\n <mask>     grammar = pygram.python_grammar_no_print_statement\n <mask>     if src_txt[-1] != \"\\n\":\n <mask>         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n <mask>         src_txt += nl\n <mask>     for grammar in GRAMMARS:\n <mask>         drv = driver.Driver(grammar, pytree.convert)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read() </s> remove         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> add         with open(src, \"w\", encoding=encoding, newline=newline) as f: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> add     with open(src, \"rb\") as buf:\n        newline, encoding, src_contents = prepare_input(buf.read())", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> from concurrent.futures import ThreadPoolExecutor\n <mask> from contextlib import contextmanager\n <mask> from functools import partial\n <mask> from io import StringIO\n <mask> import os\n <mask> from pathlib import Path\n <mask> import sys\n <mask> from tempfile import TemporaryDirectory\n <mask> from typing import Any, List, Tuple, Iterator </s> add import io </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_piping(self) -> None:\n <mask>         source, expected = read_data(\"../black\")\n <mask>         hold_stdin, hold_stdout = sys.stdin, sys.stdout\n <mask>         try:\n <mask>             sys.stdin, sys.stdout = StringIO(source), StringIO()\n <mask>             sys.stdin.name = \"<stdin>\"\n <mask>             black.format_stdin_to_stdout(\n <mask>                 line_length=ll, fast=True, write_back=black.WriteBack.YES\n <mask>             )\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read() </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl </s> add     def test_preserves_line_endings(self) -> None:\n        with TemporaryDirectory() as workspace:\n            test_file = Path(workspace) / \"test.py\"\n            for nl in [\"\\n\", \"\\r\\n\"]:\n                contents = nl.join([\"def f(  ):\", \"    pass\"])\n                test_file.write_bytes(contents.encode())\n                ff(test_file, write_back=black.WriteBack.YES)\n                updated_contents: bytes = test_file.read_bytes()\n                self.assertIn(nl.encode(), updated_contents)  # type: ignore\n                if nl == \"\\n\":\n                    self.assertNotIn(b\"\\r\\n\", updated_contents)  # type: ignore </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> add def prepare_input(src: bytes) -> Tuple[str, str, str]:\n    \"\"\"Analyze `src` and return a tuple of (newline, encoding, decoded_contents)\n\n    Where `newline` is either CRLF or LF, and `decoded_contents` is decoded with\n    universal newlines (i.e. only LF).\n    \"\"\"\n    srcbuf = io.BytesIO(src)\n    encoding, lines = tokenize.detect_encoding(srcbuf.readline)\n    newline = \"\\r\\n\" if b\"\\r\\n\" == lines[0][-2:] else \"\\n\"\n    srcbuf.seek(0)\n    return newline, encoding, io.TextIOWrapper(srcbuf, encoding).read()", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         source, _ = read_data(\"expression.py\")\n <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         hold_stdin, hold_stdout = sys.stdin, sys.stdout\n <mask>         try:\n <mask>             sys.stdin, sys.stdout = StringIO(source), StringIO()\n <mask>             sys.stdin.name = \"<stdin>\"\n <mask>             black.format_stdin_to_stdout(\n <mask>                 line_length=ll, fast=True, write_back=black.WriteBack.DIFF\n <mask>             )\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read() </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdout = StringIO() </s> add             sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\") </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff(src, dst, src_name, dst_name))\n            f.detach() </s> remove     src = sys.stdin.read() </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read())", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         tmp_file = Path(black.dump_to_file(source))\n <mask>         hold_stdout = sys.stdout\n <mask>         try:\n <mask>             sys.stdout = StringIO()\n <mask>             self.assertTrue(ff(tmp_file, write_back=black.WriteBack.DIFF))\n <mask>             sys.stdout.seek(0)\n <mask>             actual = sys.stdout.read()\n <mask>             actual = actual.replace(str(tmp_file), \"<stdin>\")\n <mask>         finally: </s> Preserve line endings when formatting a file in place (#288) </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> remove             sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = \"<stdin>\" </s> add             sys.stdin = TextIOWrapper(BytesIO(source.encode(\"utf8\")), encoding=\"utf8\")\n            sys.stdout = TextIOWrapper(BytesIO(), encoding=\"utf8\")\n            sys.stdin.buffer.name = \"<stdin>\"  # type: ignore </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(dst)\n            f.detach() </s> remove             sys.stdout.write(diff_contents) </s> add             f = io.TextIOWrapper(\n                sys.stdout.buffer,\n                encoding=encoding,\n                newline=newline,\n                write_through=True,\n            )\n            f.write(diff_contents)\n            f.detach() </s> remove     src = sys.stdin.read() </s> add     newline, encoding, src = prepare_input(sys.stdin.buffer.read()) </s> remove         nl = \"\\r\\n\" if \"\\r\\n\" in src_txt[:1024] else \"\\n\"\n        src_txt += nl", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep", "code_tokens": " <mask>             self.assertEqual(result.exit_code, 2)\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     unittest.main() </s> remove             sys.stdout.write(dst) </s> remove             sys.stdout.write(diff(src, dst, src_name, dst_name)) </s> remove             sys.stdout.write(diff_contents)", "html_url": "https://github.com/psf/black/commit/00a302560b92951c22f0f4c8d618cf63de39bd57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def visit_STRING(self, leaf: Leaf) -> Iterator[Line]:\n <mask>         if is_docstring(leaf) and \"\\\\\\n\" not in leaf.value:\n <mask>             # We're ignoring docstrings with backslash newline escapes because changing\n <mask>             # indentation of those changes the AST representation of the code.\n <mask>             prefix = get_string_prefix(leaf.value)\n <mask>             docstring = leaf.value[len(prefix) :]  # Remove the prefix\n <mask>             quote_char = docstring[0]\n <mask>             # A natural way to remove the outer quotes is to do:\n <mask>             #   docstring = docstring.strip(quote_char)\n <mask>             # but that breaks on \"\"\"\"\"x\"\"\" (which is '\"\"x').\n <mask>             # So we actually need to remove the first character and the next two </s> remove         prefix = get_string_prefix(LL[string_idx].value) </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS) </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(LL[next_str_idx].value) </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         prefix += string[prefix_idx].lower() </s> add         prefix += string[prefix_idx]", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     prefix = \"\"\n <mask>     prefix_idx = 0\n <mask>     while string[prefix_idx] in STRING_PREFIX_CHARS:\n <mask>         prefix += string[prefix_idx].lower()\n <mask>         prefix_idx += 1\n <mask> \n <mask>     return prefix\n <mask> \n <mask>  </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove             prefix = get_string_prefix(LL[next_str_idx].value) </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS) </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         prefix = get_string_prefix(LL[string_idx].value) </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             not prefix\n <mask>             and is_valid_index(next_str_idx)\n <mask>             and LL[next_str_idx].type == token.STRING\n <mask>         ):\n <mask>             prefix = get_string_prefix(LL[next_str_idx].value)\n <mask>             next_str_idx += 1\n <mask> \n <mask>         # The next loop merges the string group. The final string will be\n <mask>         # contained in 'S'.\n <mask>         # </s> remove             next_prefix = get_string_prefix(SS) </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         prefix = get_string_prefix(LL[string_idx].value) </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         prefix += string[prefix_idx].lower() </s> add         prefix += string[prefix_idx] </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         while is_valid_index(next_str_idx) and LL[next_str_idx].type == token.STRING:\n <mask>             num_of_strings += 1\n <mask> \n <mask>             SS = LL[next_str_idx].value\n <mask>             next_prefix = get_string_prefix(SS)\n <mask> \n <mask>             # If this is an f-string group but this substring is not prefixed\n <mask>             # with 'f'...\n <mask>             if \"f\" in prefix and \"f\" not in next_prefix:\n <mask>                 # Then we must escape any braces contained in this substring. </s> remove             prefix = get_string_prefix(LL[next_str_idx].value) </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove         prefix = get_string_prefix(LL[string_idx].value) </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         prefix += string[prefix_idx].lower() </s> add         prefix += string[prefix_idx] </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if has_triple_quotes(leaf.value):\n <mask>                 return TErr(\"StringMerger does NOT merge multiline strings.\")\n <mask> \n <mask>             num_of_strings += 1\n <mask>             prefix = get_string_prefix(leaf.value)\n <mask>             if \"r\" in prefix:\n <mask>                 return TErr(\"StringMerger does NOT merge raw strings.\")\n <mask> \n <mask>             set_of_prefixes.add(prefix)\n <mask>  </s> Regression fix: leave R prefixes capitalization alone (#2285)\n\n`black.strings.get_string_prefix` used to lowercase the extracted\r\nprefix before returning it. This is wrong because 1) it ignores the\r\nfact we should leave R prefixes alone because of MagicPython, and 2)\r\nthere is dedicated prefix casing handling code that fixes issue 1.\r\n`.lower` is too naive.\r\n\r\nThis was originally fixed in 20.8b0, but was reintroduced since 21.4b0.\r\n\r\nI also added proper prefix normalization for docstrings by using the\r\n`black.strings.normalize_string_prefix` helper.\r\n\r\nSome more test strings were added to make sure strings with capitalized\r\nprefixes aren't treated differently (actually happened with my original\r\npatch, Jelle had to point it out to me). </s> remove         prefix += string[prefix_idx].lower() </s> add         prefix += string[prefix_idx] </s> remove             next_prefix = get_string_prefix(SS) </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove             prefix = get_string_prefix(LL[next_str_idx].value) </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove         prefix = get_string_prefix(LL[string_idx].value) </s> add         prefix = get_string_prefix(LL[string_idx].value).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask>         insert_str_child = insert_str_child_factory(LL[string_idx])\n <mask> \n <mask>         prefix = get_string_prefix(LL[string_idx].value)\n <mask> \n <mask>         # We MAY choose to drop the 'f' prefix from substrings that don't\n <mask>         # contain any f-expressions, but ONLY if the original f-string\n <mask>         # contains at least one f-expression. Otherwise, we will alter the AST\n <mask>         # of the program. </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove             prefix = get_string_prefix(LL[next_str_idx].value) </s> add             prefix = get_string_prefix(LL[next_str_idx].value).lower() </s> remove             next_prefix = get_string_prefix(SS) </s> add             next_prefix = get_string_prefix(SS).lower() </s> remove         is_fstring = \"f\" in get_string_prefix(string) </s> add         is_fstring = \"f\" in get_string_prefix(string).lower() </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower() </s> remove         prefix += string[prefix_idx].lower() </s> add         prefix += string[prefix_idx]", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     _fexpr_slices.append(match.span())\n <mask> \n <mask>             yield from _fexpr_slices\n <mask> \n <mask>         is_fstring = \"f\" in get_string_prefix(string)\n <mask> \n <mask>         def breaks_fstring_expression(i: Index) -> bool:\n <mask>             \"\"\"\n <mask>             Returns:\n <mask>                 True iff returning @i would result in the splitting of an </s> remove             prefix = get_string_prefix(leaf.value)\n            docstring = leaf.value[len(prefix) :]  # Remove the prefix </s> add             docstring = normalize_string_prefix(leaf.value, self.remove_u_prefix)\n            prefix = get_string_prefix(docstring)\n            docstring = docstring[len(prefix) :]  # Remove the prefix </s> remove             prefix = get_string_prefix(leaf.value) </s> add             prefix = get_string_prefix(leaf.value).lower()", "html_url": "https://github.com/psf/black/commit/00e7e12a3a412ea386806d5d4eeaed345e912940", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sys.stdout.buffer, encoding=encoding, newline=newline, write_through=True\n <mask>         )\n <mask>         if write_back == WriteBack.YES:\n <mask>             # Make sure there's a newline after the content\n <mask>             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n <mask>             f.write(dst)\n <mask>         elif write_back in (WriteBack.DIFF, WriteBack.COLOR_DIFF):\n <mask>             now = datetime.utcnow()\n <mask>             src_name = f\"STDIN\\t{then} +0000\"\n <mask>             dst_name = f\"STDOUT\\t{now} +0000\"\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> add     def test_reformat_one_with_stdin_empty(self) -> None:\n        output = io.StringIO()\n        with patch(\"io.TextIOWrapper\", lambda *args, **kwargs: output):\n            try:\n                black.format_stdin_to_stdout(\n                    fast=True,\n                    content=\"\",\n                    write_back=black.WriteBack.YES,\n                    mode=DEFAULT_MODE,\n                )\n            except io.UnsupportedOperation:\n                pass  # StringIO does not support detach\n            assert output.getvalue() == \"\"\n </s> add import io", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from contextlib import contextmanager\n <mask> from dataclasses import replace\n <mask> import inspect\n <mask> from io import BytesIO\n <mask> import os\n <mask> from pathlib import Path\n <mask> from platform import system\n <mask> import regex as re\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> add     def test_reformat_one_with_stdin_empty(self) -> None:\n        output = io.StringIO()\n        with patch(\"io.TextIOWrapper\", lambda *args, **kwargs: output):\n            try:\n                black.format_stdin_to_stdout(\n                    fast=True,\n                    content=\"\",\n                    write_back=black.WriteBack.YES,\n                    mode=DEFAULT_MODE,\n                )\n            except io.UnsupportedOperation:\n                pass  # StringIO does not support detach\n            assert output.getvalue() == \"\"\n </s> remove             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n </s> add             if dst and dst[-1] != \"\\n\":\n                dst += \"\\n\"", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             # __BLACK_STDIN_FILENAME__ should have been stripped\n <mask>             report.done.assert_called_with(expected, black.Changed.YES)\n <mask> \n <mask>     def test_gitignore_exclude(self) -> None:\n <mask>         path = THIS_DIR / \"data\" / \"include_exclude_tests\"\n <mask>         include = re.compile(r\"\\.pyi?$\")\n <mask>         exclude = re.compile(r\"\")\n <mask>         report = black.Report()\n <mask>         gitignore = PathSpec.from_lines(\n </s> Accept empty stdin (close #2337) (#2346)\n\nCommit history before merge:\r\n\r\n* Accept empty stdin (close #2337)\r\n* Update tests/test_black.py\r\n* Add changelog\r\n* Assert Black reformats an empty string to an empty string (#2337) (#2346)\r\n* fix </s> remove             dst += \"\" if dst[-1] == \"\\n\" else \"\\n\"\n </s> add             if dst and dst[-1] != \"\\n\":\n                dst += \"\\n\" </s> add import io", "html_url": "https://github.com/psf/black/commit/017aafea992ca1c6d7af45d3013af7ddb7fda12a", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         ast3 = ast\n <mask> \n <mask> \n <mask> PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\"\n <mask> PY2_HINT: Final = \"Python 2 support was removed in version 22.0.\"\n <mask> \n <mask> \n <mask> class InvalidInput(ValueError):\n <mask>     \"\"\"Raised when input source code fails all parse attempts.\"\"\" </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add     python_grammar.version = (2, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            )", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             pygram.python_grammar_no_print_statement_no_exec_statement_async_keywords,\n <mask>             # Python 3.0-3.6\n <mask>             pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>         ]\n <mask> \n <mask>     grammars = []\n <mask>     # If we have to parse both, try to parse async as a keyword first\n <mask>     if not supports_feature(\n <mask>         target_versions, Feature.ASYNC_IDENTIFIERS </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\" </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             pygram.python_grammar_no_print_statement_no_exec_statement,\n <mask>         ]\n <mask> \n <mask>     grammars = []\n <mask>     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n <mask>         # Python 3.10+\n <mask>         grammars.append(pygram.python_grammar_soft_keywords)\n <mask>     # If we have to parse both, try to parse async as a keyword first\n <mask>     if not supports_feature(\n <mask>         target_versions, Feature.ASYNC_IDENTIFIERS\n <mask>     ) and not supports_feature(target_versions, Feature.PATTERN_MATCHING):\n <mask>         # Python 3.7-3.9 </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\" </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add         self.version: Tuple[int, int] = (0, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         )\n <mask>     if not supports_feature(target_versions, Feature.ASYNC_KEYWORDS):\n <mask>         # Python 3.0-3.6\n <mask>         grammars.append(pygram.python_grammar_no_print_statement_no_exec_statement)\n <mask>     # At least one of the above branches must have been taken, because every Python\n <mask>     # version has exactly one of the two 'ASYNC_*' flags\n <mask>     return grammars\n <mask> \n <mask>  </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar.version = (2, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     grammars = get_grammars(set(target_versions))\n <mask>     for grammar in grammars:\n <mask>         drv = driver.Driver(grammar)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break\n <mask>  </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)] </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\" </s> add         new.version = self.version </s> add     python_grammar_soft_keywords.version = (3, 10)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>             except IndexError:\n <mask>                 faulty_line = \"<line number missing in source>\"\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\")\n <mask> \n <mask>         except TokenError as te:\n <mask>             # In edge cases these are raised; and typically don't have a \"faulty_line\".\n <mask>             lineno, column = te.args[1]\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             lineno, column = te.args[1]\n <mask>             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\")\n <mask> \n <mask>     else:\n <mask>         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n <mask>             src_txt, pygram.python_grammar_soft_keywords\n <mask>         ):\n <mask>             original_msg = exc.args[0]\n <mask>             msg = f\"{original_msg}\\n{PY310_HINT}\"\n <mask>             raise InvalidInput(msg) from None\n <mask> \n <mask>         if matches_grammar(src_txt, pygram.python_grammar) or matches_grammar(\n <mask>             src_txt, pygram.python_grammar_no_print_statement\n <mask>         ):\n <mask>             original_msg = exc.args[0] </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> add     python_grammar.version = (2, 0) </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         self.tokens: Dict[int, int] = {}\n <mask>         self.symbol2label: Dict[str, int] = {}\n <mask>         self.start = 256\n <mask>         # Python 3.7+ parses async as a keyword, not an identifier\n <mask>         self.async_keywords = False\n <mask> \n <mask>     def dump(self, filename: Path) -> None: </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords,", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         new.labels = self.labels[:]\n <mask>         new.states = self.states[:]\n <mask>         new.start = self.start\n <mask>         new.async_keywords = self.async_keywords\n <mask>         return new\n <mask> \n <mask>     def report(self) -> None: </s> add def test_python_310_without_target_version() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode()\n    assert_format(source, expected, mode, minimum_version=(3, 10)) </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT) </s> add     python_grammar_soft_keywords.version = (3, 10)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     # Python 2\n <mask>     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir)\n <mask>     soft_keywords = python_grammar.soft_keywords.copy()\n <mask>     python_grammar.soft_keywords.clear()\n <mask> \n <mask>     python_symbols = _python_symbols(python_grammar)\n <mask> \n <mask>     # Python 2 + from __future__ import print_function </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove PY310_HINT: Final = \"Consider using --target-version py310 to parse Python 3.10 code.\" </s> add     python_grammar_soft_keywords.version = (3, 10) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add         self.version: Tuple[int, int] = (0, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     del python_grammar_no_print_statement_no_exec_statement.keywords[\"print\"]\n <mask>     del python_grammar_no_print_statement_no_exec_statement.keywords[\"exec\"]\n <mask> \n <mask>     # Python 3.7+\n <mask>     python_grammar_no_print_statement_no_exec_statement_async_keywords = (\n <mask>         python_grammar_no_print_statement_no_exec_statement.copy()\n <mask>     ) </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar.version = (2, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            )", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         True\n <mask>     )\n <mask> \n <mask>     # Python 3.10+\n <mask>     python_grammar_soft_keywords = (\n <mask>         python_grammar_no_print_statement_no_exec_statement_async_keywords.copy() </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> add     python_grammar_soft_keywords.version = (3, 10) </s> remove     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> add             # Python 3.10+\n            pygram.python_grammar_soft_keywords, </s> add     if supports_feature(target_versions, Feature.PATTERN_MATCHING):\n        # Python 3.10+\n        grammars.append(pygram.python_grammar_soft_keywords) </s> add     python_grammar.version = (2, 0)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         python_grammar_no_print_statement_no_exec_statement_async_keywords.copy()\n <mask>     )\n <mask>     python_grammar_soft_keywords.soft_keywords = soft_keywords\n <mask> \n <mask>     pattern_grammar = driver.load_packaged_grammar(\n <mask>         \"blib2to3\", _PATTERN_GRAMMAR_FILE, cache_dir\n <mask>     )\n <mask>     pattern_symbols = _pattern_symbols(pattern_grammar) </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.version = (3, 7) </s> add     python_grammar.version = (2, 0) </s> add     python_grammar_no_print_statement_no_exec_statement.version = (3, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            )", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_patma_invalid() -> None:\n <mask>     source, expected = read_data(\"pattern_matching_invalid\")\n <mask>     mode = black.Mode(target_versions={black.TargetVersion.PY310})\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info: </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove def test_patma_hint() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode(target_versions={black.TargetVersion.PY39})\n    with pytest.raises(black.parsing.InvalidInput) as exc_info:\n        assert_format(source, expected, mode, minimum_version=(3, 10))\n\n    exc_info.match(black.parsing.PY310_HINT) </s> add         new.version = self.version </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> add     python_grammar_soft_keywords.version = (3, 10)", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     exc_info.match(\"Cannot parse: 10:11\")\n <mask> \n <mask> \n <mask> def test_patma_hint() -> None:\n <mask>     source, expected = read_data(\"pattern_matching_simple\")\n <mask>     mode = black.Mode(target_versions={black.TargetVersion.PY39})\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info:\n <mask>         assert_format(source, expected, mode, minimum_version=(3, 10))\n <mask> \n <mask>     exc_info.match(black.parsing.PY310_HINT)\n <mask> \n <mask> \n <mask> def test_python_2_hint() -> None:\n <mask>     with pytest.raises(black.parsing.InvalidInput) as exc_info:\n <mask>         assert_format(\"print 'daylily'\", \"print 'daylily'\")\n <mask>     exc_info.match(black.parsing.PY2_HINT)\n <mask>  </s> Enable pattern matching by default (#2758)\n\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> add def test_python_310_without_target_version() -> None:\n    source, expected = read_data(\"pattern_matching_simple\")\n    mode = black.Mode()\n    assert_format(source, expected, mode, minimum_version=(3, 10)) </s> add         new.version = self.version </s> add         self.version: Tuple[int, int] = (0, 0) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {faulty_line}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {faulty_line}\"\n            ) </s> remove             exc = InvalidInput(f\"Cannot parse: {lineno}:{column}: {te.args[0]}\") </s> add             errors[grammar.version] = InvalidInput(\n                f\"Cannot parse: {lineno}:{column}: {te.args[0]}\"\n            ) </s> remove         if pygram.python_grammar_soft_keywords not in grammars and matches_grammar(\n            src_txt, pygram.python_grammar_soft_keywords\n        ):\n            original_msg = exc.args[0]\n            msg = f\"{original_msg}\\n{PY310_HINT}\"\n            raise InvalidInput(msg) from None </s> add         # Choose the latest version when raising the actual parsing error.\n        assert len(errors) >= 1\n        exc = errors[max(errors)]", "html_url": "https://github.com/psf/black/commit/022f89625f9bb33ab55c82c45ec0eb8512623fd3", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     YES = 2\n <mask> \n <mask> \n <mask> @click.command()\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int, </s> remove         cache = read_cache(line_length, pyi, py36) </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         reformat_one(\n <mask>             src=sources[0],\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             pyi=pyi,\n <mask>             py36=py36,\n <mask>             write_back=write_back,\n <mask>             report=report,\n <mask>         )\n <mask>     else:\n <mask>         loop = asyncio.get_event_loop() </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 schedule_formatting(\n <mask>                     sources=sources,\n <mask>                     line_length=line_length,\n <mask>                     fast=fast,\n <mask>                     pyi=pyi,\n <mask>                     py36=py36,\n <mask>                     write_back=write_back,\n <mask>                     report=report,\n <mask>                     loop=loop,\n <mask>                     executor=executor,\n <mask>                 ) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>                     fast=fast,\n <mask>                     write_back=write_back,\n <mask>                     report=report,\n <mask>                     loop=loop,\n <mask>                     executor=executor,\n <mask>                 ) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def reformat_one(\n <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     py36: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask>  </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask>  </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n <mask>             if format_stdin_to_stdout(\n <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 is_pyi=pyi,\n <mask>                 force_py36=py36,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF: </s> Refactor --pyi and --py36 into FileMode </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove                 force_pyi=pyi,\n                force_py36=py36, </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n <mask>                 cache = read_cache(line_length, pyi, py36)\n <mask>                 src = src.resolve()\n <mask>                 if src in cache and cache[src] == get_cache_info(src):\n <mask>                     changed = Changed.CACHED\n <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src, </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src,\n <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 force_pyi=pyi,\n <mask>                 force_py36=py36,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, pyi, py36) </s> Refactor --pyi and --py36 into FileMode </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         write_cache(cache, formatted, line_length, pyi, py36) </s> add         write_cache(cache, formatted, line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>                 line_length=line_length,\n <mask>                 fast=fast,\n <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, mode)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc: </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove         write_cache(cache, formatted, line_length, pyi, py36) </s> add         write_cache(cache, formatted, line_length, mode) </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> add             src_contents, line_length=line_length, fast=fast, mode=mode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 write_back=write_back,\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length, pyi, py36)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask>  </s> remove         write_cache(cache, formatted, line_length, pyi, py36) </s> add         write_cache(cache, formatted, line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> async def schedule_formatting(\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     py36: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask>     loop: BaseEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None: </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False, </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     cache: Cache = {}\n <mask>     if write_back != WriteBack.DIFF:\n <mask>         cache = read_cache(line_length, pyi, py36)\n <mask>         sources, cached = filter_cached(cache, sources)\n <mask>         for src in cached:\n <mask>             report.done(src, Changed.CACHED)\n <mask>     cancelled = []\n <mask>     formatted = [] </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False, </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 format_file_in_place,\n <mask>                 src,\n <mask>                 line_length,\n <mask>                 fast,\n <mask>                 pyi,\n <mask>                 py36,\n <mask>                 write_back,\n <mask>                 lock,\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         } </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 fast,\n <mask>                 write_back,\n <mask>                 lock,\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         }\n <mask>         pending: Iterable[asyncio.Task] = tasks.keys() </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back == WriteBack.YES and formatted:\n <mask>         write_cache(cache, formatted, line_length, pyi, py36)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int, </s> remove                 write_cache(cache, [src], line_length, pyi, py36) </s> add                 write_cache(cache, [src], line_length, mode) </s> remove                 cache = read_cache(line_length, pyi, py36) </s> add                 cache = read_cache(line_length, mode) </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> add def read_cache(line_length: int, mode: FileMode) -> Cache:", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     force_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask>  </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`. </s> Refactor --pyi and --py36 into FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep keep keep replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     is_pyi = force_pyi or src.suffix == \".pyi\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents,\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode) </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout. </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False, </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> def format_stdin_to_stdout(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length`, `fast`, `is_pyi`, and `force_py36` arguments are passed to </s> Refactor --pyi and --py36 into FileMode </s> remove     is_pyi: bool = False,\n    force_py36: bool = False, </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     is_pyi: bool = False,\n    force_py36: bool = False, </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     src = sys.stdin.read()\n <mask>     dst = src\n <mask>     try:\n <mask>         dst = format_file_contents(\n <mask>             src,\n <mask>             line_length=line_length,\n <mask>             fast=fast,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>         return True\n <mask> \n <mask>     except NothingChanged:\n <mask>         return False\n <mask>  </s> Refactor --pyi and --py36 into FileMode </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> add             src_contents, line_length=line_length, fast=fast, mode=mode </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     newdst = format_str(dst, line_length=line_length, mode=mode) </s> remove         assert_stable(\n            src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode) </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path: </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode) </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     src_contents: str,\n <mask>     *,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it. </s> Refactor --pyi and --py36 into FileMode </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     if src_contents.strip() == \"\":\n <mask>         raise NothingChanged\n <mask> \n <mask>     dst_contents = format_str(\n <mask>         src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n <mask>     )\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged\n <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents) </s> remove         assert_stable(\n            src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode) </s> remove             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> add             src_contents, line_length=line_length, fast=fast, mode=mode </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> remove                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> add                 line_length=line_length, fast=fast, write_back=write_back, mode=mode </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     newdst = format_str(dst, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace keep keep keep keep replace replace replace replace replace keep", "code_tokens": " <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(\n <mask>             src_contents,\n <mask>             dst_contents,\n <mask>             line_length=line_length,\n <mask>             is_pyi=is_pyi,\n <mask>             force_py36=force_py36,\n <mask>         )\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(\n <mask>     src_contents: str,\n <mask>     line_length: int,\n <mask>     *,\n <mask>     is_pyi: bool = False,\n <mask>     force_py36: bool = False,\n <mask> ) -> FileContent: </s> Refactor --pyi and --py36 into FileMode </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     newdst = format_str(dst, line_length=line_length, mode=mode) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     elt = EmptyLineTracker(is_pyi=is_pyi)\n <mask>     py36 = force_py36 or is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0 </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> remove     is_pyi = force_pyi or src.suffix == \".pyi\" </s> add     if src.suffix == \".pyi\":\n        mode |= FileMode.PYI </s> add class FileMode(Flag):\n    AUTO_DETECT = 0\n    PYTHON36 = 1\n    PYI = 2 </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove     dst_contents = format_str(\n        src_contents, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     dst_contents = format_str(src_contents, line_length=line_length, mode=mode) </s> remove         dst = format_file_contents(\n            src,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36,\n        ) </s> add         dst = format_file_contents(src, line_length=line_length, fast=fast, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0\n <mask>     for current_line in lines.visit(src_node):\n <mask>         for _ in range(after):\n <mask>             dst_contents += str(empty_line)\n <mask>         before, after = elt.maybe_empty_lines(current_line) </s> remove     elt = EmptyLineTracker(is_pyi=is_pyi)\n    py36 = force_py36 or is_python36(src_node) </s> add     is_pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node) </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path: </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove         cache = read_cache(line_length, pyi, py36) </s> add         cache = read_cache(line_length, mode) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> def assert_stable(\n <mask>     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n <mask> ) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(\n <mask>         dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n <mask>     )\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"), </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False, </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return False\n <mask> \n <mask> \n <mask> def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n <mask>     return (\n <mask>         CACHE_DIR\n <mask>         / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n <mask>     )\n <mask>  </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> add def read_cache(line_length: int, mode: FileMode) -> Cache: </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False, </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False </s> add     src: str, dst: str, line_length: int, mode: FileMode = FileMode.AUTO_DETECT </s> remove     is_pyi: bool = False,\n    force_py36: bool = False,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask> def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue.\n <mask>     \"\"\"\n <mask>     cache_file = get_cache_file(line_length, pyi, py36)\n <mask>     if not cache_file.exists():\n <mask>         return {}\n <mask> \n <mask>     with cache_file.open(\"rb\") as fobj: </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False, </s> add     cache: Cache, sources: List[Path], line_length: int, mode: FileMode </s> add     mode: FileMode = FileMode.AUTO_DETECT, </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path: </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep replace keep keep", "code_tokens": " <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(\n <mask>     cache: Cache,\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     pyi: bool = False,\n <mask>     py36: bool = False,\n <mask> ) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length, pyi, py36)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists(): </s> remove def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> add def read_cache(line_length: int, mode: FileMode) -> Cache: </s> remove def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path: </s> add def get_cache_file(line_length: int, mode: FileMode) -> Path:\n    pyi = bool(mode & FileMode.PYI)\n    py36 = bool(mode & FileMode.PYTHON36) </s> remove     cache_file = get_cache_file(line_length, pyi, py36) </s> add     cache_file = get_cache_file(line_length, mode) </s> remove     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> add     src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT </s> add     mode: FileMode = FileMode.AUTO_DETECT,", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_stub(self) -> None:\n <mask>         source, expected = read_data(\"stub.pyi\")\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> remove         actual = fs(source, is_pyi=True) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     newdst = format_str(dst, line_length=line_length, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep replace keep replace", "code_tokens": " <mask>         source, expected = read_data(\"stub.pyi\")\n <mask>         actual = fs(source, is_pyi=True)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_cache_broken_file(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             with cache_file.open(\"w\") as fobj:\n <mask>                 fobj.write(\"this is not a pickle\") </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     def test_cache_broken_file(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             with cache_file.open(\"w\") as fobj:\n <mask>                 fobj.write(\"this is not a pickle\")\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n <mask>             src = (workspace / \"test.py\").resolve() </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(src, cache)\n <mask> \n <mask>     def test_cache_single_file_already_cached(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve() </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertIn(src, cache)\n <mask> \n <mask>     def test_cache_single_file_already_cached(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n <mask>             result = CliRunner().invoke(black.main, [str(src)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with src.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask>  </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_cache_multiple_files(self) -> None:\n <mask>         with cache_dir() as workspace, patch(\n <mask>             \"black.ProcessPoolExecutor\", new=ThreadPoolExecutor\n <mask>         ):\n <mask>             one = (workspace / \"one.py\").resolve()\n <mask>             with one.open(\"w\") as fobj: </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1) </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 fobj.write(\"print('hello')\")\n <mask>             two = (workspace / \"two.py\").resolve()\n <mask>             with two.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH)\n <mask>             result = CliRunner().invoke(black.main, [str(workspace)])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with one.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask>             with two.open(\"r\") as fobj: </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with one.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), \"print('hello')\")\n <mask>             with two.open(\"r\") as fobj:\n <mask>                 self.assertEqual(fobj.read(), 'print(\"hello\")\\n')\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(one, cache)\n <mask>             self.assertIn(two, cache)\n <mask> \n <mask>     def test_no_cache_when_writeback_diff(self) -> None:\n <mask>         with cache_dir() as workspace: </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_no_cache_when_writeback_diff(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src), \"--diff\"]) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with src.open(\"w\") as fobj:\n <mask>                 fobj.write(\"print('hello')\")\n <mask>             result = CliRunner().invoke(black.main, [str(src), \"--diff\"])\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\") </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\")\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertFalse(cache_file.exists()) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def test_no_cache_when_stdin(self) -> None:\n <mask>         with cache_dir():\n <mask>             result = CliRunner().invoke(black.main, [\"-\"], input=\"print('hello')\")\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             self.assertFalse(cache_file.exists())\n <mask> \n <mask>     def test_read_cache_no_cachefile(self) -> None:\n <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch() </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         with cache_dir():\n <mask>             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {})\n <mask> \n <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch()\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertIn(src, cache) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_write_cache_read_cache(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             src = (workspace / \"test.py\").resolve()\n <mask>             src.touch()\n <mask>             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertIn(src, cache)\n <mask>             self.assertEqual(cache[src], black.get_cache_info(src))\n <mask> \n <mask>     def test_filter_cached(self) -> None:\n <mask>         with TemporaryDirectory() as workspace: </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH), {}) </s> add             self.assertEqual(black.read_cache(black.DEFAULT_LINE_LENGTH, mode), {}) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>             self.assertEqual(todo, [uncached, cached_but_changed])\n <mask>             self.assertEqual(done, [cached])\n <mask> \n <mask>     def test_write_cache_creates_directory_if_needed(self) -> None:\n <mask>         with cache_dir(exists=False) as workspace:\n <mask>             self.assertFalse(workspace.exists())\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode)\n <mask>             self.assertTrue(workspace.exists())\n <mask> \n <mask>     @event_loop(close=False) </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1) </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             with clean.open(\"w\") as fobj:\n <mask>                 fobj.write('print(\"hello\")\\n')\n <mask>             result = CliRunner().invoke(black.main, [str(workspace)])\n <mask>             self.assertEqual(result.exit_code, 123)\n <mask>             cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(failing, cache)\n <mask>             self.assertIn(clean, cache)\n <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock: </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock:\n <mask>             mock.side_effect = OSError\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode)\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_check_diff_use_together(self) -> None: </s> remove             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1) </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_write_cache_write_fail(self) -> None:\n <mask>         with cache_dir(), patch.object(Path, \"open\") as mock:\n <mask>             mock.side_effect = OSError\n <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n <mask> \n <mask>     @event_loop(close=False)\n <mask>     def test_check_diff_use_together(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Files which will be reformatted. </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> remove             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH) </s> add             cache_file = black.get_cache_file(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_read_cache_line_lengths(self) -> None:\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             path.touch()\n <mask>             black.write_cache({}, [path], 1, mode)\n <mask>             one = black.read_cache(1, mode)\n <mask>             self.assertIn(path, one) </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1) </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> remove             two = black.read_cache(2) </s> add             two = black.read_cache(2, mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode) </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep", "code_tokens": " <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             path.touch()\n <mask>             black.write_cache({}, [path], 1)\n <mask>             one = black.read_cache(1)\n <mask>             self.assertIn(path, one)\n <mask>             two = black.read_cache(2)\n <mask>             self.assertNotIn(path, two)\n <mask>  </s> add         mode = black.FileMode.AUTO_DETECT </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [one], black.DEFAULT_LINE_LENGTH, mode) </s> remove             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             black.write_cache({}, [src], black.DEFAULT_LINE_LENGTH, mode)\n            cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def test_single_file_force_pyi(self) -> None:\n <mask>         contents, expected = read_data(\"force_pyi\")\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             with open(path, \"w\") as fh:\n <mask>                 fh.write(contents)\n <mask>             result = CliRunner().invoke(black.main, [str(path), \"--pyi\"]) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> remove             black.write_cache({}, [path], 1)\n            one = black.read_cache(1) </s> add             black.write_cache({}, [path], 1, mode)\n            one = black.read_cache(1, mode) </s> add         mode = black.FileMode.AUTO_DETECT </s> add         mode = black.FileMode.AUTO_DETECT", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             self.assertEqual(result.exit_code, 0)\n <mask>             with open(path, \"r\") as fh:\n <mask>                 actual = fh.read()\n <mask>             # verify cache with --pyi is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n <mask>             self.assertIn(path, pyi_cache)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(path, normal_cache)\n <mask>         self.assertEqual(actual, expected)\n <mask>  </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True) </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 with open(path, \"r\") as fh:\n <mask>                     actual = fh.read()\n <mask>                 self.assertEqual(actual, expected)\n <mask>             # verify cache with --pyi is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             for path in paths:\n <mask>                 self.assertIn(path, pyi_cache)\n <mask>                 self.assertNotIn(path, normal_cache)\n <mask> \n <mask>     def test_pipe_force_pyi(self) -> None: </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True) </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         actual = result.output\n <mask>         self.assertFormatEqual(actual, expected)\n <mask> \n <mask>     def test_single_file_force_py36(self) -> None:\n <mask>         source, expected = read_data(\"force_py36\")\n <mask>         with cache_dir() as workspace:\n <mask>             path = (workspace / \"file.py\").resolve()\n <mask>             with open(path, \"w\") as fh: </s> Refactor --pyi and --py36 into FileMode </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        pyi_mode = black.FileMode.PYI </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> add         mode = black.FileMode.AUTO_DETECT </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>                 actual = fh.read()\n <mask>             # verify cache with --py36 is separate\n <mask>             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n <mask>             self.assertIn(path, py36_cache)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             self.assertNotIn(path, normal_cache) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             cache = black.read_cache(black.DEFAULT_LINE_LENGTH, mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     @event_loop(close=False)\n <mask>     def test_multi_file_force_py36(self) -> None:\n <mask>         source, expected = read_data(\"force_py36\")\n <mask>         with cache_dir() as workspace:\n <mask>             paths = [\n <mask>                 (workspace / \"file1.py\").resolve(), </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36 </s> remove         black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> add         black.assert_stable(source, actual, line_length=ll, mode=mode) </s> remove         actual = fs(source, is_pyi=True) </s> add         actual = fs(source, mode=mode)", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 with open(path, \"r\") as fh:\n <mask>                     actual = fh.read()\n <mask>                 self.assertEqual(actual, expected)\n <mask>             # verify cache with --py36 is separate\n <mask>             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True)\n <mask>             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH)\n <mask>             for path in paths:\n <mask>                 self.assertIn(path, pyi_cache)\n <mask>                 self.assertNotIn(path, normal_cache)\n <mask> \n <mask>     def test_pipe_force_py36(self) -> None: </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode)\n            normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi=True) </s> add             pyi_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, pyi_mode) </s> remove             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36=True) </s> add             py36_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, py36_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> remove             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH) </s> add             normal_cache = black.read_cache(black.DEFAULT_LINE_LENGTH, reg_mode) </s> add         reg_mode = black.FileMode.AUTO_DETECT\n        py36_mode = black.FileMode.PYTHON36", "html_url": "https://github.com/psf/black/commit/023e61a2545b70750d47fe31ac5265ffced16a0c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> \n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> ) </s> use versioneer to manage __version__ (#981) </s> remove __version__ = \"19.3b0\" </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__)) </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> \n <mask> __version__ = \"19.3b0\"\n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> )\n <mask> DEFAULT_INCLUDES = r\"\\.pyi?$\" </s> use versioneer to manage __version__ (#981) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__)) </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> DEFAULT_EXCLUDES = (\n <mask>     r\"/(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist)/\"\n <mask> )\n <mask> DEFAULT_INCLUDES = r\"\\.pyi?$\"\n <mask> CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n <mask> \n <mask> \n <mask> # types\n <mask> FileContent = str\n <mask> Encoding = str </s> use versioneer to manage __version__ (#981) </s> remove __version__ = \"19.3b0\" </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from setuptools import setup\n <mask> import sys\n <mask> \n <mask> assert sys.version_info >= (3, 6, 0), \"black requires Python 3.6+\"\n <mask> from pathlib import Path  # noqa E402\n <mask> \n <mask> CURRENT_DIR = Path(__file__).parent\n <mask>  </s> use versioneer to manage __version__ (#981) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__)) </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> remove def get_version() -> str:\n    black_py = CURRENT_DIR / \"black.py\"\n    _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n    with open(black_py, \"r\", encoding=\"utf8\") as f:\n        match = _version_re.search(f.read())\n        version = match.group(\"version\") if match is not None else '\"unknown\"'\n    return str(ast.literal_eval(version))", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     with open(readme_md, encoding=\"utf8\") as ld_file:\n <mask>         return ld_file.read()\n <mask> \n <mask> \n <mask> def get_version() -> str:\n <mask>     black_py = CURRENT_DIR / \"black.py\"\n <mask>     _version_re = re.compile(r\"__version__\\s+=\\s+(?P<version>.*)\")\n <mask>     with open(black_py, \"r\", encoding=\"utf8\") as f:\n <mask>         match = _version_re.search(f.read())\n <mask>         version = match.group(\"version\") if match is not None else '\"unknown\"'\n <mask>     return str(ast.literal_eval(version))\n <mask> \n <mask> \n <mask> setup(\n <mask>     name=\"black\",\n <mask>     version=get_version(),\n <mask>     description=\"The uncompromising code formatter.\",\n <mask>     long_description=get_long_description(), </s> use versioneer to manage __version__ (#981) </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__)) </s> add CACHE_DIR = Path(user_cache_dir(\"black\", version=__git_version__)) </s> add from _version import get_versions\n\nv = get_versions()\n__version__ = v.get(\"closest-tag\", v[\"version\"])\n__git_version__ = v.get(\"full-revisionid\") </s> remove __version__ = \"19.3b0\" </s> add", "html_url": "https://github.com/psf/black/commit/025d2ca4ba4f8e6e1f5915751eba972975dd9ff9", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             input=BytesIO(source.encode(\"utf8\")),\n <mask>         )\n <mask>         self.assertEqual(result.exit_code, 0)\n <mask>         self.assertFormatEqual(expected, result.output)\n <mask>         black.assert_equivalent(source, result.output)\n <mask>         black.assert_stable(source, result.output, DEFAULT_MODE)\n <mask> \n <mask>     def test_piping_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n <mask>             r\"\\+\\d\\d\\d\\d\" </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode) </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove         self.assertFalse(ff(path))", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             error=fail,\n <mask>             critical=fail,\n <mask>             log=fail,\n <mask>         ):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     def test_invalid_config_return_code(self) -> None:\n <mask>         tmp_file = Path(black.dump_to_file())\n <mask>         try:\n <mask>             tmp_config = Path(black.dump_to_file()) </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         self.assertFalse(ff(path)) </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode) </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE) </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE)", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from tests.util import (\n <mask>     BlackBaseTestCase,\n <mask>     fs,\n <mask>     ff,\n <mask>     DEFAULT_MODE,\n <mask>     dump_to_stderr,\n <mask>     read_data,\n <mask>     THIS_DIR,\n <mask> ) </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE) </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE) </s> remove         self.assertFalse(ff(path)) </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode) </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode)", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename\n <mask>         self.check_file(str(path), DEFAULT_MODE, data=False)\n <mask>         self.assertFalse(ff(path))\n <mask> \n <mask>     def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n <mask>         source, expected = read_data(filename, data=data)\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual) </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, mode) </s> add         if source != actual:\n            black.assert_equivalent(source, actual)\n            black.assert_stable(source, actual, mode) </s> remove             ff(THIS_FILE) </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE) </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE)", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n <mask>         source, expected = read_data(filename, data=data)\n <mask>         actual = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, mode) </s> Speed up tests even more (#2205)\n\nThere's three optimizations in this commit:\r\n\r\n1. Don't check if Black's output is stable or equivalant if no changes\r\n   were made in the first place. It's not like passing the same code\r\n   (for both source and actual) through black.assert_equivalent or\r\n   black.assert_stable is useful. It's not a big deal for the smaller\r\n   tests, but it eats a lot of time in tests/test_format.py since\r\n   its test cases are big. This is also closer to how Black works IRL.\r\n\r\n2. Use a smaller file for `test_root_logger_not_used_directly` since\r\n   the logging it's checking happens during blib2to3's startup so the\r\n   file doesn't really matter.\r\n\r\n3. If we're checking a file is formatting (i.e. test_source_is_formatted)\r\n   don't run Black over it again with `black.format_file_in_place`.\r\n   `tests/test_format.py::TestSimpleFormat.check_file` is good enough. </s> remove         self.assertFalse(ff(path)) </s> remove         black.assert_equivalent(source, result.output)\n        black.assert_stable(source, result.output, DEFAULT_MODE) </s> add         if source != result.output:\n            black.assert_equivalent(source, result.output)\n            black.assert_stable(source, result.output, DEFAULT_MODE)", "html_url": "https://github.com/psf/black/commit/036bea4aa0e2b9b3fe50d0d49addc811cce61fa4", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep", "code_tokens": " <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v1\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v1\n <mask>         with: </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove         uses: actions/setup-python@v1 </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1 </s> add       - uses: actions/checkout@v2", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>     steps:\n <mask>       - uses: actions/checkout@v1\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v1\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies\n </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".github/workflows/test.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         require_serial: true\n <mask>         types: [python]\n <mask> \n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.7.9\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove       - uses: actions/checkout@v1 </s> add       - uses: actions/checkout@v2 </s> remove         uses: actions/setup-python@v1 </s> add         uses: actions/setup-python@v2 </s> remove         uses: actions/setup-python@v1 </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1 </s> add       - uses: actions/checkout@v2", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy\n <mask>     rev: v0.761\n <mask>     hooks:\n <mask>       - id: mypy\n <mask>         exclude: ^docs/conf.py\n <mask> \n <mask>   - repo: https://github.com/prettier/prettier </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove     rev: 3.7.9 </s> remove       - uses: actions/checkout@v1 </s> add       - uses: actions/checkout@v2 </s> remove         uses: actions/setup-python@v1 </s> add         uses: actions/setup-python@v2 </s> remove         uses: actions/setup-python@v1 </s> add         uses: actions/setup-python@v2 </s> remove       - uses: actions/checkout@v1 </s> add       - uses: actions/checkout@v2", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     target_version = config.get(\"target_version\")\n <mask>     if target_version is not None and not isinstance(target_version, list):\n <mask>         raise click.BadOptionUsage(\n <mask>             \"target-version\", f\"Config key target-version must be a list\"\n <mask>         )\n <mask> \n <mask>     default_map: Dict[str, Any] = {}\n <mask>     if ctx.default_map:\n <mask>         default_map.update(ctx.default_map) </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # only report an unsplittable 'type: ignore' if this line was\n <mask>         # one line in the original code.\n <mask> \n <mask>         # Grab the first and last line numbers, skipping generated leaves\n <mask>         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n <mask>         last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0)\n <mask> \n <mask>         if first_line == last_line:\n <mask>             # We look at the last two leaves since a comma or an\n <mask>             # invisible paren could have been added at the end of the\n <mask>             # line. </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str: </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove                 and not any(l.type == token.COMMA for l in leaves) </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         # mission and return the original line in the end, or attempt a different\n <mask>         # split altogether.\n <mask>         result: List[Line] = []\n <mask>         try:\n <mask>             for l in transform(line, features):\n <mask>                 if str(l).strip(\"\\n\") == line_str:\n <mask>                     raise CannotTransform(\n <mask>                         \"Line transformer returned an unchanged result\"\n <mask>                     )\n <mask> \n <mask>                 result.extend( </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0) </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove                 and not any(l.type == token.COMMA for l in leaves) </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     )\n <mask> \n <mask>                 result.extend(\n <mask>                     transform_line(\n <mask>                         l,\n <mask>                         line_length=line_length,\n <mask>                         normalize_strings=normalize_strings,\n <mask>                         features=features,\n <mask>                     )\n <mask>                 ) </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str: </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\" </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove             \"target-version\", f\"Config key target-version must be a list\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # be careful not to add one after any comments or within type annotations.\n <mask>             no_commas = (\n <mask>                 original.is_def\n <mask>                 and opening_bracket.value == \"(\"\n <mask>                 and not any(l.type == token.COMMA for l in leaves)\n <mask>             )\n <mask> \n <mask>             if original.is_import or no_commas:\n <mask>                 for i in range(len(leaves) - 1, -1, -1):\n <mask>                     if leaves[i].type == STANDALONE_COMMENT: </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str: </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0) </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask> \n <mask>     @wraps(split_func)\n <mask>     def split_wrapper(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:\n <mask>         for l in split_func(line, features):\n <mask>             normalize_prefix(l.leaves[0], inside_brackets=True)\n <mask>             yield l\n <mask> \n <mask>     return split_wrapper\n <mask> \n <mask> \n <mask> @dont_increase_indentation </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str: </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str: </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0) </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove                 and not any(l.type == token.COMMA for l in leaves) </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves) </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LOG.debug(f\"Creating {work_path}\")\n <mask>         work_path.mkdir()\n <mask> \n <mask>     if not which(\"black\"):\n <mask>         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\")\n <mask>         return -1\n <mask> \n <mask>     try:\n <mask>         ret_val = await lib.process_queue(\n <mask>             config, work_path, workers, keep, long_checkouts, rebase </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove         LOG.error(f\"No git binary found\") </s> add         LOG.error(\"No git binary found\") </s> remove             \"target-version\", f\"Config key target-version must be a list\" </s> add             \"target-version\", \"Config key target-version must be a list\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/cli.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         f\" - {results.stats['skipped_long_checkout']} skipped due to long checkout\"\n <mask>     )\n <mask> \n <mask>     if results.failed_projects:\n <mask>         click.secho(f\"\\nFailed Projects:\\n\", bold=True)\n <mask> \n <mask>     for project_name, project_cpe in results.failed_projects.items():\n <mask>         print(f\"## {project_name}:\")\n <mask>         print(f\" - Returned {project_cpe.returncode}\")\n <mask>         if project_cpe.stderr: </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove         LOG.error(f\"Can not find 'black' executable in PATH. No point in running\") </s> add         LOG.error(\"Can not find 'black' executable in PATH. No point in running\") </s> remove             \"target-version\", f\"Config key target-version must be a list\" </s> add             \"target-version\", \"Config key target-version must be a list\"", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> Optional[Path]:\n <mask>     \"\"\"git Clone project or rebase\"\"\"\n <mask>     git_bin = str(which(\"git\"))\n <mask>     if not git_bin:\n <mask>         LOG.error(f\"No git binary found\")\n <mask>         return None\n <mask> \n <mask>     repo_url_parts = urlparse(project_config[\"git_clone_url\"])\n <mask>     path_parts = repo_url_parts.path[1:].split(\"/\", maxsplit=1)\n <mask>  </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             \"target-version\", f\"Config key target-version must be a list\" </s> add             \"target-version\", \"Config key target-version must be a list\" </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves)", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         black.assert_stable(source, result.output, black.FileMode())\n <mask> \n <mask>     def test_piping_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n <mask>             rf\"\\+\\d\\d\\d\\d\"\n <mask>         )\n <mask>         source, _ = read_data(\"expression.py\")\n <mask>         expected, _ = read_data(\"expression.diff\")\n <mask>         config = THIS_DIR / \"data\" / \"empty_pyproject.toml\"\n <mask>         args = [ </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> add             r\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\") </s> add         LOG.error(\"No git binary found\") </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\" </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove         first_line = next((l.lineno for l in self.leaves if l.lineno != 0), 0)\n        last_line = next((l.lineno for l in reversed(self.leaves) if l.lineno != 0), 0) </s> add         first_line = next((leaf.lineno for leaf in self.leaves if leaf.lineno != 0), 0)\n        last_line = next(\n            (leaf.lineno for leaf in reversed(self.leaves) if leaf.lineno != 0), 0\n        ) </s> remove             for l in transform(line, features):\n                if str(l).strip(\"\\n\") == line_str: </s> add             for transformed_line in transform(line, features):\n                if str(transformed_line).strip(\"\\n\") == line_str:", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @unittest_run_loop\n <mask>     async def test_blackd_diff(self) -> None:\n <mask>         diff_header = re.compile(\n <mask>             rf\"(In|Out)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \\+\\d\\d\\d\\d\"\n <mask>         )\n <mask> \n <mask>         source, _ = read_data(\"blackd_diff.py\")\n <mask>         expected, _ = read_data(\"blackd_diff.diff\")\n <mask>  </s> Update and fix Flake8 (#1424)\n\n* Update pre-commit\r\n\r\n* Fix F541 f-string is missing placeholders\r\n\r\n* Fix E741 ambiguous variable name 'l'\r\n\r\n* Update actions to v2 </s> remove             rf\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            rf\"\\+\\d\\d\\d\\d\" </s> add             r\"(STDIN|STDOUT)\\t\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d\\.\\d\\d\\d\\d\\d\\d \"\n            r\"\\+\\d\\d\\d\\d\" </s> remove         LOG.error(f\"No git binary found\") </s> add         LOG.error(\"No git binary found\") </s> remove         for l in split_func(line, features):\n            normalize_prefix(l.leaves[0], inside_brackets=True)\n            yield l </s> add         for line in split_func(line, features):\n            normalize_prefix(line.leaves[0], inside_brackets=True)\n            yield line </s> remove             \"target-version\", f\"Config key target-version must be a list\" </s> add             \"target-version\", \"Config key target-version must be a list\" </s> remove                 and not any(l.type == token.COMMA for l in leaves) </s> add                 and not any(leaf.type == token.COMMA for leaf in leaves)", "html_url": "https://github.com/psf/black/commit/03b8304abd2ce5d29789f8a2b220143529fa5d90", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> on:\n <mask>   push:\n <mask>     branches:\n <mask>       - \"master\"\n <mask> \n <mask> jobs:\n <mask>   docker:\n <mask>     runs-on: ubuntu-latest\n <mask>     steps:\n <mask>       - name: Checkout\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> remove           tags: pyfound/black:latest\n </s> add           tags: pyfound/black:latest,pyfound/black:${{ env.GIT_TAG }} </s> add       - name: Check + set version tag\n        run:\n          echo \"GIT_TAG=$(git describe --candidates=0 --tags 2> /dev/null || echo\n          latest_non_release)\" >> $GITHUB_ENV\n", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         with:\n <mask>           username: ${{ secrets.DOCKERHUB_USERNAME }}\n <mask>           password: ${{ secrets.DOCKERHUB_TOKEN }}\n <mask> \n <mask>       - name: Build and push\n <mask>         uses: docker/build-push-action@v2\n <mask>         with:\n <mask>           context: .\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> remove           tags: pyfound/black:latest\n </s> add           tags: pyfound/black:latest,pyfound/black:${{ env.GIT_TAG }} </s> add   release:\n    types: created", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep", "code_tokens": " <mask>         with:\n <mask>           context: .\n <mask>           platforms: linux/amd64,linux/arm64\n <mask>           push: true\n <mask>           tags: pyfound/black:latest\n <mask> \n <mask>       - name: Image digest\n <mask>         run: echo ${{ steps.docker_build.outputs.digest }}\n </s> Add automatic version tagging to Docker CI Pushes (#2132)\n\n* Add automatic version tagging to Docker Uploads\r\n- If the git comment has a tag, set that on the docker images pushed\r\n- If we don't have a tag, we just set `latest_non_release`\r\n\r\n* Add trigger on release creation too\r\n\r\n* Make prettier happy omn docker.yml </s> add       - name: Check + set version tag\n        run:\n          echo \"GIT_TAG=$(git describe --candidates=0 --tags 2> /dev/null || echo\n          latest_non_release)\" >> $GITHUB_ENV\n </s> add   release:\n    types: created", "html_url": "https://github.com/psf/black/commit/04fd4432f6c6007e419d7174930569a75ea60fed", "file_name": ".github/workflows/docker.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             before = 0\n <mask>         depth = current_line.depth\n <mask>         while self.previous_defs and self.previous_defs[-1] >= depth:\n <mask>             if self.is_pyi:\n <mask>                 before = 0 if depth else 1\n <mask>             else:\n <mask>                 if depth:\n <mask>                     before = 1\n <mask>                 elif (\n <mask>                     not depth </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1 </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1) </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "src/black/lines.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                     newlines = 1\n <mask>             elif (\n <mask>                 current_line.is_def or current_line.is_decorator\n <mask>             ) and not self.previous_line.is_def:\n <mask>                 # Blank line between a block of functions (maybe with preceding\n <mask>                 # decorators) and a block of non-functions\n <mask>                 newlines = 1\n <mask>             else:\n <mask>                 newlines = 0\n <mask>         else:\n <mask>             newlines = 2\n <mask>         if current_line.depth and newlines: </s> add                 assert self.previous_line is not None\n                if depth and not current_line.is_def and self.previous_line.is_def:\n                    # Empty lines between attributes and methods should be preserved.\n                    before = min(1, before)\n                elif depth:\n                    before = 0\n                else:\n                    before = 1 </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "src/black/lines.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> def f(): ...\n <mask> \n <mask> class C:\n <mask>     ...\n <mask> \n <mask> class B: </s> Stubs: preserve blank line between attributes and methods (#2736) </s> add class D: ... </s> remove class B: ... </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove     ... </s> add     attr: int\n    attr2: str </s> add     attr: int\n    attr2: str", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class C:\n <mask>     ...\n <mask> \n <mask> class B:\n <mask>     ...\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int:\n <mask>         ...\n <mask>  </s> Stubs: preserve blank line between attributes and methods (#2736) </s> remove class B: ... </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add class D: ... </s> add class D: \n    ... </s> add     attr: int\n    attr2: str </s> add     attr: int\n    attr2: str", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     but_this_newline_should_also_be_kept: int\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int:\n <mask>         ...\n <mask> \n <mask>     def g(self) -> str: ...\n <mask>  </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1 </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> def f(): ...\n <mask> \n <mask> class C: ...\n <mask> \n <mask> class B:\n <mask>     this_lack_of_newline_should_be_kept: int\n <mask>     def b(self) -> None: ... </s> remove class B: ... </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1 </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def f(): ...\n <mask> \n <mask> class C: ...\n <mask> class B: ...\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int: ...\n <mask>     def g(self) -> str: ...\n <mask>  </s> add     attr: int\n    attr2: str </s> add     attr: int\n    attr2: str </s> remove     ... </s> add class D: \n    ...", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     but_this_newline_should_also_be_kept: int\n <mask> \n <mask> class A:\n <mask>     def f(self) -> int: ...\n <mask>     def g(self) -> str: ...\n <mask> \n <mask> def g(): ...\n <mask> def h(): ... </s> add class B:\n    this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> add     this_lack_of_newline_should_be_kept: int\n    def b(self) -> None: ...\n\n    but_this_newline_should_also_be_kept: int </s> remove                 # Blank line between a block of functions (maybe with preceding\n                # decorators) and a block of non-functions\n                newlines = 1 </s> add                 if not current_line.depth:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n                else:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved. The +1 offset is to negate the -1 done later as\n                    # this function is indented.\n                    newlines = min(2, before + 1)", "html_url": "https://github.com/psf/black/commit/05e1fbf27d93df36b09c560791ad46c6ce3eb518", "file_name": "tests/data/stub.pyi"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> @click.command(context_settings=dict(help_option_names=[\"-h\", \"--help\"]))\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int,\n </s> Add `black -c \"code\"` (#761) </s> add     if code is not None:\n        print(format_str(code, mode=mode))\n        ctx.exit(0) </s> add     code: Optional[str],", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> def main(\n <mask>     ctx: click.Context,\n <mask>     line_length: int,\n <mask>     target_version: List[TargetVersion],\n <mask>     check: bool,\n <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n </s> Add `black -c \"code\"` (#761) </s> add     if code is not None:\n        print(format_str(code, mode=mode))\n        ctx.exit(0) </s> add @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     if config and verbose:\n <mask>         out(f\"Using configuration from {config}.\", bold=False, fg=\"blue\")\n <mask>     try:\n <mask>         include_regex = re_compile_maybe_verbose(include)\n <mask>     except re.error:\n <mask>         err(f\"Invalid regular expression for include given: {include!r}\")\n <mask>         ctx.exit(2)\n </s> Add `black -c \"code\"` (#761) </s> add     code: Optional[str], </s> add @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")", "html_url": "https://github.com/psf/black/commit/06004cd319a6623a1fc29b582eb81e315179629f", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     # this is mitigated by a try/catch in https://github.com/psf/black/pull/2974/\n <mask>     # this ignore can be removed when support for aiohttp 3.7 is dropped.\n <mask>     '''ignore:Decorator `@unittest_run_loop` is no longer needed in aiohttp 3\\.8\\+:DeprecationWarning''',\n <mask>     # this is mitigated by https://github.com/python/cpython/issues/79071 in python 3.8+\n <mask>     # this ignore can be removed when support for 3.7 is dropped.\n <mask>     '''ignore:Bare functions are deprecated, use async ones:DeprecationWarning''',\n <mask> ] </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731 </s> remove from typing import Awaitable, Callable, Iterable </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "pyproject.toml"}
{"docstring_tokens": "replace keep replace keep keep keep keep keep", "code_tokens": " <mask> from typing import Awaitable, Callable, Iterable\n <mask> \n <mask> from aiohttp.web_middlewares import middleware\n <mask> from aiohttp.web_request import Request\n <mask> from aiohttp.web_response import StreamResponse\n <mask> \n <mask> Handler = Callable[[Request], Awaitable[StreamResponse]]\n <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]] </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731 </s> remove     @middleware  # type: ignore[misc] </s> add     @middleware </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''',", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from aiohttp.web_request import Request\n <mask> from aiohttp.web_response import StreamResponse\n <mask> \n <mask> Handler = Callable[[Request], Awaitable[StreamResponse]]\n <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n <mask> \n <mask> \n <mask> def cors(allow_headers: Iterable[str]) -> Middleware: </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> remove     @middleware  # type: ignore[misc] </s> add     @middleware </s> remove from aiohttp.web_middlewares import middleware </s> add </s> remove     return impl  # type: ignore[no-any-return] </s> add     return impl </s> remove from typing import Awaitable, Callable, Iterable </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''',", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Middleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n <mask> \n <mask> \n <mask> def cors(allow_headers: Iterable[str]) -> Middleware:\n <mask>     @middleware  # type: ignore[misc]\n <mask>     async def impl(request: Request, handler: Handler) -> StreamResponse:\n <mask>         is_options = request.method == \"OPTIONS\"\n <mask>         is_preflight = is_options and \"Access-Control-Request-Method\" in request.headers\n <mask>         if is_preflight:\n <mask>             resp = StreamResponse() </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731 </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''', </s> remove from aiohttp.web_middlewares import middleware </s> remove from typing import Awaitable, Callable, Iterable </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep keep keep replace", "code_tokens": " <mask>             )\n <mask> \n <mask>         return resp\n <mask> \n <mask>     return impl  # type: ignore[no-any-return] </s> Mitigate deprecation of aiohttp's `@middleware` decorator (#3259)\n\nThis is deprecated since aiohttp 4.0. If it doesn't exist just define a\r\nno-op decorator that does nothing (after the other aiohttp imports\r\nthough!). By doing this, it's safe to ignore the DeprecationWarning\r\nwithout needing to require the latest aiohttp once they remove\r\n`@middleware`. </s> remove     @middleware  # type: ignore[misc] </s> add     # this is mitigated by a try/catch in https://github.com/psf/black/pull/3198/\n    # this ignore can be removed when support for aiohttp 3.x is dropped.\n    '''ignore:Middleware decorator is deprecated since 4\\.0 and its behaviour is default, you can simply remove this decorator:DeprecationWarning''', </s> add if TYPE_CHECKING:\n    F = TypeVar(\"F\", bound=Callable[..., Any])\n    middleware: Callable[[F], F]\nelse:\n    try:\n        from aiohttp.web_middlewares import middleware\n    except ImportError:\n        # @middleware is deprecated and its behaviour is the default since aiohttp 4.0\n        # so if it doesn't exist anymore, define a no-op for forward compatibility.\n        middleware = lambda x: x  # noqa: E731 </s> remove from typing import Awaitable, Callable, Iterable </s> add from typing import TYPE_CHECKING, Any, Awaitable, Callable, Iterable, TypeVar", "html_url": "https://github.com/psf/black/commit/062e644aae4299a320aeac59085df4c020ba6c81", "file_name": "src/blackd/middlewares.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         (two on module-level), as well as providing an extra empty line after flow\n <mask>         control keywords to make them more prominent.\n <mask>         \"\"\"\n <mask>         before, after = self._maybe_empty_lines(current_line)\n <mask>         before -= self.previous_after\n <mask>         self.previous_after = after\n <mask>         self.previous_line = current_line </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return </s> add         consumed += len(line) + 1  # adding the length of the split '\\n'", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask>     current_line: Line = Factory(Line)\n <mask> \n <mask>     def line(self, indent: int = 0) -> Iterator[Line]:\n <mask>         \"\"\"Generate a line.\n <mask> \n <mask>         If the line is empty, only emit if it makes sense.\n <mask>         If the line is too long, split it first and then generate.\n <mask>  </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         if not self.current_line:\n <mask>             self.current_line.depth += indent\n <mask>             return  # Line is empty, don't emit. Creating a new one unnecessary.\n <mask> \n <mask>         complete_line = self.current_line\n <mask>         self.current_line = Line(depth=complete_line.depth + indent)\n <mask>         yield complete_line\n <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf): </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         complete_line = self.current_line\n <mask>         self.current_line = type(depth=complete_line.depth + indent)\n <mask>         yield complete_line\n <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf):\n <mask>             any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()\n <mask>             try:\n <mask>                 for comment in generate_comments(node):\n <mask>                     if any_open_brackets: </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node) </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def visit_default(self, node: LN) -> Iterator[Line]:\n <mask>         if isinstance(node, Leaf):\n <mask>             any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()\n <mask>             for comment in generate_comments(node):\n <mask>                 if any_open_brackets:\n <mask>                     # any comment within brackets is subject to splitting\n <mask>                     self.current_line.append(comment)\n <mask>                 elif comment.type == token.COMMENT:\n <mask>                     # regular trailing comment\n <mask>                     self.current_line.append(comment)\n <mask>                     yield from self.line()\n <mask> \n <mask>                 else:\n <mask>                     # regular standalone comment\n <mask>                     yield from self.line()\n <mask> \n <mask>                     self.current_line.append(comment)\n <mask>                     yield from self.line()\n <mask> \n <mask>             normalize_prefix(node, inside_brackets=any_open_brackets)\n <mask>             if node.type not in WHITESPACE:\n <mask>                 self.current_line.append(node)\n <mask>         yield from super().visit_default(node)\n <mask> \n <mask>     def visit_INDENT(self, node: Node) -> Iterator[Line]:\n <mask>         yield from self.line(+1)\n <mask>         yield from self.visit_default(node) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node) </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         yield from self.line(+1)\n <mask>         yield from self.visit_default(node)\n <mask> \n <mask>     def visit_DEDENT(self, node: Node) -> Iterator[Line]:\n <mask>         yield from self.line(-1)\n <mask> \n <mask>     def visit_stmt(self, node: Node, keywords: Set[str]) -> Iterator[Line]:\n <mask>         \"\"\"Visit a statement. </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>     def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:\n <mask>         yield from self.visit_default(leaf)\n <mask>         yield from self.line()\n <mask> \n <mask>     def __attrs_post_init__(self) -> None:\n <mask>         \"\"\"You are in a twisty little maze of passages.\"\"\"\n <mask>         v = self.visit_stmt\n <mask>         self.visit_if_stmt = partial(v, keywords={'if', 'else', 'elif'})\n <mask>         self.visit_while_stmt = partial(v, keywords={'while', 'else'}) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         return\n <mask> \n <mask>     nlines = 0\n <mask>     for index, line in enumerate(p.split('\\n')):\n <mask>         consumed += len(line) + 1  # adding the length of the split '\\n'\n <mask>         line = line.lstrip()\n <mask>         if not line: </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     nlines = 0\n <mask>     for index, line in enumerate(p.split('\\n')):\n <mask>         line = line.lstrip()\n <mask>         if not line:\n <mask>             nlines += 1\n <mask>         if not line.startswith('#'):\n <mask>             continue </s> add     consumed = 0 </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> add     if isinstance(line, UnformattedLines):\n        yield line\n        return </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add         if isinstance(current_line, UnformattedLines):\n            return 0, 0 </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if index == 0 and leaf.type != token.ENDMARKER:\n <mask>             comment_type = token.COMMENT  # simple trailing comment\n <mask>         else:\n <mask>             comment_type = STANDALONE_COMMENT\n <mask>         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines)\n <mask> \n <mask>         nlines = 0\n <mask> \n <mask> \n <mask> def make_comment(content: str) -> str: </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add     consumed = 0 </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     If `py36` is True, splitting may generate syntax that is only compatible\n <mask>     with Python 3.6 and later.\n <mask>     \"\"\"\n <mask>     line_str = str(line).strip('\\n')\n <mask>     if len(line_str) <= line_length and '\\n' not in line_str:\n <mask>         yield line\n <mask>         return\n <mask>  </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> remove             self.current_line.depth += indent </s> add             if self.current_line.__class__ == type:\n                self.current_line.depth += indent\n            else:\n                self.current_line = type(depth=self.current_line.depth + indent) </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add         consumed += len(line) + 1  # adding the length of the split '\\n' </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "black.py"}
{"docstring_tokens": "add keep keep keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> # Some license here.\n <mask> #\n <mask> # Has many lines. Many, many lines.\n <mask> # Many, many, many lines.\n <mask> \"\"\"Module docstring.\n <mask>  </s> remove             for comment in generate_comments(node):\n                if any_open_brackets:\n                    # any comment within brackets is subject to splitting\n                    self.current_line.append(comment)\n                elif comment.type == token.COMMENT:\n                    # regular trailing comment\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n                else:\n                    # regular standalone comment\n                    yield from self.line()\n\n                    self.current_line.append(comment)\n                    yield from self.line()\n\n            normalize_prefix(node, inside_brackets=any_open_brackets)\n            if node.type not in WHITESPACE:\n                self.current_line.append(node) </s> add             try:\n                for comment in generate_comments(node):\n                    if any_open_brackets:\n                        # any comment within brackets is subject to splitting\n                        self.current_line.append(comment)\n                    elif comment.type == token.COMMENT:\n                        # regular trailing comment\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n                    else:\n                        # regular standalone comment\n                        yield from self.line()\n\n                        self.current_line.append(comment)\n                        yield from self.line()\n\n            except FormatOff as f_off:\n                f_off.trim_prefix(node)\n                yield from self.line(type=UnformattedLines)\n                yield from self.visit(node)\n\n            except FormatOn as f_on:\n                # This only happens here if somebody says \"fmt: on\" multiple\n                # times in a row.\n                f_on.trim_prefix(node)\n                yield from self.visit_default(node)\n\n            else:\n                normalize_prefix(node, inside_brackets=any_open_brackets)\n                if node.type not in WHITESPACE:\n                    self.current_line.append(node) </s> add         # DEDENT has no value. Additionally, in blib2to3 it never holds comments. </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent)", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "tests/comments.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         # black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     def test_report(self) -> None:\n <mask>         report = black.Report()\n <mask>         out_lines = []\n <mask>         err_lines = [] </s> add     def visit_unformatted(self, node: LN) -> Iterator[Line]:\n        if isinstance(node, Node):\n            for child in node.children:\n                yield from self.visit(child)\n\n        else:\n            try:\n                self.current_line.append(node)\n            except FormatOn as f_on:\n                f_on.trim_prefix(node)\n                yield from self.line()\n                yield from self.visit(node) </s> remove         self.current_line = Line(depth=complete_line.depth + indent) </s> add         self.current_line = type(depth=complete_line.depth + indent) </s> add     def visit(self, node: LN) -> Iterator[Line]:\n        \"\"\"High-level entry point to the visitor.\"\"\"\n        if isinstance(self.current_line, UnformattedLines):\n            # File contained `# fmt: off`\n            yield from self.visit_unformatted(node)\n\n        else:\n            yield from super().visit(node) </s> remove         yield Leaf(comment_type, make_comment(line), prefix='\\n' * nlines) </s> add         comment = make_comment(line)\n        yield Leaf(comment_type, comment, prefix='\\n' * nlines)\n\n        if comment in {'# fmt: on', '# yapf: enable'}:\n            raise FormatOn(consumed)\n\n        if comment in {'# fmt: off', '# yapf: disable'}:\n            raise FormatOff(consumed) </s> remove     def line(self, indent: int = 0) -> Iterator[Line]: </s> add     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/0677a539370b296399854e427ce7df2955ecfe57", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> [flake8]\n <mask> extend-ignore = E203, E266, E501\n <mask> # line length is intentionally set to 80 here because black uses Bugbear\n <mask> # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details\n <mask> max-line-length = 80\n <mask> max-complexity = 18\n <mask> select = B,C,E,F,W,T4,B9\n <mask> # We need to configure the mypy.ini because the flake8-mypy's default\n <mask> # options don't properly override it, so if we don't specify it we get </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove             version = \"master\" </s> remove     git_switch_branch(\"master\", repo=options.black_repo) </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove         git_switch_branch(\"master\", repo=repo) </s> add         git_switch_branch(\"main\", repo=repo)", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def get_package_source(package: str, version: Optional[str]) -> str:\n <mask>     if package == \"cpython\":\n <mask>         if version is None:\n <mask>             version = \"master\"\n <mask>         return f\"https://github.com/python/cpython/archive/{version}.zip\"\n <mask>     elif package == \"pypy\":\n <mask>         if version is None:\n <mask>             version = \"branch/default\"\n <mask>         return ( </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     git_switch_branch(\"master\", repo=options.black_repo) </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details </s> remove         git_switch_branch(\"master\", repo=repo) </s> add         git_switch_branch(\"main\", repo=repo) </s> remove     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>                 input_directory=options.input,\n <mask>             )\n <mask>         git_switch_branch(\"master\", repo=repo)\n <mask> \n <mask>     git_switch_branch(\"master\", repo=options.black_repo)\n <mask>  </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\") </s> remove             version = \"master\" </s> add             version = \"main\" </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         default=Path(\"/output\"),\n <mask>         type=Path,\n <mask>         help=\"Output directory to download and put result artifacts.\",\n <mask>     )\n <mask>     parser.add_argument(\"versions\", nargs=\"*\", default=(\"master\",), help=\"\")\n <mask> \n <mask>     options = parser.parse_args()\n <mask>     repos = init_repos(options)\n <mask>     format_repos(repos, options)\n <mask>  </s> Replace references to master branch (#2210)\n\nCommit history before merge:\r\n\r\n* Replace references to master branch\r\n* Update .flake8 to reference docs on RTD\r\n\r\n  We're moving away from GitHub as a documentation host to only RTD because\r\n  it's makes our lives easier creating good docs. I know this link is dead right now,\r\n  but it won't be once we release a new version with the documentation reorganization\r\n  changes (which should be soon!).\r\n\r\n  Co-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove # See https://github.com/psf/black/blob/master/docs/the_black_code_style.md#line-length for more details </s> remove     git_switch_branch(\"master\", repo=options.black_repo) </s> add     git_switch_branch(\"main\", repo=options.black_repo) </s> remove             version = \"master\" </s> remove         git_switch_branch(\"master\", repo=repo) </s> add         git_switch_branch(\"main\", repo=repo)", "html_url": "https://github.com/psf/black/commit/06ccb88bf2bd35a4dc5d591bb296b5b299d07323", "file_name": "gallery/gallery.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> }\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class FileMode:\n <mask>     target_versions: Set[TargetVersion] = field(default_factory=set)\n <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     is_pyi: bool = False\n <mask>  </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     mode: FileMode, </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove     mode = FileMode( </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:\n <mask>     return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)\n <mask> \n <mask>  </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> remove def get_cache_file(mode: FileMode) -> Path: </s> remove def read_cache(mode: FileMode) -> Cache:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         versions = PY36_VERSIONS\n <mask>     else:\n <mask>         # We'll autodetect later.\n <mask>         versions = set()\n <mask>     mode = FileMode(\n <mask>         target_versions=versions,\n <mask>         line_length=line_length,\n <mask>         is_pyi=pyi,\n <mask>         string_normalization=not skip_string_normalization,\n <mask>     ) </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> add # Legacy name, left for integrations.\nFileMode = Mode </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ctx.exit(0)\n <mask> \n <mask> \n <mask> def reformat_one(\n <mask>     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n <mask>     `fast`, `write_back`, and `mode` options are passed to\n <mask>     :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent: </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: FileMode,\n <mask>     report: \"Report\",\n <mask> ) -> None:\n <mask>     \"\"\"Reformat multiple files using a ProcessPoolExecutor.\"\"\"\n <mask>     loop = asyncio.get_event_loop()\n <mask>     worker_count = os.cpu_count()\n <mask>     if sys.platform == \"win32\": </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> async def schedule_formatting(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: FileMode,\n <mask>     report: \"Report\",\n <mask>     loop: asyncio.AbstractEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None:\n <mask>     \"\"\"Run formatting of `sources` in parallel using the provided `executor`. </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     fast: bool,\n <mask>     mode: FileMode,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask>  </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> add # Legacy name, left for integrations.\nFileMode = Mode </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is YES, write reformatted code back to stdout. If it is DIFF,\n <mask>     write a diff to stdout. The `mode` argument is passed to </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def read_cache(mode: FileMode) -> Cache: </s> add def read_cache(mode: Mode) -> Cache: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def get_cache_file(mode: FileMode) -> Path: </s> add def get_cache_file(mode: Mode) -> Path: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             f.write(diff(src, dst, src_name, dst_name))\n <mask>         f.detach()\n <mask> \n <mask> \n <mask> def format_file_contents(\n <mask>     src_contents: str, *, fast: bool, mode: FileMode\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.\n <mask>     `mode` is passed to :func:`format_str`. </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent: </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def read_cache(mode: FileMode) -> Cache: </s> add def read_cache(mode: Mode) -> Cache: </s> remove def get_cache_file(mode: FileMode) -> Path: </s> add def get_cache_file(mode: Mode) -> Path: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert_stable(src_contents, dst_contents, mode=mode)\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, *, mode: FileMode) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `mode` determines formatting options, such as how many characters per line are\n <mask>     allowed.  Example:\n <mask>  </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode())) </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> add def assert_stable(src: str, dst: str, mode: Mode) -> None: </s> remove     src: Path, fast: bool, write_back: WriteBack, mode: FileMode, report: \"Report\" </s> add     src: Path, fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def get_cache_file(mode: FileMode) -> Path: </s> add def get_cache_file(mode: Mode) -> Path:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     `mode` determines formatting options, such as how many characters per line are\n <mask>     allowed.  Example:\n <mask> \n <mask>     >>> import black\n <mask>     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode()))\n <mask>     def f(arg: str = \"\") -> None:\n <mask>         ...\n <mask> \n <mask>     A more complex example:\n <mask>     >>> print( </s> remove     ...     mode=black.FileMode( </s> add     ...     mode=black.Mode(", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     A more complex example:\n <mask>     >>> print(\n <mask>     ...   black.format_str(\n <mask>     ...     \"def f(arg:str='')->None: hey\",\n <mask>     ...     mode=black.FileMode(\n <mask>     ...       target_versions={black.TargetVersion.PY36},\n <mask>     ...       line_length=10,\n <mask>     ...       string_normalization=False,\n <mask>     ...       is_pyi=False,\n <mask>     ...     ), </s> remove     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=FileMode())) </s> add     >>> print(black.format_str(\"def f(arg:str='')->None:...\", mode=Mode()))", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, mode: FileMode) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, mode=mode)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"), </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent: </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def read_cache(mode: FileMode) -> Cache: </s> add def read_cache(mode: Mode) -> Cache: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode </s> remove def get_cache_file(mode: FileMode) -> Path: </s> add def get_cache_file(mode: Mode) -> Path:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> def get_cache_file(mode: FileMode) -> Path:\n <mask>     return CACHE_DIR / f\"cache.{mode.get_cache_key()}.pickle\"\n <mask> \n <mask> \n <mask> def read_cache(mode: FileMode) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask>  </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None: </s> add def write_cache(cache: Cache, sources: Iterable[Path], mode: Mode) -> None: </s> remove def format_str(src_contents: str, *, mode: FileMode) -> FileContent: </s> add def format_str(src_contents: str, *, mode: Mode) -> FileContent: </s> remove def format_file_contents(\n    src_contents: str, *, fast: bool, mode: FileMode\n) -> FileContent: </s> add def format_file_contents(src_contents: str, *, fast: bool, mode: Mode) -> FileContent: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None: </s> remove     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: FileMode </s> add     fast: bool, *, write_back: WriteBack = WriteBack.NO, mode: Mode", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             done.add(src)\n <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: Iterable[Path], mode: FileMode) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(mode)\n <mask>     try:\n <mask>         CACHE_DIR.mkdir(parents=True, exist_ok=True)\n <mask>         new_cache = {**cache, **{src.resolve(): get_cache_info(src) for src in sources}} </s> Rename FileMode into just Mode\n\nThe mode was never just about files to begin with.  There are no other modes in\nBlack, this can be the default one. </s> remove def read_cache(mode: FileMode) -> Cache: </s> add def read_cache(mode: Mode) -> Cache: </s> remove     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: FileMode,\n    report: \"Report\", </s> add     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> remove def get_cache_file(mode: FileMode) -> Path: </s> add def get_cache_file(mode: Mode) -> Path: </s> remove def assert_stable(src: str, dst: str, mode: FileMode) -> None:", "html_url": "https://github.com/psf/black/commit/06f2790b5ca3fea45515e33c9660ad6265120a5a", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if value_head in {'f\"', 'F\"', \"f'\", \"F'\", \"rf\", \"fr\", \"RF\", \"FR\"}:\n <mask>                 features.add(Feature.F_STRINGS)\n <mask> \n <mask>         elif n.type == token.NUMBER:\n <mask>             if \"_\" in n.value:  # type: ignore\n <mask>                 features.add(Feature.NUMERIC_UNDERSCORES)\n <mask> \n <mask>         elif n.type == token.SLASH:\n <mask>             if n.parent and n.parent.type in {\n <mask>                 syms.typedargslist, </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> remove         elif n.type == token.PRINT_STMT: </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove         elif n.type == token.EXEC_STMT:", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         elif n.type == token.NUMBER:\n <mask>             assert isinstance(n, Leaf)\n <mask>             if \"_\" in n.value:\n <mask>                 features.add(Feature.NUMERIC_UNDERSCORES)\n <mask> \n <mask>         elif n.type == token.SLASH:\n <mask>             if n.parent and n.parent.type in {\n <mask>                 syms.typedargslist, </s> add             assert isinstance(n, Leaf)\n            if \"_\" in n.value: </s> remove         elif n.type == token.PRINT_STMT: </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> remove         elif n.type == token.EXEC_STMT:", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep", "code_tokens": " <mask>                     for argch in ch.children:\n <mask>                         if argch.type in STARS:\n <mask>                             features.add(feature)\n <mask> \n <mask>         elif n.type == token.PRINT_STMT:\n <mask>             features.add(Feature.PRINT_STMT)\n <mask>         elif n.type == token.EXEC_STMT:\n <mask>             features.add(Feature.EXEC_STMT) </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL)", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     # temporary for Python 2 deprecation\n <mask>     PRINT_STMT = 200\n <mask>     EXEC_STMT = 201\n <mask> \n <mask> \n <mask> VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {\n <mask>     TargetVersion.PY27: { </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL) </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> add         Feature.AUTOMATIC_PARAMETER_UNPACKING,\n        Feature.COMMA_STYLE_EXCEPT,\n        Feature.COMMA_STYLE_RAISE,\n        Feature.LONG_INT_LITERAL,\n        Feature.OCTAL_INT_LITERAL,\n        Feature.BACKQUOTE_REPR,", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         Feature.PRINT_STMT,\n <mask>         Feature.EXEC_STMT,\n <mask>     },\n <mask>     TargetVersion.PY33: {Feature.UNICODE_LITERALS, Feature.ASYNC_IDENTIFIERS},\n <mask>     TargetVersion.PY34: {Feature.UNICODE_LITERALS, Feature.ASYNC_IDENTIFIERS},\n <mask>     TargetVersion.PY35: {\n <mask>         Feature.UNICODE_LITERALS, </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> add             elif n.value.endswith((\"L\", \"l\")):\n                # Python 2: 10L\n                features.add(Feature.LONG_INT_LITERAL)\n            elif len(n.value) >= 2 and n.value[0] == \"0\" and n.value[1].isdigit():\n                # Python 2: 0123; 00123; ...\n                if not all(char == \"0\" for char in n.value):\n                    # although we don't want to match 0000 or similar\n                    features.add(Feature.OCTAL_INT_LITERAL)", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> ERRORTOKEN: Final = 58\n <mask> COLONEQUAL: Final = 59\n <mask> N_TOKENS: Final = 60\n <mask> NT_OFFSET: Final = 256\n <mask> # temporary for Python 2 deprecation\n <mask> PRINT_STMT: Final = 316\n <mask> EXEC_STMT: Final = 288\n <mask> # --end constants--\n <mask> \n <mask> tok_name: Final[Dict[int, str]] = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0): </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> remove         elif n.type == token.PRINT_STMT: </s> add         # Python 2 only features (for its deprecation) except for integers, see above\n        elif n.type == syms.print_stmt: </s> add @pytest.mark.python2", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> @pytest.mark.parametrize(\"explicit\", [True, False], ids=[\"explicit\", \"autodetection\"])\n <mask> def test_python_2_deprecation_with_target_version(explicit: bool) -> None:\n <mask>     args = [\n <mask>         \"--config\",\n <mask>         str(THIS_DIR / \"empty.toml\"), </s> add @pytest.mark.python2\ndef test_python_2_deprecation_autodetection_extended() -> None:\n    # this test has a similar construction to test_get_features_used_decorator\n    python2, non_python2 = read_data(\"python2_detection\")\n    for python2_case in python2.split(\"###\"):\n        node = black.lib2to3_parse(python2_case)\n        assert black.detect_target_versions(node) == {TargetVersion.PY27}, python2_case\n    for non_python2_case in non_python2.split(\"###\"):\n        node = black.lib2to3_parse(non_python2_case)\n        assert black.detect_target_versions(node) != {\n            TargetVersion.PY27\n        }, non_python2_case </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207 </s> remove # temporary for Python 2 deprecation\nPRINT_STMT: Final = 316\nEXEC_STMT: Final = 288", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>         result = BlackRunner().invoke(black.main, args)\n <mask>     assert \"DEPRECATION: Python 2 support will be removed\" in result.stderr\n <mask> \n <mask> \n <mask> with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n <mask>     black_source_lines = _bf.readlines()\n <mask> \n <mask> \n <mask> def tracefunc( </s> add     AUTOMATIC_PARAMETER_UNPACKING = 202\n    COMMA_STYLE_EXCEPT = 203\n    COMMA_STYLE_RAISE = 204\n    LONG_INT_LITERAL = 205\n    OCTAL_INT_LITERAL = 206\n    BACKQUOTE_REPR = 207", "html_url": "https://github.com/psf/black/commit/0753d99519b0c90f0f9f280b73783b537900dc16", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     \"src\",\n <mask>     nargs=-1, </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor, </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> add     pyi: bool,\n    py36: bool, </s> add     pyi: bool,\n    py36: bool,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     src: List[str],\n <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     sources: List[Path] = []\n <mask>     for s in src: </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         ctx.exit(0)\n <mask>         return\n <mask> \n <mask>     elif len(sources) == 1:\n <mask>         reformat_one(sources[0], line_length, fast, write_back, report)\n <mask>     else:\n <mask>         loop = asyncio.get_event_loop()\n <mask>         executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>         try:\n <mask>             loop.run_until_complete( </s> remove                     sources, line_length, fast, write_back, report, loop, executor </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor, </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>         try:\n <mask>             loop.run_until_complete(\n <mask>                 schedule_formatting(\n <mask>                     sources, line_length, fast, write_back, report, loop, executor\n <mask>                 )\n <mask>             )\n <mask>         finally:\n <mask>             shutdown(loop)\n <mask>         if not quiet: </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask> def reformat_one(\n <mask>     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat a single file under `src` without spawning child processes.\n <mask> \n <mask>     If `quiet` is True, non-error messages are not output. `line_length`,\n <mask>     `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\": </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi = force_pyi or src.suffix == \".pyi\"", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\":\n <mask>             if format_stdin_to_stdout(\n <mask>                 line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF: </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 write_cache(cache, [src], line_length) </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         else:\n <mask>             cache: Cache = {}\n <mask>             if write_back != WriteBack.DIFF:\n <mask>                 cache = read_cache(line_length)\n <mask>                 src = src.resolve()\n <mask>                 if src in cache and cache[src] == get_cache_info(src):\n <mask>                     changed = Changed.CACHED\n <mask>             if changed is not Changed.CACHED and format_file_in_place(\n <mask>                 src, line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length) </s> remove                 write_cache(cache, [src], line_length) </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove         write_cache(cache, formatted, line_length) </s> add         write_cache(cache, formatted, line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 src, line_length=line_length, fast=fast, write_back=write_back\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back == WriteBack.YES and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask>  </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove         write_cache(cache, formatted, line_length) </s> add         write_cache(cache, formatted, line_length, pyi, py36) </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     report: \"Report\",\n <mask>     loop: BaseEventLoop,\n <mask>     executor: Executor,\n <mask> ) -> None: </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36)", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     (Use ProcessPoolExecutors for actual parallelism.)\n <mask> \n <mask>     `line_length`, `write_back`, and `fast` options are passed to\n <mask>     :func:`format_file_in_place`.\n <mask>     \"\"\"\n <mask>     cache: Cache = {}\n <mask>     if write_back != WriteBack.DIFF:\n <mask>         cache = read_cache(line_length)\n <mask>         sources, cached = filter_cached(cache, sources)\n <mask>         for src in cached:\n <mask>             report.done(src, Changed.CACHED)\n <mask>     cancelled = [] </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\",", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             manager = Manager()\n <mask>             lock = manager.Lock()\n <mask>         tasks = {\n <mask>             loop.run_in_executor(\n <mask>                 executor, format_file_in_place, src, line_length, fast, write_back, lock\n <mask>             ): src\n <mask>             for src in sorted(sources)\n <mask>         }\n <mask>         pending: Iterable[asyncio.Task] = tasks.keys()\n <mask>         try: </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove         reformat_one(sources[0], line_length, fast, write_back, report) </s> add         reformat_one(\n            src=sources[0],\n            line_length=line_length,\n            fast=fast,\n            pyi=pyi,\n            py36=py36,\n            write_back=write_back,\n            report=report,\n        ) </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove                     sources, line_length, fast, write_back, report, loop, executor </s> add                     sources=sources,\n                    line_length=line_length,\n                    fast=fast,\n                    pyi=pyi,\n                    py36=py36,\n                    write_back=write_back,\n                    report=report,\n                    loop=loop,\n                    executor=executor,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back == WriteBack.YES and formatted:\n <mask>         write_cache(cache, formatted, line_length)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path,\n <mask>     line_length: int, </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove                 write_cache(cache, [src], line_length) </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     src: Path,\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     write_back: WriteBack = WriteBack.NO,\n <mask>     lock: Any = None,  # multiprocessing.Manager().Lock() is some crazy proxy\n <mask> ) -> bool:\n <mask>     \"\"\"Format file under `src` path. Return True if changed.\n <mask>  </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask>     is_pyi = src.suffix == \".pyi\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents( </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\",", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES: </s> remove     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi </s> add             src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove                 write_cache(cache, [src], line_length) </s> add                 write_cache(cache, [src], line_length, pyi, py36) </s> remove                 line_length=line_length, fast=fast, write_back=write_back </s> add                 line_length=line_length,\n                fast=fast,\n                is_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back, </s> remove         reformat_one(sources[0], line_length, fast, write_back, report) </s> add         reformat_one(\n            src=sources[0],\n            line_length=line_length,\n            fast=fast,\n            pyi=pyi,\n            py36=py36,\n            write_back=write_back,\n            report=report,\n        ) </s> remove                 src, line_length=line_length, fast=fast, write_back=write_back </s> add                 src,\n                line_length=line_length,\n                fast=fast,\n                force_pyi=pyi,\n                force_py36=py36,\n                write_back=write_back,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_stdin_to_stdout(\n <mask>     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO\n <mask> ) -> bool:\n <mask>     \"\"\"Format file on stdin. Return True if changed.\n <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` arguments are passed to :func:`format_file_contents`. </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove     src: Path, line_length: int, fast: bool, write_back: WriteBack, report: \"Report\" </s> add     src: Path,\n    line_length: int,\n    fast: bool,\n    pyi: bool,\n    py36: bool,\n    write_back: WriteBack,\n    report: \"Report\", </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`. </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(\n <mask>             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n <mask>         )\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str( </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(\n <mask>     src_contents: str, line_length: int, *, is_pyi: bool = False\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `line_length` determines how many characters per line are allowed.\n <mask>     \"\"\" </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove             src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi </s> add             src_contents,\n            dst_contents,\n            line_length=line_length,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     `write_back`, and `fast` options are passed to :func:`format_file_in_place`. </s> add     `write_back`, `fast` and `pyi` options are passed to\n    :func:`format_file_in_place` or :func:`format_stdin_to_stdout`.", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     elt = EmptyLineTracker(is_pyi=is_pyi)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line()\n <mask>     after = 0 </s> remove             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock, </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"), </s> remove     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     newdst = format_str(\n        dst, line_length=line_length, is_pyi=is_pyi, force_py36=force_py36\n    ) </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove def read_cache(line_length: int) -> Cache: </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"),\n <mask>         ) </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None: </s> remove     src_contents: str, line_length: int, *, is_pyi: bool = False </s> add     src_contents: str,\n    line_length: int,\n    *,\n    is_pyi: bool = False,\n    force_py36: bool = False, </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove def read_cache(line_length: int) -> Cache: </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep keep", "code_tokens": " <mask>     return False\n <mask> \n <mask> \n <mask> def get_cache_file(line_length: int) -> Path:\n <mask>     return CACHE_DIR / f\"cache.{line_length}.pickle\"\n <mask> \n <mask> \n <mask> def read_cache(line_length: int) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue. </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO, </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n <mask>     If it is not well formed, the call to write_cache later should resolve the issue.\n <mask>     \"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     if not cache_file.exists():\n <mask>         return {}\n <mask> \n <mask>     with cache_file.open(\"rb\") as fobj:\n <mask>         try: </s> remove def read_cache(line_length: int) -> Cache: </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     `line_length`, `write_back`, and `fast` options are passed to </s> add     `line_length`, `write_back`, `fast`, and `pyi` options are passed to", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             done.append(src)\n <mask>     return todo, done\n <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists():\n <mask>             CACHE_DIR.mkdir(parents=True) </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def read_cache(line_length: int) -> Cache: </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> add def assert_stable(\n    src: str, dst: str, line_length: int, is_pyi: bool = False, force_py36: bool = False\n) -> None:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None:\n <mask>     \"\"\"Update the cache file.\"\"\"\n <mask>     cache_file = get_cache_file(line_length)\n <mask>     try:\n <mask>         if not CACHE_DIR.exists():\n <mask>             CACHE_DIR.mkdir(parents=True)\n <mask>         new_cache = {**cache, **{src.resolve(): get_cache_info(src) for src in sources}}\n <mask>         with cache_file.open(\"wb\") as fobj: </s> remove def write_cache(cache: Cache, sources: List[Path], line_length: int) -> None: </s> add def write_cache(\n    cache: Cache,\n    sources: List[Path],\n    line_length: int,\n    pyi: bool = False,\n    py36: bool = False,\n) -> None: </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> remove def read_cache(line_length: int) -> Cache: </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache: </s> remove         cache = read_cache(line_length) </s> add         cache = read_cache(line_length, pyi, py36) </s> remove                 cache = read_cache(line_length) </s> add                 cache = read_cache(line_length, pyi, py36) </s> remove                 executor, format_file_in_place, src, line_length, fast, write_back, lock </s> add                 executor,\n                format_file_in_place,\n                src,\n                line_length,\n                fast,\n                pyi,\n                py36,\n                write_back,\n                lock,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             black.write_cache({}, [], black.DEFAULT_LINE_LENGTH)\n <mask> \n <mask>     def test_check_diff_use_together(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Files which will be reformatted.\n <mask>             src1 = (THIS_DIR / \"string_quotes.py\").resolve()\n <mask>             result = CliRunner().invoke(black.main, [str(src1), \"--diff\", \"--check\"]) </s> Add --pyi and --py36 flags (#249)\n\nFixes #244. </s> remove def get_cache_file(line_length: int) -> Path:\n    return CACHE_DIR / f\"cache.{line_length}.pickle\" </s> add def get_cache_file(line_length: int, pyi: bool = False, py36: bool = False) -> Path:\n    return (\n        CACHE_DIR\n        / f\"cache.{line_length}{'.pyi' if pyi else ''}{'.py36' if py36 else ''}.pickle\"\n    ) </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> add def read_cache(line_length: int, pyi: bool = False, py36: bool = False) -> Cache:", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             # Multi file command.\n <mask>             result = CliRunner().invoke(\n <mask>                 black.main, [str(src1), str(src2), \"--diff\", \"--check\"]\n <mask>             )\n <mask>             self.assertEqual(result.exit_code, 1)\n <mask> \n <mask>     def test_no_files(self) -> None:\n <mask>         with cache_dir():\n <mask>             # Without an argument, black exits with error code 0.\n <mask>             result = CliRunner().invoke(black.main, []) </s> add     force_pyi: bool = False,\n    force_py36: bool = False, </s> remove     is_pyi = src.suffix == \".pyi\" </s> add     is_pyi = force_pyi or src.suffix == \".pyi\" </s> remove     cache_file = get_cache_file(line_length) </s> add     cache_file = get_cache_file(line_length, pyi, py36) </s> add             src_contents,\n            line_length=line_length,\n            fast=fast,\n            is_pyi=is_pyi,\n            force_py36=force_py36, </s> remove     line_length: int, fast: bool, write_back: WriteBack = WriteBack.NO </s> add     line_length: int,\n    fast: bool,\n    is_pyi: bool = False,\n    force_py36: bool = False,\n    write_back: WriteBack = WriteBack.NO,", "html_url": "https://github.com/psf/black/commit/07b1b2f3dd0e4f13dd5df96eb9188f3d02f5726e", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     \"\"\"Run Black and record failures\"\"\"\n <mask>     cmd = [str(which(BLACK_BINARY))]\n <mask>     if \"cli_arguments\" in project_config and project_config[\"cli_arguments\"]:\n <mask>         cmd.extend(*project_config[\"cli_arguments\"])\n <mask>     cmd.append(\"--check\")\n <mask>     if no_diff:\n <mask>         cmd.append(\".\")\n <mask>     else:\n <mask>         cmd.extend([\"--diff\", \".\"]) </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/lib.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> {\n <mask>   \"configuration_format_version\": 20200509,\n <mask>   \"projects\": {\n <mask>     \"aioexabgp\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/cooperlees/aioexabgp.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"attrs\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-attrs/attrs.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"bandersnatch\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/bandersnatch.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"channels\": { </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"channels\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/django/channels.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     },\n <mask>     \"django\": {\n <mask>       \"disabled_reason\": \"black --check --diff returned 123 on tests_syntax_error.py\",\n <mask>       \"disabled\": true,\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/django/django.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"flake8-bugbear\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/PyCQA/flake8-bugbear.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"hypothesis\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/HypothesisWorks/hypothesis.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pandas\": { </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> remove       \"cli_arguments\": [], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     },\n <mask>     \"pandas\": {\n <mask>       \"disabled_reason\": \"black-primer runs failing on Pandas - #2193\",\n <mask>       \"disabled\": true,\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/pandas-dev/pandas.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pillow\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-pillow/Pillow.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"poetry\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python-poetry/poetry.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pyanalyze\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/quora/pyanalyze.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> Enable ` --experimental-string-processing` on most primer projects (#2184)\n\n* Enable ` --experimental-string-processing` on all primer projects\r\n- We want to make this default so need to test it more\r\n- Fixed splat/star bug in extending black args for each project\r\n\r\n* Disable sqlalchemy due to crash </s> add       \"cli_arguments\": [\"--experimental-string-processing\"], </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pyramid\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/Pylons/pyramid.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"ptr\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/facebookincubator/ptr.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"pytest\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pytest-dev/pytest.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"sqlalchemy\": { </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"sqlalchemy\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/sqlalchemy/sqlalchemy.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"tox\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/tox-dev/tox.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"typeshed\": { </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"typeshed\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/python/typeshed.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     }, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"virtualenv\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": false,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/virtualenv.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"warehouse\": { </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true,", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     },\n <mask>     \"warehouse\": {\n <mask>       \"cli_arguments\": [],\n <mask>       \"expect_formatting_changes\": true,\n <mask>       \"git_clone_url\": \"https://github.com/pypa/warehouse.git\",\n <mask>       \"long_checkout\": false,\n <mask>       \"py_versions\": [\"all\"]\n <mask>     } </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [],\n      \"expect_formatting_changes\": false, </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],\n      \"expect_formatting_changes\": true, </s> remove       \"cli_arguments\": [], </s> add       \"cli_arguments\": [\"--experimental-string-processing\"],", "html_url": "https://github.com/psf/black/commit/07c8812937cf75ac5bc7ceac07ef5ea383f10f2f", "file_name": "src/black_primer/primer.json"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Holds leaves and comments. Can be printed with `str(line)`.\"\"\"\n <mask> \n <mask>     depth: int = 0\n <mask>     leaves: List[Leaf] = Factory(list)\n <mask>     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n <mask>     # in leaves\n <mask>     comments: Dict[LeafID, List[Leaf]] = Factory(dict)\n <mask>     bracket_tracker: BracketTracker = Factory(BracketTracker)\n <mask>     inside_brackets: bool = False\n <mask>     should_explode: bool = False\n <mask> \n <mask>     def append(self, leaf: Leaf, preformatted: bool = False) -> None: </s> remove         else:\n            leaf_id = id(self.leaves[-1])\n            if leaf_id not in self.comments:\n                self.comments[leaf_id] = [comment]\n            else:\n                self.comments[leaf_id].append(comment)\n            return True </s> add         self.comments.setdefault(id(self.leaves[-1]), []).append(comment)\n        return True </s> remove         # Remember, the LeafID keys of self.comments are ordered by the\n        # corresponding leaf's index in self.leaves\n        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n        # Otherwise, we insert it into self.comments, and it becomes the last entry.\n        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n        # is maintained\n        self.comments.setdefault(id(self.leaves[-2]), []).extend(\n            self.comments.get(id(self.leaves[-1]), []) </s> add         trailing_comma = self.leaves.pop()\n        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])\n        self.comments.setdefault(id(self.leaves[-1]), []).extend(\n            trailing_comma_comments </s> remove         self.comments.pop(id(self.leaves[-1]), None)\n        self.leaves.pop()", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             comment.type = STANDALONE_COMMENT\n <mask>             comment.prefix = \"\"\n <mask>             return False\n <mask> \n <mask>         else:\n <mask>             leaf_id = id(self.leaves[-1])\n <mask>             if leaf_id not in self.comments:\n <mask>                 self.comments[leaf_id] = [comment]\n <mask>             else:\n <mask>                 self.comments[leaf_id].append(comment)\n <mask>             return True\n <mask> \n <mask>     def comments_after(self, leaf: Leaf) -> List[Leaf]:\n <mask>         \"\"\"Generate comments that should appear directly after `leaf`.\"\"\"\n <mask>         return self.comments.get(id(leaf), [])\n <mask>  </s> remove     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n    # in leaves\n    comments: Dict[LeafID, List[Leaf]] = Factory(dict) </s> add     comments: Dict[LeafID, List[Leaf]] = Factory(dict)  # keys ordered like `leaves` </s> remove         # Remember, the LeafID keys of self.comments are ordered by the\n        # corresponding leaf's index in self.leaves\n        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n        # Otherwise, we insert it into self.comments, and it becomes the last entry.\n        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n        # is maintained\n        self.comments.setdefault(id(self.leaves[-2]), []).extend(\n            self.comments.get(id(self.leaves[-1]), []) </s> add         trailing_comma = self.leaves.pop()\n        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])\n        self.comments.setdefault(id(self.leaves[-1]), []).extend(\n            trailing_comma_comments </s> remove         self.comments.pop(id(self.leaves[-1]), None)\n        self.leaves.pop()", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace replace replace keep replace replace", "code_tokens": " <mask>     def remove_trailing_comma(self) -> None:\n <mask>         \"\"\"Remove the trailing comma and moves the comments attached to it.\"\"\"\n <mask>         # Remember, the LeafID keys of self.comments are ordered by the\n <mask>         # corresponding leaf's index in self.leaves\n <mask>         # If id(self.leaves[-2]) is in self.comments, the order doesn't change.\n <mask>         # Otherwise, we insert it into self.comments, and it becomes the last entry.\n <mask>         # However, since we delete id(self.leaves[-1]) from self.comments, the invariant\n <mask>         # is maintained\n <mask>         self.comments.setdefault(id(self.leaves[-2]), []).extend(\n <mask>             self.comments.get(id(self.leaves[-1]), [])\n <mask>         )\n <mask>         self.comments.pop(id(self.leaves[-1]), None)\n <mask>         self.leaves.pop() </s> remove     # The LeafID keys of comments must remain ordered by the corresponding leaf's index\n    # in leaves\n    comments: Dict[LeafID, List[Leaf]] = Factory(dict) </s> add     comments: Dict[LeafID, List[Leaf]] = Factory(dict)  # keys ordered like `leaves` </s> remove         else:\n            leaf_id = id(self.leaves[-1])\n            if leaf_id not in self.comments:\n                self.comments[leaf_id] = [comment]\n            else:\n                self.comments[leaf_id].append(comment)\n            return True </s> add         self.comments.setdefault(id(self.leaves[-1]), []).append(comment)\n        return True", "html_url": "https://github.com/psf/black/commit/087fedb17eeb6e9b1189792ca046ffa6d98579fe", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return 0\n <mask> \n <mask> \n <mask> def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:\n <mask>     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it.\n <mask> \n <mask>     The delimiter priorities returned here are from those delimiters that would\n <mask>     cause a line break before themselves.\n <mask> \n <mask>     Higher numbers are higher priority. </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> remove     if leaf.type != token.NAME: </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> add         or leaf.type == token.ASYNC", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         and previous.type == token.STRING\n <mask>     ):\n <mask>         return STRING_PRIORITY\n <mask> \n <mask>     if leaf.type != token.NAME:\n <mask>         return 0\n <mask> \n <mask>     if (\n <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> add         or leaf.type == token.ASYNC </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it. </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_for, syms.old_comp_for}\n <mask>     ):\n <mask>         if (\n <mask>             not isinstance(leaf.prev_sibling, Leaf)\n <mask>             or leaf.prev_sibling.value != \"async\"\n <mask>         ): </s> add         if (\n            not isinstance(leaf.prev_sibling, Leaf)\n            or leaf.prev_sibling.value != \"async\"\n        ):\n            return COMPREHENSION_PRIORITY </s> remove     if leaf.type != token.NAME: </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it. </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         leaf.value == \"for\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_for, syms.old_comp_for}\n <mask>     ):\n <mask>         return COMPREHENSION_PRIORITY\n <mask> \n <mask>     if (\n <mask>         leaf.value == \"if\"\n <mask>         and leaf.parent\n <mask>         and leaf.parent.type in {syms.comp_if, syms.old_comp_if} </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add         or leaf.type == token.ASYNC </s> remove     if leaf.type != token.NAME: </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove     \"\"\"Return the priority of the `leaf` delimiter, given a line before after it. </s> add     \"\"\"Return the priority of the `leaf` delimiter, given a line break before it.", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     return (i*2 async for i in arange(42))\n <mask> \n <mask> # output\n <mask> \n <mask> \n <mask> #!/usr/bin/env python3.7\n <mask> \n <mask>  </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add def g():\n    return (\n        something_long * something_long\n        async for something_long in async_generator(with_an_argument)\n    )\n\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove         return COMPREHENSION_PRIORITY </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add         or leaf.type == token.ASYNC", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "tests/data/python37.py"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask> \n <mask> \n <mask> def f():\n <mask>     return (i * 2 async for i in arange(42)) </s> Make sure `async for` is not broken up to separate lines (#503)\n\nFixes #372. </s> add def g():\n    return (something_long * something_long async for something_long in async_generator(with_an_argument))\n\nasync def func():\n    if test:\n        out_batched = [\n            i\n            async for i in aitertools._async_map(\n                self.async_inc, arange(8), batch_size=3\n            )\n        ] </s> remove         return COMPREHENSION_PRIORITY </s> remove     if leaf.type != token.NAME: </s> add     if leaf.type not in {token.NAME, token.ASYNC}: </s> add         or leaf.type == token.ASYNC", "html_url": "https://github.com/psf/black/commit/08f1cdd00b4876b2a0545d46981924d5873a3289", "file_name": "tests/data/python37.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import re\n <mask> from typing import FrozenSet, List, Set, TYPE_CHECKING\n <mask> \n <mask> import pytest\n <mask> from _pytest.store import StoreKey\n <mask> \n <mask> log = logging.getLogger(__name__)\n <mask> \n <mask> \n <mask> if TYPE_CHECKING: </s> remove from _pytest.tmpdir import tmpdir </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]() </s> add ALL_POSSIBLE_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StashKey[FrozenSet[str]]()", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/optional.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     from _pytest.mark.structures import MarkDecorator\n <mask>     from _pytest.nodes import Node\n <mask> \n <mask> \n <mask> ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n <mask> ENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\n <mask> \n <mask> \n <mask> def pytest_addoption(parser: \"Parser\") -> None:\n <mask>     group = parser.getgroup(\"collect\")\n <mask>     group.addoption( </s> add </s> add", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/optional.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> import pytest\n <mask> from black import Mode\n <mask> from _pytest.monkeypatch import MonkeyPatch\n <mask> from py.path import local\n <mask> from tests.util import DATA_DIR\n <mask> \n <mask> pytestmark = pytest.mark.jupyter\n <mask> pytest.importorskip(\"IPython\", reason=\"IPython is an optional dependency\")\n <mask> pytest.importorskip(\"tokenize_rt\", reason=\"tokenize-rt is an optional dependency\") </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove from _pytest.tmpdir import tmpdir </s> remove from _pytest.store import StoreKey </s> add try:\n    from pytest import StashKey\nexcept ImportError:\n    # pytest < 7\n    from _pytest.store import StoreKey as StashKey </s> remove ALL_POSSIBLE_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]()\nENABLED_OPTIONAL_MARKERS = StoreKey[FrozenSet[str]]() </s> remove     monkeypatch: MonkeyPatch, tmpdir: local </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     assert expected in result.output\n <mask> \n <mask> \n <mask> def test_cache_isnt_written_if_no_jupyter_deps_single(\n <mask>     monkeypatch: MonkeyPatch, tmpdir: local\n <mask> ) -> None:\n <mask>     # Check that the cache isn't written to if Jupyter dependencies aren't installed.\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst: </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     monkeypatch: MonkeyPatch, tmpdir: local </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None: </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n <mask>     assert \"No Python files are present to be formatted. Nothing to do\" in result.output\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     ) </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep", "code_tokens": " <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")])\n <mask>     assert \"reformatted\" in result.output\n <mask> \n <mask> \n <mask> def test_cache_isnt_written_if_no_jupyter_deps_dir(\n <mask>     monkeypatch: MonkeyPatch, tmpdir: local\n <mask> ) -> None: </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     monkeypatch: MonkeyPatch, tmpdir: local </s> add     monkeypatch: MonkeyPatch, tmp_path: pathlib.Path </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> remove def test_ipynb_flag(tmpdir: local) -> None: </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None: </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     # Check that the cache isn't written to if Jupyter dependencies aren't installed.\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     ) </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     monkeypatch: MonkeyPatch, tmpdir: local </s> remove     monkeypatch: MonkeyPatch, tmpdir: local </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         dst.write(src.read())\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: False\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     assert \"No Python files are present to be formatted. Nothing to do\" in result.output\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     ) </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)])", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace", "code_tokens": " <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     monkeypatch.setattr(\n <mask>         \"black.files.jupyter_dependencies_are_installed\", lambda verbose, quiet: True\n <mask>     )\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     assert \"reformatted\" in result.output\n <mask> \n <mask> \n <mask> def test_ipynb_flag(tmpdir: local) -> None: </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     result = runner.invoke(main, [str(tmpdir / \"notebook.ipynb\")]) </s> add     result = runner.invoke(main, [str(tmp_path / \"notebook.ipynb\")]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def test_ipynb_flag(tmpdir: local) -> None:\n <mask>     nb = DATA_DIR / \"notebook_trailing_newline.ipynb\"\n <mask>     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(\n <mask>         main,\n <mask>         [ </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove def test_ipynb_flag(tmpdir: local) -> None: </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None: </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None:", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_ipynb.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> import pytest\n <mask> import os\n <mask> \n <mask> from tests.util import THIS_DIR\n <mask> from black import main, jupyter_dependencies_are_installed\n <mask> from click.testing import CliRunner\n <mask> \n <mask> pytestmark = pytest.mark.no_jupyter </s> remove from _pytest.tmpdir import tmpdir </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from tests.util import THIS_DIR\n <mask> from black import main, jupyter_dependencies_are_installed\n <mask> from click.testing import CliRunner\n <mask> from _pytest.tmpdir import tmpdir\n <mask> \n <mask> pytestmark = pytest.mark.no_jupyter\n <mask> \n <mask> runner = CliRunner()\n <mask>  </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None: </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     )\n <mask>     assert expected_output in result.output\n <mask> \n <mask> \n <mask> def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None:\n <mask>     jupyter_dependencies_are_installed.cache_clear()\n <mask>     runner = CliRunner()\n <mask>     nb = os.path.join(\"tests\", \"data\", \"notebook_trailing_newline.ipynb\")\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     expected_output = ( </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     result = runner.invoke(main, [str(tmpdir)]) </s> add     result = runner.invoke(main, [str(tmp_path)]) </s> remove def test_ipynb_flag(tmpdir: local) -> None: </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     nb = os.path.join(\"tests\", \"data\", \"notebook_trailing_newline.ipynb\")\n <mask>     tmp_nb = tmpdir / \"notebook.ipynb\"\n <mask>     with open(nb) as src, open(tmp_nb, \"w\") as dst:\n <mask>         dst.write(src.read())\n <mask>     result = runner.invoke(main, [str(tmpdir)])\n <mask>     expected_output = (\n <mask>         \"Skipping .ipynb files as Jupyter dependencies are not installed.\\n\"\n <mask>         \"You can fix this by running ``pip install black[jupyter]``\\n\"\n <mask>     )\n <mask>     assert expected_output in result.output </s> Support pytest 7 by fixing broken imports (GH-2705)\n\nThe tmp_path related changes are not necessary to make pytest 7 work,\r\nbut it feels more complete this way. </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove def test_ipynb_diff_with_no_change_dir(tmpdir: tmpdir) -> None: </s> add def test_ipynb_diff_with_no_change_dir(tmp_path: pathlib.Path) -> None: </s> remove def test_ipynb_flag(tmpdir: local) -> None: </s> add def test_ipynb_flag(tmp_path: pathlib.Path) -> None: </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.ipynb\" </s> remove     tmp_nb = tmpdir / \"notebook.a_file_extension_which_is_definitely_not_ipynb\" </s> add     tmp_nb = tmp_path / \"notebook.a_file_extension_which_is_definitely_not_ipynb\"", "html_url": "https://github.com/psf/black/commit/092959ff1f9253347b01eeb2d6d72e15bad7e25a", "file_name": "tests/test_no_ipynb.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> \n <mask> [flake8]\n <mask> ignore = E203, E266, E501, W503\n <mask> max-line-length = 80\n <mask> max-complexity = 15\n <mask> select = B,C,E,F,W,T4,B9 </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try:", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from blib2to3 import pygram, pytree\n <mask> from blib2to3.pgen2 import driver, token\n <mask> from blib2to3.pgen2.parse import ParseError\n <mask> \n <mask> __version__ = \"18.4a5\"\n <mask> DEFAULT_LINE_LENGTH = 88\n <mask> \n <mask> # types\n <mask> syms = pygram.python_symbols\n <mask> FileContent = str </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import CuteLittleServiceHandlerFactoryyy </s> add from name_of_a_company.extremely_long_project_name.component.ttypes import (\n    CuteLittleServiceHandlerFactoryyy\n) </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the first matching bracket pair.\n <mask> \n <mask>     Note: this usually looks weird, only use this for function definitions.\n <mask>     Prefer RHS otherwise.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = [] </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\" </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\" </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try:", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def right_hand_split(\n <mask>     line: Line, py36: bool = False, omit: Collection[LeafID] = ()\n <mask> ) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = [] </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     assert opening_bracket and closing_bracket\n <mask>     if (\n <mask>         opening_bracket.type == token.LPAR\n <mask>         and not opening_bracket.value\n <mask>         # the closing bracket is an optional paren\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>         # there are no delimiters or standalone comments in the body </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # the closing bracket is an optional paren </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\" </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>         opening_bracket.type == token.LPAR\n <mask>         and not opening_bracket.value\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>         # there are no delimiters or standalone comments in the body\n <mask>         and not body.bracket_tracker.delimiters\n <mask>         and not line.contains_standalone_comments(0) </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # the opening bracket is an optional paren </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\" </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         and not opening_bracket.value\n <mask>         # the closing bracket is an optional paren\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>     ):\n <mask>         omit = {id(closing_bracket), *omit}\n <mask>         try:\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit) </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # the opening bracket is an optional paren </s> add         # the closing bracket is an optional paren </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses.", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         and not opening_bracket.value\n <mask>         and closing_bracket.type == token.RPAR\n <mask>         and not closing_bracket.value\n <mask>     ):\n <mask>         # These parens were optional. If there aren't any delimiters or standalone\n <mask>         # comments in the body, they were unnecessary and another split without\n <mask>         # them should be attempted.\n <mask>         if not (\n <mask>             body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n <mask>         ):\n <mask>             omit = {id(closing_bracket), *omit}\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit)\n <mask>             return\n <mask> \n <mask>     ensure_visible(opening_bracket)\n <mask>     ensure_visible(closing_bracket) </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add         # the closing bracket is an optional paren </s> add         # the opening bracket is an optional paren </s> remove     \"\"\"Split line into many lines, starting with the last matching bracket pair.\"\"\" </s> add     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n\n    If the split was by optional parentheses, attempt splitting without them, too.\n    \"\"\"", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         omit = {id(closing_bracket), *omit}\n <mask>         try:\n <mask>             yield from right_hand_split(line, py36=py36, omit=omit)\n <mask>             return\n <mask> \n <mask>     ensure_visible(opening_bracket)\n <mask>     ensure_visible(closing_bracket)\n <mask>     for result in (head, body, tail): </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove         # These parens were optional. If there aren't any delimiters or standalone\n        # comments in the body, they were unnecessary and another split without\n        # them should be attempted.\n        if not (\n            body.bracket_tracker.delimiters or line.contains_standalone_comments(0)\n        ):\n            omit = {id(closing_bracket), *omit} </s> add         omit = {id(closing_bracket), *omit}\n        try: </s> add         # there are no delimiters or standalone comments in the body\n        and not body.bracket_tracker.delimiters\n        and not line.contains_standalone_comments(0)\n        # and it's not an import (optional parens are the only thing we can split\n        # on in this case; attempting a split without them is a waste of time)\n        and not line.is_import </s> add     Prefer RHS otherwise.  This is why this function is not symmetrical with\n    :func:`right_hand_split` which also handles optional parentheses. </s> add         # the opening bracket is an optional paren", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> from some_library import (\n <mask>     Just, Enough, Libraries, To, Fit, In, This, Nice, Split, Which, We, No, Longer, Use\n <mask> )\n <mask> \n <mask> from .a.b.c.subprocess import *\n <mask> from . import (tasks)\n <mask> from . import (A, B, C)\n <mask> from . import SomeVeryLongNameAndAllOfItsAdditionalLetters1, \\ </s> Don't fail the entire right_hand_split if an optional split failed\n\nFixes splitting long import lines with only a single name. </s> remove __version__ = \"18.4a5\" </s> add __version__ = \"18.4a6\" </s> add         except CannotSplit:\n            pass", "html_url": "https://github.com/psf/black/commit/0967dfcbeba8aceaacd468b279cc23089d697878", "file_name": "tests/import_spacing.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace replace replace keep keep", "code_tokens": " <mask>     from aiohttp import web\n <mask>     import aiohttp_cors\n <mask> except ImportError as ie:\n <mask>     print(\n <mask>         f\"aiohttp dependency is not installed: {ie}. \"\n <mask>         + \"Please re-install black with the '[d]' extra install \"\n <mask>         + \"to obtain aiohttp_cors: `pip install black[d]`\",\n <mask>         file=sys.stderr,\n <mask>     )\n <mask>     sys.exit(-1)\n <mask> \n <mask> import black\n </s> Change sys.exit to raise ImportError (#2440)\n\nThe fix for #1688 in #1761 breaks help(\"modules\") introspection and also leads\r\nto unhappy results when inadvertently importing blackd from Python. Basically\r\nthe sys.exit(-1) causes the whole Python REPL to exit -- not great to suffice.\r\n\r\nCommit history before merge:\r\n\r\n* Change sys.exit to Raise.\r\n* Add #2440 to changelog.\r\n* Fix lint error from prettier\r\n* Remove exception chain for more helpful user message.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove import sys\n </s> add ", "html_url": "https://github.com/psf/black/commit/0969ca4a46c4a2081be38f7e96a81a74b308c75f", "file_name": "src/blackd/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if _initialize_black_env():\n <mask>   import black\n <mask>   import time\n <mask> \n <mask> def Black():\n <mask>   start = time.time()\n <mask>   configs = get_configs()\n <mask>   mode = black.FileMode(\n <mask>     line_length=configs[\"line_length\"],\n <mask>     string_normalization=not configs[\"skip_string_normalization\"], </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version </s> remove function black#Black()\n  :py3 Black() </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove command! Black :call black#Black() </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>   start = time.time()\n <mask>   configs = get_configs()\n <mask>   mode = black.FileMode(\n <mask>     line_length=configs[\"line_length\"],\n <mask>     string_normalization=not configs[\"skip_string_normalization\"],\n <mask>     is_pyi=vim.current.buffer.name.endswith('.pyi'),\n <mask>     **black_kwargs, </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> add     **black_kwargs, </s> remove function black#Black()\n  :py3 Black() </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove command! Black :call black#Black() </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>     string_normalization=not configs[\"skip_string_normalization\"],\n <mask>     is_pyi=vim.current.buffer.name.endswith('.pyi'),\n <mask>   )\n <mask>   quiet = configs[\"quiet\"]\n <mask> \n <mask>   buffer_str = '\\n'.join(vim.current.buffer) + '\\n'\n <mask>   try:\n <mask>     new_buffer_str = black.format_file_contents( </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>)", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>   print(f'Black, version {black.__version__} on Python {sys.version}.')\n <mask> \n <mask> EndPython3\n <mask> \n <mask> function black#Black()\n <mask>   :py3 Black()\n <mask> endfunction\n <mask> \n <mask> function black#BlackUpgrade()\n <mask>   :py3 BlackUpgrade()\n <mask> endfunction </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> remove command! Black :call black#Black() </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove def Black(): </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\" </s> add     **black_kwargs, </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "autoload/black.vim"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> endif\n <mask> if !exists(\"g:black_quiet\")\n <mask>   let g:black_quiet = 0\n <mask> endif\n <mask> \n <mask> function BlackComplete(ArgLead, CmdLine, CursorPos)\n <mask>   return [\n <mask> \\    'target_version=py27',\n <mask> \\    'target_version=py36',\n <mask> \\    'target_version=py37', </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> remove command! Black :call black#Black() </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> remove function black#Black()\n  :py3 Black() </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\"", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>   let g:black_target_version = \"\"\n <mask> endif\n <mask> \n <mask> \n <mask> command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>)\n <mask> command! BlackUpgrade :call black#BlackUpgrade()\n <mask> command! BlackVersion :call black#BlackVersion() </s> remove command! Black :call black#Black() </s> add command! -nargs=* -complete=customlist,BlackComplete Black :call black#Black(<f-args>) </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove function black#Black()\n  :py3 Black() </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\"", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask>   let g:black_quiet = 0\n <mask> endif\n <mask> \n <mask> \n <mask> command! Black :call black#Black()\n <mask> command! BlackUpgrade :call black#BlackUpgrade()\n <mask> command! BlackVersion :call black#BlackVersion() </s> add function BlackComplete(ArgLead, CmdLine, CursorPos)\n  return [\n\\    'target_version=py27',\n\\    'target_version=py36',\n\\    'target_version=py37',\n\\    'target_version=py38',\n\\    'target_version=py39',\n\\  ]\nendfunction </s> add if !exists(\"g:black_target_version\")\n  let g:black_target_version = \"\"\nendif </s> remove function black#Black()\n  :py3 Black() </s> add function black#Black(...)\n    let kwargs = {}\n    for arg in a:000\n        let arg_list = split(arg, '=')\n        let kwargs[arg_list[0]] = arg_list[1]\n    endfor\npython3 << EOF\nimport vim\nkwargs = vim.eval(\"kwargs\")\nEOF\n  :py3 Black(**kwargs) </s> add   black_kwargs = {}\n  if \"target_version\" in kwargs:\n    target_version = kwargs[\"target_version\"]\n\n    if not isinstance(target_version, (list, set)):\n      target_version = [target_version]\n    target_version = set(filter(lambda x: x, map(lambda tv: get_target_version(tv), target_version)))\n    black_kwargs[\"target_versions\"] = target_version </s> add def get_target_version(tv):\n  if isinstance(tv, black.TargetVersion):\n    return tv\n  ret = None\n  try:\n    ret = black.TargetVersion[tv.upper()]\n  except KeyError:\n    print(f\"WARNING: Target version {tv!r} not recognized by Black, using default target\")\n  return ret\n\ndef Black(**kwargs):\n  \"\"\"\n  kwargs allows you to override ``target_versions`` argument of\n  ``black.FileMode``.\n\n  ``target_version`` needs to be cleaned because ``black.FileMode``\n  expects the ``target_versions`` argument to be a set of TargetVersion enums.\n\n  Allow kwargs[\"target_version\"] to be a string to allow\n  to type it more quickly.\n\n  Using also target_version instead of target_versions to remain\n  consistent to Black's documentation of the structure of pyproject.toml.\n  \"\"\"", "html_url": "https://github.com/psf/black/commit/09915f4bd2d13652c089b9a96408b39116d82eb0", "file_name": "plugin/black.vim"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>    installation_and_usage\n <mask>    the_black_code_style\n <mask>    editor_integration\n <mask>    version_control_integration \n <mask>    contributing\n <mask>    change_log\n <mask>    reference/reference_summary\n <mask>    authors\n <mask> \n </s> Update documentation\n\n* Add \"Ignore non-modified files\" from the README\n* Add missing functions to the reference </s> add .. autofunction:: black.max_delimiter_priority_in_atom\n </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache\n </s> add .. autofunction:: black.reformat_one\n", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/index.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.format_str\n <mask> \n <mask> .. autofunction:: black.schedule_formatting\n <mask> \n <mask> File operations\n <mask> ---------------\n <mask>  </s> add .. autofunction:: black.max_delimiter_priority_in_atom </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache </s> remove    version_control_integration </s> add    version_control_integration\n   ignoring_non_modified_files", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> .. autofunction:: black.split_line\n <mask> \n <mask> .. autofunction:: black.bracket_split_succeeded_or_raise\n <mask> \n <mask> Utilities\n <mask> ---------\n <mask> \n <mask> .. py:function:: black.DebugVisitor.show(code: str) -> None\n <mask>  </s> add .. autofunction:: black.max_delimiter_priority_in_atom </s> add .. autofunction:: black.reformat_one", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.make_comment\n <mask> \n <mask> .. autofunction:: black.normalize_prefix\n <mask> \n <mask> .. autofunction:: black.normalize_string_quotes\n <mask> \n <mask> .. autofunction:: black.normalize_invisible_parens\n <mask>  </s> add Caching\n-------\n\n.. autofunction:: black.filter_cached\n\n.. autofunction:: black.get_cache_info\n\n.. autofunction:: black.read_cache\n\n.. autofunction:: black.write_cache </s> add .. autofunction:: black.reformat_one </s> remove    version_control_integration", "html_url": "https://github.com/psf/black/commit/0a340e1f227c3705ed1b0dbbbf634c98e2e82ada", "file_name": "docs/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     target_versions: Set[TargetVersion] = field(default_factory=set)\n <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     magic_trailing_comma: bool = True\n <mask>     experimental_string_processing: bool = False\n <mask> \n <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions: </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE) </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     line_length: int = DEFAULT_LINE_LENGTH\n <mask>     string_normalization: bool = True\n <mask>     magic_trailing_comma: bool = True\n <mask>     experimental_string_processing: bool = False\n <mask>     is_pyi: bool = False\n <mask> \n <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions:\n <mask>             version_str = \",\".join(\n <mask>                 str(version.value) </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE) </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>             str(int(self.string_normalization)),\n <mask>             str(int(self.is_pyi)),\n <mask>         ]\n <mask>         return \".\".join(parts)\n <mask> \n <mask> \n <mask> # Legacy name, left for integrations.\n <mask> FileMode = Mode </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False) </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False)", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep replace keep keep replace replace keep keep keep keep", "code_tokens": " <mask>     def test_string_quotes(self) -> None:\n <mask>         source, expected = read_data(\"string_quotes\")\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask>         mode = replace(DEFAULT_MODE, string_normalization=False)\n <mask>         not_normalized = fs(source, mode=mode)\n <mask>         self.assertFormatEqual(source.replace(\"\\\\\\n\", \"\"), not_normalized)\n <mask>         black.assert_equivalent(source, not_normalized)\n <mask>         black.assert_stable(source, not_normalized, mode=mode) </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE) </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path)) </s> add         black.assert_stable(source, actual, mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> SIMPLE_CASES = [\n <mask>     \"beginning_backslash\",\n <mask>     \"bracketmatch\",\n <mask>     \"cantfit\",\n <mask>     \"class_blank_parentheses\",\n <mask>     \"class_methods_new_line\",\n <mask>     \"collections\",\n <mask>     \"comments\",\n <mask>     \"comments2\", </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"comments3\",\n <mask>     \"comments4\",\n <mask>     \"comments5\",\n <mask>     \"comments6\",\n <mask>     \"comments7\",\n <mask>     \"comments_non_breaking_space\",\n <mask>     \"comment_after_escaped_newline\",\n <mask>     \"composition\",\n <mask>     \"composition_no_trailing_comma\",\n <mask>     \"docstring\", </s> fix magic comma and experimental string cache flags (#2131)\n\n* fix magic comma and experimental string cache flags\r\n\r\n* more changelog\r\n\r\n* Update CHANGES.md\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com>\r\n\r\n* fix tests\r\n\r\nCo-authored-by: Cooper Lees <me@cooperlees.com> </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n]", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep replace replace replace keep replace keep", "code_tokens": " <mask>     \"import_spacing\",\n <mask>     \"long_strings\",\n <mask>     \"long_strings__edge_case\",\n <mask>     \"long_strings__regression\",\n <mask>     \"numeric_literals_py2\",\n <mask>     \"percent_precedence\",\n <mask>     \"python2\", </s> add EXPERIMENTAL_STRING_PROCESSING_CASES = [\n    \"cantfit\",\n    \"comments7\",\n    \"long_strings\",\n    \"long_strings__edge_case\",\n    \"long_strings__regression\",\n    \"percent_precedence\",\n] </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True) </s> add DEFAULT_MODE = black.Mode() </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path)) </s> add         black.assert_stable(source, actual, mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True))", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> ]\n <mask> \n <mask> \n <mask> SOURCES = [\n <mask>     \"tests/test_black.py\",\n <mask>     \"tests/test_format.py\",\n <mask>     \"tests/test_blackd.py\",\n <mask>     \"src/black/__init__.py\", </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True) </s> add DEFAULT_MODE = black.Mode()", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> class TestSimpleFormat(BlackBaseTestCase):\n <mask>     @parameterized.expand(SIMPLE_CASES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_simple_format(self, filename: str) -> None:\n <mask>         source, expected = read_data(filename)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask> \n <mask>     @parameterized.expand(SOURCES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False) </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path)) </s> add         black.assert_stable(source, actual, mode) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True) </s> add DEFAULT_MODE = black.Mode()", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep replace replace", "code_tokens": " <mask>     @parameterized.expand(SOURCES)\n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_source_is_formatted(self, filename: str) -> None:\n <mask>         path = THIS_DIR.parent / filename\n <mask>         source, expected = read_data(str(path), data=False)\n <mask>         actual = fs(source, mode=DEFAULT_MODE)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, DEFAULT_MODE)\n <mask>         self.assertFalse(ff(path)) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove         actual = fs(source) </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        mode = replace(DEFAULT_MODE, string_normalization=False) </s> add         black.assert_stable(source, actual, mode)\n        mode = replace(mode, string_normalization=False) </s> remove DEFAULT_MODE = black.FileMode(experimental_string_processing=True) </s> add DEFAULT_MODE = black.Mode()", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> EMPTY_LINE = \"# EMPTY LINE WITH WHITESPACE\" + \" (this comment will be removed)\"\n <mask> DETERMINISTIC_HEADER = \"[Deterministic header]\"\n <mask> \n <mask> \n <mask> DEFAULT_MODE = black.FileMode(experimental_string_processing=True)\n <mask> ff = partial(black.format_file_in_place, mode=DEFAULT_MODE, fast=True)\n <mask> fs = partial(black.format_str, mode=DEFAULT_MODE)\n <mask> \n <mask> \n <mask> def dump_to_stderr(*output: str) -> str: </s> remove         source, expected = read_data(str(path), data=False)\n        actual = fs(source, mode=DEFAULT_MODE) </s> add         self.check_file(str(path), DEFAULT_MODE, data=False)\n        self.assertFalse(ff(path))\n\n    def check_file(self, filename: str, mode: black.Mode, *, data: bool = True) -> None:\n        source, expected = read_data(filename, data=data)\n        actual = fs(source, mode=mode) </s> remove         source, expected = read_data(filename)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, DEFAULT_MODE) </s> add         self.check_file(filename, DEFAULT_MODE)\n\n    @parameterized.expand(EXPERIMENTAL_STRING_PROCESSING_CASES)\n    @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_experimental_format(self, filename: str) -> None:\n        self.check_file(filename, black.Mode(experimental_string_processing=True)) </s> remove         black.assert_stable(source, actual, DEFAULT_MODE)\n        self.assertFalse(ff(path)) </s> add         black.assert_stable(source, actual, mode) </s> remove         actual = fs(source) </s> add         mode = black.Mode(experimental_string_processing=True)\n        actual = fs(source, mode=mode)", "html_url": "https://github.com/psf/black/commit/0a833b4b14953f98e81d632281a75318faa66170", "file_name": "tests/util.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> toml = \">=0.9.4\"\n <mask> black = {editable = true, path = \".\", extras = [\"d\"]}\n <mask> \n <mask> [dev-packages]\n <mask> pre-commit = \"*\"\n <mask> coverage = \"*\"\n <mask> flake8 = \"*\"\n <mask> flake8-bugbear = \"*\" </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> add BLACK_HEADERS = [\n    VERSION_HEADER,\n    LINE_LENGTH_HEADER,\n    PYTHON_VARIANT_HEADER,\n    SKIP_STRING_NORMALIZATION_HEADER,\n    SKIP_NUMERIC_UNDERSCORE_NORMALIZATION_HEADER,\n    FAST_OR_SAFE_HEADER,\n]", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "Pipfile"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from functools import partial\n <mask> import logging\n <mask> \n <mask> from aiohttp import web\n <mask> import black\n <mask> import click\n <mask> \n <mask> # This is used internally by tests to shut down the server prematurely </s> remove     app.add_routes([web.post(\"/\", partial(handle, executor=executor))]) </s> add     cors = aiohttp_cors.setup(app)\n    resource = cors.add(app.router.add_resource(\"/\"))\n    cors.add(\n        resource.add_route(\"POST\", partial(handle, executor=executor)),\n        {\n            \"*\": aiohttp_cors.ResourceOptions(\n                allow_headers=(*BLACK_HEADERS, \"Content-Type\"), expose_headers=\"*\"\n            )\n        },\n    ) </s> add aiohttp-cors = \"*\"", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> FAST_OR_SAFE_HEADER = \"X-Fast-Or-Safe\"\n <mask> \n <mask> \n <mask> @click.command(context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n <mask> @click.option(\n <mask>     \"--bind-host\", type=str, help=\"Address to bind the server to.\", default=\"localhost\"\n <mask> ) </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile.", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def make_app() -> web.Application:\n <mask>     app = web.Application()\n <mask>     executor = ProcessPoolExecutor()\n <mask>     app.add_routes([web.post(\"/\", partial(handle, executor=executor))])\n <mask>     return app\n <mask> \n <mask> \n <mask> async def handle(request: web.Request, executor: Executor) -> web.Response:\n <mask>     try:\n </s> Add CORS support to blackd (#627)\n\nSee issue #622. Use aiohttp-cors to allow cross-origin requests to blackd,\r\nand add a dependency on it to the pipfile. </s> add aiohttp-cors = \"*\" </s> add BLACK_HEADERS = [\n    VERSION_HEADER,\n    LINE_LENGTH_HEADER,\n    PYTHON_VARIANT_HEADER,\n    SKIP_STRING_NORMALIZATION_HEADER,\n    SKIP_NUMERIC_UNDERSCORE_NORMALIZATION_HEADER,\n    FAST_OR_SAFE_HEADER,\n]\n </s> add import aiohttp_cors", "html_url": "https://github.com/psf/black/commit/0b40a7badf82c53c8a23b3a03273619f8440855d", "file_name": "blackd.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if TYPE_CHECKING:\n <mask>     import colorama  # noqa: F401\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def find_project_root(\n <mask>     srcs: Sequence[str], stdin_filename: Optional[str] = None\n <mask> ) -> Tuple[Path, str]:\n <mask>     \"\"\"Return a directory containing .git, .hg, or pyproject.toml.\n <mask>  </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return SpecifierSet(\",\".join(str(s) for s in specifiers))\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def find_user_pyproject_toml() -> Path:\n <mask>     r\"\"\"Return the path to the top-level user configuration for black.\n <mask> \n <mask>     This looks for ~\\.black on Windows and ~/.config/black on Linux and other\n <mask>     Unix systems. </s> Run pyupgrade on blib2to3 and src (#3771)", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     mask: str\n <mask>     src: str\n <mask> \n <mask> \n <mask> @lru_cache()\n <mask> def jupyter_dependencies_are_installed(*, verbose: bool, quiet: bool) -> bool:\n <mask>     try:\n <mask>         # isort: off\n <mask>         # tokenize_rt is less commonly installed than IPython\n <mask>         # and IPython is expensive to import </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove @lru_cache()", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         try:\n <mask>             f = open(filename)\n <mask>         except OSError as err:\n <mask>             print(\"Can't open %s: %s\" % (filename, err))\n <mask>             return False\n <mask>         self.symbol2number = {}\n <mask>         self.number2symbol = {}\n <mask>         lineno = 0\n <mask>         for line in f: </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip())) </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> add     def calcfirst(self, name: str) -> None: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for line in f:\n <mask>             lineno += 1\n <mask>             mo = re.match(r\"^#define\\s+(\\w+)\\s+(\\d+)$\", line)\n <mask>             if not mo and line.strip():\n <mask>                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))\n <mask>             else:\n <mask>                 symbol, number = mo.groups()\n <mask>                 number = int(number)\n <mask>                 assert symbol not in self.symbol2number\n <mask>                 assert number not in self.number2symbol </s> remove             print(\"Can't open %s: %s\" % (filename, err)) </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         try:\n <mask>             f = open(filename)\n <mask>         except OSError as err:\n <mask>             print(\"Can't open %s: %s\" % (filename, err))\n <mask>             return False\n <mask>         # The code below essentially uses f's iterator-ness!\n <mask>         lineno = 0\n <mask> \n <mask>         # Expect the two #include lines </s> remove             print(\"Can't open %s: %s\" % (filename, err)) </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip())) </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace replace", "code_tokens": " <mask>     Iterable,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Iterator,\n <mask>     Tuple,\n <mask>     TypeVar,\n <mask>     Generic, </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         else:\n <mask>             return True\n <mask> \n <mask> \n <mask> class Driver(object):\n <mask>     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None:\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None, </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace", "code_tokens": " <mask>         assert p.rootnode is not None\n <mask>         return p.rootnode\n <mask> \n <mask>     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a stream and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(stream.readline, grammar=self.grammar)\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream: </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None: </s> add     def add_token(self, tok_type: int, tok_val: str, raw: bool = False) -> None: </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None: </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep", "code_tokens": " <mask> \n <mask>     def parse_file(\n <mask>         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False\n <mask>     ) -> NL:\n <mask>         \"\"\"Parse a file and return the syntax tree.\"\"\"\n <mask>         with io.open(filename, \"r\", encoding=encoding) as stream:\n <mask>             return self.parse_stream(stream, debug)\n <mask>  </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None: </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Parse a file and return the syntax tree.\"\"\"\n <mask>         with io.open(filename, \"r\", encoding=encoding) as stream:\n <mask>             return self.parse_stream(stream, debug)\n <mask> \n <mask>     def parse_string(self, text: Text, debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a string and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(\n <mask>             io.StringIO(text).readline, grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug) </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream: </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             io.StringIO(text).readline, grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]:\n <mask>         lines: List[str] = []\n <mask>         current_line = \"\"\n <mask>         current_column = 0\n <mask>         wait_for_nl = False\n <mask>         for char in prefix: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     def prefix(self, prefix: Text) -> None: </s> add     def prefix(self, prefix: str) -> None: </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 wait_for_nl = True\n <mask>         return \"\".join(lines), current_line\n <mask> \n <mask> \n <mask> def _generate_pickle_name(gt: Path, cache_dir: Optional[Path] = None) -> Text:\n <mask>     head, tail = os.path.splitext(gt)\n <mask>     if tail == \".txt\":\n <mask>         tail = \"\"\n <mask>     name = head + tail + \".\".join(map(str, sys.version_info)) + \".pickle\"\n <mask>     if cache_dir: </s> remove     package: str, grammar_source: Text, cache_dir: Optional[Path] = None </s> add     package: str, grammar_source: str, cache_dir: Optional[Path] = None </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         return name\n <mask> \n <mask> \n <mask> def load_grammar(\n <mask>     gt: Text = \"Grammar.txt\",\n <mask>     gp: Optional[Text] = None,\n <mask>     save: bool = True,\n <mask>     force: bool = False,\n <mask>     logger: Optional[Logger] = None,\n <mask> ) -> Grammar:\n <mask>     \"\"\"Load the grammar (maybe from a pickle).\"\"\" </s> remove     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]: </s> add     def determine_route(self, value: Optional[str] = None, force: bool = False) -> Optional[int]: </s> remove class Driver(object):", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         g.load(gp)\n <mask>     return g\n <mask> \n <mask> \n <mask> def _newer(a: Text, b: Text) -> bool:\n <mask>     \"\"\"Inquire whether file a was written since file b.\"\"\"\n <mask>     if not os.path.exists(a):\n <mask>         return False\n <mask>     if not os.path.exists(b):\n <mask>         return True </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream: </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return os.path.getmtime(a) >= os.path.getmtime(b)\n <mask> \n <mask> \n <mask> def load_packaged_grammar(\n <mask>     package: str, grammar_source: Text, cache_dir: Optional[Path] = None\n <mask> ) -> grammar.Grammar:\n <mask>     \"\"\"Normally, loads a pickled grammar by doing\n <mask>         pkgutil.get_data(package, pickled_grammar)\n <mask>     where *pickled_grammar* is computed from *grammar_source* by adding the\n <mask>     Python version and using a ``.pickle`` extension. </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text: </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL: </s> remove     gt: Text = \"Grammar.txt\",\n    gp: Optional[Text] = None, </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     g.loads(data)\n <mask>     return g\n <mask> \n <mask> \n <mask> def main(*args: Text) -> bool:\n <mask>     \"\"\"Main program, when run as a script: produce grammar pickle files.\n <mask> \n <mask>     Calls load_grammar for each argument, a path to a grammar text file.\n <mask>     \"\"\"\n <mask>     if not args: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     package: str, grammar_source: Text, cache_dir: Optional[Path] = None </s> add     package: str, grammar_source: str, cache_dir: Optional[Path] = None </s> add     gt: str = \"Grammar.txt\",\n    gp: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Python imports\n <mask> import os\n <mask> import pickle\n <mask> import tempfile\n <mask> from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union\n <mask> \n <mask> # Local imports\n <mask> from . import token\n <mask> \n <mask> _P = TypeVar(\"_P\", bound=\"Grammar\") </s> remove from .pgen2 import token", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Local imports\n <mask> from . import token\n <mask> \n <mask> _P = TypeVar(\"_P\", bound=\"Grammar\")\n <mask> Label = Tuple[int, Optional[Text]]\n <mask> DFA = List[List[Tuple[int, int]]]\n <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> Path = Union[str, \"os.PathLike[str]\"]\n <mask> \n <mask>  </s> remove class Grammar(object): </s> remove Context = Tuple[Text, Tuple[int, int]]\nRawNode = Tuple[int, Optional[Text], Optional[Context], Optional[List[NL]]] </s> remove _type_reprs: Dict[int, Union[Text, int]] = {} </s> remove def type_repr(type_num: int) -> Union[Text, int]: </s> add def type_repr(type_num: int) -> Union[str, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> Path = Union[str, \"os.PathLike[str]\"]\n <mask> \n <mask> \n <mask> class Grammar(object):\n <mask>     \"\"\"Pgen parsing tables conversion class.\n <mask> \n <mask>     Once initialized, this class supplies the grammar tables for the\n <mask>     parsing engine implemented by parse.py.  The parsing engine\n <mask>     accesses the instance variables directly.  The class here does not </s> remove Label = Tuple[int, Optional[Text]] </s> add Label = Tuple[int, Optional[str]] </s> add </s> remove class Parser(object): </s> add class Parser: </s> remove class Base(object): </s> add class Base: </s> remove Results = Dict[Text, NL] </s> add Results = Dict[str, NL] </s> remove class Symbols(object): </s> add class Symbols:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Safely evaluate Python string literals without using eval().\"\"\"\n <mask> \n <mask> import re\n <mask> \n <mask> from typing import Dict, Match, Text\n <mask> \n <mask> \n <mask> simple_escapes: Dict[Text, Text] = {\n <mask>     \"a\": \"\\a\",\n <mask>     \"b\": \"\\b\", </s> remove simple_escapes: Dict[Text, Text] = { </s> add simple_escapes: Dict[str, str] = { </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove     Text,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from typing import Dict, Match, Text\n <mask> \n <mask> \n <mask> simple_escapes: Dict[Text, Text] = {\n <mask>     \"a\": \"\\a\",\n <mask>     \"b\": \"\\b\",\n <mask>     \"f\": \"\\f\",\n <mask>     \"n\": \"\\n\",\n <mask>     \"r\": \"\\r\", </s> remove from typing import Dict, Match, Text </s> add from typing import Dict, Match </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union </s> remove     Text,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\\\\\": \"\\\\\",\n <mask> }\n <mask> \n <mask> \n <mask> def escape(m: Match[Text]) -> Text:\n <mask>     all, tail = m.group(0, 1)\n <mask>     assert all.startswith(\"\\\\\")\n <mask>     esc = simple_escapes.get(tail)\n <mask>     if esc is not None:\n <mask>         return esc </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             raise ValueError(\"invalid octal string escape ('\\\\%s')\" % tail) from None\n <mask>     return chr(i)\n <mask> \n <mask> \n <mask> def evalString(s: Text) -> Text:\n <mask>     assert s.startswith(\"'\") or s.startswith('\"'), repr(s[:1])\n <mask>     q = s[0]\n <mask>     if s[:3] == q * 3:\n <mask>         q = q * 3\n <mask>     assert s.endswith(q), repr(s[-len(q) :]) </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text: </s> remove         return \"%s(%s, %r)\" % ( </s> add         return \"{}({}, {!r})\".format( </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> See Parser/parser.c in the Python distribution for additional info on\n <mask> how this parsing engine works.\n <mask> \n <mask> \"\"\"\n <mask> import copy\n <mask> from contextlib import contextmanager\n <mask> \n <mask> # Local imports\n <mask> from . import grammar, token, tokenize\n <mask> from typing import ( </s> remove from .pgen2 import token", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from typing import (\n <mask>     cast,\n <mask>     Any,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Union,\n <mask>     Tuple,\n <mask>     Dict,\n <mask>     List,\n <mask>     Iterator, </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> if TYPE_CHECKING:\n <mask>     from blib2to3.pgen2.driver import TokenProxy\n <mask> \n <mask> \n <mask> Results = Dict[Text, NL]\n <mask> Convert = Callable[[Grammar, RawNode], Union[Node, Leaf]]\n <mask> DFA = List[List[Tuple[int, int]]]\n <mask> DFAS = Tuple[DFA, Dict[int, int]]\n <mask> \n <mask>  </s> remove Label = Tuple[int, Optional[Text]] </s> add Label = Tuple[int, Optional[str]] </s> remove _type_reprs: Dict[int, Union[Text, int]] = {} </s> remove class Grammar(object): </s> remove _Results = Dict[Text, NL] </s> add _Results = Dict[str, NL] </s> remove def type_repr(type_num: int) -> Union[Text, int]: </s> add def type_repr(type_num: int) -> Union[str, int]: </s> remove     first: Dict[Text, Optional[Dict[Text, int]]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield\n <mask>         finally:\n <mask>             self.parser.is_backtracking = is_backtracking\n <mask> \n <mask>     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:\n <mask>         func: Callable[..., Any]\n <mask>         if raw:\n <mask>             func = self.parser._addtoken\n <mask>         else:\n <mask>             func = self.parser.addtoken </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 if raw:\n <mask>                     args.insert(0, ilabel)\n <mask>                 func(*args)\n <mask> \n <mask>     def determine_route(self, value: Optional[Text] = None, force: bool = False) -> Optional[int]:\n <mask>         alive_ilabels = self.ilabels\n <mask>         if len(alive_ilabels) == 0:\n <mask>             *_, most_successful_ilabel = self._dead_ilabels\n <mask>             raise ParseError(\"bad input\", most_successful_ilabel, value, self.context)\n <mask>  </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask>     \"\"\"Exception to signal the parser is stuck.\"\"\"\n <mask> \n <mask>     def __init__(\n <mask>         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context\n <mask>     ) -> None:\n <mask>         Exception.__init__(\n <mask>             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n <mask>         ) </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.value = value\n <mask>         self.context = context\n <mask> \n <mask> \n <mask> class Parser(object):\n <mask>     \"\"\"Parser engine.\n <mask> \n <mask>     The proper usage sequence is:\n <mask> \n <mask>     p = Parser(grammar, [converter])  # create instance </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context) </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\" </s> remove class Grammar(object): </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove class Symbols(object): </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.rootnode: Optional[NL] = None\n <mask>         self.used_names: Set[str] = set()\n <mask>         self.proxy = proxy\n <mask> \n <mask>     def addtoken(self, type: int, value: Text, context: Context) -> bool:\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabels = self.classify(type, value, context)\n <mask>         assert len(ilabels) >= 1\n <mask>  </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\"", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert ilabel is not None\n <mask> \n <mask>         return self._addtoken(ilabel, type, value, context)\n <mask> \n <mask>     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:\n <mask>         # Loop until the token is shifted; may raise exceptions\n <mask>         while True:\n <mask>             dfa, state, node = self.stack[-1]\n <mask>             states, first = dfa\n <mask>             arcs = states[state] </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type: int, value: Text, context: Context) -> List[int]:\n <mask>         \"\"\"Turn a token into a label.  (Internal)\n <mask> \n <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if ilabel is None:\n <mask>             raise ParseError(\"bad token\", type, value, context)\n <mask>         return [ilabel]\n <mask> \n <mask>     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:\n <mask>         \"\"\"Shift a token.  (Internal)\"\"\"\n <mask>         if self.is_backtracking:\n <mask>             dfa, state, _ = self.stack[-1]\n <mask>             self.stack[-1] = (dfa, newstate, DUMMY_NODE)\n <mask>         else: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     IO,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     Union,\n <mask>     Sequence,\n <mask>     NoReturn,\n <mask> ) </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace keep keep keep", "code_tokens": " <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> \n <mask> class ParserGenerator(object):\n <mask>     filename: Path\n <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask> \n <mask> \n <mask> class ParserGenerator(object):\n <mask>     filename: Path\n <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask>  </s> remove     first: Dict[Text, Optional[Dict[Text, int]]] </s> add     first: Dict[str, Optional[Dict[str, int]]] </s> remove     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None: </s> add     def __init__(self, filename: Path, stream: Optional[IO[str]] = None) -> None: </s> remove class Grammar(object): </s> remove class DFAState(object): </s> add class DFAState: </s> remove class BasePattern(object):", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>     stream: IO[Text]\n <mask>     generator: Iterator[GoodTokenInfo]\n <mask>     first: Dict[Text, Optional[Dict[Text, int]]]\n <mask> \n <mask>     def __init__(self, filename: Path, stream: Optional[IO[Text]] = None) -> None: </s> remove     stream: IO[Text] </s> add     stream: IO[str] </s> remove class ParserGenerator(object): </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream: </s> add         with open(filename, encoding=encoding) as stream: </s> remove         self, filename: Path, encoding: Optional[Text] = None, debug: bool = False </s> add         self, filename: Path, encoding: Optional[str] = None, debug: bool = False", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             c.dfas[c.symbol2number[name]] = (states, self.make_first(c, name))\n <mask>         c.start = c.symbol2number[self.startsymbol]\n <mask>         return c\n <mask> \n <mask>     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]:\n <mask>         rawfirst = self.first[name]\n <mask>         assert rawfirst is not None\n <mask>         first = {}\n <mask>         for label in sorted(rawfirst):\n <mask>             ilabel = self.make_label(c, label) </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def calcfirst(self, name: Text) -> None: </s> add     def calcfirst(self, name: str) -> None: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]: </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove def type_repr(type_num: int) -> Union[Text, int]: </s> add def type_repr(type_num: int) -> Union[str, int]:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             ##assert ilabel not in first # XXX failed on <> ... !=\n <mask>             first[ilabel] = 1\n <mask>         return first\n <mask> \n <mask>     def make_label(self, c: PgenGrammar, label: Text) -> int:\n <mask>         # XXX Maybe this should be a method on a subclass of converter?\n <mask>         ilabel = len(c.labels)\n <mask>         if label[0].isalpha():\n <mask>             # Either a symbol name or a named token\n <mask>             if label in c.symbol2number: </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]: </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     used_names: Optional[Set[Text]] </s> add     used_names: Optional[Set[str]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def calcfirst(self, name: Text) -> None: </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if name not in self.first:\n <mask>                 self.calcfirst(name)\n <mask>             # print name, self.first[name].keys()\n <mask> \n <mask>     def calcfirst(self, name: Text) -> None:\n <mask>         dfa = self.dfas[name]\n <mask>         self.first[name] = None  # dummy to detect left recursion\n <mask>         state = dfa[0]\n <mask>         totalset: Dict[str, int] = {}\n <mask>         overlapcheck = {} </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]: </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]: </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove _type_reprs: Dict[int, Union[Text, int]] = {} </s> add _type_reprs: Dict[int, Union[str, int]] = {}", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     )\n <mask>                 inverse[symbol] = label\n <mask>         self.first[name] = totalset\n <mask> \n <mask>     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]:\n <mask>         dfas = {}\n <mask>         startsymbol: Optional[str] = None\n <mask>         # MSTART: (NEWLINE | RULE)* ENDMARKER\n <mask>         while self.type != token.ENDMARKER:\n <mask>             while self.type == token.NEWLINE: </s> add     def calcfirst(self, name: str) -> None: </s> add     def __repr__(self) -> str: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     states.append(st)\n <mask>                 state.addarc(st, label)\n <mask>         return states  # List of DFAState instances; first one is start\n <mask> \n <mask>     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None:\n <mask>         print(\"Dump of NFA for\", name)\n <mask>         todo = [start]\n <mask>         for i, state in enumerate(todo):\n <mask>             print(\"  State\", i, state is finish and \"(final)\" or \"\")\n <mask>             for label, next in state.arcs: </s> remove     def dump_dfa(self, name: Text, dfa: Sequence[\"DFAState\"]) -> None: </s> add     def dump_dfa(self, name: str, dfa: Sequence[\"DFAState\"]) -> None: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> add     def calcfirst(self, name: str) -> None: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     print(\"    -> %d\" % j)\n <mask>                 else:\n <mask>                     print(\"    %s -> %d\" % (label, j))\n <mask> \n <mask>     def dump_dfa(self, name: Text, dfa: Sequence[\"DFAState\"]) -> None:\n <mask>         print(\"Dump of DFA for\", name)\n <mask>         for i, state in enumerate(dfa):\n <mask>             print(\"  State\", i, state.isfinal and \"(final)\" or \"\")\n <mask>             for label, next in sorted(state.arcs.items()):\n <mask>                 print(\"    %s -> %d\" % (label, dfa.index(next))) </s> remove     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None: </s> add     def dump_nfa(self, name: str, start: \"NFAState\", finish: \"NFAState\") -> None: </s> add     def calcfirst(self, name: str) -> None: </s> add     def __repr__(self) -> str: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]] </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n <mask>             )\n <mask>             assert False\n <mask> \n <mask>     def expect(self, type: int, value: Optional[Any] = None) -> Text:\n <mask>         if self.type != type or (value is not None and self.value != value):\n <mask>             self.raise_error(\n <mask>                 \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n <mask>             )\n <mask>         value = self.value </s> remove             self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context) </s> add             self, f\"{msg}: type={type!r}, value={value!r}, context={context!r}\" </s> remove     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> add     def classify(self, type: int, value: str, context: Context) -> List[int]: </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 msg = \" \".join([msg] + list(map(str, args)))\n <mask>         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line))\n <mask> \n <mask> \n <mask> class NFAState(object):\n <mask>     arcs: List[Tuple[Optional[Text], \"NFAState\"]]\n <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> add     tokens: List[str] </s> remove     arcs: Dict[Text, \"DFAState\"] </s> add     arcs: Dict[str, \"DFAState\"] </s> remove class DFAState(object): </s> add class DFAState:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None:\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask>  </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]] </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None: </s> remove class DFAState(object): </s> add class DFAState: </s> remove     arcs: Dict[Text, \"DFAState\"] </s> add     arcs: Dict[str, \"DFAState\"] </s> remove     def dump_nfa(self, name: Text, start: \"NFAState\", finish: \"NFAState\") -> None: </s> add     def dump_nfa(self, name: str, start: \"NFAState\", finish: \"NFAState\") -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask> \n <mask> class DFAState(object):\n <mask>     nfaset: Dict[NFAState, Any]\n <mask>     isfinal: bool\n <mask>     arcs: Dict[Text, \"DFAState\"]\n <mask> \n <mask>     def __init__(self, nfaset: Dict[NFAState, Any], final: NFAState) -> None: </s> remove     arcs: Dict[Text, \"DFAState\"] </s> add     arcs: Dict[str, \"DFAState\"] </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]] </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> add     stream: IO[str] </s> remove     first: Dict[Text, Optional[Dict[Text, int]]] </s> add     first: Dict[str, Optional[Dict[str, int]]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class DFAState(object):\n <mask>     nfaset: Dict[NFAState, Any]\n <mask>     isfinal: bool\n <mask>     arcs: Dict[Text, \"DFAState\"]\n <mask> \n <mask>     def __init__(self, nfaset: Dict[NFAState, Any], final: NFAState) -> None:\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState) </s> remove class DFAState(object): </s> add class DFAState: </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]] </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> remove     def addarc(self, next: \"DFAState\", label: Text) -> None: </s> add     def addarc(self, next: \"DFAState\", label: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.nfaset = nfaset\n <mask>         self.isfinal = final in nfaset\n <mask>         self.arcs = {}  # map from label to DFAState\n <mask> \n <mask>     def addarc(self, next: \"DFAState\", label: Text) -> None:\n <mask>         assert isinstance(label, str)\n <mask>         assert label not in self.arcs\n <mask>         assert isinstance(next, DFAState)\n <mask>         self.arcs[label] = next\n <mask>  </s> remove     def addarc(self, next: \"NFAState\", label: Optional[Text] = None) -> None: </s> add     def addarc(self, next: \"NFAState\", label: Optional[str] = None) -> None: </s> remove class NFAState(object):\n    arcs: List[Tuple[Optional[Text], \"NFAState\"]] </s> add class NFAState:\n    arcs: List[Tuple[Optional[str], \"NFAState\"]] </s> add     def calcfirst(self, name: str) -> None: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Token constants (from \"token.h\").\"\"\"\n <mask> \n <mask> import sys\n <mask> from typing import Dict\n <mask> \n <mask> from typing import Final\n <mask> \n <mask> #  Taken from Python (r53757) and modified to include some tokens </s> remove from .pgen2 import token", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # --end constants--\n <mask> \n <mask> tok_name: Final[Dict[int, str]] = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0):\n <mask>         tok_name[_value] = _name\n <mask> \n <mask> \n <mask> def ISTERMINAL(x: int) -> bool:\n <mask>     return x < NT_OFFSET </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Set,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     Pattern,\n <mask>     Union,\n <mask>     cast,\n <mask> ) </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return group(*choices) + \"?\"\n <mask> \n <mask> \n <mask> def _combinations(*l: str) -> Set[str]:\n <mask>     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold())\n <mask> \n <mask> \n <mask> Whitespace = r\"[ \\f\\t]*\"\n <mask> Comment = r\"#[^\\r\\n]*\"\n <mask> Ignore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment) </s> add     def get_suffix(self) -> str: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> Coord = Tuple[int, int]\n <mask> \n <mask> \n <mask> def printtoken(\n <mask>     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text\n <mask> ) -> None:  # for testing\n <mask>     (srow, scol) = srow_col\n <mask>     (erow, ecol) = erow_col\n <mask>     print(\n <mask>         \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token)) </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None] </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove                 Tuple[int, Text, Coord, Coord, Text], t </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None: </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token))\n <mask>     )\n <mask> \n <mask> \n <mask> TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n <mask> \n <mask> \n <mask> def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None: </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> remove                 Tuple[int, Text, Coord, Coord, Text], t </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> TokenEater = Callable[[int, Text, Coord, Coord, Text], None]\n <mask> \n <mask> \n <mask> def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None:\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the\n <mask>     input stream, and one providing an output mechanism for tokenize().\n <mask> \n <mask>     The first parameter, readline, must be a callable object which provides </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None] </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove                 Tuple[int, Text, Coord, Coord, Text], t </s> add                 Tuple[int, str, Coord, Coord, str], t </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask> \n <mask> # backwards compatible interface\n <mask> def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None:\n <mask>     for token_info in generate_tokens(readline):\n <mask>         tokeneater(*token_info)\n <mask> \n <mask> \n <mask> GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None] </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None: </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> TokenInfo = Union[Tuple[int, str], GoodTokenInfo]\n <mask> \n <mask> \n <mask> class Untokenizer:\n <mask>     tokens: List[Text]\n <mask>     prev_row: int\n <mask>     prev_col: int\n <mask> \n <mask>     def __init__(self) -> None:\n <mask>         self.tokens = [] </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove         content: Optional[Text] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         col_offset = col - self.prev_col\n <mask>         if col_offset:\n <mask>             self.tokens.append(\" \" * col_offset)\n <mask> \n <mask>     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text:\n <mask>         for t in iterable:\n <mask>             if len(t) == 2:\n <mask>                 self.compat(cast(Tuple[int, str], t), iterable)\n <mask>                 break\n <mask>             tok_type, token, start, end, line = cast( </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip())) </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\")", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             if len(t) == 2:\n <mask>                 self.compat(cast(Tuple[int, str], t), iterable)\n <mask>                 break\n <mask>             tok_type, token, start, end, line = cast(\n <mask>                 Tuple[int, Text, Coord, Coord, Text], t\n <mask>             )\n <mask>             self.add_whitespace(start)\n <mask>             self.tokens.append(token)\n <mask>             self.prev_row, self.prev_col = end\n <mask>             if tok_type in (NEWLINE, NL): </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text: </s> add     def untokenize(self, iterable: Iterable[TokenInfo]) -> str: </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> add GoodTokenInfo = Tuple[int, str, Coord, Coord, str] </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None: </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None] </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 self.prev_row += 1\n <mask>                 self.prev_col = 0\n <mask>         return \"\".join(self.tokens)\n <mask> \n <mask>     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:\n <mask>         startline = False\n <mask>         indents = []\n <mask>         toks_append = self.tokens.append\n <mask>         toknum, tokval = token\n <mask>         if toknum in (NAME, NUMBER): </s> remove     def untokenize(self, iterable: Iterable[TokenInfo]) -> Text: </s> add     def untokenize(self, iterable: Iterable[TokenInfo]) -> str: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     type: int, token: Text, srow_col: Coord, erow_col: Coord, line: Text </s> add     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip())) </s> add                 print(f\"{filename}({lineno}): can't parse {line.strip()}\") </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def read_or_stop() -> bytes:\n <mask>         try:\n <mask>             return readline()\n <mask>         except StopIteration:\n <mask>             return bytes()\n <mask> \n <mask>     def find_cookie(line: bytes) -> Optional[str]:\n <mask>         try:\n <mask>             line_string = line.decode(\"ascii\")\n <mask>         except UnicodeDecodeError: </s> remove     readline: Callable[[], Text], grammar: Optional[Grammar] = None </s> add     readline: Callable[[], str], grammar: Optional[Grammar] = None", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     return default, [first, second]\n <mask> \n <mask> \n <mask> def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n <mask>     \"\"\"Transform tokens back into Python source code.\n <mask> \n <mask>     Each element returned by the iterable must be a token sequence\n <mask>     with at least two elements, a token number and token value.  If\n <mask>     only two tokens are passed, the resulting output is poor. </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None: </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove     def parse_string(self, text: Text, debug: bool = False) -> NL: </s> add     def parse_string(self, text: str, debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     return ut.untokenize(iterable)\n <mask> \n <mask> \n <mask> def generate_tokens(\n <mask>     readline: Callable[[], Text], grammar: Optional[Grammar] = None\n <mask> ) -> Iterator[GoodTokenInfo]:\n <mask>     \"\"\"\n <mask>     The generate_tokens() generator requires one argument, readline, which\n <mask>     must be a callable object which provides the same interface as the\n <mask>     readline() method of built-in file objects. Each call to the function </s> remove def tokenize(readline: Callable[[], Text], tokeneater: TokenEater = printtoken) -> None: </s> add def tokenize(readline: Callable[[], str], tokeneater: TokenEater = printtoken) -> None: </s> remove TokenEater = Callable[[int, Text, Coord, Coord, Text], None] </s> add TokenEater = Callable[[int, str, Coord, Coord, str], None] </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text: </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove         with io.open(filename, \"r\", encoding=encoding) as stream: </s> remove def tokenize_loop(readline: Callable[[], Text], tokeneater: TokenEater) -> None: </s> add def tokenize_loop(readline: Callable[[], str], tokeneater: TokenEater) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n <mask> #                                      \"PatternGrammar.txt\")\n <mask> \n <mask> \n <mask> class Symbols(object):\n <mask>     def __init__(self, grammar: Grammar) -> None:\n <mask>         \"\"\"Initializer.\n <mask> \n <mask>         Creates an attribute for each grammar symbol (nonterminal),\n <mask>         whose value is the symbol's type (an int >= 256). </s> remove class Driver(object): </s> add class Driver: </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove def main(*args: Text) -> bool: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Dict,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Tuple,\n <mask>     TypeVar,\n <mask>     Union,\n <mask>     Set,\n <mask>     Iterable, </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove     Text, </s> remove from typing import Any, Dict, List, Optional, Text, Tuple, TypeVar, Union </s> add from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from io import StringIO\n <mask> \n <mask> HUGE: int = 0x7FFFFFFF  # maximum repeat count, default max\n <mask> \n <mask> _type_reprs: Dict[int, Union[Text, int]] = {}\n <mask> \n <mask> \n <mask> def type_repr(type_num: int) -> Union[Text, int]:\n <mask>     global _type_reprs\n <mask>     if not _type_reprs: </s> remove def type_repr(type_num: int) -> Union[Text, int]: </s> add def type_repr(type_num: int) -> Union[str, int]: </s> remove Label = Tuple[int, Optional[Text]] </s> add Label = Tuple[int, Optional[str]] </s> remove     def calcfirst(self, name: Text) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _type_reprs: Dict[int, Union[Text, int]] = {}\n <mask> \n <mask> \n <mask> def type_repr(type_num: int) -> Union[Text, int]:\n <mask>     global _type_reprs\n <mask>     if not _type_reprs:\n <mask>         from .pygram import python_symbols\n <mask> \n <mask>         # printing tokens is possible but not as useful </s> remove _type_reprs: Dict[int, Union[Text, int]] = {} </s> add _type_reprs: Dict[int, Union[str, int]] = {} </s> remove     def make_first(self, c: PgenGrammar, name: Text) -> Dict[int, int]: </s> add     def make_first(self, c: PgenGrammar, name: str) -> Dict[int, int]: </s> add     if type(_value) is int: </s> remove Label = Tuple[int, Optional[Text]] </s> add Label = Tuple[int, Optional[str]] </s> remove     def calcfirst(self, name: Text) -> None: </s> add     def calcfirst(self, name: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep replace replace keep keep replace keep keep keep", "code_tokens": " <mask> _P = TypeVar(\"_P\", bound=\"Base\")\n <mask> \n <mask> NL = Union[\"Node\", \"Leaf\"]\n <mask> Context = Tuple[Text, Tuple[int, int]]\n <mask> RawNode = Tuple[int, Optional[Text], Optional[Context], Optional[List[NL]]]\n <mask> \n <mask> \n <mask> class Base(object):\n <mask> \n <mask>     \"\"\"\n <mask>     Abstract base class for Node and Leaf. </s> remove Label = Tuple[int, Optional[Text]] </s> add Label = Tuple[int, Optional[str]] </s> remove GoodTokenInfo = Tuple[int, Text, Coord, Coord, Text] </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _eq(self: _P, other: _P) -> bool:\n <mask>         \"\"\"\n <mask>         Compare two nodes for equality. </s> remove     def prefix(self) -> Text: </s> remove     def prefix(self) -> Text: </s> remove def main(*args: Text) -> bool: </s> remove def _newer(a: Text, b: Text) -> bool: </s> add def _newer(a: str, b: str) -> bool:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.parent is None:\n <mask>             return 0\n <mask>         return 1 + self.parent.depth()\n <mask> \n <mask>     def get_suffix(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return the string immediately following the invocant node. This is\n <mask>         effectively equivalent to node.next_sibling.prefix\n <mask>         \"\"\"\n <mask>         next_sib = self.next_sibling </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def compat(self, token: Tuple[int, Text], iterable: Iterable[TokenInfo]) -> None: </s> add     def compat(self, token: Tuple[int, str], iterable: Iterable[TokenInfo]) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     \"\"\"Concrete implementation for interior nodes.\"\"\"\n <mask> \n <mask>     fixers_applied: Optional[List[Any]]\n <mask>     used_names: Optional[Set[Text]]\n <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: int,\n <mask>         children: List[NL], </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         self, msg: Text, type: Optional[int], value: Optional[Text], context: Context </s> add         self, msg: str, type: Optional[int], value: Optional[str], context: Context", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self,\n <mask>         type: int,\n <mask>         children: List[NL],\n <mask>         context: Optional[Any] = None,\n <mask>         prefix: Optional[Text] = None,\n <mask>         fixers_applied: Optional[List[Any]] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask>  </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         name: Optional[Text] = None, </s> add         name: Optional[str] = None, </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> add     used_names: Optional[Set[str]]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace keep keep replace keep keep keep", "code_tokens": " <mask>             self.fixers_applied = None\n <mask> \n <mask>     def __repr__(self) -> Text:\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         assert self.type is not None\n <mask>         return \"%s(%s, %r)\" % (\n <mask>             self.__class__.__name__,\n <mask>             type_repr(self.type),\n <mask>             self.children, </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args))) </s> remove def evalString(s: Text) -> Text:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             type_repr(self.type),\n <mask>             self.children,\n <mask>         )\n <mask> \n <mask>     def __str__(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\" </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def get_suffix(self) -> Text: </s> add     def get_suffix(self) -> str: </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text: </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for child in self.children:\n <mask>             yield from child.pre_order()\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         \"\"\"\n <mask>         The whitespace and comments preceding this node in the input.\n <mask>         \"\"\"\n <mask>         if not self.children:\n <mask>             return \"\" </s> Run pyupgrade on blib2to3 and src (#3771) </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def prefix(self, prefix: Text) -> None: </s> add     def prefix(self, prefix: str) -> None: </s> remove     used_names: Optional[Set[Text]] </s> add     used_names: Optional[Set[str]] </s> remove     def get_suffix(self) -> Text: </s> add     def get_suffix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return \"\"\n <mask>         return self.children[0].prefix\n <mask> \n <mask>     @prefix.setter\n <mask>     def prefix(self, prefix: Text) -> None:\n <mask>         if self.children:\n <mask>             self.children[0].prefix = prefix\n <mask> \n <mask>     def set_child(self, i: int, child: NL) -> None:\n <mask>         \"\"\" </s> remove     def prefix(self, prefix: Text) -> None: </s> add     def prefix(self, prefix: str) -> None: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> add     def shift(self, type: int, value: str, newstate: int, context: Context) -> None: </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask>     \"\"\"Concrete implementation for leaf nodes.\"\"\"\n <mask> \n <mask>     # Default values for instance variables\n <mask>     value: Text\n <mask>     fixers_applied: List[Any]\n <mask>     bracket_depth: int\n <mask>     # Changed later in brackets.py\n <mask>     opening_bracket: Optional[\"Leaf\"] = None\n <mask>     used_names: Optional[Set[Text]]\n <mask>     _prefix = \"\"  # Whitespace and comments preceding this token in the input\n <mask>     lineno: int = 0  # Line where this token starts in the input\n <mask>     column: int = 0  # Column where this token starts in the input </s> remove     used_names: Optional[Set[Text]] </s> remove     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> add     def addtoken(self, type: int, value: str, context: Context) -> bool: </s> remove     def make_label(self, c: PgenGrammar, label: Text) -> int: </s> add     def make_label(self, c: PgenGrammar, label: str) -> int:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep", "code_tokens": " <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: int,\n <mask>         value: Text,\n <mask>         context: Optional[Context] = None,\n <mask>         prefix: Optional[Text] = None,\n <mask>         fixers_applied: List[Any] = [],\n <mask>         opening_bracket: Optional[\"Leaf\"] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         content: Optional[Text] = None, </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         name: Optional[Text] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             tok_name.get(self.type, self.type),\n <mask>             self.value,\n <mask>         )\n <mask> \n <mask>     def __str__(self) -> Text:\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\" </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove def untokenize(iterable: Iterable[TokenInfo]) -> Text: </s> add def untokenize(iterable: Iterable[TokenInfo]) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"Return a pre-order iterator for the tree.\"\"\"\n <mask>         yield self\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         \"\"\"\n <mask>         The whitespace and comments preceding this token in the input.\n <mask>         \"\"\"\n <mask>         return self._prefix\n <mask>  </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def prefix(self) -> Text: </s> add     def prefix(self) -> str: </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def __str__(self) -> Text: </s> add     def __str__(self) -> str: </s> remove     def prefix(self, prefix: Text) -> None: </s> add     def prefix(self, prefix: str) -> None:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         return self._prefix\n <mask> \n <mask>     @prefix.setter\n <mask>     def prefix(self, prefix: Text) -> None:\n <mask>         self.changed()\n <mask>         self._prefix = prefix\n <mask> \n <mask> \n <mask> def convert(gr: Grammar, raw_node: RawNode) -> NL: </s> remove     def prefix(self, prefix: Text) -> None: </s> add     def prefix(self, prefix: str) -> None: </s> remove     def prefix(self) -> Text: </s> remove     def _partially_consume_prefix(self, prefix: Text, column: int) -> Tuple[Text, Text]: </s> add     def _partially_consume_prefix(self, prefix: str, column: int) -> Tuple[str, str]: </s> remove     def parse_stream_raw(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream_raw(self, stream: IO[str], debug: bool = False) -> NL: </s> remove     def parse_stream(self, stream: IO[Text], debug: bool = False) -> NL: </s> add     def parse_stream(self, stream: IO[str], debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         return Leaf(type, value or \"\", context=context)\n <mask> \n <mask> \n <mask> _Results = Dict[Text, NL]\n <mask> \n <mask> \n <mask> class BasePattern(object):\n <mask> \n <mask>     \"\"\" </s> remove class BasePattern(object): </s> remove Results = Dict[Text, NL] </s> add Results = Dict[str, NL]", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> _Results = Dict[Text, NL]\n <mask> \n <mask> \n <mask> class BasePattern(object):\n <mask> \n <mask>     \"\"\"\n <mask>     A pattern is a tree matching pattern.\n <mask> \n <mask>     It looks for a specific node type (token or symbol), and </s> remove _Results = Dict[Text, NL] </s> add _Results = Dict[str, NL] </s> remove     name: Optional[Text] = None  # Optional name used to store match in results dict </s> add     name: Optional[str] = None  # Optional name used to store match in results dict </s> remove Results = Dict[Text, NL] </s> add Results = Dict[str, NL] </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove     def expect(self, type: int, value: Optional[Any] = None) -> Text: </s> add     def expect(self, type: int, value: Optional[Any] = None) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # Defaults for instance variables\n <mask>     type: Optional[int]\n <mask>     type = None  # Node type (token if < 256, symbol if >= 256)\n <mask>     content: Any = None  # Optional content matching pattern\n <mask>     name: Optional[Text] = None  # Optional name used to store match in results dict\n <mask> \n <mask>     def __new__(cls, *args, **kwds):\n <mask>         \"\"\"Constructor that prevents BasePattern from being instantiated.\"\"\"\n <mask>         assert cls is not BasePattern, \"Cannot instantiate BasePattern\"\n <mask>         return object.__new__(cls) </s> remove     def __repr__(self) -> Text: </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove     def calcfirst(self, name: Text) -> None: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove class BasePattern(object): </s> add class BasePattern:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask>         return object.__new__(cls)\n <mask> \n <mask>     def __repr__(self) -> Text:\n <mask>         assert self.type is not None\n <mask>         args = [type_repr(self.type), self.content, self.name]\n <mask>         while args and args[-1] is None:\n <mask>             del args[-1]\n <mask>         return \"%s(%s)\" % (self.__class__.__name__, \", \".join(map(repr, args)))\n <mask> \n <mask>     def _submatch(self, node, results=None) -> bool: </s> remove     def __repr__(self) -> Text: </s> add     def __repr__(self) -> str: </s> remove     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: str, context: Context) -> bool: </s> remove     def parse(self) -> Tuple[Dict[Text, List[\"DFAState\"]], Text]: </s> add     def parse(self) -> Tuple[Dict[str, List[\"DFAState\"]], str]: </s> remove def escape(m: Match[Text]) -> Text: </s> add def escape(m: Match[str]) -> str:", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> class LeafPattern(BasePattern):\n <mask>     def __init__(\n <mask>         self,\n <mask>         type: Optional[int] = None,\n <mask>         content: Optional[Text] = None,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.  Takes optional type, content, and name.\n <mask> \n <mask>         The type, if given must be a token type (< 256).  If not given, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Text] = None, </s> add         content: Optional[str] = None, </s> remove         name: Optional[Text] = None, </s> add         name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         type: Optional[int] = None,\n <mask>         content: Optional[Iterable[Text]] = None,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None:\n <mask>         \"\"\"\n <mask>         Initializer.  Takes optional type, content, and name.\n <mask> \n <mask>         The type, if given, must be a symbol type (>= 256).  If the </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Text] = None, </s> add         content: Optional[str] = None, </s> remove         name: Optional[Text] = None, </s> add         name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep replace keep keep replace keep", "code_tokens": " <mask>         self,\n <mask>         content: Optional[Text] = None,\n <mask>         min: int = 0,\n <mask>         max: int = HUGE,\n <mask>         name: Optional[Text] = None,\n <mask>     ) -> None: </s> remove         content: Optional[Text] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[str] = None,\n        name: Optional[str] = None, </s> remove         content: Optional[Iterable[Text]] = None,\n        name: Optional[Text] = None, </s> add         content: Optional[Iterable[str]] = None,\n        name: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None, </s> remove         prefix: Optional[Text] = None, </s> add         prefix: Optional[str] = None,", "html_url": "https://github.com/psf/black/commit/0b4d7d55f78913be9e0a3738681ef3aafd5d9a5a", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>         python-version: [3.7]\n <mask>         os: [ubuntu-16.04, windows-2019]\n <mask>         include:\n <mask>           - os: windows-2019\n <mask>             pathsep: \";\"\n <mask>             executable_suffix: \".exe\"\n <mask>             executable_mime: \"application/vnd.microsoft.portable-executable\"\n <mask>           - os: ubuntu-16.04\n <mask>             pathsep: \":\" </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           - os: ubuntu-16.04 </s> add           - os: ubuntu-20.04 </s> remove             executable_suffix: \".elf\" </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }}", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep replace keep replace keep", "code_tokens": " <mask>             executable_mime: \"application/vnd.microsoft.portable-executable\"\n <mask>           - os: ubuntu-16.04\n <mask>             pathsep: \":\"\n <mask>             executable_suffix: \".elf\"\n <mask>             executable_mime: \"application/x-executable\" </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             pathsep: \":\"\n <mask>             asset_name: black_linux\n <mask>             executable_mime: \"application/x-executable\"\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask>  </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           - os: ubuntu-16.04 </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }} </s> add           asset_path: dist/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }}", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>           python -m pip install pyinstaller\n <mask> \n <mask>       - name: Build binary\n <mask>         run: |\n <mask>           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py\n <mask> \n <mask>       - name: Upload binary as release asset\n <mask>         uses: actions/upload-release-asset@v1\n <mask>         env:\n <mask>           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           asset_path: dist/black${{ matrix.executable_suffix }}\n          asset_name: black${{ matrix.executable_suffix }} </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove           - os: ubuntu-16.04", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace replace keep", "code_tokens": " <mask>         env:\n <mask>           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n <mask>         with:\n <mask>           upload_url: ${{ github.event.release.upload_url }}\n <mask>           asset_path: dist/black${{ matrix.executable_suffix }}\n <mask>           asset_name: black${{ matrix.executable_suffix }}\n <mask>           asset_content_type: ${{ matrix.executable_mime }} </s> Build macOS releases (#2198)\n\n* Add macOS release target\r\n* Update ubuntu runner\r\n\r\nUbuntu 16.04 runner environment is deprecated\r\nhttps://github.blog/changelog/2021-04-29-github-actions-ubuntu-16-04-lts-virtual-environment-will-be-removed-on-september-20-2021/ </s> remove           python -m PyInstaller -F --name black${{ matrix.executable_suffix }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           python -m PyInstaller -F --name ${{ matrix.asset_name }} --add-data 'src/blib2to3${{ matrix.pathsep }}blib2to3' src/black/__main__.py </s> add           - os: macos-latest\n            pathsep: \":\"\n            asset_name: black_macos\n            executable_mime: \"application/x-mach-binary\" </s> remove           - os: ubuntu-16.04", "html_url": "https://github.com/psf/black/commit/0b9b7dbdab8c14bb8c33165583e3b540046944e7", "file_name": ".github/workflows/upload_binary.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 if leaf.bracket_depth <= depth_limit:\n <mask>                     return True\n <mask>         return False\n <mask> \n <mask>     def contains_inner_type_comments(self) -> bool:\n <mask>         ignored_ids = set()\n <mask>         try:\n <mask>             last_leaf = self.leaves[-1]\n <mask>             ignored_ids.add(id(last_leaf))\n <mask>             if last_leaf.type == token.COMMA or ( </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> remove         not line.contains_inner_type_comments() </s> add         not line.contains_uncollapsable_type_comments() </s> remove             if leaf_id in ignored_ids:\n                continue </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         except IndexError:\n <mask>             return False\n <mask> \n <mask>         for leaf_id, comments in self.comments.items():\n <mask>             for comment in comments:\n <mask>                 if is_type_comment(comment):\n <mask>                     if leaf_id not in ignored_ids or comment_seen:\n <mask>                         return True\n <mask>  </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> remove             if leaf_id in ignored_ids:\n                continue </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> remove     def contains_inner_type_comments(self) -> bool: </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> remove         not line.contains_inner_type_comments() </s> add         not line.contains_uncollapsable_type_comments() </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace keep", "code_tokens": " <mask>             return False\n <mask> \n <mask>         for leaf_id, comments in self.comments.items():\n <mask>             if leaf_id in ignored_ids:\n <mask>                 continue\n <mask> \n <mask>             for comment in comments:\n <mask>                 if is_type_comment(comment):\n <mask>                     return True\n <mask>  </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> remove     def contains_inner_type_comments(self) -> bool: </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> remove         not line.contains_inner_type_comments() </s> add         not line.contains_uncollapsable_type_comments() </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     line_str = str(line).strip(\"\\n\")\n <mask> \n <mask>     if (\n <mask>         not line.contains_inner_type_comments()\n <mask>         and not line.should_explode\n <mask>         and is_line_short_enough(line, line_length=line_length, line_str=line_str)\n <mask>     ):\n <mask>         yield line\n <mask>         return </s> Don't allow type comments to be merged behind regular comments (#1027)\n\nType comments only apply if they are the first comment on the line,\r\nwhich means that allowing them to be pushed behind a regular comment\r\nwhen joining lines is a semantic change (and, indeed, one that black\r\ncatches and fails on). </s> remove     def contains_inner_type_comments(self) -> bool: </s> add     def contains_uncollapsable_type_comments(self) -> bool: </s> add def f(\n    x,  # not a type comment\n    y,  # type: int\n):\n    # type: (...) -> None\n    pass\n\n\ndef f(\n    x,  # not a type comment\n):  # type: (int) -> None\n    pass </s> add                     if leaf_id not in ignored_ids or comment_seen:\n                        return True\n\n            comment_seen = True </s> add         # A type comment is uncollapsable if it is attached to a leaf\n        # that isn't at the end of the line (since that could cause it\n        # to get associated to a different argument) or if there are\n        # comments before it (since that could cause it to get hidden\n        # behind a comment.\n        comment_seen = False </s> remove             if leaf_id in ignored_ids:\n                continue", "html_url": "https://github.com/psf/black/commit/0c44220e216f6d253087f96341110c693d3ef2d4", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     Note: this usually looks weird, only use this for function definitions.\n <mask>     Prefer RHS otherwise.  This is why this function is not symmetrical with\n <mask>     :func:`right_hand_split` which also handles optional parentheses.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = []\n <mask>     head_leaves: List[Leaf] = []\n <mask>     current_leaves = head_leaves\n <mask>     matching_bracket = None </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth) </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True) </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         if current_leaves is head_leaves:\n <mask>             if leaf.type in OPENING_BRACKETS:\n <mask>                 matching_bracket = leaf\n <mask>                 current_leaves = body_leaves\n <mask>     # Since body is a new indent level, remove spurious leading whitespace.\n <mask>     if body_leaves:\n <mask>         normalize_prefix(body_leaves[0], inside_brackets=True)\n <mask>     # Build the new lines.\n <mask>     for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n <mask>         for leaf in leaves:\n <mask>             result.append(leaf, preformatted=True)\n <mask>             for comment_after in line.comments_after(leaf):\n <mask>                 result.append(comment_after, preformatted=True)\n <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     for result in (head, body, tail):\n <mask>         if result:\n <mask>             yield result\n <mask>  </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth) </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if result:\n <mask>             yield result\n <mask> \n <mask> \n <mask> def right_hand_split(  # noqa C901\n <mask>     line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()\n <mask> ) -> Iterator[Line]:\n <mask>     \"\"\"Split line into many lines, starting with the last matching bracket pair.\n <mask> \n <mask>     If the split was by optional parentheses, attempt splitting without them, too. </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True) </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth) </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     this split.\n <mask> \n <mask>     Note: running this function modifies `bracket_depth` on the leaves of `line`.\n <mask>     \"\"\"\n <mask>     head = Line(depth=line.depth)\n <mask>     body = Line(depth=line.depth + 1, inside_brackets=True)\n <mask>     tail = Line(depth=line.depth)\n <mask>     tail_leaves: List[Leaf] = []\n <mask>     body_leaves: List[Leaf] = []\n <mask>     head_leaves: List[Leaf] = []\n <mask>     current_leaves = tail_leaves\n <mask>     opening_bracket = None </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth) </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True) </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     if line.is_import and len(body_leaves) == 1:\n        body_leaves.append(Leaf(token.COMMA, \",\"))\n\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True)\n    assert opening_bracket and closing_bracket </s> add     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove     tail_leaves.reverse()\n    body_leaves.reverse()\n    head_leaves.reverse()\n    # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    if not head_leaves:\n        # No `head` means the split failed. Either `tail` has all content or </s> add     if not (opening_bracket and closing_bracket and head_leaves):\n        # If there is no opening or closing_bracket that means the split failed and\n        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>                 opening_bracket = leaf.opening_bracket\n <mask>                 closing_bracket = leaf\n <mask>                 current_leaves = body_leaves\n <mask>     tail_leaves.reverse()\n <mask>     body_leaves.reverse()\n <mask>     head_leaves.reverse()\n <mask>     # Since body is a new indent level, remove spurious leading whitespace.\n <mask>     if body_leaves:\n <mask>         normalize_prefix(body_leaves[0], inside_brackets=True)\n <mask>     if not head_leaves:\n <mask>         # No `head` means the split failed. Either `tail` has all content or\n <mask>         # the matching `opening_bracket` wasn't available on `line` anymore.\n <mask>         raise CannotSplit(\"No brackets found\")\n <mask> \n <mask>     if line.is_import and len(body_leaves) == 1:\n <mask>         body_leaves.append(Leaf(token.COMMA, \",\"))\n <mask> \n <mask>     # Build the new lines.\n <mask>     for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n <mask>         for leaf in leaves:\n <mask>             result.append(leaf, preformatted=True)\n <mask>             for comment_after in line.comments_after(leaf):\n <mask>                 result.append(comment_after, preformatted=True)\n <mask>     assert opening_bracket and closing_bracket\n <mask>     body.should_explode = should_explode(body, opening_bracket)\n <mask>     bracket_split_succeeded_or_raise(head, body, tail)\n <mask>     if (\n <mask>         # the body shouldn't be exploded </s> Refactor left_hand_split and right_hand_split to deduplicate line building logic </s> remove     # Since body is a new indent level, remove spurious leading whitespace.\n    if body_leaves:\n        normalize_prefix(body_leaves[0], inside_brackets=True)\n    # Build the new lines.\n    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):\n        for leaf in leaves:\n            result.append(leaf, preformatted=True)\n            for comment_after in line.comments_after(leaf):\n                result.append(comment_after, preformatted=True) </s> add     head = bracket_split_build_line(head_leaves, line)\n    body = bracket_split_build_line(body_leaves, line, is_body=True)\n    tail = bracket_split_build_line(tail_leaves, line) </s> remove def right_hand_split(  # noqa C901 </s> add def right_hand_split( </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth) </s> remove     head = Line(depth=line.depth)\n    body = Line(depth=line.depth + 1, inside_brackets=True)\n    tail = Line(depth=line.depth)", "html_url": "https://github.com/psf/black/commit/0c5c5374313566dd9047c3e992a3c23a7ea4b8f2", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep", "code_tokens": " <mask> \n <mask> [flake8]\n <mask> ignore = E266, E501\n <mask> max-line-length = 80\n <mask> max-complexity = 12\n <mask> select = B,C,E,F,W,T4,B9 </s> remove def whitespace(leaf: Leaf) -> str: </s> add def whitespace(leaf: Leaf) -> str:  # noqa C901 </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi </s> add - pip install flake8 flake8-bugbear mypy", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".flake8"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> sudo: false\n <mask> language: python\n <mask> cache: pip\n <mask> before_script:\n <mask> - pip install mypy\n <mask> - pip install -e .\n <mask> script:\n <mask> - python setup.py test\n <mask> - if [[ $TRAVIS_PYTHON_VERSION == '3.6' ]]; then mypy black.py tests/test_black.py; fi\n <mask> notifications: </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> - pip install -e .\n <mask> script:\n <mask> - python setup.py test\n <mask> - if [[ $TRAVIS_PYTHON_VERSION == '3.6' ]]; then mypy black.py tests/test_black.py; fi\n <mask> notifications:\n <mask>   on_success: change\n <mask>   on_failure: always\n <mask> matrix:\n <mask>   include:\n <mask>     - python: 3.6 </s> remove - pip install mypy </s> add - pip install flake8 flake8-bugbear mypy", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": ".travis.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\n <mask> ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, token.COLON, STANDALONE_COMMENT}\n <mask> \n <mask> \n <mask> def whitespace(leaf: Leaf) -> str:\n <mask>     \"\"\"Return whitespace prefix if needed for the given `leaf`.\"\"\"\n <mask>     NO = ''\n <mask>     SPACE = ' '\n <mask>     DOUBLESPACE = '  '\n <mask>     t = leaf.type </s> add - if [[ $TRAVIS_PYTHON_VERSION == '3.6-dev' ]]; then flake8 black.py tests/test_black.py; fi </s> remove max-complexity = 12 </s> add max-complexity = 15", "html_url": "https://github.com/psf/black/commit/0de0851a47cc36173028b52743caff0af0344278", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from click.core import ParameterSource\n <mask> from mypy_extensions import mypyc_attr\n <mask> from pathspec.patterns.gitwildmatch import GitWildMatchPatternError\n <mask> \n <mask> from _black_version import version as __version__\n <mask> from black.cache import Cache, get_cache_info, read_cache, write_cache </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx) </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None </s> add                 if root_gitignore == p_gitignore:\n                    gitignore = root_gitignore\n                else:\n                    gitignore = root_gitignore + p_gitignore </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root) </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root)", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>     \"\"\"Compute the set of files to be formatted.\"\"\"\n <mask>     sources: Set[Path] = set()\n <mask>     root = ctx.obj[\"root\"]\n <mask> \n <mask>     for s in src:\n <mask>         if s == \"-\" and stdin_filename:\n <mask>             p = Path(stdin_filename)\n <mask>             is_stdin = True </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx) </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root) </s> add from pathspec import PathSpec", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep replace replace replace replace keep keep keep", "code_tokens": " <mask>                 continue\n <mask> \n <mask>             sources.add(p)\n <mask>         elif p.is_dir():\n <mask>             if exclude is None:\n <mask>                 exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n <mask>                 gitignore = get_gitignore(root)\n <mask>                 p_gitignore = get_gitignore(p)\n <mask>                 # No need to use p's gitignore if it is identical to root's gitignore\n <mask>                 # (i.e. root and p point to the same directory).\n <mask>                 if gitignore != p_gitignore:\n <mask>                     gitignore += p_gitignore\n <mask>             else:\n <mask>                 gitignore = None\n <mask>             sources.update(\n <mask>                 gen_python_files(\n <mask>                     p.iterdir(),\n </s> Apply .gitignore correctly in every source entry (#3336)\n\nWhen passing multiple src directories, the root gitignore was only\r\napplied to the first processed source. The reason is that, in the\r\nfirst source, exclude is `None`, but then the value gets overridden by\r\n`re_compile_maybe_verbose(DEFAULT_EXCLUDES)`, so in the next iteration\r\nwhere the source is a directory, the condition is not met and sets the\r\nvalue of `gitignore` to `None`.\r\n\r\nTo fix this problem, we store a boolean indicating if `exclude` is\r\n`None` and set the value of `exclude` to its default value if that's\r\nthe case. This makes sure that the flow enters the correct condition on\r\nfollowing iterations and also keeps the original value if the condition\r\nis not met.\r\n\r\nAlso, the value of `gitignore` is initialized as `None` and overriden\r\nif necessary. The value of `root_gitignore` is always calculated to\r\navoid using additional variables (at the small cost of additional\r\ncomputations).\r\n\r\nSigned-off-by: Antonio Ossa Guerra <aaossa@uc.cl> </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root)\n </s> add     def test_gitignore_used_on_multiple_sources(self) -> None:\n        root = Path(DATA_DIR / \"gitignore_used_on_multiple_sources\")\n        expected = [\n            root / \"dir1\" / \"b.py\",\n            root / \"dir2\" / \"b.py\",\n        ]\n        ctx = FakeContext()\n        ctx.obj[\"root\"] = root\n        src = [root / \"dir1\", root / \"dir2\"]\n        assert_collected_sources(src, expected, ctx=ctx)\n </s> add from pathspec import PathSpec", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         assert_collected_sources(src, expected, ctx=ctx, extend_exclude=r\"/exclude/\")\n <mask> \n <mask>     @patch(\"black.find_project_root\", lambda *args: (THIS_DIR.resolve(), None))\n <mask>     def test_exclude_for_issue_1572(self) -> None:\n <mask>         # Exclude shouldn't touch files that were explicitly given to Black through the\n <mask>         # CLI. Exclude is supposed to only apply to the recursive discovery of files. </s> remove             if exclude is None:\n                exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES)\n                gitignore = get_gitignore(root) </s> add     exclude_is_None = exclude is None\n    exclude = re_compile_maybe_verbose(DEFAULT_EXCLUDES) if exclude is None else exclude\n    gitignore = None  # type: Optional[PathSpec]\n    root_gitignore = get_gitignore(root) </s> remove                 if gitignore != p_gitignore:\n                    gitignore += p_gitignore\n            else:\n                gitignore = None </s> add                 if root_gitignore == p_gitignore:\n                    gitignore = root_gitignore\n                else:\n                    gitignore = root_gitignore + p_gitignore", "html_url": "https://github.com/psf/black/commit/0e9d29ab73d608a79028e22a713ee717b5dcca96", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-   1\n <mask>     ): print(1)\n <mask>     case c(\n <mask>         very_complex=True,\n <mask>         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ): print(2)\n <mask>     case a: pass\n <mask> \n <mask> # output\n <mask> \n </s> Fix handling of standalone match/case with newlines/comments (#2760)\n\nResolves #2759 </s> remove         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         very_complex=True,\n        perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1, </s> add                 if next_token_type in (tokenize.COMMENT, tokenize.NL):\n                    counter += 1\n                    continue\n", "html_url": "https://github.com/psf/black/commit/0f26a0369efc7305a1a0120355f78d85b3030e56", "file_name": "tests/data/pattern_matching_style.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ):\n <mask>         print(1)\n <mask>     case c(\n <mask>         very_complex=True, perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n <mask>     ):\n <mask>         print(2)\n <mask>     case a:\n <mask>         pass\n </s> Fix handling of standalone match/case with newlines/comments (#2760)\n\nResolves #2759 </s> remove         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1\n </s> add         perhaps_even_loooooooooooooooooooooooooooooooooooooong=-1, </s> add                 if next_token_type in (tokenize.COMMENT, tokenize.NL):\n                    counter += 1\n                    continue\n", "html_url": "https://github.com/psf/black/commit/0f26a0369efc7305a1a0120355f78d85b3030e56", "file_name": "tests/data/pattern_matching_style.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     src, line_length=line_length, fast=fast, write_back=write_back\n <mask>                 )\n <mask>             ):\n <mask>                 changed = Changed.YES\n <mask>             if write_back != WriteBack.DIFF and changed is not Changed.NO:\n <mask>                 write_cache(cache, [src], line_length)\n <mask>         report.done(src, changed)\n <mask>     except Exception as exc:\n <mask>         report.failed(src, str(exc))\n <mask>  </s> remove     if write_back != WriteBack.DIFF and formatted: </s> add     if write_back == WriteBack.YES and formatted:", "html_url": "https://github.com/psf/black/commit/0f3ecb7e500f9668a7f9ec74a43d8d565df6e2ea", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 report.done(src, Changed.YES if task.result() else Changed.NO)\n <mask> \n <mask>     if cancelled:\n <mask>         await asyncio.gather(*cancelled, loop=loop, return_exceptions=True)\n <mask>     if write_back != WriteBack.DIFF and formatted:\n <mask>         write_cache(cache, formatted, line_length)\n <mask> \n <mask> \n <mask> def format_file_in_place(\n <mask>     src: Path, </s> remove             if write_back != WriteBack.DIFF and changed is not Changed.NO: </s> add             if write_back == WriteBack.YES and changed is not Changed.NO:", "html_url": "https://github.com/psf/black/commit/0f3ecb7e500f9668a7f9ec74a43d8d565df6e2ea", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> # Legacy name, left for integrations.\n <mask> FileMode = Mode\n <mask> \n <mask> \n <mask> def read_pyproject_toml(\n <mask>     ctx: click.Context, param: click.Parameter, value: Optional[str]\n <mask> ) -> Optional[str]:\n <mask>     \"\"\"Inject Black configuration from \"pyproject.toml\" into defaults in `ctx`. </s> remove     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> add     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    workers: Optional[int],", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.option(\n <mask>     \"-q\",\n <mask>     \"--quiet\",\n <mask>     is_flag=True, </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     force_exclude: Optional[Pattern],\n <mask>     stdin_filename: Optional[str],\n <mask>     src: Tuple[str, ...],\n <mask>     config: Optional[str],\n <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     if config and verbose: </s> remove     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\" </s> add     sources: Set[Path],\n    fast: bool,\n    write_back: WriteBack,\n    mode: Mode,\n    report: \"Report\",\n    workers: Optional[int], </s> add @click.option(\n    \"-W\",\n    \"--workers\",\n    type=click.IntRange(min=1),\n    default=DEFAULT_WORKERS,\n    show_default=True,\n    help=\"Number of parallel workers\",\n)", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path], fast: bool, write_back: WriteBack, mode: Mode, report: \"Report\"\n <mask> ) -> None:\n <mask>     \"\"\"Reformat multiple files using a ProcessPoolExecutor.\"\"\"\n <mask>     executor: Executor\n <mask>     loop = asyncio.get_event_loop()\n <mask>     worker_count = os.cpu_count()\n <mask>     if sys.platform == \"win32\":\n <mask>         # Work around https://bugs.python.org/issue26903\n </s> Add --workers CLI parameter (fixes #2513) (#2514)\n\nFixes #2513 </s> add DEFAULT_WORKERS = os.cpu_count()\n </s> add     workers: int, </s> add @click.option(\n    \"-W\",\n    \"--workers\",\n    type=click.IntRange(min=1),\n    default=DEFAULT_WORKERS,\n    show_default=True,\n    help=\"Number of parallel workers\",\n)", "html_url": "https://github.com/psf/black/commit/0fd353f1639c580c32599bf435902d08dbd9a560", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         for line in f:\n <mask>             lineno += 1\n <mask>             mo = re.match(r\"^#define\\s+(\\w+)\\s+(\\d+)$\", line)\n <mask>             if not mo and line.strip():\n <mask>                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n <mask>                                                   line.strip()))\n <mask>             else:\n <mask>                 symbol, number = mo.groups()\n <mask>                 number = int(number)\n <mask>                 assert symbol not in self.symbol2number\n <mask>                 assert number not in self.number2symbol </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line) </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256) </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # The code below essentially uses f's iterator-ness!\n <mask>         lineno = 0\n <mask> \n <mask>         # Expect the two #include lines\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"pgenheaders.h\"\\n', (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         # Expect the two #include lines\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"pgenheaders.h\"\\n', (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         allarcs = {} </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace replace keep", "code_tokens": " <mask>         assert line == '#include \"grammar.h\"\\n', (lineno, line)\n <mask> \n <mask>         # Parse the state definitions\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         allarcs = {}\n <mask>         states = []\n <mask>         while line.startswith(\"static arc \"):\n <mask>             while line.startswith(\"static arc \"):\n <mask>                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n <mask>                               line)\n <mask>                 assert mo, (lineno, line) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace", "code_tokens": " <mask>                 arcs = []\n <mask>                 for _ in range(k):\n <mask>                     lineno, line = lineno+1, next(f)\n <mask>                     mo = re.match(r\"\\s+{(\\d+), (\\d+)},$\", line)\n <mask>                     assert mo, (lineno, line)\n <mask>                     i, j = list(map(int, mo.groups()))\n <mask>                     arcs.append((i, j))\n <mask>                 lineno, line = lineno+1, next(f) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line) </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     arcs.append((i, j))\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>                 assert line == \"};\\n\", (lineno, line)\n <mask>                 allarcs[(n, m)] = arcs\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r\"static state states_(\\d+)\\[(\\d+)\\] = {$\", line)\n <mask>             assert mo, (lineno, line)\n <mask>             s, t = list(map(int, mo.groups()))\n <mask>             assert s == len(states), (lineno, line)\n <mask>             state = [] </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                     lineno, line = lineno+1, next(f) </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line) </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             s, t = list(map(int, mo.groups()))\n <mask>             assert s == len(states), (lineno, line)\n <mask>             state = []\n <mask>             for _ in range(t):\n <mask>                 lineno, line = lineno+1, next(f)\n <mask>                 mo = re.match(r\"\\s+{(\\d+), arcs_(\\d+)_(\\d+)},$\", line)\n <mask>                 assert mo, (lineno, line)\n <mask>                 k, n, m = list(map(int, mo.groups()))\n <mask>                 arcs = allarcs[n, m]\n <mask>                 assert k == len(arcs), (lineno, line) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     lineno, line = lineno+1, next(f) </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line) </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep replace", "code_tokens": " <mask>                 state.append(arcs)\n <mask>             states.append(state)\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             assert line == \"};\\n\", (lineno, line)\n <mask>             lineno, line = lineno+1, next(f) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         mo = re.match(r\"static dfa dfas\\[(\\d+)\\] = {$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         ndfas = int(mo.group(1))\n <mask>         for i in range(ndfas):\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n <mask>                           line)\n <mask>             assert mo, (lineno, line)\n <mask>             symbol = mo.group(2)\n <mask>             number, x, y, z = list(map(int, mo.group(1, 3, 4, 5)))\n <mask>             assert self.symbol2number[symbol] == number, (lineno, line)\n <mask>             assert self.number2symbol[number] == symbol, (lineno, line) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             assert self.number2symbol[number] == symbol, (lineno, line)\n <mask>             assert x == 0, (lineno, line)\n <mask>             state = states[z]\n <mask>             assert y == len(state), (lineno, line)\n <mask>             lineno, line = lineno+1, next(f)\n <mask>             mo = re.match(r'\\s+(\"(?:\\\\\\d\\d\\d)*\")},$', line)\n <mask>             assert mo, (lineno, line)\n <mask>             first = {}\n <mask>             rawbitset = eval(mo.group(1))\n <mask>             for i, c in enumerate(rawbitset): </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line) </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace replace keep replace keep", "code_tokens": " <mask>                 for j in range(8):\n <mask>                     if byte & (1<<j):\n <mask>                         first[i*8 + j] = 1\n <mask>             dfas[number] = (state, first)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace", "code_tokens": " <mask>         labels = []\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"static label labels\\[(\\d+)\\] = {$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         nlabels = int(mo.group(1))\n <mask>         for i in range(nlabels):\n <mask>             lineno, line = lineno+1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>                 y = eval(y)\n <mask>             labels.append((x, y))\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line)\n <mask>         self.labels = labels\n <mask> \n <mask>         # Parse the grammar struct\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"grammar _PyParser_Grammar = {\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+),$\", line)\n <mask>         assert mo, (lineno, line) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep", "code_tokens": " <mask>         assert line == \"grammar _PyParser_Grammar = {\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+),$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         ndfas = int(mo.group(1))\n <mask>         assert ndfas == len(self.dfas)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"\\tdfas,\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         ndfas = int(mo.group(1))\n <mask>         assert ndfas == len(self.dfas)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"\\tdfas,\\n\", (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+{(\\d+), labels},$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         nlabels = int(mo.group(1))\n <mask>         assert nlabels == len(self.labels), (lineno, line)\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         mo = re.match(r\"\\s+(\\d+)$\", line)\n <mask>         assert mo, (lineno, line)\n <mask>         start = int(mo.group(1))\n <mask>         assert start in self.number2symbol, (lineno, line) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep replace keep keep replace keep", "code_tokens": " <mask>         start = int(mo.group(1))\n <mask>         assert start in self.number2symbol, (lineno, line)\n <mask>         self.start = start\n <mask>         lineno, line = lineno+1, next(f)\n <mask>         assert line == \"};\\n\", (lineno, line)\n <mask>         try:\n <mask>             lineno, line = lineno+1, next(f)\n <mask>         except StopIteration: </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert 0, (lineno, line)\n <mask> \n <mask>     def finish_off(self):\n <mask>         \"\"\"Create additional useful structures.  (Internal).\"\"\"\n <mask>         self.keywords = {} # map from keyword strings to arc labels\n <mask>         self.tokens = {}   # map from numeric token values to arc labels\n <mask>         for ilabel, (type, value) in enumerate(self.labels):\n <mask>             if type == token.NAME and value is not None:\n <mask>                 self.keywords[value] = ilabel\n <mask>             elif value is None:\n <mask>                 self.tokens[type] = ilabel </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState </s> remove         self.gettoken() # Initialize lookahead </s> add         self.gettoken()  # Initialize lookahead </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop() </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line) </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/conv.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> \n <mask> \n <mask> class Driver(object):\n <mask> \n <mask>     def __init__(\n <mask>         self,\n <mask>         grammar,\n <mask>         convert=None,\n <mask>         logger=None,\n <mask>     ):\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger\n <mask>         self.convert = convert </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None): </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\") </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"] </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 continue\n <mask>             if type == token.OP:\n <mask>                 type = grammar.opmap[value]\n <mask>             if debug:\n <mask>                 self.logger.debug(\"%s %r (prefix=%r)\",\n <mask>                                   token.tok_name[type], value, prefix)\n <mask>             if type == token.INDENT:\n <mask>                 indent_columns.append(len(value))\n <mask>                 _prefix = prefix + value\n <mask>                 prefix = \"\"\n <mask>                 value = \"\" </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value) </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            ) </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     type = None     # Node type (token if < 256, symbol if >= 256) </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):] </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 lineno += 1\n <mask>                 column = 0\n <mask>         else:\n <mask>             # We never broke out -- EOF is too soon (how can this happen???)\n <mask>             raise parse.ParseError(\"incomplete input\",\n <mask>                                    type, value, (prefix, start))\n <mask>         return p.rootnode\n <mask> \n <mask>     def parse_stream_raw(self, stream, debug=False):\n <mask>         \"\"\"Parse a stream and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(stream.readline, grammar=self.grammar) </s> remove             io.StringIO(text).readline,\n            grammar=self.grammar </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop() </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def parse_string(self, text, debug=False):\n <mask>         \"\"\"Parse a string and return the syntax tree.\"\"\"\n <mask>         tokens = tokenize.generate_tokens(\n <mask>             io.StringIO(text).readline,\n <mask>             grammar=self.grammar\n <mask>         )\n <mask>         return self.parse_tokens(tokens, debug)\n <mask> \n <mask>     def _partially_consume_prefix(self, prefix, column):\n <mask>         lines = [] </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied) </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value) </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace keep keep", "code_tokens": " <mask>         for char in prefix:\n <mask>             current_line += char\n <mask>             if wait_for_nl:\n <mask>                 if char == '\\n':\n <mask>                     if current_line.strip() and current_column < column:\n <mask>                         res = ''.join(lines)\n <mask>                         return res, prefix[len(res):]\n <mask> \n <mask>                     lines.append(current_line) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             elif char in ' \\t': </s> add             elif char in \" \\t\": </s> remove             elif char == '\\n': </s> add             elif char == \"\\n\": </s> remove         return ''.join(lines), current_line </s> add         return \"\".join(lines), current_line </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig' </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>                     current_line = \"\"\n <mask>                     current_column = 0\n <mask>                     wait_for_nl = False\n <mask>             elif char in ' \\t':\n <mask>                 current_column += 1\n <mask>             elif char == '\\n':\n <mask>                 # unexpected empty line\n <mask>                 current_column = 0\n <mask>             else: </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):] </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :] </s> remove         return ''.join(lines), current_line </s> add         return \"\".join(lines), current_line </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove             if not line: break </s> add             if not line:\n                break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 current_column = 0\n <mask>             else:\n <mask>                 # indent is finished\n <mask>                 wait_for_nl = True\n <mask>         return ''.join(lines), current_line\n <mask> \n <mask> \n <mask> def _generate_pickle_name(gt, cache_dir=None):\n <mask>     head, tail = os.path.splitext(gt)\n <mask>     if tail == \".txt\": </s> remove                         res = ''.join(lines)\n                        return res, prefix[len(res):] </s> add                         res = \"\".join(lines)\n                        return res, prefix[len(res) :]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     else:\n <mask>         return name\n <mask> \n <mask> \n <mask> def load_grammar(gt=\"Grammar.txt\", gp=None,\n <mask>                  save=True, force=False, logger=None):\n <mask>     \"\"\"Load the grammar (maybe from a pickle).\"\"\"\n <mask>     if logger is None:\n <mask>         logger = logging.getLogger(__name__)\n <mask>     gp = _generate_pickle_name(gt) if gp is None else gp\n <mask>     if force or not _newer(gp, gt): </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ): </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove             if subpattern is not None and  self.name == subpattern.name: </s> add             if subpattern is not None and self.name == subpattern.name:", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     Calls load_grammar for each argument, a path to a grammar text file.\n <mask>     \"\"\"\n <mask>     if not args:\n <mask>         args = sys.argv[1:]\n <mask>     logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n <mask>                         format='%(message)s')\n <mask>     for gt in args:\n <mask>         load_grammar(gt, save=True, force=True)\n <mask>     return True\n <mask> \n <mask> if __name__ == \"__main__\": </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None): </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.async_keywords = False\n <mask> \n <mask>     def dump(self, filename):\n <mask>         \"\"\"Dump the grammar tables to a pickle file.\"\"\"\n <mask>         with tempfile.NamedTemporaryFile(dir=os.path.dirname(filename), delete=False) as f:\n <mask>             pickle.dump(self.__dict__, f, pickle.HIGHEST_PROTOCOL)\n <mask>         os.replace(f.name, filename)\n <mask> \n <mask>     def load(self, filename):\n <mask>         \"\"\"Load the grammar tables from a pickle file.\"\"\" </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None): </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None): </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ): </s> add     def __init__(self, grammar, convert=None, logger=None):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         Copy the grammar.\n <mask>         \"\"\"\n <mask>         new = self.__class__()\n <mask>         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n <mask>                           \"tokens\", \"symbol2label\"):\n <mask>             setattr(new, dict_attr, getattr(self, dict_attr).copy())\n <mask>         new.labels = self.labels[:]\n <mask>         new.states = self.states[:]\n <mask>         new.start = self.start\n <mask>         new.async_keywords = self.async_keywords </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0 </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0 </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256) </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/grammar.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \"\"\"Safely evaluate Python string literals without using eval().\"\"\"\n <mask> \n <mask> import regex as re\n <mask> \n <mask> simple_escapes = {\"a\": \"\\a\",\n <mask>                   \"b\": \"\\b\",\n <mask>                   \"f\": \"\\f\",\n <mask>                   \"n\": \"\\n\",\n <mask>                   \"r\": \"\\r\",\n <mask>                   \"t\": \"\\t\",\n <mask>                   \"v\": \"\\v\",\n <mask>                   \"'\": \"'\",\n <mask>                   '\"': '\"',\n <mask>                   \"\\\\\": \"\\\\\"}\n <mask> \n <mask> def escape(m):\n <mask>     all, tail = m.group(0, 1)\n <mask>     assert all.startswith(\"\\\\\")\n <mask>     esc = simple_escapes.get(tail) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return ''.join(lines), current_line </s> add         return \"\".join(lines), current_line </s> remove endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n            \"'''\": single3prog, '\"\"\"': double3prog,\n            **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n            **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n            **{prefix: None for prefix in _strprefixes}} </s> add endprogs = {\n    \"'\": re.compile(Single),\n    '\"': re.compile(Double),\n    \"'''\": single3prog,\n    '\"\"\"': double3prog,\n    **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n    **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n    **{prefix: None for prefix in _strprefixes},\n} </s> add             if type(val) == int:\n                _type_reprs[val] = name </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def evalString(s):\n <mask>     assert s.startswith(\"'\") or s.startswith('\"'), repr(s[:1])\n <mask>     q = s[0]\n <mask>     if s[:3] == q*3:\n <mask>         q = q*3\n <mask>     assert s.endswith(q), repr(s[-len(q):])\n <mask>     assert len(s) >= 2*len(q)\n <mask>     s = s[len(q):-len(q)]\n <mask>     return re.sub(r\"\\\\(\\'|\\\"|\\\\|[abfnrtv]|x.{0,2}|[0-7]{1,3})\", escape, s)\n <mask> \n <mask> def test():\n <mask>     for i in range(256):\n <mask>         c = chr(i) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add             lineno, line = lineno + 1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> add                 lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/literals.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> class ParseError(Exception):\n <mask>     \"\"\"Exception to signal the parser is stuck.\"\"\"\n <mask> \n <mask>     def __init__(self, msg, type, value, context):\n <mask>         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n <mask>                            (msg, type, value, context))\n <mask>         self.msg = msg\n <mask>         self.type = type\n <mask>         self.value = value\n <mask>         self.context = context\n <mask>  </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value) </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            ) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]): </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix) </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> remove             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n                             self.type, self.value) </s> add             self.raise_error(\n                \"expected (...) or NAME or STRING, got %s/%s\", self.type, self.value\n            ) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         newnode = (start, None, None, [])\n <mask>         stackentry = (self.grammar.dfas[start], 0, newnode)\n <mask>         self.stack = [stackentry]\n <mask>         self.rootnode = None\n <mask>         self.used_names = set() # Aliased to self.rootnode.used_names in pop()\n <mask> \n <mask>     def addtoken(self, type, value, context):\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabel = self.classify(type, value, context) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     itsstates, itsfirst = itsdfa\n <mask>                     if ilabel in itsfirst:\n <mask>                         # Push a symbol\n <mask>                         self.push(t, self.grammar.dfas[t], newstate, context)\n <mask>                         break # To continue the outer while loop\n <mask>             else:\n <mask>                 if (0, state) in arcs:\n <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack: </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove                 itoken = grammar.opmap[value] # Fails if unknown token </s> add                 itoken = grammar.opmap[value]  # Fails if unknown token </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> remove             while column < indents[-1]:        # count dedents </s> add             while column < indents[-1]:  # count dedents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack:\n <mask>                         # Done parsing, but another token is input\n <mask>                         raise ParseError(\"too much input\",\n <mask>                                          type, value, context)\n <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type, value, context): </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]): </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context)) </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop() </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove             self.raise_error(\"expected %s/%s, got %s/%s\",\n                             type, value, self.type, self.value) </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> class ParserGenerator(object):\n <mask> \n <mask>     def __init__(self, filename, stream=None):\n <mask>         close_stream = None\n <mask>         if stream is None:\n <mask>             stream = open(filename) </s> add class ParserGenerator(object): </s> remove class StopTokenizing(Exception): pass </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ): </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove class TokenError(Exception): pass", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> class PgenGrammar(grammar.Grammar):\n <mask>     pass\n <mask> \n <mask> \n <mask>     def __init__(self, filename, stream=None):\n <mask>         close_stream = None\n <mask>         if stream is None:\n <mask>             stream = open(filename) </s> remove class ParserGenerator(object): </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ): </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove     while 1:                                   # loop over lines in stream </s> add     while 1:  # loop over lines in stream", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         self.filename = filename\n <mask>         self.stream = stream\n <mask>         self.generator = tokenize.generate_tokens(stream.readline)\n <mask>         self.gettoken() # Initialize lookahead\n <mask>         self.dfas, self.startsymbol = self.parse()\n <mask>         if close_stream is not None:\n <mask>             close_stream()\n <mask>         self.first = {} # map from symbol name to set of tokens\n <mask>         self.addfirstsets()\n <mask> \n <mask>     def make_grammar(self):\n <mask>         c = PgenGrammar() </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     c.keywords[value] = ilabel\n <mask>                     return ilabel\n <mask>             else:\n <mask>                 # An operator (any non-numeric token)\n <mask>                 itoken = grammar.opmap[value] # Fails if unknown token\n <mask>                 if itoken in c.tokens:\n <mask>                     return c.tokens[itoken]\n <mask>                 else:\n <mask>                     c.labels.append((itoken, None))\n <mask>                     c.tokens[itoken] = ilabel </s> remove                         break # To continue the outer while loop </s> add                         break  # To continue the outer while loop </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop() </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove         return ''.join(lines), current_line </s> add         return \"\".join(lines), current_line </s> add         else:  # continued statement </s> add                     else:  # ordinary string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask>                 self.calcfirst(name)\n <mask>             #print name, self.first[name].keys()\n <mask> \n <mask>     def calcfirst(self, name):\n <mask>         dfa = self.dfas[name]\n <mask>         self.first[name] = None # dummy to detect left recursion\n <mask>         state = dfa[0]\n <mask>         totalset = {}\n <mask>         overlapcheck = {} </s> remove             #self.dump_dfa(name, dfa) </s> add             # self.dump_dfa(name, dfa) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         inverse = {}\n <mask>         for label, itsfirst in overlapcheck.items():\n <mask>             for symbol in itsfirst:\n <mask>                 if symbol in inverse:\n <mask>                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n <mask>                                      \" first sets of %s as well as %s\" %\n <mask>                                      (name, symbol, label, inverse[symbol]))\n <mask>                 inverse[symbol] = label\n <mask>         self.first[name] = totalset\n <mask> \n <mask>     def parse(self):\n <mask>         dfas = {} </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n                                                  line.strip())) </s> add                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>             name = self.expect(token.NAME)\n <mask>             self.expect(token.OP, \":\")\n <mask>             a, z = self.parse_rhs()\n <mask>             self.expect(token.NEWLINE)\n <mask>             #self.dump_nfa(name, a, z)\n <mask>             dfa = self.make_dfa(a, z)\n <mask>             #self.dump_dfa(name, dfa)\n <mask>             oldlen = len(dfa)\n <mask>             self.simplify_dfa(dfa)\n <mask>             newlen = len(dfa) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #print name, oldlen, newlen </s> add             # print name, oldlen, newlen </s> remove         while (self.value in (\"(\", \"[\") or\n               self.type in (token.NAME, token.STRING)): </s> add         while self.value in (\"(\", \"[\") or self.type in (token.NAME, token.STRING): </s> remove             #print name, self.first[name].keys() </s> add             lineno, line = lineno + 1, next(f)\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$', line) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             oldlen = len(dfa)\n <mask>             self.simplify_dfa(dfa)\n <mask>             newlen = len(dfa)\n <mask>             dfas[name] = dfa\n <mask>             #print name, oldlen, newlen\n <mask>             if startsymbol is None:\n <mask>                 startsymbol = name\n <mask>         return dfas, startsymbol\n <mask> \n <mask>     def make_dfa(self, start, finish): </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #self.dump_dfa(name, dfa) </s> add             # self.dump_dfa(name, dfa) </s> remove             #self.dump_nfa(name, a, z) </s> add             # self.dump_nfa(name, a, z) </s> remove             #print name, self.first[name].keys() </s> add             # print name, self.first[name].keys() </s> remove         return states # List of DFAState instances; first one is start </s> add         return states  # List of DFAState instances; first one is start", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             for label, next in state.arcs:\n <mask>                 if label is None:\n <mask>                     addclosure(next, base)\n <mask>         states = [DFAState(closure(start), finish)]\n <mask>         for state in states: # NB states grows while we're iterating\n <mask>             arcs = {}\n <mask>             for nfastate in state.nfaset:\n <mask>                 for label, next in nfastate.arcs:\n <mask>                     if label is not None:\n <mask>                         addclosure(next, arcs.setdefault(label, {})) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         self.first[name] = None # dummy to detect left recursion </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove         return states # List of DFAState instances; first one is start </s> add         return states  # List of DFAState instances; first one is start </s> remove                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line) </s> add                 mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\", line) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> add     __hash__ = None  # For Py3 compatibility.", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     st = DFAState(nfaset, finish)\n <mask>                     states.append(st)\n <mask>                 state.addarc(st, label)\n <mask>         return states # List of DFAState instances; first one is start\n <mask> \n <mask>     def dump_nfa(self, name, start, finish):\n <mask>         print(\"Dump of NFA for\", name)\n <mask>         todo = [start]\n <mask>         for i, state in enumerate(todo): </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             #print name, oldlen, newlen </s> add             # print name, oldlen, newlen </s> remove         for state in states: # NB states grows while we're iterating </s> add         for state in states:  # NB states grows while we're iterating </s> remove             #print name, self.first[name].keys() </s> add             # print name, self.first[name].keys() </s> remove                         #print \"  unify\", i, j </s> add                         # print \"  unify\", i, j", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep replace keep keep keep keep", "code_tokens": " <mask>         changes = True\n <mask>         while changes:\n <mask>             changes = False\n <mask>             for i, state_i in enumerate(dfa):\n <mask>                 for j in range(i+1, len(dfa)):\n <mask>                     state_j = dfa[j]\n <mask>                     if state_i == state_j:\n <mask>                         #print \"  unify\", i, j\n <mask>                         del dfa[j]\n <mask>                         for state in dfa:\n <mask>                             state.unifystate(state_j, state_i)\n <mask>                         changes = True </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add                     if byte & (1 << j):\n                        first[i * 8 + j] = 1 </s> remove                     lineno, line = lineno+1, next(f) </s> add                     lineno, line = lineno + 1, next(f) </s> remove                 lineno, line = lineno+1, next(f) </s> add                 lineno, line = lineno + 1, next(f) </s> remove             tokval += ' ' </s> add             tokval += \" \" </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def parse_alt(self):\n <mask>         # ALT: ITEM+\n <mask>         a, b = self.parse_item()\n <mask>         while (self.value in (\"(\", \"[\") or\n <mask>                self.type in (token.NAME, token.STRING)):\n <mask>             c, d = self.parse_item()\n <mask>             b.addarc(c)\n <mask>             b = d\n <mask>         return a, b\n <mask>  </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep replace replace keep keep keep replace replace", "code_tokens": " <mask>             return a, z\n <mask>         else:\n <mask>             self.raise_error(\"expected (...) or NAME or STRING, got %s/%s\",\n <mask>                              self.type, self.value)\n <mask> \n <mask>     def expect(self, type, value=None):\n <mask>         if self.type != type or (value is not None and self.value != value):\n <mask>             self.raise_error(\"expected %s/%s, got %s/%s\",\n <mask>                              type, value, self.type, self.value) </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context)) </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied) </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         tup = next(self.generator)\n <mask>         while tup[0] in (tokenize.COMMENT, tokenize.NL):\n <mask>             tup = next(self.generator)\n <mask>         self.type, self.value, self.begin, self.end, self.line = tup\n <mask>         #print token.tok_name[self.type], repr(self.value)\n <mask> \n <mask>     def raise_error(self, msg, *args):\n <mask>         if args:\n <mask>             try:\n <mask>                 msg = msg % args </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line)) </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> remove     while 1:                                   # loop over lines in stream </s> add     while 1:  # loop over lines in stream", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace", "code_tokens": " <mask>                 msg = msg % args\n <mask>             except:\n <mask>                 msg = \" \".join([msg] + list(map(str, args)))\n <mask>         raise SyntaxError(msg, (self.filename, self.end[0],\n <mask>                                 self.end[1], self.line))\n <mask> \n <mask> class NFAState(object): </s> remove         Exception.__init__(self, \"%s: type=%r, value=%r, context=%r\" %\n                           (msg, type, value, context)) </s> add         Exception.__init__(\n            self, \"%s: type=%r, value=%r, context=%r\" % (msg, type, value, context)\n        ) </s> add class NFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self):\n <mask>         self.arcs = []  # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next, label=None):\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState) </s> remove         self.arcs = [] # list of (label, NFAState) pairs </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> remove class NFAState(object): </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState </s> remove class DFAState(object): </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line)) </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add class DFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> class NFAState(object):\n <mask> \n <mask>     def __init__(self):\n <mask>         self.arcs = [] # list of (label, NFAState) pairs\n <mask> \n <mask>     def addarc(self, next, label=None):\n <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next)) </s> add class NFAState(object): </s> remove class NFAState(object): </s> remove class DFAState(object): </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line)) </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> add class DFAState(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert label is None or isinstance(label, str)\n <mask>         assert isinstance(next, NFAState)\n <mask>         self.arcs.append((label, next))\n <mask> \n <mask> class DFAState(object):\n <mask> \n <mask>     def __init__(self, nfaset, final):\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState) </s> add class DFAState(object): </s> remove         self.arcs = [] # list of (label, NFAState) pairs </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class NFAState(object): </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState </s> remove class NFAState(object): </s> remove     if s[:3] == q*3:\n        q = q*3\n    assert s.endswith(q), repr(s[-len(q):])\n    assert len(s) >= 2*len(q)\n    s = s[len(q):-len(q)] </s> add     if s[:3] == q * 3:\n        q = q * 3\n    assert s.endswith(q), repr(s[-len(q) :])\n    assert len(s) >= 2 * len(q)\n    s = s[len(q) : -len(q)]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self, nfaset, final):\n <mask>         assert isinstance(nfaset, dict)\n <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n <mask>         self.nfaset = nfaset </s> remove class DFAState(object): </s> remove         self.arcs = {} # map from label to DFAState </s> add         self.arcs = {}  # map from label to DFAState </s> remove         self.arcs = [] # list of (label, NFAState) pairs </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class NFAState(object): </s> remove class NFAState(object): </s> remove     if s[:3] == q*3:\n        q = q*3\n    assert s.endswith(q), repr(s[-len(q):])\n    assert len(s) >= 2*len(q)\n    s = s[len(q):-len(q)] </s> add     if s[:3] == q * 3:\n        q = q * 3\n    assert s.endswith(q), repr(s[-len(q) :])\n    assert len(s) >= 2 * len(q)\n    s = s[len(q) : -len(q)]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert isinstance(next(iter(nfaset)), NFAState)\n <mask>         assert isinstance(final, NFAState)\n <mask>         self.nfaset = nfaset\n <mask>         self.isfinal = final in nfaset\n <mask>         self.arcs = {} # map from label to DFAState\n <mask> \n <mask>     def addarc(self, next, label):\n <mask>         assert isinstance(label, str)\n <mask>         assert label not in self.arcs\n <mask>         assert isinstance(next, DFAState) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> add class NFAState(object): </s> remove         self.arcs = [] # list of (label, NFAState) pairs </s> add         self.arcs = []  # list of (label, NFAState) pairs </s> add class DFAState(object): </s> remove class DFAState(object): </s> add </s> remove class NFAState(object): </s> add </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             if next is not other.arcs.get(label):\n <mask>                 return False\n <mask>         return True\n <mask> \n <mask>     __hash__ = None # For Py3 compatibility.\n <mask> \n <mask> def generate_grammar(filename=\"Grammar.txt\"):\n <mask>     p = ParserGenerator(filename)\n <mask>     return p.make_grammar() </s> remove             if subpattern is not None and  self.name == subpattern.name: </s> add             if subpattern is not None and self.name == subpattern.name:", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/pgen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> #  Taken from Python (r53757) and modified to include some tokens\n <mask> #   originally monkeypatched in by pgen2.tokenize\n <mask> \n <mask> #--start constants--\n <mask> ENDMARKER = 0\n <mask> NAME = 1\n <mask> NUMBER = 2\n <mask> STRING = 3\n <mask> NEWLINE = 4 </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.gettoken() # Initialize lookahead </s> add         self.gettoken()  # Initialize lookahead </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove #--end constants-- </s> add # --end constants--", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ERRORTOKEN = 58\n <mask> COLONEQUAL = 59\n <mask> N_TOKENS = 60\n <mask> NT_OFFSET = 256\n <mask> #--end constants--\n <mask> \n <mask> tok_name = {}\n <mask> for _name, _value in list(globals().items()):\n <mask>     if type(_value) is type(0):\n <mask>         tok_name[_value] = _name </s> remove         self.first[name] = None # dummy to detect left recursion </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove         self.gettoken() # Initialize lookahead </s> add         self.gettoken()  # Initialize lookahead </s> remove                     raise ValueError(\"rule %s is ambiguous; %s is in the\"\n                                     \" first sets of %s as well as %s\" %\n                                     (name, symbol, label, inverse[symbol])) </s> add                     raise ValueError(\n                        \"rule %s is ambiguous; %s is in the\"\n                        \" first sets of %s as well as %s\"\n                        % (name, symbol, label, inverse[symbol])\n                    )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/token.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> are the same, except instead of generating tokens, tokeneater is a callback\n <mask> function to which the 5 fields described above are passed as 5 arguments,\n <mask> each time a new token is found.\"\"\"\n <mask> \n <mask> __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n <mask> __credits__ = \\\n <mask>     'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'\n <mask> \n <mask> import regex as re\n <mask> from codecs import BOM_UTF8, lookup\n <mask> from blib2to3.pgen2.token import *\n <mask>  </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"] </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n]", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from codecs import BOM_UTF8, lookup\n <mask> from blib2to3.pgen2.token import *\n <mask> \n <mask> from . import token\n <mask> __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n <mask>            \"generate_tokens\", \"untokenize\"]\n <mask> del token\n <mask> \n <mask> try:\n <mask>     bytes\n <mask> except NameError: </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace replace replace keep keep", "code_tokens": " <mask>     # Support bytes type in Python <= 2.5, so 2to3 turns itself into\n <mask>     # valid Python 3 code.\n <mask>     bytes = str\n <mask> \n <mask> def group(*choices): return '(' + '|'.join(choices) + ')'\n <mask> def any(*choices): return group(*choices) + '*'\n <mask> def maybe(*choices): return group(*choices) + '?'\n <mask> def _combinations(*l):\n <mask>     return set(\n <mask>         x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n <mask>     )\n <mask> \n <mask> Whitespace = r'[ \\f\\t]*' </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups </s> add </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig' </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace replace replace replace", "code_tokens": " <mask>     return set(\n <mask>         x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n <mask>     )\n <mask> \n <mask> Whitespace = r'[ \\f\\t]*'\n <mask> Comment = r'#[^\\r\\n]*'\n <mask> Ignore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\n <mask> Name = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups\n <mask> \n <mask> Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\n <mask> Hexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\n <mask> Octnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\n <mask> Decnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?') </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     return set(\n        x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()\n    ) </s> add     return set(x + y for x in l for y in l + (\"\",) if x.casefold() != y.casefold()) </s> remove def group(*choices): return '(' + '|'.join(choices) + ')'\ndef any(*choices): return group(*choices) + '*'\ndef maybe(*choices): return group(*choices) + '?' </s> add def group(*choices):\n    return \"(\" + \"|\".join(choices) + \")\"\n\n\ndef any(*choices):\n    return group(*choices) + \"*\"\n\n\ndef maybe(*choices):\n    return group(*choices) + \"?\" </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace keep keep keep", "code_tokens": " <mask> Intnumber = group(Binnumber, Hexnumber, Octnumber, Decnumber)\n <mask> Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\n <mask> Pointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\n <mask> Expfloat = r'\\d+(?:_\\d+)*' + Exponent\n <mask> Floatnumber = group(Pointfloat, Expfloat)\n <mask> Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]')\n <mask> Number = group(Imagnumber, Floatnumber, Intnumber)\n <mask> \n <mask> # Tail end of ' string. </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?') </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"') </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n) </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple) </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups </s> add         if contstr:  # continued string", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace keep keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask> # Single-line ' or \" string.\n <mask> String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n <mask>                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"')\n <mask> \n <mask> # Because of leftmost-then-longest match semantics, be sure to put the\n <mask> # longest operators first (e.g., if = came before ==, == would get\n <mask> # recognized as two instances of =).\n <mask> Operator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"<>\", r\"!=\",\n <mask>                  r\"//=?\", r\"->\",\n <mask>                  r\"[+\\-*/%&@|^=<>:]=?\",\n <mask>                  r\"~\")\n <mask> \n <mask> Bracket = '[][(){}]'\n <mask> Special = group(r'\\r?\\n', r'[:;.,`@]')\n <mask> Funny = group(Operator, Bracket, Special) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Bracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'[:;.,`@]') </s> add Bracket = \"[][(){}]\"\nSpecial = group(r\"\\r?\\n\", r\"[:;.,`@]\") </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple) </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]') </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\") </s> add         self.first = {}  # map from symbol name to set of tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                  r\"//=?\", r\"->\",\n <mask>                  r\"[+\\-*/%&@|^=<>:]=?\",\n <mask>                  r\"~\")\n <mask> \n <mask> Bracket = '[][(){}]'\n <mask> Special = group(r'\\r?\\n', r'[:;.,`@]')\n <mask> Funny = group(Operator, Bracket, Special)\n <mask> \n <mask> PlainToken = group(Number, Funny, String, Name)\n <mask> Token = Ignore + PlainToken\n <mask>  </s> remove Operator = group(r\"\\*\\*=?\", r\">>=?\", r\"<<=?\", r\"<>\", r\"!=\",\n                 r\"//=?\", r\"->\",\n                 r\"[+\\-*/%&@|^=<>:]=?\",\n                 r\"~\") </s> add Operator = group(\n    r\"\\*\\*=?\",\n    r\">>=?\",\n    r\"<<=?\",\n    r\"<>\",\n    r\"!=\",\n    r\"//=?\",\n    r\"->\",\n    r\"[+\\-*/%&@|^=<>:]=?\",\n    r\"~\",\n) </s> remove ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n                group(\"'\", r'\\\\\\r?\\n'),\n                _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n                group('\"', r'\\\\\\r?\\n'))\nPseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple) </s> add ContStr = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" + group(\"'\", r\"\\\\\\r?\\n\"),\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' + group('\"', r\"\\\\\\r?\\n\"),\n)\nPseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple) </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?') </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]') </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> PlainToken = group(Number, Funny, String, Name)\n <mask> Token = Ignore + PlainToken\n <mask> \n <mask> # First (or only) line of ' or \" string.\n <mask> ContStr = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*\" +\n <mask>                 group(\"'\", r'\\\\\\r?\\n'),\n <mask>                 _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*' +\n <mask>                 group('\"', r'\\\\\\r?\\n'))\n <mask> PseudoExtras = group(r'\\\\\\r?\\n', Comment, Triple)\n <mask> PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n <mask> \n <mask> tokenprog = re.compile(Token, re.UNICODE)\n <mask> pseudoprog = re.compile(PseudoToken, re.UNICODE)\n <mask> single3prog = re.compile(Single3) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove Bracket = '[][(){}]'\nSpecial = group(r'\\r?\\n', r'[:;.,`@]') </s> add Bracket = \"[][(){}]\"\nSpecial = group(r\"\\r?\\n\", r\"[:;.,`@]\") </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"') </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n) </s> remove Imagnumber = group(r'\\d+(?:_\\d+)*[jJ]', Floatnumber + r'[jJ]') </s> add Imagnumber = group(r\"\\d+(?:_\\d+)*[jJ]\", Floatnumber + r\"[jJ]\") </s> remove Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'\nHexnumber = r'0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?'\nOctnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'\nDecnumber = group(r'[1-9]\\d*(?:_\\d+)*[lL]?', '0[lL]?') </s> add Whitespace = r\"[ \\f\\t]*\"\nComment = r\"#[^\\r\\n]*\"\nIgnore = Whitespace + any(r\"\\\\\\r?\\n\" + Whitespace) + maybe(Comment)\nName = r\"\\w+\"  # this is invalid but it's fine because Name comes after Number in all groups\n\nBinnumber = r\"0[bB]_?[01]+(?:_[01]+)*\"\nHexnumber = r\"0[xX]_?[\\da-fA-F]+(?:_[\\da-fA-F]+)*[lL]?\"\nOctnumber = r\"0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?\"\nDecnumber = group(r\"[1-9]\\d*(?:_\\d+)*[lL]?\", \"0[lL]?\") </s> remove Exponent = r'[eE][-+]?\\d+(?:_\\d+)*'\nPointfloat = group(r'\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?', r'\\.\\d+(?:_\\d+)*') + maybe(Exponent)\nExpfloat = r'\\d+(?:_\\d+)*' + Exponent </s> add Exponent = r\"[eE][-+]?\\d+(?:_\\d+)*\"\nPointfloat = group(r\"\\d+(?:_\\d+)*\\.(?:\\d+(?:_\\d+)*)?\", r\"\\.\\d+(?:_\\d+)*\") + maybe(\n    Exponent\n)\nExpfloat = r\"\\d+(?:_\\d+)*\" + Exponent </s> remove Whitespace = r'[ \\f\\t]*'\nComment = r'#[^\\r\\n]*'\nIgnore = Whitespace + any(r'\\\\\\r?\\n' + Whitespace) + maybe(Comment)\nName = r'\\w+'  # this is invalid but it's fine because Name comes after Number in all groups </s> add", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace replace replace replace replace keep", "code_tokens": " <mask> double3prog = re.compile(Double3)\n <mask> \n <mask> _strprefixes = (\n <mask>     _combinations('r', 'R', 'f', 'F') |\n <mask>     _combinations('r', 'R', 'b', 'B') |\n <mask>     {'u', 'U', 'ur', 'uR', 'Ur', 'UR'}\n <mask> )\n <mask> \n <mask> endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n <mask>             \"'''\": single3prog, '\"\"\"': double3prog,\n <mask>             **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n <mask>             **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n <mask>             **{prefix: None for prefix in _strprefixes}}\n <mask>  </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove     {\"'''\", '\"\"\"'} |\n    {f\"{prefix}'''\" for prefix in _strprefixes} |\n    {f'{prefix}\"\"\"' for prefix in _strprefixes} </s> add     {\"'''\", '\"\"\"'}\n    | {f\"{prefix}'''\" for prefix in _strprefixes}\n    | {f'{prefix}\"\"\"' for prefix in _strprefixes} </s> remove     {\"'\", '\"'} |\n    {f\"{prefix}'\" for prefix in _strprefixes} |\n    {f'{prefix}\"' for prefix in _strprefixes} </s> add     {\"'\", '\"'}\n    | {f\"{prefix}'\" for prefix in _strprefixes}\n    | {f'{prefix}\"' for prefix in _strprefixes} </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix) </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n                          \"tokens\", \"symbol2label\"): </s> add         for dict_attr in (\n            \"symbol2number\",\n            \"number2symbol\",\n            \"dfas\",\n            \"keywords\",\n            \"tokens\",\n            \"symbol2label\",\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep keep replace replace replace keep", "code_tokens": " <mask>             **{prefix: None for prefix in _strprefixes}}\n <mask> \n <mask> triple_quoted = (\n <mask>     {\"'''\", '\"\"\"'} |\n <mask>     {f\"{prefix}'''\" for prefix in _strprefixes} |\n <mask>     {f'{prefix}\"\"\"' for prefix in _strprefixes}\n <mask> )\n <mask> single_quoted = (\n <mask>     {\"'\", '\"'} |\n <mask>     {f\"{prefix}'\" for prefix in _strprefixes} |\n <mask>     {f'{prefix}\"' for prefix in _strprefixes}\n <mask> ) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove endprogs = {\"'\": re.compile(Single), '\"': re.compile(Double),\n            \"'''\": single3prog, '\"\"\"': double3prog,\n            **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n            **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n            **{prefix: None for prefix in _strprefixes}} </s> add endprogs = {\n    \"'\": re.compile(Single),\n    '\"': re.compile(Double),\n    \"'''\": single3prog,\n    '\"\"\"': double3prog,\n    **{f\"{prefix}'''\": single3prog for prefix in _strprefixes},\n    **{f'{prefix}\"\"\"': double3prog for prefix in _strprefixes},\n    **{prefix: None for prefix in _strprefixes},\n} </s> remove     _combinations('r', 'R', 'f', 'F') |\n    _combinations('r', 'R', 'b', 'B') |\n    {'u', 'U', 'ur', 'uR', 'Ur', 'UR'} </s> add     _combinations(\"r\", \"R\", \"f\", \"F\")\n    | _combinations(\"r\", \"R\", \"b\", \"B\")\n    | {\"u\", \"U\", \"ur\", \"uR\", \"Ur\", \"UR\"} </s> remove                 self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix) </s> add                 self.logger.debug(\n                    \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n                ) </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove         for dict_attr in (\"symbol2number\", \"number2symbol\", \"dfas\", \"keywords\",\n                          \"tokens\", \"symbol2label\"): </s> add         for dict_attr in (\n            \"symbol2number\",\n            \"number2symbol\",\n            \"dfas\",\n            \"keywords\",\n            \"tokens\",\n            \"symbol2label\",\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep replace keep keep keep keep", "code_tokens": " <mask> tabsize = 8\n <mask> \n <mask> class TokenError(Exception): pass\n <mask> \n <mask> class StopTokenizing(Exception): pass\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1 </s> remove def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing </s> add def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line):  # for testing </s> remove     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n        (srow, scol, erow, ecol, tok_name[type], repr(token))) </s> add     print(\n        \"%d,%d-%d,%d:\\t%s\\t%s\" % (srow, scol, erow, ecol, tok_name[type], repr(token))\n    ) </s> add class ParserGenerator(object): </s> remove class ParserGenerator(object):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep keep keep keep", "code_tokens": " <mask> class TokenError(Exception): pass\n <mask> \n <mask> class StopTokenizing(Exception): pass\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1\n <mask>     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n <mask>         (srow, scol, erow, ecol, tok_name[type], repr(token)))\n <mask> \n <mask> def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing\n <mask>     (srow, scol) = xxx_todo_changeme\n <mask>     (erow, ecol) = xxx_todo_changeme1\n <mask>     print(\"%d,%d-%d,%d:\\t%s\\t%s\" % \\\n <mask>         (srow, scol, erow, ecol, tok_name[type], repr(token)))\n <mask> \n <mask> def tokenize(readline, tokeneater=printtoken):\n <mask>     \"\"\"\n <mask>     The tokenize() function accepts two parameters: one representing the </s> remove class StopTokenizing(Exception): pass </s> add class TokenError(Exception):\n    pass\n\n\nclass StopTokenizing(Exception):\n    pass </s> remove class TokenError(Exception): pass </s> remove class ParserGenerator(object): </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> def tokenize_loop(readline, tokeneater):\n <mask>     for token_info in generate_tokens(readline):\n <mask>         tokeneater(*token_info)\n <mask> \n <mask> class Untokenizer:\n <mask> \n <mask>     def __init__(self):\n <mask>         self.tokens = []\n <mask>         self.prev_row = 1\n <mask>         self.prev_col = 0 </s> add class Untokenizer: </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line)) </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line)) </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask>     def __init__(self):\n <mask>         self.tokens = []\n <mask>         self.prev_row = 1\n <mask>         self.prev_col = 0 </s> remove class Untokenizer: </s> remove         raise SyntaxError(msg, (self.filename, self.end[0],\n                                self.end[1], self.line)) </s> add         raise SyntaxError(msg, (self.filename, self.end[0], self.end[1], self.line))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         indents = []\n <mask>         toks_append = self.tokens.append\n <mask>         toknum, tokval = token\n <mask>         if toknum in (NAME, NUMBER):\n <mask>             tokval += ' '\n <mask>         if toknum in (NEWLINE, NL):\n <mask>             startline = True\n <mask>         for tok in iterable:\n <mask>             toknum, tokval = tok[:2]\n <mask>  </s> remove                 tokval += ' ' </s> add                 tokval += \" \" </s> remove                     if token == 'async' and not stashed: </s> add                     if token == \"async\" and not stashed: </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'): </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\": </s> remove             elif char == '\\n': </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         for tok in iterable:\n <mask>             toknum, tokval = tok[:2]\n <mask> \n <mask>             if toknum in (NAME, NUMBER, ASYNC, AWAIT):\n <mask>                 tokval += ' '\n <mask> \n <mask>             if toknum == INDENT:\n <mask>                 indents.append(tokval)\n <mask>                 continue\n <mask>             elif toknum == DEDENT: </s> remove             tokval += ' ' </s> add             tokval += \" \" </s> remove                     if token == 'async' and not stashed: </s> add                     if token == \"async\" and not stashed: </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove             if not line: break </s> add             if not line:\n                break </s> remove             elif char == '\\n': </s> add             elif char == \"\\n\": </s> remove             elif char in ' \\t': </s> add             elif char in \" \\t\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 toks_append(indents[-1])\n <mask>                 startline = False\n <mask>             toks_append(tokval)\n <mask> \n <mask> cookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\n <mask> blank_re = re.compile(br'^[ \\t\\f]*(?:[#\\r\\n]|$)', re.ASCII)\n <mask> \n <mask> def _get_normal_name(orig_enc):\n <mask>     \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n <mask>     # Only care about the first 12 characters.\n <mask>     enc = orig_enc[:12].lower().replace(\"_\", \"-\") </s> remove     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n       enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")): </s> add     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or enc.startswith(\n        (\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")\n    ): </s> add         else:  # continued statement </s> remove         default = 'utf-8-sig' </s> add         default = \"utf-8-sig\" </s> remove String = group(_litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n               _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"') </s> add String = group(\n    _litprefix + r\"'[^\\n'\\\\]*(?:\\\\.[^\\n'\\\\]*)*'\",\n    _litprefix + r'\"[^\\n\"\\\\]*(?:\\\\.[^\\n\"\\\\]*)*\"',\n)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     # Only care about the first 12 characters.\n <mask>     enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n <mask>     if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n <mask>         return \"utf-8\"\n <mask>     if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n <mask>        enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n <mask>         return \"iso-8859-1\"\n <mask>     return orig_enc\n <mask> \n <mask> def detect_encoding(readline):\n <mask>     \"\"\" </s> remove cookie_re = re.compile(r'^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)', re.ASCII)\nblank_re = re.compile(br'^[ \\t\\f]*(?:[#\\r\\n]|$)', re.ASCII) </s> add cookie_re = re.compile(r\"^[ \\t\\f]*#.*?coding[:=][ \\t]*([-\\w.]+)\", re.ASCII)\nblank_re = re.compile(br\"^[ \\t\\f]*(?:[#\\r\\n]|$)\", re.ASCII) </s> remove     default = 'utf-8' </s> add     default = \"utf-8\" </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig' </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove         default = 'utf-8-sig' </s> add         default = \"utf-8-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     If no encoding is specified, then the default of 'utf-8' will be returned.\n <mask>     \"\"\"\n <mask>     bom_found = False\n <mask>     encoding = None\n <mask>     default = 'utf-8'\n <mask>     def read_or_stop():\n <mask>         try:\n <mask>             return readline()\n <mask>         except StopIteration:\n <mask>             return bytes() </s> remove         default = 'utf-8-sig' </s> remove             line_string = line.decode('ascii') </s> add             line_string = line.decode(\"ascii\") </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig' </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove     while 1:                                   # loop over lines in stream", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return bytes()\n <mask> \n <mask>     def find_cookie(line):\n <mask>         try:\n <mask>             line_string = line.decode('ascii')\n <mask>         except UnicodeDecodeError:\n <mask>             return None\n <mask>         match = cookie_re.match(line_string)\n <mask>         if not match:\n <mask>             return None </s> remove     default = 'utf-8' </s> remove     __hash__ = None # For Py3 compatibility. </s> add     __hash__ = None  # For Py3 compatibility. </s> remove     __hash__ = None # For Py3 compatibility. </s> add     __hash__ = None  # For Py3 compatibility. </s> remove     name = None     # Optional name used to store match in results dict </s> add     name = None  # Optional name used to store match in results dict </s> remove             if subpattern is not None and  self.name == subpattern.name: </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1): </s> add         if (\n            self.content is not None\n            and len(self.content) == 1\n            and len(self.content[0]) == 1\n        ):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep keep keep keep replace replace keep", "code_tokens": " <mask>             # This behaviour mimics the Python interpreter\n <mask>             raise SyntaxError(\"unknown encoding: \" + encoding)\n <mask> \n <mask>         if bom_found:\n <mask>             if codec.name != 'utf-8':\n <mask>                 # This behaviour mimics the Python interpreter\n <mask>                 raise SyntaxError('encoding problem: utf-8')\n <mask>             encoding += '-sig'\n <mask>         return encoding\n <mask> \n <mask>         if bom_found:\n <mask>             if codec.name != 'utf-8':\n <mask>                 # This behaviour mimics the Python interpreter\n <mask>                 raise SyntaxError('encoding problem: utf-8')\n <mask>             encoding += '-sig'\n <mask>         return encoding </s> remove         default = 'utf-8-sig' </s> add         default = \"utf-8-sig\" </s> remove     default = 'utf-8' </s> add     default = \"utf-8\" </s> add def group(*choices):\n    return \"(\" + \"|\".join(choices) + \")\"\n\n\ndef any(*choices):\n    return group(*choices) + \"*\"\n\n\ndef maybe(*choices):\n    return group(*choices) + \"?\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     first = read_or_stop()\n <mask>     if first.startswith(BOM_UTF8):\n <mask>         bom_found = True\n <mask>         first = first[3:]\n <mask>         default = 'utf-8-sig'\n <mask>     if not first:\n <mask>         return default, []\n <mask> \n <mask>     encoding = find_cookie(first)\n <mask>     if encoding: </s> remove                 raise SyntaxError('encoding problem: utf-8')\n            encoding += '-sig' </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\" </s> remove     default = 'utf-8' </s> remove     __hash__ = None # For Py3 compatibility. </s> add     __hash__ = None  # For Py3 compatibility. </s> remove             line_string = line.decode('ascii') </s> add             line_string = line.decode(\"ascii\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     and the line on which the token was found. The line passed is the\n <mask>     logical line; continuation lines are included.\n <mask>     \"\"\"\n <mask>     lnum = parenlev = continued = 0\n <mask>     numchars = '0123456789'\n <mask>     contstr, needcont = '', 0\n <mask>     contline = None\n <mask>     indents = [0]\n <mask> \n <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and\n <mask>     # `await` as keywords. </s> remove             elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n                yield (ERRORTOKEN, contstr + line,\n                           strstart, (lnum, len(line)), contline)\n                contstr = '' </s> add             elif needcont and line[-2:] != \"\\\\\\n\" and line[-3:] != \"\\\\\\r\\n\":\n                yield (\n                    ERRORTOKEN,\n                    contstr + line,\n                    strstart,\n                    (lnum, len(line)),\n                    contline,\n                )\n                contstr = \"\" </s> remove                 yield (STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0 </s> add                 yield (\n                    STRING,\n                    contstr + line[:end],\n                    strstart,\n                    (lnum, end),\n                    contline + line,\n                )\n                contstr, needcont = \"\", 0 </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove     while 1:                                   # loop over lines in stream </s> remove __author__ = 'Ka-Ping Yee <ping@lfw.org>'\n__credits__ = \\\n    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep replace keep", "code_tokens": " <mask>     async_def_nl = False\n <mask> \n <mask>     while 1:                                   # loop over lines in stream\n <mask>         try:\n <mask>             line = readline()\n <mask>         except StopIteration:\n <mask>             line = ''\n <mask>         lnum = lnum + 1 </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f) </s> remove         lineno, line = lineno+1, next(f) </s> add         lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             line = ''\n <mask>         lnum = lnum + 1\n <mask>         pos, max = 0, len(line)\n <mask> \n <mask>         if contstr:                            # continued string\n <mask>             if not line:\n <mask>                 raise TokenError(\"EOF in multi-line string\", strstart)\n <mask>             endmatch = endprog.match(line)\n <mask>             if endmatch:\n <mask>                 pos = end = endmatch.end(0) </s> remove             line = '' </s> add             line = \"\" </s> remove                 yield (STRING, contstr + line[:end],\n                       strstart, (lnum, end), contline + line)\n                contstr, needcont = '', 0 </s> add                 yield (\n                    STRING,\n                    contstr + line[:end],\n                    strstart,\n                    (lnum, end),\n                    contline + line,\n                )\n                contstr, needcont = \"\", 0 </s> remove         else:                                  # continued statement </s> add         else:  # continued statement </s> remove                     if endmatch:                           # all on one line </s> add                     if endmatch:  # all on one line </s> remove     while 1:                                   # loop over lines in stream </s> add     while 1:  # loop over lines in stream </s> remove             if not line: break </s> add             if not line:\n                break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace replace replace replace keep keep", "code_tokens": " <mask>                 pos = end = endmatch.end(0)\n <mask>                 yield (STRING, contstr + line[:end],\n <mask>                        strstart, (lnum, end), contline + line)\n <mask>                 contstr, needcont = '', 0\n <mask>                 contline = None\n <mask>             elif needcont and line[-2:] != '\\\\\\n' and line[-3:] != '\\\\\\r\\n':\n <mask>                 yield (ERRORTOKEN, contstr + line,\n <mask>                            strstart, (lnum, len(line)), contline)\n <mask>                 contstr = ''\n <mask>                 contline = None\n <mask>                 continue </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0 </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0 </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace keep keep", "code_tokens": " <mask>         elif parenlev == 0 and not continued:  # new statement\n <mask>             if not line: break\n <mask>             column = 0\n <mask>             while pos < max:                   # measure leading whitespace\n <mask>                 if line[pos] == ' ': column = column + 1\n <mask>                 elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n <mask>                 elif line[pos] == '\\f': column = 0\n <mask>                 else: break\n <mask>                 pos = pos + 1\n <mask>             if pos == max: break </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if pos == max: break </s> add             if pos == max:\n                break </s> remove         else:                                  # continued statement </s> add         else:  # continued statement </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line) </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n') </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\") </s> remove             if pseudomatch:                                # scan for tokens </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n <mask>                 elif line[pos] == '\\f': column = 0\n <mask>                 else: break\n <mask>                 pos = pos + 1\n <mask>             if pos == max: break\n <mask> \n <mask>             if stashed:\n <mask>                 yield stashed\n <mask>                 stashed = None\n <mask>  </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break </s> remove             if not line: break </s> add             if not line:\n                break </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n') </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace", "code_tokens": " <mask>                 yield stashed\n <mask>                 stashed = None\n <mask> \n <mask>             if line[pos] in '\\r\\n':            # skip blank lines\n <mask>                 yield (NL, line[pos:], (lnum, pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask> \n <mask>             if line[pos] == '#':               # skip comments\n <mask>                 comment_token = line[pos:].rstrip('\\r\\n') </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line) </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 elif initial == '\\\\':                      # continued stmt </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines </s> remove             if column > indents[-1]:           # count indents </s> add             if column > indents[-1]:  # count indents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep replace keep", "code_tokens": " <mask> \n <mask>             if line[pos] == '#':               # skip comments\n <mask>                 comment_token = line[pos:].rstrip('\\r\\n')\n <mask>                 nl_pos = pos + len(comment_token)\n <mask>                 yield (COMMENT, comment_token,\n <mask>                         (lnum, pos), (lnum, pos + len(comment_token)), line)\n <mask>                 yield (NL, line[nl_pos:],\n <mask>                         (lnum, nl_pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask> \n <mask>             if column > indents[-1]:           # count indents\n <mask>                 indents.append(column) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n') </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\") </s> remove             if line[pos] in '\\r\\n':            # skip blank lines </s> add             if line[pos] in \"\\r\\n\":  # skip blank lines </s> remove             while column < indents[-1]:        # count dedents </s> add             while column < indents[-1]:  # count dedents </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line) </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask>             if column > indents[-1]:           # count indents\n <mask>                 indents.append(column)\n <mask>                 yield (INDENT, line[:pos], (lnum, 0), (lnum, pos), line)\n <mask> \n <mask>             while column < indents[-1]:        # count dedents\n <mask>                 if column not in indents:\n <mask>                     raise IndentationError(\n <mask>                         \"unindent does not match any outer indentation level\",\n <mask>                         (\"<tokenize>\", lnum, pos, line))\n <mask>                 indents = indents[:-1]\n <mask> \n <mask>                 if async_def and async_def_indent >= indents[-1]:\n <mask>                     async_def = False </s> remove             if column > indents[-1]:           # count indents </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line) </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line) </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove         else:                                  # continued statement </s> add         else:  # continued statement </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     async_def = False\n <mask>                     async_def_nl = False\n <mask>                     async_def_indent = 0\n <mask> \n <mask>                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line)\n <mask> \n <mask>             if async_def and async_def_nl and async_def_indent >= indents[-1]:\n <mask>                 async_def = False\n <mask>                 async_def_nl = False\n <mask>                 async_def_indent = 0 </s> remove         else:                                  # continued statement </s> add         else:  # continued statement </s> remove     while 1:                                   # loop over lines in stream </s> add     while 1:  # loop over lines in stream </s> remove                             yield (ASYNC, stashed[1],\n                                   stashed[2], stashed[3],\n                                   stashed[4]) </s> add                             yield (\n                                ASYNC,\n                                stashed[1],\n                                stashed[2],\n                                stashed[3],\n                                stashed[4],\n                            ) </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'): </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\":", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 async_def = False\n <mask>                 async_def_nl = False\n <mask>                 async_def_indent = 0\n <mask> \n <mask>         else:                                  # continued statement\n <mask>             if not line:\n <mask>                 raise TokenError(\"EOF in multi-line statement\", (lnum, 0))\n <mask>             continued = 0\n <mask> \n <mask>         while pos < max: </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line) </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove             while pos < max:                   # measure leading whitespace\n                if line[pos] == ' ': column = column + 1\n                elif line[pos] == '\\t': column = (column//tabsize + 1)*tabsize\n                elif line[pos] == '\\f': column = 0\n                else: break </s> add             while pos < max:  # measure leading whitespace\n                if line[pos] == \" \":\n                    column = column + 1\n                elif line[pos] == \"\\t\":\n                    column = (column // tabsize + 1) * tabsize\n                elif line[pos] == \"\\f\":\n                    column = 0\n                else:\n                    break", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace replace keep keep keep", "code_tokens": " <mask>         while pos < max:\n <mask>             pseudomatch = pseudoprog.match(line, pos)\n <mask>             if pseudomatch:                                # scan for tokens\n <mask>                 start, end = pseudomatch.span(1)\n <mask>                 spos, epos, pos = (lnum, start), (lnum, end), end\n <mask>                 token, initial = line[start:end], line[start]\n <mask> \n <mask>                 if initial in numchars or \\\n <mask>                    (initial == '.' and token != '.'):      # ordinary number\n <mask>                     yield (NUMBER, token, spos, epos, line)\n <mask>                 elif initial in '\\r\\n':\n <mask>                     newline = NEWLINE </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 elif initial in '\\r\\n': </s> add                 elif initial in \"\\r\\n\": </s> remove                 elif initial == '#': </s> add                 elif initial == \"#\": </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 if initial in numchars or \\\n <mask>                    (initial == '.' and token != '.'):      # ordinary number\n <mask>                     yield (NUMBER, token, spos, epos, line)\n <mask>                 elif initial in '\\r\\n':\n <mask>                     newline = NEWLINE\n <mask>                     if parenlev > 0:\n <mask>                         newline = NL\n <mask>                     elif async_def:\n <mask>                         async_def_nl = True </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'): </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 elif initial == '#': </s> remove             if pseudomatch:                                # scan for tokens </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (newline, token, spos, epos, line)\n <mask> \n <mask>                 elif initial == '#':\n <mask>                     assert not token.endswith(\"\\n\")\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (COMMENT, token, spos, epos, line) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial == '\\\\':                      # continued stmt </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'): </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                     if endmatch:                           # all on one line </s> add                     if endmatch:  # all on one line </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     yield (COMMENT, token, spos, epos, line)\n <mask>                 elif token in triple_quoted:\n <mask>                     endprog = endprogs[token]\n <mask>                     endmatch = endprog.match(line, pos)\n <mask>                     if endmatch:                           # all on one line\n <mask>                         pos = endmatch.end(0)\n <mask>                         token = line[start:pos]\n <mask>                         if stashed:\n <mask>                             yield stashed\n <mask>                             stashed = None </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'): </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace replace", "code_tokens": " <mask>                             stashed = None\n <mask>                         yield (STRING, token, spos, (lnum, pos), line)\n <mask>                     else:\n <mask>                         strstart = (lnum, start)           # multiple lines\n <mask>                         contstr = line[start:]\n <mask>                         contline = line\n <mask>                         break\n <mask>                 elif initial in single_quoted or \\\n <mask>                     token[:2] in single_quoted or \\\n <mask>                     token[:3] in single_quoted:\n <mask>                     if token[-1] == '\\n':                  # continued string </s> remove                         endprog = (endprogs[initial] or endprogs[token[1]] or\n                                   endprogs[token[2]]) </s> add                         endprog = (\n                            endprogs[initial]\n                            or endprogs[token[1]]\n                            or endprogs[token[2]]\n                        ) </s> remove                 elif initial == '\\\\':                      # continued stmt </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep replace keep", "code_tokens": " <mask>                     token[:2] in single_quoted or \\\n <mask>                     token[:3] in single_quoted:\n <mask>                     if token[-1] == '\\n':                  # continued string\n <mask>                         strstart = (lnum, start)\n <mask>                         endprog = (endprogs[initial] or endprogs[token[1]] or\n <mask>                                    endprogs[token[2]])\n <mask>                         contstr, needcont = line[start:], 1\n <mask>                         contline = line\n <mask>                         break\n <mask>                     else:                                  # ordinary string\n <mask>                         if stashed: </s> remove                 elif initial in single_quoted or \\\n                    token[:2] in single_quoted or \\\n                    token[:3] in single_quoted:\n                    if token[-1] == '\\n':                  # continued string </s> add                 elif (\n                    initial in single_quoted\n                    or token[:2] in single_quoted\n                    or token[:3] in single_quoted\n                ):\n                    if token[-1] == \"\\n\":  # continued string </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines </s> remove         if contstr:                            # continued string </s> add         if contstr:  # continued string </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number </s> remove             if pseudomatch:                                # scan for tokens </s> add             if pseudomatch:  # scan for tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace replace keep", "code_tokens": " <mask>                             yield stashed\n <mask>                             stashed = None\n <mask>                         yield (STRING, token, spos, epos, line)\n <mask>                 elif initial.isidentifier():               # ordinary name\n <mask>                     if token in ('async', 'await'):\n <mask>                         if async_keywords or async_def:\n <mask>                             yield (ASYNC if token == 'async' else AWAIT,\n <mask>                                    token, spos, epos, line)\n <mask>                             continue </s> remove                     if token == 'async' and not stashed: </s> add                     if token == \"async\" and not stashed:", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace replace keep keep keep keep", "code_tokens": " <mask>                             continue\n <mask> \n <mask>                     tok = (NAME, token, spos, epos, line)\n <mask>                     if token == 'async' and not stashed:\n <mask>                         stashed = tok\n <mask>                         continue\n <mask> \n <mask>                     if token in ('def', 'for'):\n <mask>                         if (stashed\n <mask>                                 and stashed[0] == NAME\n <mask>                                 and stashed[1] == 'async'):\n <mask> \n <mask>                             if token == 'def':\n <mask>                                 async_def = True\n <mask>                                 async_def_indent = indents[-1] </s> remove                             if token == 'def': </s> add                             if token == \"def\": </s> remove                             yield (ASYNC if token == 'async' else AWAIT,\n                                   token, spos, epos, line) </s> add                             yield (\n                                ASYNC if token == \"async\" else AWAIT,\n                                token,\n                                spos,\n                                epos,\n                                line,\n                            ) </s> remove                 elif initial.isidentifier():               # ordinary name\n                    if token in ('async', 'await'): </s> add                 elif initial.isidentifier():  # ordinary name\n                    if token in (\"async\", \"await\"): </s> remove                             yield (ASYNC, stashed[1],\n                                   stashed[2], stashed[3],\n                                   stashed[4]) </s> add                             yield (\n                                ASYNC,\n                                stashed[1],\n                                stashed[2],\n                                stashed[3],\n                                stashed[4],\n                            ) </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace replace replace keep keep keep keep", "code_tokens": " <mask>                                 and stashed[0] == NAME\n <mask>                                 and stashed[1] == 'async'):\n <mask> \n <mask>                             if token == 'def':\n <mask>                                 async_def = True\n <mask>                                 async_def_indent = indents[-1]\n <mask> \n <mask>                             yield (ASYNC, stashed[1],\n <mask>                                    stashed[2], stashed[3],\n <mask>                                    stashed[4])\n <mask>                             stashed = None\n <mask> \n <mask>                     if stashed:\n <mask>                         yield stashed </s> remove                     if token in ('def', 'for'):\n                        if (stashed\n                                and stashed[0] == NAME\n                                and stashed[1] == 'async'): </s> add                     if token in (\"def\", \"for\"):\n                        if stashed and stashed[0] == NAME and stashed[1] == \"async\": </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line) </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove                     if token == 'async' and not stashed: </s> add                     if token == \"async\" and not stashed: </s> remove                 elif initial == '\\\\':                      # continued stmt", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask> \n <mask>                     yield tok\n <mask>                 elif initial == '\\\\':                      # continued stmt\n <mask>                     # This yield is new; needed for better idempotency:\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (NL, token, spos, (lnum, pos), line) </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines </s> remove             if line[pos] in '\\r\\n':            # skip blank lines </s> add             if line[pos] in \"\\r\\n\":  # skip blank lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                         stashed = None\n <mask>                     yield (NL, token, spos, (lnum, pos), line)\n <mask>                     continued = 1\n <mask>                 else:\n <mask>                     if initial in '([{': parenlev = parenlev + 1\n <mask>                     elif initial in ')]}': parenlev = parenlev - 1\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else: </s> remove                 yield (ERRORTOKEN, line[pos],\n                           (lnum, pos), (lnum, pos+1), line) </s> add                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line) </s> remove                 elif initial == '\\\\':                      # continued stmt </s> add                 elif initial == \"\\\\\":  # continued stmt </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines </s> remove                 if initial in numchars or \\\n                   (initial == '.' and token != '.'):      # ordinary number </s> add                 if initial in numchars or (\n                    initial == \".\" and token != \".\"\n                ):  # ordinary number", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                         yield stashed\n <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else:\n <mask>                 yield (ERRORTOKEN, line[pos],\n <mask>                            (lnum, pos), (lnum, pos+1), line)\n <mask>                 pos = pos + 1\n <mask> \n <mask>     if stashed:\n <mask>         yield stashed\n <mask>         stashed = None </s> remove                     if initial in '([{': parenlev = parenlev + 1\n                    elif initial in ')]}': parenlev = parenlev - 1 </s> add                     if initial in \"([{\":\n                        parenlev = parenlev + 1\n                    elif initial in \")]}\":\n                        parenlev = parenlev - 1 </s> remove                 elif initial == '\\\\':                      # continued stmt </s> remove                     if endmatch:                           # all on one line </s> add                     if endmatch:  # all on one line </s> remove                         strstart = (lnum, start)           # multiple lines </s> add                         strstart = (lnum, start)  # multiple lines", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace replace replace keep replace", "code_tokens": " <mask> \n <mask>     for indent in indents[1:]:                 # pop remaining indent levels\n <mask>         yield (DEDENT, '', (lnum, 0), (lnum, 0), '')\n <mask>     yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n <mask> \n <mask> if __name__ == '__main__':                     # testing </s> remove     if len(sys.argv) > 1: tokenize(open(sys.argv[1]).readline)\n    else: tokenize(sys.stdin.readline) </s> add     if len(sys.argv) > 1:\n        tokenize(open(sys.argv[1]).readline)\n    else:\n        tokenize(sys.stdin.readline) </s> remove             if column > indents[-1]:           # count indents </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line) </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove                 yield (DEDENT, '', (lnum, pos), (lnum, pos), line) </s> add                 yield (DEDENT, \"\", (lnum, pos), (lnum, pos), line) </s> remove             while column < indents[-1]:        # count dedents </s> add             while column < indents[-1]:  # count dedents", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace", "code_tokens": " <mask>     yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')\n <mask> \n <mask> if __name__ == '__main__':                     # testing\n <mask>     import sys\n <mask>     if len(sys.argv) > 1: tokenize(open(sys.argv[1]).readline)\n <mask>     else: tokenize(sys.stdin.readline) </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove if __name__ == '__main__':                     # testing </s> add if __name__ == \"__main__\":  # testing </s> remove     for indent in indents[1:]:                 # pop remaining indent levels\n        yield (DEDENT, '', (lnum, 0), (lnum, 0), '')\n    yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '') </s> add     for indent in indents[1:]:  # pop remaining indent levels\n        yield (DEDENT, \"\", (lnum, 0), (lnum, 0), \"\")\n    yield (ENDMARKER, \"\", (lnum, 0), (lnum, 0), \"\") </s> remove             if column > indents[-1]:           # count indents </s> add             if column > indents[-1]:  # count indents </s> remove                 yield (COMMENT, comment_token,\n                        (lnum, pos), (lnum, pos + len(comment_token)), line)\n                yield (NL, line[nl_pos:],\n                        (lnum, nl_pos), (lnum, len(line)), line) </s> add                 yield (\n                    COMMENT,\n                    comment_token,\n                    (lnum, pos),\n                    (lnum, pos + len(comment_token)),\n                    line,\n                )\n                yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line) </s> remove             while column < indents[-1]:        # count dedents </s> add             while column < indents[-1]:  # count dedents </s> remove             if line[pos] == '#':               # skip comments\n                comment_token = line[pos:].rstrip('\\r\\n') </s> add             if line[pos] == \"#\":  # skip comments\n                comment_token = line[pos:].rstrip(\"\\r\\n\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from .pgen2 import driver\n <mask> \n <mask> # The grammar file\n <mask> _GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"Grammar.txt\")\n <mask> _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n <mask>                                      \"PatternGrammar.txt\")\n <mask> \n <mask> \n <mask> class Symbols(object):\n <mask> \n <mask>     def __init__(self, grammar): </s> remove \n    def __init__(\n        self,\n        grammar,\n        convert=None,\n        logger=None,\n    ): </s> add     def __init__(self, grammar, convert=None, logger=None): </s> remove class ParserGenerator(object): </s> add class ParserGenerator(object): </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir) </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     global pattern_grammar\n <mask>     global pattern_symbols\n <mask> \n <mask>     # Python 2\n <mask>     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n <mask>                                                   cache_dir)\n <mask> \n <mask>     python_symbols = Symbols(python_grammar)\n <mask> \n <mask>     # Python 2 + from __future__ import print_function\n <mask>     python_grammar_no_print_statement = python_grammar.copy() </s> remove     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True </s> add     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = (\n        True\n    ) </s> remove     pattern_grammar = driver.load_packaged_grammar(\"blib2to3\", _PATTERN_GRAMMAR_FILE,\n                                                   cache_dir) </s> add     pattern_grammar = driver.load_packaged_grammar(\n        \"blib2to3\", _PATTERN_GRAMMAR_FILE, cache_dir\n    ) </s> remove _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),\n                                     \"PatternGrammar.txt\") </s> add _PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), \"PatternGrammar.txt\") </s> add                 raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep replace keep replace replace", "code_tokens": " <mask>     )\n <mask>     python_grammar_no_print_statement_no_exec_statement_async_keywords.async_keywords = True\n <mask> \n <mask>     pattern_grammar = driver.load_packaged_grammar(\"blib2to3\", _PATTERN_GRAMMAR_FILE,\n <mask>                                                    cache_dir) </s> remove     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE,\n                                                  cache_dir) </s> add     python_grammar = driver.load_packaged_grammar(\"blib2to3\", _GRAMMAR_FILE, cache_dir)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pygram.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from .pygram import python_symbols\n <mask>         # printing tokens is possible but not as useful\n <mask>         # from .pgen2 import token // token.__dict__.items():\n <mask>         for name, val in python_symbols.__dict__.items():\n <mask>             if type(val) == int: _type_reprs[val] = name\n <mask>     return _type_reprs.setdefault(type_num, type_num)\n <mask> \n <mask> class Base(object):\n <mask> \n <mask>     \"\"\" </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens </s> remove __all__ = [x for x in dir(token) if x[0] != '_'] + [\"tokenize\",\n           \"generate_tokens\", \"untokenize\"] </s> add __all__ = [x for x in dir(token) if x[0] != \"_\"] + [\n    \"tokenize\",\n    \"generate_tokens\",\n    \"untokenize\",\n] </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     A node may be a subnode of at most one parent.\n <mask>     \"\"\"\n <mask> \n <mask>     # Default values for instance variables\n <mask>     type = None    # int: token number (< 256) or symbol number (>= 256)\n <mask>     parent = None  # Parent node pointer, or None\n <mask>     children = ()  # Tuple of subnodes\n <mask>     was_changed = False\n <mask>     was_checked = False\n <mask>  </s> remove     type = None     # Node type (token if < 256, symbol if >= 256) </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         if self.__class__ is not other.__class__:\n <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     __hash__ = None # For Py3 compatibility.\n <mask> \n <mask>     def _eq(self, other):\n <mask>         \"\"\"\n <mask>         Compare two nodes for equality.\n <mask>  </s> remove     __hash__ = None # For Py3 compatibility. </s> add     __hash__ = None  # For Py3 compatibility.", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> class Node(Base):\n <mask> \n <mask>     \"\"\"Concrete implementation for interior nodes.\"\"\"\n <mask> \n <mask>     def __init__(self,type, children,\n <mask>                  context=None,\n <mask>                  prefix=None,\n <mask>                  fixers_applied=None):\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask> \n <mask>         Takes a type constant (a symbol number >= 256), a sequence of\n <mask>         child nodes, and an optional context keyword argument. </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove     type = None     # Node type (token if < 256, symbol if >= 256) </s> add     type = None  # Node type (token if < 256, symbol if >= 256) </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256) </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove     lineno = 0    # Line where this token starts in the input\n    column = 0    # Column where this token starts in the input </s> add     lineno = 0  # Line where this token starts in the input\n    column = 0  # Column where this token starts in the input </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied) </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove                 print(\"%s(%s): can't parse %s\" % (filename, lineno,\n                                                  line.strip())) </s> add                 print(\"%s(%s): can't parse %s\" % (filename, lineno, line.strip()))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             self.fixers_applied = None\n <mask> \n <mask>     def __repr__(self):\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         return \"%s(%s, %r)\" % (self.__class__.__name__,\n <mask>                                type_repr(self.type),\n <mask>                                self.children)\n <mask> \n <mask>     def __unicode__(self):\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask>  </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value) </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied) </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> add             io.StringIO(text).readline, grammar=self.grammar </s> remove     def __init__(self, type, value,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=[]): </s> add     def __init__(self, type, value, context=None, prefix=None, fixers_applied=[]): </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied) </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         return (self.type, self.children) == (other.type, other.children)\n <mask> \n <mask>     def clone(self):\n <mask>         \"\"\"Return a cloned (deep) copy of self.\"\"\"\n <mask>         return Node(self.type, [ch.clone() for ch in self.children],\n <mask>                     fixers_applied=self.fixers_applied)\n <mask> \n <mask>     def post_order(self):\n <mask>         \"\"\"Return a post-order iterator for the tree.\"\"\"\n <mask>         for child in self.children:\n <mask>             yield from child.post_order() </s> remove         return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied) </s> add         return Leaf(\n            self.type,\n            self.value,\n            (self.prefix, (self.lineno, self.column)),\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children) </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove     def __init__(self,type, children,\n                 context=None,\n                 prefix=None,\n                 fixers_applied=None): </s> add     def __init__(self, type, children, context=None, prefix=None, fixers_applied=None):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep replace replace keep replace replace replace replace keep keep keep", "code_tokens": " <mask>     # Default values for instance variables\n <mask>     _prefix = \"\"  # Whitespace and comments preceding this token in the input\n <mask>     lineno = 0    # Line where this token starts in the input\n <mask>     column = 0    # Column where this token starts in the input\n <mask> \n <mask>     def __init__(self, type, value,\n <mask>                  context=None,\n <mask>                  prefix=None,\n <mask>                  fixers_applied=[]):\n <mask>         \"\"\"\n <mask>         Initializer.\n <mask>  </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove         self.used_names = set() # Aliased to self.rootnode.used_names in pop() </s> add         self.used_names = set()  # Aliased to self.rootnode.used_names in pop() </s> remove     type = None    # int: token number (< 256) or symbol number (>= 256) </s> add     type = None  # int: token number (< 256) or symbol number (>= 256) </s> remove                         raise ParseError(\"too much input\",\n                                         type, value, context) </s> add                         raise ParseError(\"too much input\", type, value, context) </s> remove     numchars = '0123456789'\n    contstr, needcont = '', 0 </s> add     numchars = \"0123456789\"\n    contstr, needcont = \"\", 0", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def __repr__(self):\n <mask>         \"\"\"Return a canonical string representation.\"\"\"\n <mask>         from .pgen2.token import tok_name\n <mask>         return \"%s(%s, %r)\" % (self.__class__.__name__,\n <mask>                                tok_name.get(self.type, self.type),\n <mask>                                self.value)\n <mask> \n <mask>     def __unicode__(self):\n <mask>         \"\"\"\n <mask>         Return a pretty string representation.\n <mask>  </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied) </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         return (self.type, self.value) == (other.type, other.value)\n <mask> \n <mask>     def clone(self):\n <mask>         \"\"\"Return a cloned (deep) copy of self.\"\"\"\n <mask>         return Leaf(self.type, self.value,\n <mask>                     (self.prefix, (self.lineno, self.column)),\n <mask>                     fixers_applied=self.fixers_applied)\n <mask> \n <mask>     def leaves(self):\n <mask>         yield self\n <mask> \n <mask>     def post_order(self): </s> Blacken .py files in blib2to3 (#1011)\n\n* Blacken .py files in blib2to3\r\n\r\nThis is in preparation for adding type annotations to blib2to3 in\r\norder to compiling it with mypyc (#1009, which I can rebase on top of\r\nthis).\r\n\r\nTo enforce that it stays blackened, I just cargo-culted the existing\r\ntest code used for validating formatting. It feels pretty clunky now,\r\nthough, so I can abstract the common logic out into a helper if that\r\nseems better. (But error messages might be less clear then?)\r\n\r\n* Tidy up the tests </s> remove         return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied) </s> add         return Node(\n            self.type,\n            [ch.clone() for ch in self.children],\n            fixers_applied=self.fixers_applied,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               tok_name.get(self.type, self.type),\n                               self.value) </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            tok_name.get(self.type, self.type),\n            self.value,\n        ) </s> remove         return \"%s(%s, %r)\" % (self.__class__.__name__,\n                               type_repr(self.type),\n                               self.children) </s> add         return \"%s(%s, %r)\" % (\n            self.__class__.__name__,\n            type_repr(self.type),\n            self.children,\n        ) </s> add             self.raise_error(\n                \"expected %s/%s, got %s/%s\", type, value, self.type, self.value\n            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     - WildcardPattern matches a sequence of nodes of variable length.\n <mask>     \"\"\"\n <mask> \n <mask>     # Defaults for instance variables\n <mask>     type = None     # Node type (token if < 256, symbol if >= 256)\n <mask>     content = None  # Optional content matching pattern\n <mask>     name = None     # Optional name used to store match in results dict\n <mask> \n <mask>     def __new__(cls, *args, **kwds):\n <mask>         \"\"\"Constructor that prevents BasePattern from being instantiated.\"\"\" </s> remove     name = None     # Optional name used to store match in results dict </s> add     name = None  # Optional name used to store match in results dict </s> remove         self.first = {} # map from symbol name to set of tokens </s> add         self.first = {}  # map from symbol name to set of tokens", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             content = tuple(map(tuple, content))  # Protect against alterations\n <mask>             # Check sanity of alternatives\n <mask>             assert len(content), repr(content)  # Can't have zero alternatives\n <mask>             for alt in content:\n <mask>                 assert len(alt), repr(alt) # Can have empty alternatives\n <mask>         self.content = content\n <mask>         self.min = min\n <mask>         self.max = max\n <mask>         self.name = name\n <mask>  </s> remove     type = None     # Node type (token if < 256, symbol if >= 256) </s> add     type = None  # Node type (token if < 256, symbol if >= 256)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask>     def optimize(self):\n <mask>         \"\"\"Optimize certain stacked wildcard patterns.\"\"\"\n <mask>         subpattern = None\n <mask>         if (self.content is not None and\n <mask>             len(self.content) == 1 and len(self.content[0]) == 1):\n <mask>             subpattern = self.content[0][0]\n <mask>         if self.min == 1 and self.max == 1:\n <mask>             if self.content is None:\n <mask>                 return NodePattern(name=self.name)\n <mask>             if subpattern is not None and  self.name == subpattern.name:\n <mask>                 return subpattern.optimize()\n <mask>         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n <mask>             subpattern.min <= 1 and self.name == subpattern.name): </s> remove         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n            subpattern.min <= 1 and self.name == subpattern.name):\n            return WildcardPattern(subpattern.content,\n                                   self.min*subpattern.min,\n                                   self.max*subpattern.max,\n                                   subpattern.name) </s> add         if (\n            self.min <= 1\n            and isinstance(subpattern, WildcardPattern)\n            and subpattern.min <= 1\n            and self.name == subpattern.name\n        ):\n            return WildcardPattern(\n                subpattern.content,\n                self.min * subpattern.min,\n                self.max * subpattern.max,\n                subpattern.name,\n            )", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             if self.content is None:\n <mask>                 return NodePattern(name=self.name)\n <mask>             if subpattern is not None and  self.name == subpattern.name:\n <mask>                 return subpattern.optimize()\n <mask>         if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n <mask>             subpattern.min <= 1 and self.name == subpattern.name):\n <mask>             return WildcardPattern(subpattern.content,\n <mask>                                    self.min*subpattern.min,\n <mask>                                    self.max*subpattern.max,\n <mask>                                    subpattern.name)\n <mask>         return self\n <mask> \n <mask>     def match(self, node, results=None):\n <mask>         \"\"\"Does this pattern exactly match a node?\"\"\"\n <mask>         return self.match_seq([node], results) </s> remove             if subpattern is not None and  self.name == subpattern.name: </s> add             if subpattern is not None and self.name == subpattern.name: </s> remove         if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1): </s> remove             raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start)) </s> add             raise parse.ParseError(\"incomplete input\", type, value, (prefix, start)) </s> remove def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None): </s> add def load_grammar(gt=\"Grammar.txt\", gp=None, save=True, force=False, logger=None):", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield 0, {}\n <mask>         if count < self.max:\n <mask>             for alt in self.content:\n <mask>                 for c0, r0 in generate_matches(alt, nodes):\n <mask>                     for c1, r1 in self._recursive_matches(nodes[c0:], count+1):\n <mask>                         r = {}\n <mask>                         r.update(r0)\n <mask>                         r.update(r1)\n <mask>                         yield c0 + c1, r\n <mask>  </s> remove         self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels </s> add         self.keywords = {}  # map from keyword strings to arc labels\n        self.tokens = {}  # map from numeric token values to arc labels </s> remove         self.first[name] = None # dummy to detect left recursion </s> add         self.first[name] = None  # dummy to detect left recursion </s> remove             lineno, line = lineno+1, next(f) </s> add             lineno, line = lineno + 1, next(f)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "blib2to3/pytree.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         result = runner.invoke(black.main, args)\n <mask>         self.assertEqual(result.exit_code, exit_code, msg=runner.stderr_bytes.decode())\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_empty(self) -> None:\n <mask>         source = expected = \"\"\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual) </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE)) </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\")) </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         finally:\n <mask>             os.unlink(tmp_file)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_self(self) -> None:\n <mask>         source, expected = read_data(\"test_black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual) </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE)) </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path)) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\")) </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\")) </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\")", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace replace replace replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_self(self) -> None:\n <mask>         source, expected = read_data(\"test_black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_FILE))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path)) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\")) </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         self.assertFalse(ff(THIS_FILE))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\"))\n <mask> \n <mask>     def test_piping(self) -> None:\n <mask>         source, expected = read_data(\"../black\", data=False)\n <mask>         result = BlackRunner().invoke(\n <mask>             black.main, </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE)) </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_setup(self) -> None:\n        source, expected = read_data(\"../setup\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\")) </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path)) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr)", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = diff_header.sub(\"[Deterministic header]\", result.output)\n <mask>         actual = actual.rstrip() + \"\\n\"  # the diff output has a trailing space\n <mask>         self.assertEqual(expected, actual)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_setup(self) -> None:\n <mask>         source, expected = read_data(\"../setup\", data=False)\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, black.FileMode())\n <mask>         self.assertFalse(ff(THIS_DIR / \"..\" / \"setup.py\"))\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_function(self) -> None:\n <mask>         source, expected = read_data(\"function\")\n <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual) </s> remove         source, expected = read_data(\"test_black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_FILE)) </s> add         self.checkSourceFile(\"tests/test_black.py\") </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def checkSourceFile(self, name: str) -> None:\n        path = THIS_DIR.parent / name\n        source, expected = read_data(str(path), data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(path)) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> remove     @patch(\"black.dump_to_file\", dump_to_stderr) </s> remove         source, expected = read_data(\"../black\", data=False)\n        actual = fs(source)\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, black.FileMode())\n        self.assertFalse(ff(THIS_DIR / \"..\" / \"black.py\")) </s> add         self.checkSourceFile(\"black.py\")\n\n    def test_pygram(self) -> None:\n        self.checkSourceFile(\"blib2to3/pygram.py\")\n\n    def test_pytree(self) -> None:\n        self.checkSourceFile(\"blib2to3/pytree.py\")\n\n    def test_conv(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/conv.py\")\n\n    def test_driver(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/driver.py\")\n\n    def test_grammar(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/grammar.py\")\n\n    def test_literals(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/literals.py\")\n\n    def test_parse(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/parse.py\")\n\n    def test_pgen(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/pgen.py\")\n\n    def test_tokenize(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/tokenize.py\")\n\n    def test_token(self) -> None:\n        self.checkSourceFile(\"blib2to3/pgen2/token.py\")\n\n    def test_setup(self) -> None:\n        self.checkSourceFile(\"setup.py\") </s> remove             #print name, oldlen, newlen", "html_url": "https://github.com/psf/black/commit/0ff718e1e2b434477bca134e6c8aa0f67c898cbc", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"platformdirs>=2\",\n <mask>         \"tomli>=0.2.6,<2.0.0\",\n <mask>         \"typed-ast>=1.4.2; python_version < '3.8'\",\n <mask>         \"regex>=2020.1.8\",\n <mask>         \"pathspec>=0.8.1, <1\",\n <mask>         \"dataclasses>=0.6; python_version < '3.7'\",\n <mask>         \"typing_extensions>=3.10.0.0; python_version < '3.10'\",\n <mask>         \"mypy_extensions>=0.4.3\",\n <mask>     ],\n <mask>     extras_require={ </s> remove     return PathSpec.from_lines(\"gitwildmatch\", lines) </s> add     try:\n        return PathSpec.from_lines(\"gitwildmatch\", lines)\n    except GitWildMatchPatternError as e:\n        err(f\"Could not parse {gitignore}: {e}\")\n        raise </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import io\n <mask> from multiprocessing import Manager, freeze_support\n <mask> import os\n <mask> from pathlib import Path\n <mask> import regex as re\n <mask> import signal\n <mask> import sys\n <mask> import tokenize\n <mask> import traceback\n <mask> from typing import ( </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> from pathspec import PathSpec\n <mask> import tomli\n <mask> \n <mask> from black.output import err\n <mask> from black.report import Report\n <mask> from black.handle_ipynb_magics import jupyter_dependencies_are_installed\n <mask>  </s> remove     return PathSpec.from_lines(\"gitwildmatch\", lines) </s> add     try:\n        return PathSpec.from_lines(\"gitwildmatch\", lines)\n    except GitWildMatchPatternError as e:\n        err(f\"Could not parse {gitignore}: {e}\")\n        raise </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     lines: List[str] = []\n <mask>     if gitignore.is_file():\n <mask>         with gitignore.open(encoding=\"utf-8\") as gf:\n <mask>             lines = gf.readlines()\n <mask>     return PathSpec.from_lines(\"gitwildmatch\", lines)\n <mask> \n <mask> \n <mask> def normalize_path_maybe_ignore(\n <mask>     path: Path, root: Path, report: Report\n <mask> ) -> Optional[str]: </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError </s> add from pathspec.patterns.gitwildmatch import GitWildMatchPatternError", "html_url": "https://github.com/psf/black/commit/104aec555fae0883ef5b53709569bd9c4d420bc5", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> .. autofunction:: black.cache.filter_cached\n <mask> \n <mask> .. autofunction:: black.cache.get_cache_file\n <mask> \n <mask> .. autofunction:: black.cache.get_cache_info\n <mask> \n <mask> .. autofunction:: black.cache.read_cache </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove from black.cache import get_cache_file </s> add from black.cache import get_cache_dir, get_cache_file </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__)) </s> add def get_cache_dir() -> Path:\n    \"\"\"Get the cache directory used by black.\n\n    Users can customize this directory on all systems using `BLACK_CACHE_DIR`\n    environment variable. By default, the cache directory is the user cache directory\n    under the black application.\n\n    This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid\n    repeated calls.\n    \"\"\"\n    # NOTE: Function mostly exists as a clean way to test getting the cache directory.\n    default_cache_dir = user_cache_dir(\"black\", version=__version__)\n    cache_dir = Path(os.environ.get(\"BLACK_CACHE_DIR\", default_cache_dir))\n    return cache_dir\n\n\nCACHE_DIR = get_cache_dir()", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "docs/contributing/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> CacheInfo = Tuple[Timestamp, FileSize]\n <mask> Cache = Dict[str, CacheInfo]\n <mask> \n <mask> \n <mask> CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n <mask> \n <mask> \n <mask> def read_cache(mode: Mode) -> Cache:\n <mask>     \"\"\"Read the cache if it exists and is well formed.\n <mask> \n </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove from black.cache import get_cache_file\n </s> add from black.cache import get_cache_dir, get_cache_file </s> add .. autofunction:: black.cache.get_cache_dir\n", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "src/black/cache.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import black\n <mask> import black.files\n <mask> from black import Feature, TargetVersion\n <mask> from black import re_compile_maybe_verbose as compile_pattern\n <mask> from black.cache import get_cache_file\n <mask> from black.debug import DebugVisitor\n <mask> from black.output import color_diff, diff\n <mask> from black.report import Report\n <mask> \n <mask> # Import other test classes\n </s> Allow setting custom cache directory on all platforms (#2739)\n\nFixes #2506\r\n\r\n``XDG_CACHE_HOME`` does not work on Windows. To allow for users to set a custom cache directory on all systems I added a new environment variable ``BLACK_CACHE_DIR`` to set the cache directory. The default remains the same so users will only notice a change if that environment variable is set.\r\n\r\nThe specific use case I have for this is I need to run black on in different processes at the same time. There is a race condition with the cache pickle file that made this rather difficult. A custom cache directory will remove the race condition.\r\n\r\nI created ``get_cache_dir`` function in order to test the logic. This is only used to set the ``CACHE_DIR`` constant. </s> remove CACHE_DIR = Path(user_cache_dir(\"black\", version=__version__))\n </s> add def get_cache_dir() -> Path:\n    \"\"\"Get the cache directory used by black.\n\n    Users can customize this directory on all systems using `BLACK_CACHE_DIR`\n    environment variable. By default, the cache directory is the user cache directory\n    under the black application.\n\n    This result is immediately set to a constant `black.cache.CACHE_DIR` as to avoid\n    repeated calls.\n    \"\"\"\n    # NOTE: Function mostly exists as a clean way to test getting the cache directory.\n    default_cache_dir = user_cache_dir(\"black\", version=__version__)\n    cache_dir = Path(os.environ.get(\"BLACK_CACHE_DIR\", default_cache_dir))\n    return cache_dir\n\n\nCACHE_DIR = get_cache_dir() </s> add .. autofunction:: black.cache.get_cache_dir\n", "html_url": "https://github.com/psf/black/commit/10677baa40f818ca06c6a9d5efa0dca052865bfb", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     'src',\n <mask>     nargs=-1,\n <mask>     type=click.Path(exists=True, file_okay=True, dir_okay=True, readable=True),\n <mask> )\n <mask> @click.pass_context\n <mask> def main(\n <mask>     ctx: click.Context, line_length: int, check: bool, fast: bool, src: List[str]\n <mask> ) -> None: </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>             sources.extend(gen_python_files_in_dir(p))\n <mask>         elif p.is_file():\n <mask>             # if a file was explicitly given, we don't care about its extension\n <mask>             sources.append(p)\n <mask>         else:\n <mask>             err(f'invalid path: {s}')\n <mask>     if len(sources) == 0:\n <mask>         ctx.exit(0) </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove         raise NothingChanged(src) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove         raise NothingChanged(src) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     elif len(sources) == 1:\n <mask>         p = sources[0]\n <mask>         report = Report()\n <mask>         try:\n <mask>             changed = format_file_in_place(\n <mask>                 p, line_length=line_length, fast=fast, write_back=not check\n <mask>             )\n <mask>             report.done(p, changed)\n <mask>         except Exception as exc:\n <mask>             report.failed(p, str(exc))\n <mask>         ctx.exit(report.return_code)\n <mask>     else: </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> ) -> bool:\n <mask>     \"\"\"Format the file and rewrite if changed. Return True if changed.\"\"\"\n <mask>     try:\n <mask>         contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast\n <mask>         )\n <mask>     except NothingChanged: </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         with open(src, \"w\", encoding=encoding) as f: </s> add         with open(src, \"w\", encoding=src_buffer.encoding) as f: </s> remove         raise NothingChanged(src)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>     \"\"\"Format the file and rewrite if changed. Return True if changed.\"\"\"\n <mask>     try:\n <mask>         contents, encoding = format_file(src, line_length=line_length, fast=fast)\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back:\n <mask>         with open(src, \"w\", encoding=encoding) as f:\n <mask>             f.write(contents)\n <mask>     return True\n <mask> \n <mask>  </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove     return dst_contents, src_buffer.encoding </s> remove         raise NothingChanged(src)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace replace replace keep replace replace keep keep keep", "code_tokens": " <mask>     return True\n <mask> \n <mask> \n <mask> def format_file(\n <mask>     src: Path, line_length: int, fast: bool\n <mask> ) -> Tuple[FileContent, Encoding]:\n <mask>     \"\"\"Reformats a file and returns its contents and encoding.\"\"\"\n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     if src_contents.strip() == '':\n <mask>         raise NothingChanged(src)\n <mask>  </s> remove         raise NothingChanged(src) </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove     return dst_contents, src_buffer.encoding </s> add     return dst_contents </s> remove         raise NothingChanged(src)", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep keep keep keep replace keep keep", "code_tokens": " <mask>         src_contents = src_buffer.read()\n <mask>     if src_contents.strip() == '':\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged(src)\n <mask> \n <mask>     if not fast: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     return dst_contents, src_buffer.encoding </s> add     return dst_contents </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(src_contents, dst_contents, line_length=line_length)\n <mask>     return dst_contents, src_buffer.encoding\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, line_length: int) -> FileContent:\n <mask>     \"\"\"Reformats a string and returns new contents.\"\"\"\n <mask>     src_node = lib2to3_parse(src_contents) </s> remove         raise NothingChanged(src) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         raise NothingChanged(src) </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> from functools import partial\n <mask> from pathlib import Path\n <mask> import sys\n <mask> from typing import Any, List, Tuple\n <mask> import unittest </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent:", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> #!/usr/bin/env python3\n <mask> from functools import partial\n <mask> from io import StringIO\n <mask> from pathlib import Path\n <mask> from typing import Any, List, Tuple\n <mask> import unittest\n <mask> from unittest.mock import patch\n <mask> \n <mask> from click import unstyle\n <mask>  </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> add from io import StringIO </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove def format_file(\n    src: Path, line_length: int, fast: bool\n) -> Tuple[FileContent, Encoding]: </s> add def format_stdin_to_stdout(line_length: int, fast: bool) -> bool:\n    \"\"\"Format file on stdin and pipe output to stdout. Return True if changed.\"\"\"\n    contents = sys.stdin.read()\n    try:\n        contents = format_file_contents(contents, line_length=line_length, fast=fast)\n        return True\n\n    except NothingChanged:\n        return False\n\n    finally:\n        sys.stdout.write(contents)\n\n\ndef format_file_contents(\n    src_contents: str, line_length: int, fast: bool\n) -> FileContent: </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> import black\n <mask> \n <mask> ll = 88\n <mask> ff = partial(black.format_file, line_length=ll, fast=True)\n <mask> fs = partial(black.format_str, line_length=ll)\n <mask> THIS_FILE = Path(__file__)\n <mask> THIS_DIR = THIS_FILE.parent\n <mask> \n <mask>  </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove             changed = format_file_in_place(\n                p, line_length=line_length, fast=fast, write_back=not check\n            ) </s> add             if not p.is_file() and str(p) == '-':\n                changed = format_stdin_to_stdout(line_length=line_length, fast=fast)\n            else:\n                changed = format_file_in_place(\n                    p, line_length=line_length, fast=fast, write_back=not check\n                ) </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_black(self) -> None:\n <mask>         source, expected = read_data('../black')\n <mask>         actual = fs(source) </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove ff = partial(black.format_file, line_length=ll, fast=True) </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        )", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_setup(self) -> None:\n <mask>         source, expected = read_data('../setup')\n <mask>         actual = fs(source) </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'setup.py')) </s> remove ff = partial(black.format_file, line_length=ll, fast=True) </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         actual = fs(source)\n <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_equivalent(source, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask>         with self.assertRaises(black.NothingChanged):\n <mask>             ff(THIS_FILE)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_function(self) -> None:\n <mask>         source, expected = read_data('function')\n <mask>         actual = fs(source) </s> Add piping from stdin to stdout with a - (#25)\n\nBeing able to format code by piping it through the formatter makes it much easier to integrate with tools like google/vim-codefmt or Chiel92/vim-autoformat. </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_FILE)) </s> remove         with self.assertRaises(black.NothingChanged):\n            ff(THIS_FILE) </s> add         self.assertFalse(ff(THIS_DIR / '..' / 'black.py'))\n\n    def test_piping(self) -> None:\n        source, expected = read_data('../black')\n        hold_stdin, hold_stdout = sys.stdin, sys.stdout\n        try:\n            sys.stdin, sys.stdout = StringIO(source), StringIO()\n            sys.stdin.name = '<stdin>'\n            black.format_stdin_to_stdout(line_length=ll, fast=True)\n            sys.stdout.seek(0)\n            actual = sys.stdout.read()\n        finally:\n            sys.stdin, sys.stdout = hold_stdin, hold_stdout\n        self.assertFormatEqual(expected, actual)\n        black.assert_equivalent(source, actual)\n        black.assert_stable(source, actual, line_length=ll) </s> remove ff = partial(black.format_file, line_length=ll, fast=True) </s> add ff = partial(black.format_file_in_place, line_length=ll, fast=True) </s> add     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read() </s> remove         contents, encoding = format_file(src, line_length=line_length, fast=fast) </s> add         contents = format_file_contents(\n            src_contents, line_length=line_length, fast=fast\n        ) </s> remove     with tokenize.open(src) as src_buffer:\n        src_contents = src_buffer.read()", "html_url": "https://github.com/psf/black/commit/10d8976a79f5a7f7e5e36369a81d9e5c983332d1", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> .. autofunction:: black.strings.normalize_string_quotes\n <mask> \n <mask> .. autofunction:: black.linegen.normalize_invisible_parens\n <mask> \n <mask> .. autofunction:: black.patch_click\n <mask> \n <mask> .. autofunction:: black.nodes.preceding_leaf\n <mask> \n <mask> .. autofunction:: black.re_compile_maybe_verbose\n <mask> \n <mask> .. autofunction:: black.linegen.should_split_line </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\") </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "docs/contributing/reference/reference_functions.rst"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     yield\n <mask> \n <mask> \n <mask> def patch_click() -> None:\n <mask>     \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n <mask> \n <mask>     On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n <mask>     default which restricts paths that it can access during the lifetime of the\n <mask>     application.  Click refuses to work in this scenario by raising a RuntimeError.\n <mask> \n <mask>     In case of Black the likelihood that non-ASCII characters are going to be used in\n <mask>     file paths is minimal since it's Python source code.  Moreover, this crash was\n <mask>     spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n <mask>     \"\"\"\n <mask>     modules: List[Any] = []\n <mask>     try:\n <mask>         from click import core\n <mask>     except ImportError:\n <mask>         pass\n <mask>     else:\n <mask>         modules.append(core)\n <mask>     try:\n <mask>         # Removed in Click 8.1.0 and newer; we keep this around for users who have\n <mask>         # older versions installed.\n <mask>         from click import _unicodefun  # type: ignore\n <mask>     except ImportError:\n <mask>         pass\n <mask>     else:\n <mask>         modules.append(_unicodefun)\n <mask> \n <mask>     for module in modules:\n <mask>         if hasattr(module, \"_verify_python3_env\"):\n <mask>             module._verify_python3_env = lambda: None\n <mask>         if hasattr(module, \"_verify_python_env\"):\n <mask>             module._verify_python_env = lambda: None\n <mask> \n <mask> \n <mask> def patched_main() -> None:\n <mask>     # PyInstaller patches multiprocessing to need freeze_support() even in non-Windows\n <mask>     # environments so just assume we always need to call it if frozen.\n <mask>     if getattr(sys, \"frozen\", False):\n <mask>         from multiprocessing import freeze_support </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\") </s> remove .. autofunction:: black.patch_click", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         from multiprocessing import freeze_support\n <mask> \n <mask>         freeze_support()\n <mask> \n <mask>     patch_click()\n <mask>     main()\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     patched_main() </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     black.patch_click() </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\") </s> remove .. autofunction:: black.patch_click", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> def patched_main() -> None:\n <mask>     maybe_install_uvloop()\n <mask>     freeze_support()\n <mask>     black.patch_click()\n <mask>     main()\n <mask> \n <mask> \n <mask> if __name__ == \"__main__\":\n <mask>     patched_main() </s> Remove click patch (#3768)\n\nApparently this was only needed on Python 3.6. We've now dropped support\r\nfor 3.6 and 3.7. It's also not needed on new enough click. </s> remove     def test_shhh_click(self) -> None:\n        try:\n            from click import _unicodefun  # type: ignore\n        except ImportError:\n            self.skipTest(\"Incompatible Click version\")\n\n        if not hasattr(_unicodefun, \"_verify_python_env\"):\n            self.skipTest(\"Incompatible Click version\")\n\n        # First, let's see if Click is crashing with a preferred ASCII charset.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            with self.assertRaises(RuntimeError):\n                _unicodefun._verify_python_env()\n        # Now, let's silence Click...\n        black.patch_click()\n        # ...and confirm it's silent.\n        with patch(\"locale.getpreferredencoding\") as gpe:\n            gpe.return_value = \"ASCII\"\n            try:\n                _unicodefun._verify_python_env()\n            except RuntimeError as re:\n                self.fail(f\"`patch_click()` failed, exception still raised: {re}\") </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None </s> remove .. autofunction:: black.patch_click", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "src/blackd/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def test_assert_equivalent_different_asts(self) -> None:\n <mask>         with self.assertRaises(AssertionError):\n <mask>             black.assert_equivalent(\"{}\", \"None\")\n <mask> \n <mask>     def test_shhh_click(self) -> None:\n <mask>         try:\n <mask>             from click import _unicodefun  # type: ignore\n <mask>         except ImportError:\n <mask>             self.skipTest(\"Incompatible Click version\")\n <mask> \n <mask>         if not hasattr(_unicodefun, \"_verify_python_env\"):\n <mask>             self.skipTest(\"Incompatible Click version\")\n <mask> \n <mask>         # First, let's see if Click is crashing with a preferred ASCII charset.\n <mask>         with patch(\"locale.getpreferredencoding\") as gpe:\n <mask>             gpe.return_value = \"ASCII\"\n <mask>             with self.assertRaises(RuntimeError):\n <mask>                 _unicodefun._verify_python_env()\n <mask>         # Now, let's silence Click...\n <mask>         black.patch_click()\n <mask>         # ...and confirm it's silent.\n <mask>         with patch(\"locale.getpreferredencoding\") as gpe:\n <mask>             gpe.return_value = \"ASCII\"\n <mask>             try:\n <mask>                 _unicodefun._verify_python_env()\n <mask>             except RuntimeError as re:\n <mask>                 self.fail(f\"`patch_click()` failed, exception still raised: {re}\")\n <mask> \n <mask>     def test_root_logger_not_used_directly(self) -> None:\n <mask>         def fail(*args: Any, **kwargs: Any) -> None:\n <mask>             self.fail(\"Record created with root logger\")\n <mask> \n <mask>         with patch.multiple( </s> remove def patch_click() -> None:\n    \"\"\"Make Click not crash on Python 3.6 with LANG=C.\n\n    On certain misconfigured environments, Python 3 selects the ASCII encoding as the\n    default which restricts paths that it can access during the lifetime of the\n    application.  Click refuses to work in this scenario by raising a RuntimeError.\n\n    In case of Black the likelihood that non-ASCII characters are going to be used in\n    file paths is minimal since it's Python source code.  Moreover, this crash was\n    spurious on Python 3.7 thanks to PEP 538 and PEP 540.\n    \"\"\"\n    modules: List[Any] = []\n    try:\n        from click import core\n    except ImportError:\n        pass\n    else:\n        modules.append(core)\n    try:\n        # Removed in Click 8.1.0 and newer; we keep this around for users who have\n        # older versions installed.\n        from click import _unicodefun  # type: ignore\n    except ImportError:\n        pass\n    else:\n        modules.append(_unicodefun)\n\n    for module in modules:\n        if hasattr(module, \"_verify_python3_env\"):\n            module._verify_python3_env = lambda: None\n        if hasattr(module, \"_verify_python_env\"):\n            module._verify_python_env = lambda: None </s> remove .. autofunction:: black.patch_click", "html_url": "https://github.com/psf/black/commit/114e8357e65384e17baaa3c31aa528371e15679b", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # Specify the target platform details in config, so your developers are\n <mask> # free to run mypy on Windows, Linux, or macOS and get consistent\n <mask> # results.\n <mask> python_version=3.6\n <mask> platform=linux\n <mask> \n <mask> mypy_path=src\n <mask> \n <mask> show_column_numbers=True\n <mask>  </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)): </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "mypy.ini"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> warn_unused_ignores=True\n <mask> disallow_any_generics=True\n <mask> \n <mask> # The following are off by default.  Flip them on if you feel\n <mask> # adventurous.\n <mask> disallow_untyped_defs=True\n <mask> check_untyped_defs=True\n <mask>  </s> add [mypy-black]\n# The following is because of `patch_click()`. Remove when\n# we drop Python 3.6 support.\nwarn_unused_ignores=False", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "mypy.ini"}
{"docstring_tokens": "keep keep keep add", "code_tokens": " <mask>   \"no_python2: run when `python2` extra NOT installed\",\n <mask>   \"no_blackd: run when `d` extra NOT installed\",\n <mask>   \"no_jupyter: run when `jupyter` extra NOT installed\",\n <mask> ] </s> Implementing mypyc support pt. 2  (#2431) </s> remove platform=linux </s> add </s> remove class BracketMatchError(KeyError): </s> add class BracketMatchError(Exception): </s> add [mypy-black]\n# The following is because of `patch_click()`. Remove when\n# we drop Python 3.6 support.\nwarn_unused_ignores=False </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "pyproject.toml"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> import os\n <mask> \n <mask> assert sys.version_info >= (3, 6, 2), \"black requires Python 3.6.2+\"\n <mask> from pathlib import Path  # noqa E402\n <mask> \n <mask> CURRENT_DIR = Path(__file__).parent\n <mask> sys.path.insert(0, str(CURRENT_DIR))  # for setuptools.build_meta\n <mask>  </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse: </s> add if sys.version_info >= (3, 8): </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> USE_MYPYC = False\n <mask> # To compile with mypyc, a mypyc checkout must be present on the PYTHONPATH\n <mask> if len(sys.argv) > 1 and sys.argv[1] == \"--use-mypyc\":\n <mask>     sys.argv.pop(1)\n <mask>     USE_MYPYC = True\n <mask> if os.getenv(\"BLACK_USE_MYPYC\", None) == \"1\": </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\", </s> add         # HACK: nested functions (like _rhs) compiled by mypyc don't retain their\n        # __name__ attribute which is needed in `run_transformer` further down.\n        # Unfortunately a nested class breaks mypyc too. So a class must be created\n        # via type ... https://github.com/mypyc/mypyc/issues/884\n        rhs = type(\"rhs\", (), {\"__call__\": _rhs})()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace replace replace keep keep replace replace keep keep keep keep", "code_tokens": " <mask> \n <mask> if USE_MYPYC:\n <mask>     mypyc_targets = [\n <mask>         \"src/black/__init__.py\",\n <mask>         \"src/blib2to3/pytree.py\",\n <mask>         \"src/blib2to3/pygram.py\",\n <mask>         \"src/blib2to3/pgen2/parse.py\",\n <mask>         \"src/blib2to3/pgen2/grammar.py\",\n <mask>         \"src/blib2to3/pgen2/token.py\",\n <mask>         \"src/blib2to3/pgen2/driver.py\",\n <mask>         \"src/blib2to3/pgen2/pgen.py\",\n <mask>     ]\n <mask> \n <mask>     from mypyc.build import mypycify\n <mask> \n <mask>     opt_level = os.getenv(\"MYPYC_OPT_LEVEL\", \"3\")\n <mask>     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n <mask> else:\n <mask>     ext_modules = [] </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level) </s> add     ext_modules = mypycify(mypyc_targets, opt_level=opt_level, verbose=True) </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value) </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     from mypyc.build import mypycify\n <mask> \n <mask>     opt_level = os.getenv(\"MYPYC_OPT_LEVEL\", \"3\")\n <mask>     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)\n <mask> else:\n <mask>     ext_modules = []\n <mask> \n <mask> setup(\n <mask>     name=\"black\", </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\", </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Tuple,\n <mask>     Union,\n <mask> )\n <mask> \n <mask> from dataclasses import replace\n <mask> import click\n <mask> \n <mask> from black.const import DEFAULT_LINE_LENGTH, DEFAULT_INCLUDES, DEFAULT_EXCLUDES\n <mask> from black.const import STDIN_PLACEHOLDER\n <mask> from black.nodes import STARS, syms, is_simple_decorator_expression </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> from _black_version import version as __version__\n <mask> \n <mask> # types\n <mask> FileContent = str\n <mask> Encoding = str\n <mask> NewLine = str </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value) </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\")) </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     except re.error:\n <mask>         raise click.BadParameter(\"Not a valid regular expression\") from None\n <mask> \n <mask> \n <mask> @click.command(context_settings=dict(help_option_names=[\"-h\", \"--help\"]))\n <mask> @click.option(\"-c\", \"--code\", type=str, help=\"Format the code passed in as a string.\")\n <mask> @click.option(\n <mask>     \"-l\",\n <mask>     \"--line-length\",\n <mask>     type=int, </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"Also emit messages to stderr about files that were not changed or were ignored\"\n <mask>         \" due to exclusion patterns.\"\n <mask>     ),\n <mask> )\n <mask> @click.version_option(version=__version__)\n <mask> @click.argument(\n <mask>     \"src\",\n <mask>     nargs=-1,\n <mask>     type=click.Path(\n <mask>         exists=True, file_okay=True, dir_okay=True, readable=True, allow_dash=True </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage </s> add         pyproject_toml = tomli.loads(f.read())", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     skip_magic_trailing_comma: bool,\n <mask>     experimental_string_processing: bool,\n <mask>     quiet: bool,\n <mask>     verbose: bool,\n <mask>     required_version: str,\n <mask>     include: Pattern[str],\n <mask>     exclude: Optional[Pattern[str]],\n <mask>     extend_exclude: Optional[Pattern[str]],\n <mask>     force_exclude: Optional[Pattern[str]],\n <mask>     stdin_filename: Optional[str], </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask>             traceback.print_exc()\n <mask>         report.failed(src, str(exc))\n <mask> \n <mask> \n <mask> def reformat_many(\n <mask>     sources: Set[Path],\n <mask>     fast: bool,\n <mask>     write_back: WriteBack,\n <mask>     mode: Mode, </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove     cell_magic: Optional[CellMagic] = None </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/__init__.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> }\n <mask> DOT_PRIORITY: Final = 1\n <mask> \n <mask> \n <mask> class BracketMatchError(KeyError):\n <mask>     \"\"\"Raised when an opening bracket is unable to be matched to a closing bracket.\"\"\"\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class BracketTracker: </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> add FMT_OFF: Final = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\nFMT_SKIP: Final = {\"# fmt: skip\", \"# fmt:skip\"}\nFMT_PASS: Final = {*FMT_OFF, *FMT_SKIP}\nFMT_ON: Final = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"} </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/brackets.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> from functools import lru_cache\n <mask> import regex as re\n <mask> from typing import Iterator, List, Optional, Union\n <mask> \n <mask> from blib2to3.pytree import Node, Leaf\n <mask> from blib2to3.pgen2 import token\n <mask> \n <mask> from black.nodes import first_leaf_column, preceding_leaf, container_of </s> remove from blib2to3 import pygram, pytree </s> add from blib2to3 import pygram", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/comments.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> # types\n <mask> LN = Union[Leaf, Node]\n <mask> \n <mask> \n <mask> FMT_OFF = {\"# fmt: off\", \"# fmt:off\", \"# yapf: disable\"}\n <mask> FMT_SKIP = {\"# fmt: skip\", \"# fmt:skip\"}\n <mask> FMT_PASS = {*FMT_OFF, *FMT_SKIP}\n <mask> FMT_ON = {\"# fmt: on\", \"# fmt:on\", \"# yapf: enable\"}\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class ProtoComment:\n <mask>     \"\"\"Describes a piece of syntax that is a comment. </s> add         p = parse.Parser(self.grammar) </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL: </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line) </s> add         match = FIRST_NON_WHITESPACE_RE.match(line)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/comments.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> \n <mask> from pathspec import PathSpec\n <mask> from pathspec.patterns.gitwildmatch import GitWildMatchPatternError\n <mask> import tomli\n <mask> \n <mask> from black.output import err\n <mask> from black.report import Report </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> remove from dataclasses import replace </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         err(f\"Ignoring user configuration directory due to {e!r}\")\n <mask>         return None\n <mask> \n <mask> \n <mask> def parse_pyproject_toml(path_config: str) -> Dict[str, Any]:\n <mask>     \"\"\"Parse a pyproject toml file, pulling out relevant parts for Black\n <mask> \n <mask>     If parsing fails, will raise a tomli.TOMLDecodeError </s> remove         pyproject_toml = tomli.load(f)  # type: ignore  # due to deprecated API usage </s> add         pyproject_toml = tomli.loads(f.read())", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/files.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             return f\"%%{self.name} {self.params}\"\n <mask>         return f\"%%{self.name}\"\n <mask> \n <mask> \n <mask> @dataclasses.dataclass\n <mask> class CellMagicFinder(ast.NodeVisitor):\n <mask>     \"\"\"Find cell magics.\n <mask> \n <mask>     Note that the source of the abstract syntax tree\n <mask>     will already have been processed by IPython's </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove     cell_magic: Optional[CellMagic] = None </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     and we look for instances of the latter.\n <mask>     \"\"\"\n <mask> \n <mask>     cell_magic: Optional[CellMagic] = None\n <mask> \n <mask>     def visit_Expr(self, node: ast.Expr) -> None:\n <mask>         \"\"\"Find cell magic, extract header and body.\"\"\"\n <mask>         if (\n <mask>             isinstance(node.value, ast.Call) </s> remove     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n        default_factory=lambda: collections.defaultdict(list)\n    ) </s> add     def __init__(self) -> None:\n        self.magics: Dict[int, List[OffsetAndMagic]] = collections.defaultdict(list) </s> remove     stashed = None </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> add # ast.NodeVisitor + dataclass = breakage under mypyc.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     col_offset: int\n <mask>     magic: str\n <mask> \n <mask> \n <mask> @dataclasses.dataclass\n <mask> class MagicFinder(ast.NodeVisitor):\n <mask>     \"\"\"Visit cell to look for get_ipython calls.\n <mask> \n <mask>     Note that the source of the abstract syntax tree\n <mask>     will already have been processed by IPython's </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> add # Unreachable blocks have been an issue when compiling mypyc, let's try\n# to avoid 'em in the first place.\nwarn_unreachable=True </s> remove     cell_magic: Optional[CellMagic] = None </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> add         **post-note: the convert argument is ignored since for Black's\n        usage, convert will always be blib2to3.pytree.convert. Allowing\n        this to be dynamic hurts mypyc's ability to use early binding.\n        These docs are left for historical and informational value.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     and we look for instances of the latter (and likewise for other\n <mask>     types of magics).\n <mask>     \"\"\"\n <mask> \n <mask>     magics: Dict[int, List[OffsetAndMagic]] = dataclasses.field(\n <mask>         default_factory=lambda: collections.defaultdict(list)\n <mask>     )\n <mask> \n <mask>     def visit_Assign(self, node: ast.Assign) -> None:\n <mask>         \"\"\"Look for system assign magics.\n <mask> \n <mask>         For example, </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line) </s> add         match = FIRST_NON_WHITESPACE_RE.match(line) </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)): </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/handle_ipynb_magics.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> from functools import partial, wraps\n <mask> import sys\n <mask> from typing import Collection, Iterator, List, Optional, Set, Union\n <mask> \n <mask> from dataclasses import dataclass, field\n <mask> \n <mask> from black.nodes import WHITESPACE, RARROW, STATEMENT, STANDALONE_COMMENT\n <mask> from black.nodes import ASSIGNMENTS, OPENING_BRACKETS, CLOSING_BRACKETS\n <mask> from black.nodes import Visitor, syms, first_child_is_arith, ensure_visible\n <mask> from black.nodes import is_docstring, is_empty_tuple, is_one_tuple, is_one_tuple_between\n <mask> from black.nodes import is_walrus_assignment, is_yield, is_vararg, is_multiline_string </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> class CannotSplit(CannotTransform):\n <mask>     \"\"\"A readable split that fits the allotted line length is impossible.\"\"\"\n <mask> \n <mask> \n <mask> @dataclass\n <mask> class LineGenerator(Visitor[Line]):\n <mask>     \"\"\"Generates reformatted Line objects.  Empty lines are not emitted.\n <mask> \n <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree. </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask> \n <mask>     mode: Mode\n <mask>     remove_u_prefix: bool = False\n <mask>     current_line: Line = field(init=False)\n <mask> \n <mask>     def line(self, indent: int = 0) -> Iterator[Line]:\n <mask>         \"\"\"Generate a line.\n <mask> \n <mask>         If the line is empty, only emit if it makes sense. </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> add # Unsurprisingly, subclassing ast.NodeVisitor means we can't use dataclasses here\n# as mypyc will generate broken code. </s> add # ast.NodeVisitor + dataclass = breakage under mypyc.", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     elif line.is_def:\n <mask>         transformers = [left_hand_split]\n <mask>     else:\n <mask> \n <mask>         def rhs(line: Line, features: Collection[Feature]) -> Iterator[Line]:\n <mask>             \"\"\"Wraps calls to `right_hand_split`.\n <mask> \n <mask>             The calls increasingly `omit` right-hand trailers (bracket pairs with\n <mask>             content), meaning the trailers get glued together to split on another\n <mask>             bracket pair instead. </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)): </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>                 line, line_length=mode.line_length, features=features\n <mask>             )\n <mask> \n <mask>         if mode.experimental_string_processing:\n <mask>             if line.inside_brackets:\n <mask>                 transformers = [\n <mask>                     string_merge,\n <mask>                     string_paren_strip, </s> remove                     (lnum, pos + len(comment_token)), </s> remove         def rhs(line: Line, features: Collection[Feature]) -> Iterator[Line]: </s> add         def _rhs(\n            self: object, line: Line, features: Collection[Feature]\n        ) -> Iterator[Line]:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> from dataclasses import dataclass, field\n <mask> from enum import Enum\n <mask> from typing import Dict, Set\n <mask> \n <mask> from black.const import DEFAULT_LINE_LENGTH\n <mask> \n <mask> \n <mask> class TargetVersion(Enum): </s> remove from dataclasses import dataclass, field </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     def get_cache_key(self) -> str:\n <mask>         if self.target_versions:\n <mask>             version_str = \",\".join(\n <mask>                 str(version.value)\n <mask>                 for version in sorted(self.target_versions, key=lambda v: v.value)\n <mask>             )\n <mask>         else:\n <mask>             version_str = \"-\"\n <mask>         parts = [\n <mask>             version_str, </s> remove         \"src/black/__init__.py\",\n        \"src/blib2to3/pytree.py\",\n        \"src/blib2to3/pygram.py\",\n        \"src/blib2to3/pgen2/parse.py\",\n        \"src/blib2to3/pgen2/grammar.py\",\n        \"src/blib2to3/pgen2/token.py\",\n        \"src/blib2to3/pgen2/driver.py\",\n        \"src/blib2to3/pgen2/pgen.py\",", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     TypeVar,\n <mask>     Union,\n <mask> )\n <mask> \n <mask> if sys.version_info < (3, 8):\n <mask>     from typing_extensions import Final\n <mask> else:\n <mask>     from typing import Final\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf, type_repr\n <mask> from blib2to3 import pygram </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from blib2to3 import pygram, pytree </s> add from blib2to3 import pygram </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> if sys.version_info >= (3, 8):\n <mask>     from typing import Final\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf, type_repr\n <mask> from blib2to3 import pygram\n <mask> from blib2to3.pgen2 import token </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse: </s> add if sys.version_info >= (3, 8): </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> remove from blib2to3 import pygram, pytree </s> add from blib2to3 import pygram </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> from black.strings import has_triple_quotes\n <mask> \n <mask> \n <mask> pygram.initialize(CACHE_DIR)\n <mask> syms = pygram.python_symbols\n <mask> \n <mask> \n <mask> # types\n <mask> T = TypeVar(\"T\")\n <mask> LN = Union[Leaf, Node] </s> remove     ext_modules = mypycify(mypyc_targets, opt_level=opt_level)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     \"**=\",\n <mask>     \"//=\",\n <mask> }\n <mask> \n <mask> IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\n <mask> BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\n <mask> OPENING_BRACKETS = set(BRACKET.keys())\n <mask> CLOSING_BRACKETS = set(BRACKET.values())\n <mask> BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\n <mask> ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}\n <mask> \n <mask> RARROW = 55\n <mask> \n <mask> \n <mask> class Visitor(Generic[T]): </s> remove triple_quoted = ( </s> add triple_quoted: Final = ( </s> remove single_quoted = ( </s> add single_quoted: Final = ( </s> remove class BracketMatchError(KeyError): </s> add class BracketMatchError(Exception):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask> RARROW = 55\n <mask> \n <mask> \n <mask> class Visitor(Generic[T]):\n <mask>     \"\"\"Basic lib2to3 visitor that yields things of type `T` on `visit()`.\"\"\"\n <mask> \n <mask>     def visit(self, node: LN) -> Iterator[T]:\n <mask>         \"\"\"Main method to visit `node` and its children.\n <mask>  </s> add ast3_AST: Final[Type[ast3.AST]] = ast3.AST\nast27_AST: Final[Type[ast27.AST]] = ast27.AST </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     `complex_subscript` signals whether the given leaf is part of a subscription\n <mask>     which has non-trivial arguments, like arithmetic expressions or function calls.\n <mask>     \"\"\"\n <mask>     NO = \"\"\n <mask>     SPACE = \" \"\n <mask>     DOUBLESPACE = \"  \"\n <mask>     t = leaf.type\n <mask>     p = leaf.parent\n <mask>     v = leaf.value\n <mask>     if t in ALWAYS_NO_SPACE:\n <mask>         return NO </s> remove                     column = column + 1 </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i: </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove                     assert t < 256", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def last_two_except(leaves: List[Leaf], omit: Collection[LeafID]) -> Tuple[Leaf, Leaf]:\n <mask>     \"\"\"Return (penultimate, last) leaves skipping brackets in `omit` and contents.\"\"\"\n <mask>     stop_after = None\n <mask>     last = None\n <mask>     for leaf in reversed(leaves):\n <mask>         if stop_after:\n <mask>             if leaf is stop_after:\n <mask>                 stop_after = None\n <mask>             continue </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/nodes.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def _err(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None:\n <mask>     if message is not None:\n <mask>         if \"fg\" not in styles:\n <mask>             styles[\"fg\"] = \"red\"\n <mask>         message = style(message, **styles) </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None: </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/output.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>     echo(message, nl=nl, err=True)\n <mask> \n <mask> \n <mask> def out(message: Optional[str] = None, nl: bool = True, **styles: Any) -> None:\n <mask>     _out(message, nl=nl, **styles)\n <mask> \n <mask>  </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/output.py"}
{"docstring_tokens": "keep replace keep keep keep replace keep keep keep", "code_tokens": " <mask> import sys\n <mask> from typing import Iterable, Iterator, List, Set, Union, Tuple\n <mask> \n <mask> # lib2to3 fork\n <mask> from blib2to3.pytree import Node, Leaf\n <mask> from blib2to3 import pygram, pytree\n <mask> from blib2to3.pgen2 import driver\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pgen2.parse import ParseError </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info >= (3, 8): </s> remove from blib2to3.pytree import NL, Context, RawNode, Leaf, Node </s> add from blib2to3.pytree import convert, NL, Context, RawNode, Leaf, Node", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> from black.mode import TargetVersion, Feature, supports_feature\n <mask> from black.nodes import syms\n <mask> \n <mask> _IS_PYPY = platform.python_implementation() == \"PyPy\"\n <mask> \n <mask> try:\n <mask>     from typed_ast import ast3, ast27 </s> remove from blib2to3 import pygram, pytree </s> add from dataclasses import replace\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     if not src_txt.endswith(\"\\n\"):\n <mask>         src_txt += \"\\n\"\n <mask> \n <mask>     for grammar in get_grammars(set(target_versions)):\n <mask>         drv = driver.Driver(grammar, pytree.convert)\n <mask>         try:\n <mask>             result = drv.parse_string(src_txt, True)\n <mask>             break\n <mask> \n <mask>         except ParseError as pe: </s> remove with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n    black_source_lines = _bf.readlines() </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise </s> remove                     next_token_type = grammar.opmap[cast(str, next_token_value)] </s> add                     next_token_type = grammar.opmap[next_token_value]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     raise SyntaxError(first_error)\n <mask> \n <mask> \n <mask> def stringify_ast(\n <mask>     node: Union[ast.AST, ast3.AST, ast27.AST], depth: int = 0\n <mask> ) -> Iterator[str]:\n <mask>     \"\"\"Simple visitor generating strings to compare ASTs by content.\"\"\"\n <mask> \n <mask>     node = fixup_ast_constants(node) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__() </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]: </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None: </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>                 elif isinstance(item, (ast.AST, ast3.AST, ast27.AST)):\n <mask>                     yield from stringify_ast(item, depth + 2)\n <mask> \n <mask>         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)):\n <mask>             yield from stringify_ast(value, depth + 2)\n <mask> \n <mask>         else:\n <mask>             # Constant strings may be indented across newlines, if they are\n <mask>             # docstrings; fold spaces after newlines when comparing. Similarly, </s> remove                         parenlev = parenlev - 1 </s> remove                         parenlev = parenlev + 1 </s> remove                     column = column + 1 </s> remove                     (lnum, pos + len(comment_token)),", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/parsing.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> import regex as re\n <mask> import sys\n <mask> from typing import List, Pattern\n <mask> \n <mask> if sys.version_info < (3, 8):\n <mask>     from typing_extensions import Final\n <mask> else: </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse: </s> add else:\n    from typing_extensions import Final\n\nfrom mypy_extensions import mypyc_attr </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> from functools import lru_cache\n <mask> from typing import List, Pattern\n <mask> \n <mask> \n <mask> \n <mask> STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\n <mask> STRING_PREFIX_RE: Final = re.compile(\n <mask>     r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters. </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> add from functools import lru_cache </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL) </s> add     match = STRING_PREFIX_RE.match(s)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> from typing import List, Pattern\n <mask> \n <mask> \n <mask> STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters.\n <mask> \n <mask> \n <mask> def sub_twice(regex: Pattern[str], replacement: str, original: str) -> str:\n <mask>     \"\"\"Replace `regex` with `replacement` twice on `original`.\n <mask>  </s> add from functools import lru_cache", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     lines = []\n <mask>     for line in s.splitlines():\n <mask>         # Find the index of the first non-whitespace character after a string of\n <mask>         # whitespace that includes at least one tab\n <mask>         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line)\n <mask>         if match:\n <mask>             first_non_whitespace_idx = match.start(1)\n <mask> \n <mask>             lines.append(\n <mask>                 line[:first_non_whitespace_idx].expandtabs() </s> remove         p = parse.Parser(self.grammar, self.convert) </s> add         p = parse.Parser(self.grammar) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i: </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL) </s> add     match = STRING_PREFIX_RE.match(s) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"Make all string prefixes lowercase.\n <mask> \n <mask>     If remove_u_prefix is given, also removes any u prefix from the string.\n <mask>     \"\"\"\n <mask>     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL)\n <mask>     assert match is not None, f\"failed to match string {s!r}\"\n <mask>     orig_prefix = match.group(1)\n <mask>     new_prefix = orig_prefix.replace(\"F\", \"f\").replace(\"B\", \"b\").replace(\"U\", \"u\")\n <mask>     if remove_u_prefix:\n <mask>         new_prefix = new_prefix.replace(\"u\", \"\") </s> remove STRING_PREFIX_CHARS = \"furbFURB\"  # All possible string prefix characters. </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> add if sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove     STRING_OPERATORS = [ </s> add     STRING_OPERATORS: Final = [", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def normalize_string_quotes(s: str) -> str:\n <mask>     \"\"\"Prefer double quotes but only if it doesn't cause more escaping.\n <mask> \n <mask>     Adds or removes backslashes as appropriate. Doesn't parse and fix\n <mask>     strings nested in f-strings. </s> add STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.\nSTRING_PREFIX_RE: Final = re.compile(\n    r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL\n)\nFIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*\\t+\\s*(\\S)\") </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/strings.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             AND\n <mask>         * The target string is not a multiline (i.e. triple-quote) string.\n <mask>     \"\"\"\n <mask> \n <mask>     STRING_OPERATORS = [\n <mask>         token.EQEQUAL,\n <mask>         token.GREATER,\n <mask>         token.GREATEREQUAL,\n <mask>         token.LESS,\n <mask>         token.LESSEQUAL, </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL) </s> add     match = STRING_PREFIX_RE.match(s)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         max_string_length = self.line_length - offset\n <mask>         return max_string_length\n <mask> \n <mask> \n <mask> class StringSplitter(CustomSplitMapMixin, BaseStringSplitter):\n <mask>     \"\"\"\n <mask>     StringTransformer that splits \"atom\" strings (i.e. strings which exist on\n <mask>     lines by themselves).\n <mask> \n <mask>     Requirements: </s> Implementing mypyc support pt. 2  (#2431) </s> remove class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringParenWrapper(BaseStringSplitter, CustomSplitMapMixin): </s> add # Re(gex) does actually cache patterns internally but this still improves\n# performance on a long list literal of strings by 5-9% since lru_cache's\n# caching overhead is much lower.\n@lru_cache(maxsize=64)\ndef _cached_compile(pattern: str) -> re.Pattern:\n    return re.compile(pattern) </s> remove @dataclass </s> add # This isn't a dataclass because @dataclass + Generic breaks mypyc.\n# See also https://github.com/mypyc/mypyc/issues/827. </s> add # ast.NodeVisitor + dataclass = breakage under mypyc. </s> remove     numchars = \"0123456789\" </s> add     numchars: Final = \"0123456789\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep replace keep replace", "code_tokens": " <mask>         CustomSplit objects and add them to the custom split map.\n <mask>     \"\"\"\n <mask> \n <mask>     MIN_SUBSTR_SIZE = 6\n <mask>     # Matches an \"f-expression\" (e.g. {var}) that might be found in an f-string.\n <mask>     RE_FEXPR = r\"\"\" </s> remove class BracketMatchError(KeyError): </s> add class BracketMatchError(Exception): </s> remove     _goto: Dict[Tuple[ParserState, NodeType], ParserState] = { </s> add     _goto: Final[Dict[Tuple[ParserState, NodeType], ParserState]] = {", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             i += 1\n <mask>         return string_op_leaves\n <mask> \n <mask> \n <mask> class StringParenWrapper(CustomSplitMapMixin, BaseStringSplitter):\n <mask>     \"\"\"\n <mask>     StringTransformer that splits non-\"atom\" strings (i.e. strings that do not\n <mask>     exist on lines by themselves).\n <mask> \n <mask>     Requirements: </s> remove class StringSplitter(CustomSplitMapMixin, BaseStringSplitter): </s> add class StringSplitter(BaseStringSplitter, CustomSplitMapMixin): </s> add # Re(gex) does actually cache patterns internally but this still improves\n# performance on a long list literal of strings by 5-9% since lru_cache's\n# caching overhead is much lower.\n@lru_cache(maxsize=64)\ndef _cached_compile(pattern: str) -> re.Pattern:\n    return re.compile(pattern) </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         assert line.leaves[idx].type == token.PLUS\n <mask>         ```\n <mask>     \"\"\"\n <mask> \n <mask>     DEFAULT_TOKEN = -1\n <mask> \n <mask>     # String Parser States\n <mask>     START = 1\n <mask>     DOT = 2\n <mask>     NAME = 3 </s> remove                     next_token_type = grammar.opmap[cast(str, next_token_value)] </s> add                     next_token_type = grammar.opmap[next_token_value]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace replace keep keep replace keep keep keep", "code_tokens": " <mask>     # String Parser States\n <mask>     START = 1\n <mask>     DOT = 2\n <mask>     NAME = 3\n <mask>     PERCENT = 4\n <mask>     SINGLE_FMT_ARG = 5\n <mask>     LPAR = 6\n <mask>     RPAR = 7\n <mask>     DONE = 8\n <mask> \n <mask>     # Lookup Table for Next State\n <mask>     _goto: Dict[Tuple[ParserState, NodeType], ParserState] = {\n <mask>         # A string trailer may start with '.' OR '%'.\n <mask>         (START, token.DOT): DOT,\n <mask>         (START, token.PERCENT): PERCENT, </s> remove     DEFAULT_TOKEN = -1 </s> add     DEFAULT_TOKEN: Final = 20210605 </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if not keep and work_path.exists():\n <mask>             LOG.debug(f\"Removing {work_path}\")\n <mask>             rmtree(work_path, onerror=lib.handle_PermissionError)\n <mask> \n <mask>     return -2\n <mask> \n <mask> \n <mask> @click.command(context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n <mask> @click.option(\n <mask>     \"-c\",\n <mask>     \"--config\", </s> add def find_python_files(base: Path) -> List[Path]:\n    files = []\n    for entry in base.iterdir():\n        if entry.is_file() and entry.suffix == \".py\":\n            files.append(entry)\n        elif entry.is_dir():\n            files.extend(find_python_files(entry))\n\n    return files", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/black_primer/cli.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask> import pkgutil\n <mask> import sys\n <mask> from typing import (\n <mask>     Any,\n <mask>     IO,\n <mask>     Iterable,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text,\n <mask>     Iterator, </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     Generic,\n <mask>     Union,\n <mask> )\n <mask> from dataclasses import dataclass, field\n <mask> \n <mask> # Pgen imports\n <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> from logging import Logger\n <mask> from blib2to3.pytree import NL </s> remove from blib2to3.pytree import _Convert, NL </s> add from blib2to3.pytree import NL </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo </s> remove from dataclasses import dataclass, field </s> remove from blib2to3 import pygram, pytree", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask> from . import grammar, parse, token, tokenize, pgen\n <mask> from logging import Logger\n <mask> from blib2to3.pytree import _Convert, NL\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from contextlib import contextmanager\n <mask>  </s> add from contextlib import contextmanager </s> remove from blib2to3.pytree import NL, Context, RawNode, Leaf, Node </s> add from blib2to3.pytree import convert, NL, Context, RawNode, Leaf, Node </s> remove from blib2to3 import pygram, pytree </s> add from blib2to3 import pygram </s> add if sys.version_info >= (3, 8):\n    from typing import Final\nelse:\n    from typing_extensions import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace replace replace replace replace replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> class Driver(object):\n <mask>     def __init__(\n <mask>         self,\n <mask>         grammar: Grammar,\n <mask>         convert: Optional[_Convert] = None,\n <mask>         logger: Optional[Logger] = None,\n <mask>     ) -> None:\n <mask>         self.grammar = grammar\n <mask>         if logger is None:\n <mask>             logger = logging.getLogger(__name__)\n <mask>         self.logger = logger\n <mask>         self.convert = convert\n <mask> \n <mask>     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a series of tokens and return the syntax tree.\"\"\" </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL: </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL: </s> remove         p = parse.Parser(self.grammar, self.convert) </s> add         p = parse.Parser(self.grammar) </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]: </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None: </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep keep replace keep keep keep keep", "code_tokens": " <mask>         self.logger = logger\n <mask>         self.convert = convert\n <mask> \n <mask>     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL:\n <mask>         \"\"\"Parse a series of tokens and return the syntax tree.\"\"\"\n <mask>         # XXX Move the prefix computation into a wrapper around tokenize.\n <mask>         proxy = TokenProxy(tokens)\n <mask> \n <mask>         p = parse.Parser(self.grammar, self.convert)\n <mask>         p.setup(proxy=proxy)\n <mask> \n <mask>         lineno = 1\n <mask>         column = 0 </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None: </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         p.setup(proxy=proxy)\n <mask> \n <mask>         lineno = 1\n <mask>         column = 0\n <mask>         indent_columns = []\n <mask>         type = value = start = end = line_text = None\n <mask>         prefix = \"\"\n <mask> \n <mask>         for quintuple in proxy:\n <mask>             type, value, start, end, line_text = quintuple </s> remove             if p.addtoken(type, value, (prefix, start)): </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove                     column = column + 1 </s> add                     column += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>                 type = grammar.opmap[value]\n <mask>             if debug:\n <mask>                 self.logger.debug(\n <mask>                     \"%s %r (prefix=%r)\", token.tok_name[type], value, prefix\n <mask>                 )\n <mask>             if type == token.INDENT:\n <mask>                 indent_columns.append(len(value)) </s> remove             if p.addtoken(type, value, (prefix, start)): </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove         indent_columns = [] </s> add         indent_columns: List[int] = [] </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL: </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 value = \"\"\n <mask>             elif type == token.DEDENT:\n <mask>                 _indent_col = indent_columns.pop()\n <mask>                 prefix, _prefix = self._partially_consume_prefix(prefix, _indent_col)\n <mask>             if p.addtoken(type, value, (prefix, start)):\n <mask>                 if debug:\n <mask>                     self.logger.debug(\"Stop.\")\n <mask>                 break\n <mask>             prefix = \"\"\n <mask>             if type in {token.INDENT, token.DEDENT}: </s> remove         indent_columns = [] </s> add         indent_columns: List[int] = [] </s> remove                     column = column + 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/driver.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     Set,\n <mask>     TYPE_CHECKING,\n <mask> )\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> from blib2to3.pytree import NL, Context, RawNode, Leaf, Node\n <mask> \n <mask> if TYPE_CHECKING:\n <mask>     from blib2to3.driver import TokenProxy\n <mask> \n <mask>  </s> remove from blib2to3 import pygram, pytree </s> add from blib2to3 import pygram </s> remove from blib2to3.pytree import _Convert, NL </s> add from blib2to3.pytree import NL </s> remove from contextlib import contextmanager </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo </s> add if sys.version_info >= (3, 8):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             self._dead_ilabels.add(ilabel)\n <mask>         finally:\n <mask>             self.parser.stack = self._start_point\n <mask> \n <mask>     def add_token(\n <mask>         self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n <mask>     ) -> None:\n <mask>         func: Callable[..., Any]\n <mask>         if raw:\n <mask>             func = self.parser._addtoken\n <mask>         else:\n <mask>             func = self.parser.addtoken </s> remove     def determine_route(\n        self, value: Optional[Text] = None, force: bool = False\n    ) -> Optional[int]: </s> add     def determine_route(self, value: Text = None, force: bool = False) -> Optional[int]: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None: </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                 if raw:\n <mask>                     args.insert(0, ilabel)\n <mask>                 func(*args)\n <mask> \n <mask>     def determine_route(\n <mask>         self, value: Optional[Text] = None, force: bool = False\n <mask>     ) -> Optional[int]:\n <mask>         alive_ilabels = self.ilabels\n <mask>         if len(alive_ilabels) == 0:\n <mask>             *_, most_successful_ilabel = self._dead_ilabels\n <mask>             raise ParseError(\"bad input\", most_successful_ilabel, value, self.context)\n <mask>  </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>         up.\n <mask> \n <mask>         A concrete syntax tree node is a (type, value, context, nodes)\n <mask>         tuple, where type is the node type (a token or symbol number),\n <mask>         value is None for symbols and a string for tokens, context is\n <mask>         None or an opaque value used for error reporting (typically a </s> remove         assert value is not None\n        assert context is not None </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None: </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask>         \"\"\"\n <mask>         self.grammar = grammar\n <mask>         self.convert = convert or lam_sub\n <mask> \n <mask>     def setup(self, proxy: \"TokenProxy\", start: Optional[int] = None) -> None:\n <mask>         \"\"\"Prepare for parsing.\n <mask> \n <mask>         This *must* be called before starting to parse. </s> remove     def __init__(\n        self,\n        grammar: Grammar,\n        convert: Optional[_Convert] = None,\n        logger: Optional[Logger] = None,\n    ) -> None: </s> add     def __init__(self, grammar: Grammar, logger: Optional[Logger] = None) -> None: </s> remove     def parse_tokens(self, tokens: Iterable[Any], debug: bool = False) -> NL: </s> add     def parse_tokens(self, tokens: Iterable[GoodTokenInfo], debug: bool = False) -> NL:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         self.rootnode: Optional[NL] = None\n <mask>         self.used_names: Set[str] = set()\n <mask>         self.proxy = proxy\n <mask> \n <mask>     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool:\n <mask>         \"\"\"Add a token; return True iff this is the end of the program.\"\"\"\n <mask>         # Map from token to label\n <mask>         ilabels = self.classify(type, value, context)\n <mask>         assert len(ilabels) >= 1\n <mask>  </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i: </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                     break\n <mask> \n <mask>                 next_token_type, next_token_value, *_ = proxy.eat(counter)\n <mask>                 if next_token_type == tokenize.OP:\n <mask>                     next_token_type = grammar.opmap[cast(str, next_token_value)]\n <mask> \n <mask>                 recorder.add_token(next_token_type, next_token_value)\n <mask>                 counter += 1\n <mask> \n <mask>             ilabel = cast(int, recorder.determine_route(next_token_value, force=force)) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i: </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert ilabel is not None\n <mask> \n <mask>         return self._addtoken(ilabel, type, value, context)\n <mask> \n <mask>     def _addtoken(\n <mask>         self, ilabel: int, type: int, value: Optional[Text], context: Context\n <mask>     ) -> bool:\n <mask>         # Loop until the token is shifted; may raise exceptions\n <mask>         while True:\n <mask>             dfa, state, node = self.stack[-1]\n <mask>             states, first = dfa\n <mask>             arcs = states[state] </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep replace replace keep replace keep keep", "code_tokens": " <mask>             arcs = states[state]\n <mask>             # Look for a state with this label\n <mask>             for i, newstate in arcs:\n <mask>                 t, v = self.grammar.labels[i]\n <mask>                 if ilabel == i:\n <mask>                     # Look it up in the list of labels\n <mask>                     assert t < 256\n <mask>                     # Shift a token; we're done with it\n <mask>                     self.shift(type, value, newstate, context) </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>                         dfa, state, node = self.stack[-1]\n <mask>                         states, first = dfa\n <mask>                     # Done with this token\n <mask>                     return False\n <mask>                 elif t >= 256:\n <mask>                     # See if it's a symbol and if we're in its first set\n <mask>                     itsdfa = self.grammar.dfas[t]\n <mask>                     itsstates, itsfirst = itsdfa\n <mask>                     if ilabel in itsfirst:\n <mask>                         # Push a symbol\n <mask>                         self.push(t, self.grammar.dfas[t], newstate, context)\n <mask>                         break  # To continue the outer while loop\n <mask>             else:\n <mask>                 if (0, state) in arcs:\n <mask>                     # An accepting state, pop it and try something else\n <mask>                     self.pop()\n <mask>                     if not self.stack: </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 t, v = self.grammar.labels[i]\n                if ilabel == i: </s> add                 t = self.grammar.labels[i][0]\n                if t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, itsdfa, newstate, context)\n                        break  # To continue the outer while loop\n\n                elif ilabel == i: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove                     assert t < 256 </s> add </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 else:\n <mask>                     # No success finding a transition\n <mask>                     raise ParseError(\"bad input\", type, value, context)\n <mask> \n <mask>     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]:\n <mask>         \"\"\"Turn a token into a label.  (Internal)\n <mask> \n <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME: </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Depending on whether the value is a soft-keyword or not,\n <mask>         this function may return multiple labels to choose from.\"\"\"\n <mask>         if type == token.NAME:\n <mask>             # Keep a listing of all used names\n <mask>             assert value is not None\n <mask>             self.used_names.add(value)\n <mask>             # Check for reserved words\n <mask>             if value in self.grammar.keywords:\n <mask>                 return [self.grammar.keywords[value]]\n <mask>             elif value in self.grammar.soft_keywords: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove             if p.addtoken(type, value, (prefix, start)): </s> add             if p.addtoken(cast(int, type), value, (prefix, start)): </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep replace replace keep", "code_tokens": " <mask>         if ilabel is None:\n <mask>             raise ParseError(\"bad token\", type, value, context)\n <mask>         return [ilabel]\n <mask> \n <mask>     def shift(\n <mask>         self, type: int, value: Optional[Text], newstate: int, context: Context\n <mask>     ) -> None:\n <mask>         \"\"\"Shift a token.  (Internal)\"\"\"\n <mask>         dfa, state, node = self.stack[-1]\n <mask>         assert value is not None\n <mask>         assert context is not None\n <mask>         rawnode: RawNode = (type, value, context, None) </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         dfa, state, node = self.stack[-1]\n <mask>         assert value is not None\n <mask>         assert context is not None\n <mask>         rawnode: RawNode = (type, value, context, None)\n <mask>         newnode = self.convert(self.grammar, rawnode)\n <mask>         if newnode is not None:\n <mask>             assert node[-1] is not None\n <mask>             node[-1].append(newnode)\n <mask>         self.stack[-1] = (dfa, newstate, node)\n <mask> \n <mask>     def push(self, type: int, newdfa: DFAS, newstate: int, context: Context) -> None:\n <mask>         \"\"\"Push a nonterminal.  (Internal)\"\"\"\n <mask>         dfa, state, node = self.stack[-1] </s> remove         assert value is not None\n        assert context is not None </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None: </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> add     result = runner.invoke(black.main, args, catch_exceptions=False)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask>     def pop(self) -> None:\n <mask>         \"\"\"Pop a nonterminal.  (Internal)\"\"\"\n <mask>         popdfa, popstate, popnode = self.stack.pop()\n <mask>         newnode = self.convert(self.grammar, popnode)\n <mask>         if newnode is not None:\n <mask>             if self.stack:\n <mask>                 dfa, state, node = self.stack[-1]\n <mask>                 assert node[-1] is not None\n <mask>                 node[-1].append(newnode)\n <mask>             else:\n <mask>                 self.rootnode = newnode\n <mask>                 self.rootnode.used_names = self.used_names </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         assert value is not None\n        assert context is not None </s> remove     def shift(\n        self, type: int, value: Optional[Text], newstate: int, context: Context\n    ) -> None: </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None: </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool: </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/parse.py"}
{"docstring_tokens": "keep add keep keep keep keep keep keep", "code_tokens": " <mask> each time a new token is found.\"\"\"\n <mask> \n <mask> from typing import (\n <mask>     Callable,\n <mask>     Iterable,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional, </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final </s> remove from dataclasses import dataclass, field", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     Pattern,\n <mask>     Union,\n <mask>     cast,\n <mask> )\n <mask> from blib2to3.pgen2.token import *\n <mask> from blib2to3.pgen2.grammar import Grammar\n <mask> \n <mask> __author__ = \"Ka-Ping Yee <ping@lfw.org>\"\n <mask> __credits__ = \"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro\"\n <mask>  </s> add from blib2to3.pgen2.tokenize import GoodTokenInfo", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> )\n <mask> PseudoExtras = group(r\"\\\\\\r?\\n\", Comment, Triple)\n <mask> PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)\n <mask> \n <mask> pseudoprog = re.compile(PseudoToken, re.UNICODE)\n <mask> single3prog = re.compile(Single3)\n <mask> double3prog = re.compile(Double3)\n <mask> \n <mask> _strprefixes = (\n <mask>     _combinations(\"r\", \"R\", \"f\", \"F\") </s> remove triple_quoted = ( </s> add triple_quoted: Final = ( </s> remove single_quoted = ( </s> add single_quoted: Final = ( </s> remove     match = re.match(r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", s, re.DOTALL) </s> add     match = STRING_PREFIX_RE.match(s)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     | _combinations(\"r\", \"R\", \"b\", \"B\")\n <mask>     | {\"u\", \"U\", \"ur\", \"uR\", \"Ur\", \"UR\"}\n <mask> )\n <mask> \n <mask> endprogs = {\n <mask>     \"'\": re.compile(Single),\n <mask>     '\"': re.compile(Double),\n <mask>     \"'''\": single3prog,\n <mask>     '\"\"\"': double3prog,\n <mask>     **{f\"{prefix}'''\": single3prog for prefix in _strprefixes}, </s> remove triple_quoted = ( </s> add triple_quoted: Final = ( </s> remove single_quoted = ( </s> add single_quoted: Final = ( </s> remove pseudoprog = re.compile(PseudoToken, re.UNICODE) </s> add pseudoprog: Final = re.compile(PseudoToken, re.UNICODE) </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove     RE_FEXPR = r\"\"\" </s> add     RE_FEXPR: Final = r\"\"\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep replace keep keep keep keep replace keep keep keep", "code_tokens": " <mask> \n <mask> triple_quoted = (\n <mask>     {\"'''\", '\"\"\"'}\n <mask>     | {f\"{prefix}'''\" for prefix in _strprefixes}\n <mask>     | {f'{prefix}\"\"\"' for prefix in _strprefixes}\n <mask> )\n <mask> single_quoted = (\n <mask>     {\"'\", '\"'}\n <mask>     | {f\"{prefix}'\" for prefix in _strprefixes}\n <mask>     | {f'{prefix}\"' for prefix in _strprefixes} </s> remove     RE_FEXPR = r\"\"\" </s> add     RE_FEXPR: Final = r\"\"\" </s> remove IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}\nOPENING_BRACKETS = set(BRACKET.keys())\nCLOSING_BRACKETS = set(BRACKET.values())\nBRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> add IMPLICIT_TUPLE: Final = {syms.testlist, syms.testlist_star_expr, syms.exprlist}\nBRACKET: Final = {\n    token.LPAR: token.RPAR,\n    token.LSQB: token.RSQB,\n    token.LBRACE: token.RBRACE,\n}\nOPENING_BRACKETS: Final = set(BRACKET.keys())\nCLOSING_BRACKETS: Final = set(BRACKET.values())\nBRACKETS: Final = OPENING_BRACKETS | CLOSING_BRACKETS\nALWAYS_NO_SPACE: Final = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} </s> remove         indent_columns = [] </s> add         indent_columns: List[int] = [] </s> remove                 for version in sorted(self.target_versions, key=lambda v: v.value) </s> add                 for version in sorted(self.target_versions, key=attrgetter(\"value\"))", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     and the line on which the token was found. The line passed is the\n <mask>     logical line; continuation lines are included.\n <mask>     \"\"\"\n <mask>     lnum = parenlev = continued = 0\n <mask>     numchars = \"0123456789\"\n <mask>     contstr, needcont = \"\", 0\n <mask>     contline: Optional[str] = None\n <mask>     indents = [0]\n <mask> \n <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and </s> add     stashed: Optional[GoodTokenInfo] = None </s> remove         p = parse.Parser(self.grammar, self.convert) </s> add         p = parse.Parser(self.grammar) </s> remove     cell_magic: Optional[CellMagic] = None </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic </s> remove         match = re.match(r\"\\s*\\t+\\s*(\\S)\", line) </s> add         match = FIRST_NON_WHITESPACE_RE.match(line) </s> remove     mode: Mode\n    remove_u_prefix: bool = False\n    current_line: Line = field(init=False) </s> add     def __init__(self, mode: Mode, remove_u_prefix: bool = False) -> None:\n        self.mode = mode\n        self.remove_u_prefix = remove_u_prefix\n        self.current_line: Line\n        self.__post_init__()", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     # If we know we're parsing 3.7+, we can unconditionally parse `async` and\n <mask>     # `await` as keywords.\n <mask>     async_keywords = False if grammar is None else grammar.async_keywords\n <mask>     # 'stashed' and 'async_*' are used for async/await parsing\n <mask>     stashed = None\n <mask>     async_def = False\n <mask>     async_def_indent = 0\n <mask>     async_def_nl = False\n <mask> \n <mask>     strstart: Tuple[int, int] </s> remove                 elif t >= 256:\n                    # See if it's a symbol and if we're in its first set\n                    itsdfa = self.grammar.dfas[t]\n                    itsstates, itsfirst = itsdfa\n                    if ilabel in itsfirst:\n                        # Push a symbol\n                        self.push(t, self.grammar.dfas[t], newstate, context)\n                        break  # To continue the outer while loop </s> add     def __init__(self, cell_magic: Optional[CellMagic] = None) -> None:\n        self.cell_magic = cell_magic", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         try:\n <mask>             line = readline()\n <mask>         except StopIteration:\n <mask>             line = \"\"\n <mask>         lnum = lnum + 1\n <mask>         pos, max = 0, len(line)\n <mask> \n <mask>         if contstr:  # continued string\n <mask>             assert contline is not None\n <mask>             if not line: </s> add         assert worker_count is not None </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 break\n <mask>             column = 0\n <mask>             while pos < max:  # measure leading whitespace\n <mask>                 if line[pos] == \" \":\n <mask>                     column = column + 1\n <mask>                 elif line[pos] == \"\\t\":\n <mask>                     column = (column // tabsize + 1) * tabsize\n <mask>                 elif line[pos] == \"\\f\":\n <mask>                     column = 0\n <mask>                 else: </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove         indent_columns = [] </s> add         indent_columns: List[int] = [] </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1 </s> add                         parenlev -= 1 </s> remove                         parenlev = parenlev + 1 </s> add                         parenlev += 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 elif line[pos] == \"\\f\":\n <mask>                     column = 0\n <mask>                 else:\n <mask>                     break\n <mask>                 pos = pos + 1\n <mask>             if pos == max:\n <mask>                 break\n <mask> \n <mask>             if stashed:\n <mask>                 yield stashed </s> Implementing mypyc support pt. 2  (#2431) </s> remove                     column = column + 1 </s> add                     column += 1 </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1 </s> add                         parenlev -= 1 </s> remove                         parenlev = parenlev + 1 </s> add                         parenlev += 1 </s> remove                     (lnum, pos + len(comment_token)), </s> add                     (lnum, nl_pos),", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                 yield (\n <mask>                     COMMENT,\n <mask>                     comment_token,\n <mask>                     (lnum, pos),\n <mask>                     (lnum, pos + len(comment_token)),\n <mask>                     line,\n <mask>                 )\n <mask>                 yield (NL, line[nl_pos:], (lnum, nl_pos), (lnum, len(line)), line)\n <mask>                 continue\n <mask>  </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                         parenlev = parenlev + 1 </s> add                         parenlev += 1 </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                         parenlev = parenlev - 1 </s> add                         parenlev -= 1 </s> add </s> remove         elif isinstance(value, (ast.AST, ast3.AST, ast27.AST)): </s> add         # Note that we are referencing the typed-ast ASTs via global variables and not\n        # direct module attribute accesses because that breaks mypyc. It's probably\n        # something to do with the ast3 / ast27 variables being marked as Any leading\n        # mypy to think this branch is always taken, leaving the rest of the code\n        # unanalyzed. Tighting up the types for the typed-ast AST types avoids the\n        # mypyc crash.\n        elif isinstance(value, (ast.AST, ast3_AST, ast27_AST)):", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace keep keep keep", "code_tokens": " <mask>                     yield (NL, token, spos, (lnum, pos), line)\n <mask>                     continued = 1\n <mask>                 else:\n <mask>                     if initial in \"([{\":\n <mask>                         parenlev = parenlev + 1\n <mask>                     elif initial in \")]}\":\n <mask>                         parenlev = parenlev - 1\n <mask>                     if stashed:\n <mask>                         yield stashed\n <mask>                         stashed = None </s> Implementing mypyc support pt. 2  (#2431) </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                 pos = pos + 1 </s> add                 pos += 1 </s> remove                     (lnum, pos + len(comment_token)), </s> add                     (lnum, nl_pos), </s> remove         lnum = lnum + 1 </s> add         lnum += 1 </s> remove     numchars = \"0123456789\" </s> add     numchars: Final = \"0123456789\"", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>                         stashed = None\n <mask>                     yield (OP, token, spos, epos, line)\n <mask>             else:\n <mask>                 yield (ERRORTOKEN, line[pos], (lnum, pos), (lnum, pos + 1), line)\n <mask>                 pos = pos + 1\n <mask> \n <mask>     if stashed:\n <mask>         yield stashed\n <mask>         stashed = None\n <mask>  </s> remove                 pos = pos + 1 </s> remove                     (lnum, pos + len(comment_token)), </s> remove                     column = column + 1", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pgen2/tokenize.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> # mypy: allow-untyped-defs\n <mask> \n <mask> from typing import (\n <mask>     Any,\n <mask>     Callable,\n <mask>     Dict,\n <mask>     Iterator,\n <mask>     List,\n <mask>     Optional,\n <mask>     Text, </s> remove from typing import Iterable, Iterator, List, Set, Union, Tuple </s> add from typing import Any, Iterable, Iterator, List, Set, Tuple, Type, Union\n\nif sys.version_info < (3, 8):\n    from typing_extensions import Final\nelse:\n    from typing import Final", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if self.__class__ is not other.__class__:\n <mask>             return NotImplemented\n <mask>         return self._eq(other)\n <mask> \n <mask>     __hash__ = None  # type: Any  # For Py3 compatibility.\n <mask> \n <mask>     @property\n <mask>     def prefix(self) -> Text:\n <mask>         raise NotImplementedError\n <mask> \n <mask>     def _eq(self: _P, other: _P) -> bool: </s> remove     def classify(self, type: int, value: Optional[Text], context: Context) -> List[int]: </s> add     def classify(self, type: int, value: Text, context: Context) -> List[int]: </s> remove                 if isinstance(item, WildcardPattern):\n                    self.wildcards = True </s> add                 # I don't even think this code is used anywhere, but it does cause\n                # unreachable errors from mypy. This function's signature does look\n                # odd though *shrug*.\n                if isinstance(item, WildcardPattern):  # type: ignore[unreachable]\n                    self.wildcards = True  # type: ignore[unreachable]", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         Return a pretty string representation.\n <mask> \n <mask>         This reproduces the input source exactly.\n <mask>         \"\"\"\n <mask>         return self.prefix + str(self.value)\n <mask> \n <mask>     def _eq(self, other) -> bool:\n <mask>         \"\"\"Compare two nodes for equality.\"\"\"\n <mask>         return (self.type, self.value) == (other.type, other.value)\n <mask>  </s> remove             assert value is not None", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             assert not isinstance(content, str), repr(content)\n <mask>             newcontent = list(content)\n <mask>             for i, item in enumerate(newcontent):\n <mask>                 assert isinstance(item, BasePattern), (i, item)\n <mask>                 if isinstance(item, WildcardPattern):\n <mask>                     self.wildcards = True\n <mask>         self.type = type\n <mask>         self.content = newcontent\n <mask>         self.name = name\n <mask> \n <mask>     def _submatch(self, node, results=None) -> bool: </s> remove     def addtoken(self, type: int, value: Optional[Text], context: Context) -> bool: </s> add     def addtoken(self, type: int, value: Text, context: Context) -> bool: </s> remove         newnode = self.convert(self.grammar, rawnode)\n        if newnode is not None:\n            assert node[-1] is not None\n            node[-1].append(newnode) </s> add         newnode = convert(self.grammar, rawnode)\n        assert node[-1] is not None\n        node[-1].append(newnode) </s> remove         newnode = self.convert(self.grammar, popnode)\n        if newnode is not None:\n            if self.stack:\n                dfa, state, node = self.stack[-1]\n                assert node[-1] is not None\n                node[-1].append(newnode)\n            else:\n                self.rootnode = newnode\n                self.rootnode.used_names = self.used_names </s> add         newnode = convert(self.grammar, popnode)\n        if self.stack:\n            dfa, state, node = self.stack[-1]\n            assert node[-1] is not None\n            node[-1].append(newnode)\n        else:\n            self.rootnode = newnode\n            self.rootnode.used_names = self.used_names </s> remove     def _addtoken(\n        self, ilabel: int, type: int, value: Optional[Text], context: Context\n    ) -> bool: </s> add     def _addtoken(self, ilabel: int, type: int, value: Text, context: Context) -> bool:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace", "code_tokens": " <mask>                     r = {}\n <mask>                     r.update(r0)\n <mask>                     r.update(r1)\n <mask>                     yield c0 + c1, r\n <mask> \n <mask> \n <mask> _Convert = Callable[[Grammar, RawNode], Any] </s> remove     def add_token(\n        self, tok_type: int, tok_val: Optional[Text], raw: bool = False\n    ) -> None: </s> add     def add_token(self, tok_type: int, tok_val: Text, raw: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "src/blib2to3/pytree.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     runner = BlackRunner()\n <mask>     if ignore_config:\n <mask>         args = [\"--verbose\", \"--config\", str(THIS_DIR / \"empty.toml\"), *args]\n <mask>     result = runner.invoke(black.main, args)\n <mask>     assert result.stdout_bytes is not None\n <mask>     assert result.stderr_bytes is not None\n <mask>     msg = (\n <mask>         f\"Failed with args: {args}\\n\"\n <mask>         f\"stdout: {result.stdout_bytes.decode()!r}\\n\" </s> add     def shift(self, type: int, value: Text, newstate: int, context: Context) -> None:", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         )\n <mask>         self.assertEqual({\"unicode_literals\", \"print\"}, black.get_future_imports(node))\n <mask> \n <mask>     def test_debug_visitor(self) -> None:\n <mask>         source, _ = read_data(\"debug_visitor.py\")\n <mask>         expected, _ = read_data(\"debug_visitor.out\")\n <mask>         out_lines = []\n <mask>         err_lines = []\n <mask>  </s> remove         indent_columns = [] </s> add         indent_columns: List[int] = [] </s> remove         p = parse.Parser(self.grammar, self.convert) </s> add         p = parse.Parser(self.grammar)", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>         self.assertEqual(n.type, black.syms.file_input)\n <mask>         self.assertEqual(len(n.children), 1)\n <mask>         self.assertEqual(n.children[0].type, black.token.ENDMARKER)\n <mask> \n <mask>     @unittest.skipIf(os.environ.get(\"SKIP_AST_PRINT\"), \"user set SKIP_AST_PRINT\")\n <mask>     def test_assertFormatEqual(self) -> None:\n <mask>         out_lines = []\n <mask>         err_lines = []\n <mask> \n <mask>         def out(msg: str, **kwargs: Any) -> None: </s> add         indent_columns: List[int] = []", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask>         self.assertEqual(config[\"target_version\"], [\"py36\", \"py37\", \"py38\"])\n <mask>         self.assertEqual(config[\"exclude\"], r\"\\.pyi?$\")\n <mask>         self.assertEqual(config[\"include\"], r\"\\.py?$\")\n <mask> \n <mask>     def test_find_project_root(self) -> None:\n <mask>         with TemporaryDirectory() as workspace:\n <mask>             root = Path(workspace)\n <mask>             test_dir = root / \"test\" </s> add try:\n    with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n        black_source_lines = _bf.readlines()\nexcept UnicodeDecodeError:\n    if not black.COMPILED:\n        raise", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>         assert output == result_diff, \"The output did not match the expected value.\"\n <mask>         assert result.exit_code == 0, \"The exit code is incorrect.\"\n <mask> \n <mask>     def test_code_option_safe(self) -> None:\n <mask>         \"\"\"Test that the code option throws an error when the sanity checks fail.\"\"\"\n <mask>         # Patch black.assert_equivalent to ensure the sanity checks fail\n <mask>         with patch.object(black, \"assert_equivalent\", side_effect=AssertionError):\n <mask>             code = 'print(\"Hello world\")' </s> add     @pytest.mark.incompatible_with_mypyc </s> add     @pytest.mark.incompatible_with_mypyc", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>             TargetVersion.PY27\n <mask>         }, non_python2_case\n <mask> \n <mask> \n <mask> with open(black.__file__, \"r\", encoding=\"utf-8\") as _bf:\n <mask>     black_source_lines = _bf.readlines()\n <mask> \n <mask> \n <mask> def tracefunc(\n <mask>     frame: types.FrameType, event: str, arg: Any\n <mask> ) -> Callable[[types.FrameType, str, Any], Any]: </s> remove     required_version: str, </s> add     required_version: Optional[str],", "html_url": "https://github.com/psf/black/commit/117891878e5be4d6b771ae5de299e51b679cea27", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>       github.event_name == 'push' || github.event.pull_request.head.repo.full_name !=\n <mask>       github.repository\n <mask> \n <mask>     runs-on: ubuntu-latest\n <mask>     strategy:\n <mask>       matrix:\n <mask>         python-version: [3.7]\n <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }} </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }} </s> remove           python-version: ${{ matrix.python-version }} </s> add           python-version: 3.7", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     steps:\n <mask>       - uses: actions/checkout@v2\n <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v2\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove           python-version: ${{ matrix.python-version }} </s> add           python-version: 3.7 </s> remove     strategy:\n      matrix:\n        python-version: [3.7]", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>       - name: Set up Python ${{ matrix.python-version }}\n <mask>         uses: actions/setup-python@v2\n <mask>         with:\n <mask>           python-version: ${{ matrix.python-version }}\n <mask> \n <mask>       - name: Install dependencies\n <mask>         run: |\n <mask>           python -m pip install --upgrade pip\n <mask>           python -m pip install --upgrade pre-commit </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }} </s> add       - name: Set up Python </s> remove     strategy:\n      matrix:\n        python-version: [3.7]", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".github/workflows/lint.yml"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         require_serial: true\n <mask>         types_or: [python, pyi]\n <mask> \n <mask>   - repo: https://gitlab.com/pycqa/flake8\n <mask>     rev: 3.8.1\n <mask>     hooks:\n <mask>       - id: flake8\n <mask>         additional_dependencies: [flake8-bugbear]\n <mask> \n <mask>   - repo: https://github.com/pre-commit/mirrors-mypy </s> Add a GitHub Action to build + Upload black to PyPI (#1848)\n\n* Add a GitHub Action to build + Upload black to PyPI\r\n- Build a wheel + sdist\r\n- Upload via twine using token stored in GitHub secrets </s> remove       - name: Set up Python ${{ matrix.python-version }} </s> add       - name: Set up Python </s> remove     strategy:\n      matrix:\n        python-version: [3.7] </s> remove           python-version: ${{ matrix.python-version }} </s> add           python-version: 3.7", "html_url": "https://github.com/psf/black/commit/125ed5b2601f0e74ded03b666132e3c37ae8af07", "file_name": ".pre-commit-config.yaml"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     ),\n <mask> )\n <mask> @click.option(\n <mask>     \"--pyi\",\n <mask>     is_flag=True,\n <mask>     help=(\n <mask>         \"Format all input files like typing stubs regardless of file extension \"\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> remove         versions = set(target_version)\n </s> add         if py36:\n            err(f\"Cannot use both --target-version and --py36\")\n            ctx.exit(2)\n        else:\n            versions = set(target_version)\n    elif py36:\n        err(\n            \"--py36 is deprecated and will be removed in a future version. \"\n            \"Use --target-version py36 instead.\"\n        )\n        versions = PY36_VERSIONS </s> add     py36: bool,", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep keep", "code_tokens": " <mask>     diff: bool,\n <mask>     fast: bool,\n <mask>     pyi: bool,\n <mask>     skip_string_normalization: bool,\n <mask>     quiet: bool,\n <mask>     verbose: bool,\n <mask>     include: str,\n <mask>     exclude: str,\n <mask>     src: Tuple[str],\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> remove         versions = set(target_version)\n </s> add         if py36:\n            err(f\"Cannot use both --target-version and --py36\")\n            ctx.exit(2)\n        else:\n            versions = set(target_version)\n    elif py36:\n        err(\n            \"--py36 is deprecated and will be removed in a future version. \"\n            \"Use --target-version py36 instead.\"\n        )\n        versions = PY36_VERSIONS </s> add @click.option(\n    \"--py36\",\n    is_flag=True,\n    help=(\n        \"Allow using Python 3.6-only syntax on all input files.  This will put \"\n        \"trailing commas in function signatures and calls also after *args and \"\n        \"**kwargs. Deprecated; use --target-version instead. \"\n        \"[default: per-file auto-detection]\"\n    ),\n)", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> ) -> None:\n <mask>     \"\"\"The uncompromising code formatter.\"\"\"\n <mask>     write_back = WriteBack.from_configuration(check=check, diff=diff)\n <mask>     if target_version:\n <mask>         versions = set(target_version)\n <mask>     else:\n <mask>         # We'll autodetect later.\n <mask>         versions = set()\n <mask>     mode = FileMode(\n <mask>         target_versions=versions,\n </s> Add back --py36 as a deprecated option (#750)\n\nThis partially reverts commit 21ab37a5d92c866a289320cba7c4689df70b3342. </s> add @click.option(\n    \"--py36\",\n    is_flag=True,\n    help=(\n        \"Allow using Python 3.6-only syntax on all input files.  This will put \"\n        \"trailing commas in function signatures and calls also after *args and \"\n        \"**kwargs. Deprecated; use --target-version instead. \"\n        \"[default: per-file auto-detection]\"\n    ),\n) </s> add     py36: bool,", "html_url": "https://github.com/psf/black/commit/129ebd53a66b4a8069321742aeecfafb44c76fd9", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         # justify pushing it all onto one line. Thus we\n <mask>         # (unfortunately) need to check the actual source lines and\n <mask>         # only report an unsplittable 'type: ignore' if this line was\n <mask>         # one line in the original code.\n <mask>         if self.leaves[0].lineno == self.leaves[-1].lineno:\n <mask>             for comment in self.comments.get(id(self.leaves[-1]), []):\n <mask>                 if is_type_comment(comment, \" ignore\"):\n <mask>                     return True\n <mask> \n <mask>         return False\n <mask> \n <mask>     def contains_multiline_strings(self) -> bool:\n <mask>         for leaf in self.leaves:\n </s> Fix missed cases in the `# type: ignore` logic (#1059)\n\nIn #1040 I had convinced myself that the type ignore logic didn't\r\nneed anything like the ignored_ids from the type comment logic, but I\r\nwas wrong, and we do.\r\n\r\nWe hit these cases in practice a bunch. </s> remove         parameters.children = [\n            parameters.what_if_this_was_actually_long.children[0],\n            body,\n            parameters.children[-1],\n        ]  # type: ignore\n </s> add         parameters.children = [parameters.what_if_this_was_actually_long.children[0], body, parameters.children[-1]]  # type: ignore </s> add AAAAAAAAAAAAA = [AAAAAAAAAAAAA] + SHARED_AAAAAAAAAAAAA + USER_AAAAAAAAAAAAA + AAAAAAAAAAAAA  # type: ignore\n\ncall_to_some_function_asdf(\n    foo,\n    [AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, BBBBBBBBBBBB],  # type: ignore\n)", "html_url": "https://github.com/psf/black/commit/133609463459b2b6a98f08bcf41a07f6b14ab747", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>             parameters.children[0],  # (2 what if this was actually long\n <mask>             body,\n <mask>             parameters.children[-1],  # )2\n <mask>         ]\n <mask>         parameters.children = [\n <mask>             parameters.what_if_this_was_actually_long.children[0],\n <mask>             body,\n <mask>             parameters.children[-1],\n <mask>         ]  # type: ignore\n <mask>     if (\n <mask>         self._proc is not None\n <mask>         # has the child process finished?\n <mask>         and self._returncode is None\n <mask>         # the child process has finished, but the\n </s> Fix missed cases in the `# type: ignore` logic (#1059)\n\nIn #1040 I had convinced myself that the type ignore logic didn't\r\nneed anything like the ignored_ids from the type comment logic, but I\r\nwas wrong, and we do.\r\n\r\nWe hit these cases in practice a bunch. </s> remove         if self.leaves[0].lineno == self.leaves[-1].lineno:\n            for comment in self.comments.get(id(self.leaves[-1]), []):\n                if is_type_comment(comment, \" ignore\"):\n                    return True\n </s> add         # Like in the type comment check above, we need to skip a black added\n        # trailing comma or invisible paren, since it will be the original leaf\n        # before it that has the original line number.\n        last_idx = -1\n        last_leaf = self.leaves[-1]\n        if len(self.leaves) > 2 and (\n            last_leaf.type == token.COMMA\n            or (last_leaf.type == token.RPAR and not last_leaf.value)\n        ):\n            last_idx = -2\n\n        if self.leaves[0].lineno == self.leaves[last_idx].lineno:\n            for node in self.leaves[last_idx:]:\n                for comment in self.comments.get(id(node), []):\n                    if is_type_comment(comment, \" ignore\"):\n                        return True </s> add AAAAAAAAAAAAA = [AAAAAAAAAAAAA] + SHARED_AAAAAAAAAAAAA + USER_AAAAAAAAAAAAA + AAAAAAAAAAAAA  # type: ignore\n\ncall_to_some_function_asdf(\n    foo,\n    [AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, AAAAAAAAAAAAAAAAAAAAAAA, BBBBBBBBBBBB],  # type: ignore\n)", "html_url": "https://github.com/psf/black/commit/133609463459b2b6a98f08bcf41a07f6b14ab747", "file_name": "tests/data/comments2.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         \"typing_extensions>=3.7.4\",\n <mask>         \"mypy_extensions>=0.4.3\",\n <mask>     ],\n <mask>     extras_require={\"d\": [\"aiohttp>=3.3.2\", \"aiohttp-cors\"]},\n <mask>     test_suite=\"tests.test_black\",\n <mask>     classifiers=[\n <mask>         \"Development Status :: 4 - Beta\",\n <mask>         \"Environment :: Console\",\n <mask>         \"Intended Audience :: Developers\",\n <mask>         \"License :: OSI Approved :: MIT License\", </s> Remove deprecated use of 'setup.py test' (#1275)\n\nSince setuptools v41.5.0 (27 Oct 2019), the 'test' command is formally\r\ndeprecated and should not be used. Now use unittest as the test entry\r\npoint.", "html_url": "https://github.com/psf/black/commit/1382eabb3f27d7c9cd5328fb7fddd1ded98121fb", "file_name": "setup.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>       - name: Upload coverage to Coveralls\n <mask>         # Upload coverage if we are on the main repository and\n <mask>         # we're running on Linux (this action only supports Linux)\n <mask>         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest'\n <mask>         uses: AndreMiras/coveralls-python-action@v20201129\n <mask>         with:\n <mask>           github-token: ${{ secrets.GITHUB_TOKEN }}\n <mask>           parallel: true\n <mask>           flag-name: py${{ matrix.python-version }}-${{ matrix.os }} </s> remove         ci: --numprocesses 1 \\\n        --cov --cov-append {posargs}\n    coverage report </s> remove         ci: --numprocesses 1 \\\n        --cov {posargs}", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": ".github/workflows/test.yml"}
{"docstring_tokens": "keep replace keep keep keep replace replace keep keep", "code_tokens": " <mask>     pip install -e .[d]\n <mask>     coverage erase\n <mask>     pytest tests \\\n <mask>         --run-optional no_jupyter \\\n <mask>         !ci: --numprocesses auto \\\n <mask>         ci: --numprocesses 1 \\\n <mask>         --cov {posargs}\n <mask>     pip install -e .[jupyter]\n <mask>     pytest tests --run-optional jupyter \\ </s> remove         ci: --numprocesses 1 \\\n        --cov --cov-append {posargs}\n    coverage report </s> remove         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' </s> add         if:\n          github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' &&\n          !startsWith(matrix.python-version, 'pypy')", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     pip install -e .[jupyter]\n <mask>     pytest tests --run-optional jupyter \\\n <mask>         -m jupyter \\\n <mask>         !ci: --numprocesses auto \\\n <mask>         ci: --numprocesses 1 \\\n <mask>         --cov --cov-append {posargs}\n <mask>     coverage report\n <mask> \n <mask> [testenv:{,ci-}311]\n <mask> setenv =\n <mask>   PYTHONPATH = {toxinidir}/src\n <mask>   AIOHTTP_NO_EXTENSIONS = 1 </s> remove         ci: --numprocesses 1 \\\n        --cov {posargs} </s> remove         if: github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' </s> add         if:\n          github.repository == 'psf/black' && matrix.os == 'ubuntu-latest' &&\n          !startsWith(matrix.python-version, 'pypy')", "html_url": "https://github.com/psf/black/commit/138769aa27d6bd86507a0cd98d9a5bf8f63a8e99", "file_name": "tox.ini"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask> -{'2.7', '3.6', '3.7', '3.8', '3.9', '4.0' if gilectomy else '3.10'}\n <mask> +{\"2.7\": dead, \"3.7\": long_live or die_hard}\n <mask> +{\"2.7\", \"3.6\", \"3.7\", \"3.8\", \"3.9\", \"4.0\" if gilectomy else \"3.10\"}\n <mask>  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]\n <mask> -(SomeName)\n <mask> +SomeName\n <mask>  SomeName\n <mask>  (Good, Bad, Ugly)\n <mask>  (i for i in (1, 2, 3))\n <mask>  ((i ** 2) for i in (1, 2, 3))\n <mask> -((i ** 2) for i, _ in ((1, 'a'), (2, 'b'), (3, 'c'))) </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove SomeName </s> add (SomeName) </s> add </s> remove x = 3 </s> remove print(1) </s> add </s> remove (x) = (3) </s> add", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/expression.diff"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> (str or None) if (sys.version_info[0] > (3,)) else (str or bytes or None)\n <mask> {\"2.7\": dead, \"3.7\": long_live or die_hard}\n <mask> {\"2.7\", \"3.6\", \"3.7\", \"3.8\", \"3.9\", \"4.0\" if gilectomy else \"3.10\"}\n <mask> [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]\n <mask> SomeName\n <mask> SomeName\n <mask> (Good, Bad, Ugly)\n <mask> (i for i in (1, 2, 3))\n <mask> ((i ** 2) for i in (1, 2, 3))\n <mask> ((i ** 2) for i, _ in ((1, \"a\"), (2, \"b\"), (3, \"c\"))) </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove -(SomeName)\n+SomeName </s> add  (SomeName) </s> remove (x) = (3)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/expression.py"}
{"docstring_tokens": "replace keep keep replace keep keep keep keep keep", "code_tokens": " <mask> print((1))\n <mask> x = (1)\n <mask> x = (1.2)\n <mask> (x) = (3)\n <mask> \n <mask> \n <mask> def example():\n <mask>     return ((\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"))\n <mask>  </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove x = 3 </s> remove print(1) </s> add </s> add </s> remove SomeName </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask> x = (1)\n <mask> x = (1.2)\n <mask> \n <mask> \n <mask> def example():\n <mask>     return ((\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"))\n <mask> \n <mask>  </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove (x) = (3) </s> remove print((1)) </s> remove x = 3 </s> remove print(1) </s> remove SomeName </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep replace keep keep replace keep keep keep", "code_tokens": " <mask> # output\n <mask> print(1)\n <mask> x = 1\n <mask> x = 1.2\n <mask> x = 3\n <mask> \n <mask> \n <mask> def example(): </s> Back out #850 (#1079)\n\nFixes #1042 (and probably #1044 which looks like the same thing).\r\n\r\nThe issue with the \"obviously unnecessary\" parentheses that #850 removed is that sometimes they're necessary to help Black fit something in one line. I didn't see an obvious solution that still removes the parens #850 was intended to remove, so let's back out this change for now in the interest of unblocking a release.\r\n\r\nThis PR also adds a test adapted from the failing example in #1042, so that if we try to reapply the #850 change we don't break the same case again. </s> remove (x) = (3) </s> add </s> remove print((1)) </s> add </s> add </s> remove SomeName </s> add (SomeName)", "html_url": "https://github.com/psf/black/commit/14b28c89c22659e1f935bc0ac22ee03d90bcc290", "file_name": "tests/data/remove_parens.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     If `write_back` is True, write reformatted code back to stdout.\n <mask>     `line_length` and `fast` options are passed to :func:`format_file_contents`.\n <mask>     \"\"\"\n <mask> \n <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try: </s> remove             src_contents, line_length=line_length, fast=fast </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove     dst_contents = format_str(src_contents, line_length=line_length) </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     with tokenize.open(src) as src_buffer:\n <mask>         src_contents = src_buffer.read()\n <mask>     try:\n <mask>         dst_contents = format_file_contents(\n <mask>             src_contents, line_length=line_length, fast=fast\n <mask>         )\n <mask>     except NothingChanged:\n <mask>         return False\n <mask> \n <mask>     if write_back == write_back.YES: </s> add     is_pyi = src.suffix == \".pyi\" </s> remove     dst_contents = format_str(src_contents, line_length=line_length) </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        ) </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             sys.stdout.write(diff(src, dst, src_name, dst_name))\n <mask> \n <mask> \n <mask> def format_file_contents(\n <mask>     src_contents: str, line_length: int, fast: bool\n <mask> ) -> FileContent:\n <mask>     \"\"\"Reformat contents a file and return new contents.\n <mask> \n <mask>     If `fast` is False, additionally confirm that the reformatted code is\n <mask>     valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it. </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> add     is_pyi = src.suffix == \".pyi\" </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length) </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>     \"\"\"\n <mask>     if src_contents.strip() == \"\":\n <mask>         raise NothingChanged\n <mask> \n <mask>     dst_contents = format_str(src_contents, line_length=line_length)\n <mask>     if src_contents == dst_contents:\n <mask>         raise NothingChanged\n <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents) </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove             src_contents, line_length=line_length, fast=fast </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add     is_pyi = src.suffix == \".pyi\" </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep keep keep", "code_tokens": " <mask> \n <mask>     if not fast:\n <mask>         assert_equivalent(src_contents, dst_contents)\n <mask>         assert_stable(src_contents, dst_contents, line_length=line_length)\n <mask>     return dst_contents\n <mask> \n <mask> \n <mask> def format_str(src_contents: str, line_length: int) -> FileContent:\n <mask>     \"\"\"Reformat a string and return new contents.\n <mask> \n <mask>     `line_length` determines how many characters per line are allowed.\n <mask>     \"\"\" </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove     dst_contents = format_str(src_contents, line_length=line_length) </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length) </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        )", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(\n <mask>         remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n <mask>     )\n <mask>     empty_line = Line() </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")): </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>     src_node = lib2to3_parse(src_contents)\n <mask>     dst_contents = \"\"\n <mask>     future_imports = get_future_imports(src_node)\n <mask>     py36 = is_python36(src_node)\n <mask>     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n <mask>     elt = EmptyLineTracker()\n <mask>     empty_line = Line()\n <mask>     after = 0\n <mask>     for current_line in lines.visit(src_node):\n <mask>         for _ in range(after):\n <mask>             dst_contents += str(empty_line) </s> add     elt = EmptyLineTracker(is_pyi=is_pyi) </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>             and self.leaves[0].value == \"class\"\n <mask>         )\n <mask> \n <mask>     @property\n <mask>     def is_def(self) -> bool:\n <mask>         \"\"\"Is this a function definition? (Also returns True for async defs.)\"\"\"\n <mask>         try: </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>     are consumed by `maybe_empty_lines()` and included in the computation.\n <mask>     \"\"\"\n <mask>     previous_line: Optional[Line] = None\n <mask>     previous_after: int = 0\n <mask>     previous_defs: List[int] = Factory(list)\n <mask> \n <mask>     def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]: </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>     def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:\n <mask>         max_allowed = 1\n <mask>         if current_line.depth == 0:\n <mask>             max_allowed = 2\n <mask>         if current_line.leaves:\n <mask>             # Consume the first leaf's extra newlines.\n <mask>             first_leaf = current_line.leaves[0]\n <mask>             before = first_leaf.prefix.count(\"\\n\")\n <mask>             before = min(before, max_allowed) </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove     newdst = format_str(dst, line_length=line_length) </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             before = 0\n <mask>         depth = current_line.depth\n <mask>         while self.previous_defs and self.previous_defs[-1] >= depth:\n <mask>             self.previous_defs.pop()\n <mask>             before = 1 if depth else 2\n <mask>         is_decorator = current_line.is_decorator\n <mask>         if is_decorator or current_line.is_def or current_line.is_class:\n <mask>             if not is_decorator:\n <mask>                 self.previous_defs.append(depth)\n <mask>             if self.previous_line is None: </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> remove     dst_contents = format_str(src_contents, line_length=line_length) </s> add     dst_contents = format_str(src_contents, line_length=line_length, is_pyi=is_pyi) </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>                 and before == 0\n <mask>             ):\n <mask>                 return 0, 0\n <mask> \n <mask>             newlines = 2\n <mask>             if current_line.depth:\n <mask>                 newlines -= 1\n <mask>             return newlines, 0\n <mask> \n <mask>         if (\n <mask>             self.previous_line </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> remove             yield from self.line() </s> add             if (\n                not self.is_pyi\n                or not node.parent\n                or not self.is_trivial_suite(node.parent)\n            ):\n                yield from self.line()", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     Note: destroys the tree it's visiting by mutating prefixes of its leaves\n <mask>     in ways that will no longer stringify to valid Python code on the tree.\n <mask>     \"\"\"\n <mask>     current_line: Line = Factory(Line)\n <mask>     remove_u_prefix: bool = False\n <mask> \n <mask>     def line(self, indent: int = 0, type: Type[Line] = Line) -> Iterator[Line]: </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep keep keep keep keep", "code_tokens": " <mask>     def visit_simple_stmt(self, node: Node) -> Iterator[Line]:\n <mask>         \"\"\"Visit a statement without nested statements.\"\"\"\n <mask>         is_suite_like = node.parent and node.parent.type in STATEMENT\n <mask>         if is_suite_like:\n <mask>             yield from self.line(+1)\n <mask>             yield from self.visit_default(node)\n <mask>             yield from self.line(-1)\n <mask> \n <mask>         else:\n <mask>             yield from self.line()\n <mask>             yield from self.visit_default(node)\n <mask>  </s> remove             yield from self.line() </s> add             if (\n                not self.is_pyi\n                or not node.parent\n                or not self.is_trivial_suite(node.parent)\n            ):\n                yield from self.line() </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> add     @property\n    def is_trivial_class(self) -> bool:\n        \"\"\"Is this line a class definition with a body consisting only of \"...\"?\"\"\"\n        return (\n            self.is_class\n            and self.leaves[-3:] == [Leaf(token.DOT, \".\") for _ in range(3)]\n        ) </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             yield from self.visit_default(node)\n <mask>             yield from self.line(-1)\n <mask> \n <mask>         else:\n <mask>             yield from self.line()\n <mask>             yield from self.visit_default(node)\n <mask> \n <mask>     def visit_async_stmt(self, node: Node) -> Iterator[Line]:\n <mask>         \"\"\"Visit `async def`, `async for`, `async with`.\"\"\"\n <mask>         yield from self.line() </s> remove             yield from self.line(+1)\n            yield from self.visit_default(node)\n            yield from self.line(-1) </s> add             if self.is_pyi and self.is_trivial_body(node):\n                yield from self.visit_default(node)\n            else:\n                yield from self.line(+1)\n                yield from self.visit_default(node)\n                yield from self.line(-1) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove             newlines = 2\n            if current_line.depth: </s> add             if self.is_pyi:\n                if self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_class or self.previous_line.is_class:\n                    if (\n                        current_line.is_trivial_class\n                        and self.previous_line.is_trivial_class\n                    ):\n                        newlines = 0\n                    else:\n                        newlines = 1\n                else:\n                    newlines = 0\n            else:\n                newlines = 2\n            if current_line.depth and newlines: </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent:", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             break\n <mask>     return imports\n <mask> \n <mask> \n <mask> PYTHON_EXTENSIONS = {\".py\"}\n <mask> BLACKLISTED_DIRECTORIES = {\n <mask>     \"build\", \"buck-out\", \"dist\", \"_build\", \".git\", \".hg\", \".mypy_cache\", \".tox\", \".venv\"\n <mask> }\n <mask> \n <mask>  </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> add             max_allowed = 1 if self.is_pyi else 2", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             f\"This diff might be helpful: {log}\"\n <mask>         ) from None\n <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"), </s> remove     newdst = format_str(dst, line_length=line_length) </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> remove             yield from self.line(+1)\n            yield from self.visit_default(node)\n            yield from self.line(-1) </s> add             if self.is_pyi and self.is_trivial_body(node):\n                yield from self.visit_default(node)\n            else:\n                yield from self.line(+1)\n                yield from self.visit_default(node)\n                yield from self.line(-1)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_stable(src: str, dst: str, line_length: int) -> None:\n <mask>     \"\"\"Raise AssertionError if `dst` reformats differently the second time.\"\"\"\n <mask>     newdst = format_str(dst, line_length=line_length)\n <mask>     if dst != newdst:\n <mask>         log = dump_to_file(\n <mask>             diff(src, dst, \"source\", \"first pass\"),\n <mask>             diff(dst, newdst, \"first pass\", \"second pass\"),\n <mask>         ) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove def format_str(src_contents: str, line_length: int) -> FileContent: </s> add def format_str(\n    src_contents: str, line_length: int, *, is_pyi: bool = False\n) -> FileContent: </s> remove         assert_stable(src_contents, dst_contents, line_length=line_length) </s> add         assert_stable(\n            src_contents, dst_contents, line_length=line_length, is_pyi=is_pyi\n        ) </s> remove     src_contents: str, line_length: int, fast: bool </s> add     src_contents: str, *, line_length: int, fast: bool, is_pyi: bool = False </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def read_data(name: str) -> Tuple[str, str]:\n <mask>     \"\"\"read_data('test_name') -> 'input', 'output'\"\"\"\n <mask>     if not name.endswith((\".py\", \".out\", \".diff\")):\n <mask>         name += \".py\"\n <mask>     _input: List[str] = []\n <mask>     _output: List[str] = []\n <mask>     with open(THIS_DIR / name, \"r\", encoding=\"utf8\") as test:\n <mask>         lines = test.readlines() </s> remove     lines = LineGenerator(remove_u_prefix=py36 or \"unicode_literals\" in future_imports)\n    elt = EmptyLineTracker() </s> add     lines = LineGenerator(\n        remove_u_prefix=py36 or \"unicode_literals\" in future_imports, is_pyi=is_pyi\n    ) </s> remove             src_contents, line_length=line_length, fast=fast </s> add             src_contents, line_length=line_length, fast=fast, is_pyi=is_pyi </s> add     @patch(\"black.dump_to_file\", dump_to_stderr)\n    def test_stub(self) -> None:\n        source, expected = read_data(\"stub.pyi\")\n        actual = fs(source, is_pyi=True)\n        self.assertFormatEqual(expected, actual)\n        black.assert_stable(source, actual, line_length=ll, is_pyi=True) </s> add     elt = EmptyLineTracker(is_pyi=is_pyi)", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask>         self.assertFormatEqual(expected, actual)\n <mask>         black.assert_stable(source, actual, line_length=ll)\n <mask> \n <mask>     @patch(\"black.dump_to_file\", dump_to_stderr)\n <mask>     def test_fmtonoff(self) -> None:\n <mask>         source, expected = read_data(\"fmtonoff\")\n <mask>         actual = fs(source) </s> remove def assert_stable(src: str, dst: str, line_length: int) -> None: </s> add def assert_stable(src: str, dst: str, line_length: int, is_pyi: bool = False) -> None: </s> remove     newdst = format_str(dst, line_length=line_length) </s> add     newdst = format_str(dst, line_length=line_length, is_pyi=is_pyi) </s> add             if self.is_pyi:\n                before = 0 if depth else 1\n            else:\n                before = 1 if depth else 2 </s> remove     if not name.endswith((\".py\", \".out\", \".diff\")): </s> add     if not name.endswith((\".py\", \".pyi\", \".out\", \".diff\")):", "html_url": "https://github.com/psf/black/commit/14ba1bf8b6248e6860ba6a0cb9468c4c1c25a102", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             check_lpar = True\n <mask> \n <mask>         if check_lpar:\n <mask>             if child.type == syms.atom:\n <mask>                 if maybe_make_parens_invisible_in_atom(child, parent=node):\n <mask>                     wrap_in_parentheses(node, child, visible=False)\n <mask>             elif is_one_tuple(child):\n <mask>                 wrap_in_parentheses(node, child, visible=True)\n <mask>             elif node.type == syms.import_from:\n <mask>                 # \"import from\" nodes store parentheses directly as part of </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent) </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool: </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask>         check_lpar = isinstance(child, Leaf) and child.value in parens_after\n <mask> \n <mask> \n <mask> def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:\n <mask>     \"\"\"If it's safe, make the parens in the atom `node` invisible, recursively.\n <mask>     Additionally, remove repeated, adjacent invisible parens from the atom `node`\n <mask>     as they are redundant.\n <mask> \n <mask>     Returns whether the node should itself be wrapped in invisible parentheses. </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent) </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node): </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     Returns whether the node should itself be wrapped in invisible parentheses.\n <mask> \n <mask>     \"\"\"\n <mask> \n <mask>     if (\n <mask>         node.type != syms.atom\n <mask>         or is_empty_tuple(node)\n <mask>         or is_one_tuple(node) </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY </s> add         or (max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY and for_stmt_check) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool: </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> remove         maybe_make_parens_invisible_in_atom(middle, parent=parent) </s> add         maybe_make_parens_invisible_in_atom(middle, parent=parent, preview=preview) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         node.type != syms.atom\n <mask>         or is_empty_tuple(node)\n <mask>         or is_one_tuple(node)\n <mask>         or (is_yield(node) and parent.type != syms.expr_stmt)\n <mask>         or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY\n <mask>     ):\n <mask>         return False\n <mask> \n <mask>     if is_walrus_assignment(node):\n <mask>         if parent.type in [ </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node): </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         middle = node.children[1]\n <mask>         # make parentheses invisible\n <mask>         first.value = \"\"\n <mask>         last.value = \"\"\n <mask>         maybe_make_parens_invisible_in_atom(middle, parent=parent)\n <mask> \n <mask>         if is_atom_with_invisible_parens(middle):\n <mask>             # Strip the invisible parens from `middle` by replacing\n <mask>             # it with the child in-between the invisible parens\n <mask>             middle.replace(middle.children[1]) </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool: </s> add def maybe_make_parens_invisible_in_atom(\n    node: LN,\n    parent: LN,\n    preview: bool = False,\n) -> bool: </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node): </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask>     string_processing = auto()\n <mask>     one_element_subscript = auto()\n <mask> \n <mask> \n <mask> class Deprecated(UserWarning): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/mode.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LL = line.leaves\n <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>         for (i, leaf) in enumerate(LL):\n <mask>             if (\n <mask>                 leaf.type == token.STRING\n <mask>                 and is_valid_index(i + 1)\n <mask>                 and LL[i + 1].type == token.STRING\n <mask>             ): </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             replace_child(atom_node, string_leaf)\n <mask> \n <mask>         # Build the final line ('new_line') that this method will later return.\n <mask>         new_line = line.clone()\n <mask>         for (i, leaf) in enumerate(LL):\n <mask>             if i == string_idx:\n <mask>                 new_line.append(string_leaf)\n <mask> \n <mask>             if string_idx <= i < string_idx + num_of_strings:\n <mask>                 for comment_leaf in line.comments_after(LL[i]): </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         LL = line.leaves\n <mask> \n <mask>         is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>         for (idx, leaf) in enumerate(LL):\n <mask>             # Should be a string...\n <mask>             if leaf.type != token.STRING:\n <mask>                 continue\n <mask> \n <mask>             # If this is a \"pointless\" string... </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # contains the \"assert\" keyword...\n <mask>         if parent_type(LL[0]) == syms.assert_stmt and LL[0].value == \"assert\":\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find a comma...\n <mask>                 if leaf.type == token.COMMA:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That comma MUST be followed by a string... </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>             and LL[0].type == token.NAME\n <mask>         ):\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find either an '=' or '+=' symbol...\n <mask>                 if leaf.type in [token.EQUAL, token.PLUSEQUAL]:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That symbol MUST be followed by a string... </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> add     if (\n        preview\n        and parent.type == syms.for_stmt\n        and isinstance(node.prev_sibling, Leaf)\n        and node.prev_sibling.type == token.NAME\n        and node.prev_sibling.value == \"for\"\n    ):\n        for_stmt_check = False\n    else:\n        for_stmt_check = True", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask>         # If this line is apart of a dictionary key assignment...\n <mask>         if syms.dictsetmaker in [parent_type(LL[0]), parent_type(LL[0].parent)]:\n <mask>             is_valid_index = is_valid_index_factory(LL)\n <mask> \n <mask>             for (i, leaf) in enumerate(LL):\n <mask>                 # We MUST find a colon...\n <mask>                 if leaf.type == token.COLON:\n <mask>                     idx = i + 2 if is_empty_par(LL[i + 1]) else i + 1\n <mask> \n <mask>                     # That colon MUST be followed by a string... </s> Remove unnecessary parentheses from tuple unpacking in `for` loops (#2945) </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove             for (i, leaf) in enumerate(LL): </s> add             for i, leaf in enumerate(LL): </s> remove         for (idx, leaf) in enumerate(LL): </s> add         for idx, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove         for (i, leaf) in enumerate(LL): </s> add         for i, leaf in enumerate(LL): </s> remove                 if maybe_make_parens_invisible_in_atom(child, parent=node): </s> add                 if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    preview=preview,\n                ):", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "src/black/trans.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>     \"long_strings__regression\",\n <mask>     \"percent_precedence\",\n <mask>     \"one_element_subscript\",\n <mask> ]\n <mask> \n <mask> SOURCES: List[str] = [ </s> add     remove_redundant_parens = auto()", "html_url": "https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579", "file_name": "tests/test_format.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> import asyncio\n <mask> import logging\n <mask> from concurrent.futures import ThreadPoolExecutor\n <mask> from contextlib import contextmanager\n <mask> from functools import partial, wraps\n <mask> from io import BytesIO, TextIOWrapper\n <mask> import os\n <mask> from pathlib import Path\n <mask> import re\n <mask> import sys </s> remove from typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Coroutine,\n    Generator,\n    List,\n    Tuple,\n    Iterator,\n    TypeVar,\n) </s> add from typing import Any, BinaryIO, Generator, List, Tuple, Iterator, TypeVar </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> remove     old_loop = policy.get_event_loop() </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask> from pathlib import Path\n <mask> import re\n <mask> import sys\n <mask> from tempfile import TemporaryDirectory\n <mask> from typing import (\n <mask>     Any,\n <mask>     BinaryIO,\n <mask>     Callable,\n <mask>     Coroutine,\n <mask>     Generator,\n <mask>     List,\n <mask>     Tuple,\n <mask>     Iterator,\n <mask>     TypeVar,\n <mask> )\n <mask> import unittest\n <mask> from unittest.mock import patch, MagicMock\n <mask> \n <mask> from click import unstyle\n <mask> from click.testing import CliRunner </s> remove from functools import partial, wraps </s> add from functools import partial </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> add         else:\n            raise exc </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep keep keep keep", "code_tokens": " <mask> \n <mask> @contextmanager\n <mask> def event_loop(close: bool) -> Iterator[None]:\n <mask>     policy = asyncio.get_event_loop_policy()\n <mask>     old_loop = policy.get_event_loop()\n <mask>     loop = policy.new_event_loop()\n <mask>     asyncio.set_event_loop(loop)\n <mask>     try:\n <mask>         yield\n <mask>  </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper </s> remove         policy.set_event_loop(old_loop) </s> add     from aiohttp.test_utils import AioHTTPTestCase, unittest_run_loop\n    from aiohttp import web </s> add     @unittest_run_loop </s> add     @unittest_run_loop", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep keep keep keep replace replace replace replace replace replace replace replace replace", "code_tokens": " <mask> \n <mask>     finally:\n <mask>         policy.set_event_loop(old_loop)\n <mask>         if close:\n <mask>             loop.close()\n <mask> \n <mask> \n <mask> def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n <mask>     @event_loop(close=True)\n <mask>     @wraps(f)\n <mask>     def wrapper(*args: Any, **kwargs: Any) -> None:\n <mask>         asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n <mask> \n <mask>     return wrapper\n <mask> \n <mask>  </s> add     @unittest_run_loop", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep keep", "code_tokens": " <mask>     except Exception as exc:\n <mask>         if exc.__class__.__name__ == e:\n <mask>             unittest.skip(f\"Encountered expected exception {exc}, skipping\")\n <mask> \n <mask> \n <mask> class BlackRunner(CliRunner):\n <mask>     \"\"\"Modify CliRunner so that stderr is not merged with stdout.\n <mask>  </s> remove def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:\n    @event_loop(close=True)\n    @wraps(f)\n    def wrapper(*args: Any, **kwargs: Any) -> None:\n        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))\n\n    return wrapper </s> add     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n\n\nclass BlackDTestCase(AioHTTPTestCase):\n    async def get_application(self) -> web.Application:\n        return blackd.make_app() </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep keep", "code_tokens": " <mask>             ff(THIS_FILE)\n <mask> \n <mask>     # TODO: remove these decorators once the below is released\n <mask>     # https://github.com/aio-libs/aiohttp/pull/3727\n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @unittest_run_loop </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>     # https://github.com/aio-libs/aiohttp/pull/3727\n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_needs_formatting(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b\"print('hello world')\")\n <mask>             self.assertEqual(response.status, 200)\n <mask>             self.assertEqual(response.charset, \"utf8\")\n <mask>             self.assertEqual(await response.read(), b'print(\"hello world\")\\n')\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\") </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_no_change(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n <mask>             self.assertEqual(response.status, 204)\n <mask>             self.assertEqual(await response.read(), b\"\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> add         response = await self.client.post(\"/\", data=b\"print('hello world')\")\n        self.assertEqual(response.status, 200)\n        self.assertEqual(response.charset, \"utf8\")\n        self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> remove     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>             self.assertEqual(await response.read(), b\"\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_request_syntax_error(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\"/\", data=b\"what even ( is\")\n <mask>             self.assertEqual(response.status, 400)\n <mask>             content = await response.text()\n <mask>             self.assertTrue(\n <mask>                 content.startswith(\"Cannot parse\"),\n <mask>                 msg=f\"Expected error to start with 'Cannot parse', got {repr(content)}\",\n <mask>             )\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\") </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> add         response = await self.client.post(\"/\", data=b\"print('hello world')\")\n        self.assertEqual(response.status, 200)\n        self.assertEqual(response.charset, \"utf8\")\n        self.assertEqual(await response.read(), b'print(\"hello world\")\\n') </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep replace keep replace replace replace replace replace replace keep keep", "code_tokens": " <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_unsupported_version(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 501)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_supported_version(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_invalid_python_variant(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask> \n <mask>             async def check(header_value: str, expected_status: int = 400) -> None:\n <mask>                 response = await client.post(\n <mask>                     \"/\",\n <mask>                     data=b\"what\",\n <mask>                     headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask> \n <mask>             await check(\"lol\")\n <mask>             await check(\"ruby3.5\")\n <mask>             await check(\"pyi3.6\")\n <mask>             await check(\"py1.5\")\n <mask>             await check(\"2.8\")\n <mask>             await check(\"py2.8\")\n <mask>             await check(\"3.0\")\n <mask>             await check(\"pypy3.0\")\n <mask>             await check(\"jython3.4\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove             async def check(header_value: str, expected_status: int) -> None:\n                response = await client.post(\n                    \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n                )\n                self.assertEqual(response.status, expected_status) </s> add         async def check(header_value: str, expected_status: int) -> None:\n            response = await self.client.post(\n                \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status) </s> remove     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace replace replace keep keep keep keep", "code_tokens": " <mask>             await check(\"jython3.4\")\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_pyi(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             source, expected = read_data(\"stub.pyi\")\n <mask>             response = await client.post(\n <mask>                 \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200)\n <mask>             self.assertEqual(await response.text(), expected)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\") </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b\"print('hello world')\")\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.charset, \"utf8\")\n            self.assertEqual(await response.read(), b'print(\"hello world\")\\n')", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace keep", "code_tokens": " <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_python_variant(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         code = ( </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep replace keep replace replace replace replace replace keep", "code_tokens": " <mask>             \"    pass\\n\"\n <mask>         )\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask> \n <mask>             async def check(header_value: str, expected_status: int) -> None:\n <mask>                 response = await client.post(\n <mask>                     \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask>  </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\") </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            source, expected = read_data(\"stub.pyi\")\n            response = await client.post(\n                \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n            )\n            self.assertEqual(response.status, 200)\n            self.assertEqual(await response.text(), expected) </s> add         source, expected = read_data(\"stub.pyi\")\n        response = await self.client.post(\n            \"/\", data=source, headers={blackd.PYTHON_VARIANT_HEADER: \"pyi\"}\n        )\n        self.assertEqual(response.status, 200)\n        self.assertEqual(await response.text(), expected) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> add         response = await self.client.post(\n            \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n        )\n        self.assertEqual(response.status, 501) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace keep replace replace replace replace replace keep", "code_tokens": " <mask>                     \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n <mask>                 )\n <mask>                 self.assertEqual(response.status, expected_status)\n <mask> \n <mask>             await check(\"3.6\", 200)\n <mask>             await check(\"py3.6\", 200)\n <mask>             await check(\"3.6,3.7\", 200)\n <mask>             await check(\"3.6,py3.7\", 200)\n <mask> \n <mask>             await check(\"2\", 204)\n <mask>             await check(\"2.7\", 204)\n <mask>             await check(\"py2.7\", 204)\n <mask>             await check(\"3.4\", 204)\n <mask>             await check(\"py3.4\", 204)\n <mask>  </s> remove             async def check(header_value: str, expected_status: int) -> None:\n                response = await client.post(\n                    \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n                )\n                self.assertEqual(response.status, expected_status) </s> add         async def check(header_value: str, expected_status: int) -> None:\n            response = await self.client.post(\n                \"/\", data=code, headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status) </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n\n            async def check(header_value: str, expected_status: int = 400) -> None:\n                response = await client.post(\n                    \"/\",\n                    data=b\"what\",\n                    headers={blackd.PYTHON_VARIANT_HEADER: header_value},\n                )\n                self.assertEqual(response.status, expected_status)\n\n            await check(\"lol\")\n            await check(\"ruby3.5\")\n            await check(\"pyi3.6\")\n            await check(\"py1.5\")\n            await check(\"2.8\")\n            await check(\"py2.8\")\n            await check(\"3.0\")\n            await check(\"pypy3.0\")\n            await check(\"jython3.4\") </s> add         async def check(header_value: str, expected_status: int = 400) -> None:\n            response = await self.client.post(\n                \"/\", data=b\"what\", headers={blackd.PYTHON_VARIANT_HEADER: header_value}\n            )\n            self.assertEqual(response.status, expected_status)\n\n        await check(\"lol\")\n        await check(\"ruby3.5\")\n        await check(\"pyi3.6\")\n        await check(\"py1.5\")\n        await check(\"2.8\")\n        await check(\"py2.8\")\n        await check(\"3.0\")\n        await check(\"pypy3.0\")\n        await check(\"jython3.4\")", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep keep keep keep replace keep replace replace replace replace replace replace keep keep keep", "code_tokens": " <mask>             await check(\"py3.4\", 204)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_line_length(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n <mask>             )\n <mask>             self.assertEqual(response.status, 200)\n <mask> \n <mask>     @skip_if_exception(\"ClientOSError\")\n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\") </s> Fix async blackd tests which won't fail currently (#966) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\",\n                data=b'print(\"hello\")\\n',\n                headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n            )\n            self.assertEqual(response.status, 400)\n\n    @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"NaN\"}\n        )\n        self.assertEqual(response.status, 400) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\"/\", data=b'print(\"hello world\")\\n')\n            self.assertEqual(response.status, 204)\n            self.assertEqual(await response.read(), b\"\") </s> add         response = await self.client.post(\"/\", data=b'print(\"hello world\")\\n')\n        self.assertEqual(response.status, 204)\n        self.assertEqual(await response.read(), b\"\") </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501) </s> remove     @async_test", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep replace keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep", "code_tokens": " <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     @async_test\n <mask>     async def test_blackd_invalid_line_length(self) -> None:\n <mask>         app = blackd.make_app()\n <mask>         async with TestClient(TestServer(app)) as client:\n <mask>             response = await client.post(\n <mask>                 \"/\",\n <mask>                 data=b'print(\"hello\")\\n',\n <mask>                 headers={blackd.LINE_LENGTH_HEADER: \"NaN\"},\n <mask>             )\n <mask>             self.assertEqual(response.status, 400)\n <mask> \n <mask>     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n <mask>     def test_blackd_main(self) -> None:\n <mask>         with patch(\"blackd.web.run_app\"):\n <mask>             result = CliRunner().invoke(blackd.main, [])\n <mask>             if result.exception is not None:\n <mask>                 raise result.exception\n <mask>             self.assertEqual(result.exit_code, 0)\n <mask> \n <mask>  </s> Fix async blackd tests which won't fail currently (#966) </s> add     @unittest.skipUnless(has_blackd_deps, \"blackd's dependencies are not installed\")\n    def test_blackd_main(self) -> None:\n        with patch(\"blackd.web.run_app\"):\n            result = CliRunner().invoke(blackd.main, [])\n            if result.exception is not None:\n                raise result.exception\n            self.assertEqual(result.exit_code, 0)\n\n\nclass BlackDTestCase(AioHTTPTestCase):\n    async def get_application(self) -> web.Application:\n        return blackd.make_app() </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n            )\n            self.assertEqual(response.status, 200) </s> add         response = await self.client.post(\n            \"/\", data=b'print(\"hello\")\\n', headers={blackd.LINE_LENGTH_HEADER: \"7\"}\n        )\n        self.assertEqual(response.status, 200) </s> remove     @async_test </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"1\"}\n            )\n            self.assertEqual(response.status, 200) </s> remove         app = blackd.make_app()\n        async with TestClient(TestServer(app)) as client:\n            response = await client.post(\n                \"/\", data=b\"what\", headers={blackd.VERSION_HEADER: \"2\"}\n            )\n            self.assertEqual(response.status, 501)", "html_url": "https://github.com/psf/black/commit/154b98579d3904a042fd3e02a9d77a76be63b36c", "file_name": "tests/test_black.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask>             syms.assert_stmt,\n <mask>             syms.return_stmt,\n <mask>             # these ones aren't useful to end users, but they do please fuzzers\n <mask>             syms.for_stmt,\n <mask>             syms.del_stmt,\n <mask>         ]: </s> remove     _assert_format_equal(expected, actual) </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> remove         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "src/black/linegen.py"}
{"docstring_tokens": "keep keep keep keep replace keep keep", "code_tokens": " <mask> \n <mask> \n <mask> match bar1:\n <mask>     case Foo(\n <mask>         normal=x, perhaps=[list, {an: d, dict: 1.0}] as y, otherwise=something, q=t as u\n <mask>     ):\n <mask>         pass </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com>", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/data/py_310/pattern_matching_extras.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> import sys\n <mask> import unittest\n <mask> from contextlib import contextmanager\n <mask> from functools import partial\n <mask> from pathlib import Path\n <mask> from typing import Any, Iterator, List, Optional, Tuple\n <mask>  </s> add class FormatFailure(Exception):\n    \"\"\"Used to wrap failures when assert_format() runs in an extra mode.\"\"\"", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep add keep keep keep keep", "code_tokens": " <mask> \n <mask> \n <mask> def assert_format(\n <mask>     source: str,\n <mask>     expected: str,\n <mask>     mode: black.Mode = DEFAULT_MODE, </s> Check stability for both preview and non-preview styles (#3423)\n\nAnd fix parens-related test failures this found.\r\n\r\nCo-authored-by: Richard Si <63936253+ichard26@users.noreply.github.com> </s> remove     _assert_format_equal(expected, actual) </s> add     if expected is not None:\n        _assert_format_equal(expected, actual) </s> remove     if not fast and source != expected:", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep keep keep replace keep keep keep replace keep keep", "code_tokens": " <mask>     separate from TargetVerson Mode configuration.\n <mask>     \"\"\"\n <mask>     actual = black.format_str(source, mode=mode)\n <mask>     _assert_format_equal(expected, actual)\n <mask>     # It's not useful to run safety checks if we're expecting no changes anyway. The\n <mask>     # assertion right above will raise if reality does actually make changes. This just\n <mask>     # avoids wasted CPU cycles.\n <mask>     if not fast and source != expected:\n <mask>         # Unfortunately the AST equivalence check relies on the built-in ast module\n <mask>         # being able to parse the code being formatted. This doesn't always work out </s> add         normal=x, perhaps=[list, {\"x\": d, \"y\": 1.0}] as y, otherwise=something, q=t as u", "html_url": "https://github.com/psf/black/commit/159984a7351bfc4789bc0fc85b5f408112efca85", "file_name": "tests/util.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace keep replace keep keep keep keep", "code_tokens": " <mask>         ctx.exit(0)\n <mask>         return\n <mask> \n <mask>     elif len(sources) == 1:\n <mask>         return_code = run_single_file_mode(\n <mask>             line_length, check, fast, quiet, write_back, sources[0]\n <mask>         )\n <mask>     else:\n <mask>         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources)\n <mask>     ctx.exit(return_code)\n <mask> \n <mask> \n <mask> def run_single_file_mode( </s> Simplify single-file vs. multi-file modes </s> remove def run_multi_file_mode(\n    line_length: int,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    sources: List[Path],\n) -> int:\n    loop = asyncio.get_event_loop()\n    executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n    return_code = 1\n    try:\n        return_code = loop.run_until_complete(\n            schedule_formatting(\n                sources, line_length, write_back, fast, quiet, loop, executor\n            )\n        )\n    finally:\n        shutdown(loop)\n        return return_code </s> remove def run_single_file_mode(\n    line_length: int,\n    check: bool,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    src: Path, </s> add def reformat_one(\n    src: Path, line_length: int, fast: bool, quiet: bool, write_back: WriteBack </s> add     \"\"\"Reformat a single file under `src` without spawning child processes.\n\n    If `quiet` is True, non-error messages are not output. `line_length`,\n    `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n    \"\"\"\n    report = Report(check=write_back is WriteBack.NO, quiet=quiet)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep replace replace replace replace replace replace replace keep replace keep keep keep", "code_tokens": " <mask> \n <mask> def run_single_file_mode(\n <mask>     line_length: int,\n <mask>     check: bool,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     write_back: WriteBack,\n <mask>     src: Path,\n <mask> ) -> int:\n <mask>     report = Report(check=check, quiet=quiet)\n <mask>     try:\n <mask>         changed = Changed.NO\n <mask>         if not src.is_file() and str(src) == \"-\": </s> remove         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources) </s> add         loop = asyncio.get_event_loop()\n        executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n        return_code = 1\n        try:\n            return_code = loop.run_until_complete(\n                schedule_formatting(\n                    sources, line_length, write_back, fast, quiet, loop, executor\n                )\n            )\n        finally:\n            shutdown(loop) </s> remove         return_code = run_single_file_mode(\n            line_length, check, fast, quiet, write_back, sources[0]\n        ) </s> add         return_code = reformat_one(sources[0], line_length, fast, quiet, write_back)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace replace keep keep keep keep keep", "code_tokens": " <mask>         report.failed(src, str(exc))\n <mask>     return report.return_code\n <mask> \n <mask> \n <mask> def run_multi_file_mode(\n <mask>     line_length: int,\n <mask>     fast: bool,\n <mask>     quiet: bool,\n <mask>     write_back: WriteBack,\n <mask>     sources: List[Path],\n <mask> ) -> int:\n <mask>     loop = asyncio.get_event_loop()\n <mask>     executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n <mask>     return_code = 1\n <mask>     try:\n <mask>         return_code = loop.run_until_complete(\n <mask>             schedule_formatting(\n <mask>                 sources, line_length, write_back, fast, quiet, loop, executor\n <mask>             )\n <mask>         )\n <mask>     finally:\n <mask>         shutdown(loop)\n <mask>         return return_code\n <mask> \n <mask> \n <mask> async def schedule_formatting(\n <mask>     sources: List[Path],\n <mask>     line_length: int,\n <mask>     write_back: WriteBack,\n <mask>     fast: bool, </s> remove         return_code = run_multi_file_mode(line_length, fast, quiet, write_back, sources) </s> add         loop = asyncio.get_event_loop()\n        executor = ProcessPoolExecutor(max_workers=os.cpu_count())\n        return_code = 1\n        try:\n            return_code = loop.run_until_complete(\n                schedule_formatting(\n                    sources, line_length, write_back, fast, quiet, loop, executor\n                )\n            )\n        finally:\n            shutdown(loop) </s> remove def run_single_file_mode(\n    line_length: int,\n    check: bool,\n    fast: bool,\n    quiet: bool,\n    write_back: WriteBack,\n    src: Path, </s> add def reformat_one(\n    src: Path, line_length: int, fast: bool, quiet: bool, write_back: WriteBack </s> remove         return_code = run_single_file_mode(\n            line_length, check, fast, quiet, write_back, sources[0]\n        ) </s> add         return_code = reformat_one(sources[0], line_length, fast, quiet, write_back) </s> remove     report = Report(check=check, quiet=quiet) </s> add     \"\"\"Reformat a single file under `src` without spawning child processes.\n\n    If `quiet` is True, non-error messages are not output. `line_length`,\n    `write_back`, and `fast` options are passed to :func:`format_file_in_place`.\n    \"\"\"\n    report = Report(check=write_back is WriteBack.NO, quiet=quiet)", "html_url": "https://github.com/psf/black/commit/15d5e36ea38988084584639b02aafcaaa2744dcf", "file_name": "black.py"}
{"docstring_tokens": "keep keep keep keep replace replace keep keep keep keep keep", "code_tokens": " <mask>         if leaves:\n <mask>             # Since body is a new indent level, remove spurious leading whitespace.\n <mask>             normalize_prefix(leaves[0], inside_brackets=True)\n <mask>             # Ensure a trailing comma when expected.\n <mask>             if original.is_import and len(leaves) == 1:\n <mask>                 leaves.append(Leaf(token.COMMA, \",\"))\n <mask>     # Populate the line\n <mask>     for leaf in leaves:\n <mask>         result.append(leaf, preformatted=True)\n <mask>         for comment_after in original.comments_after(leaf):\n <mask>             result.append(comment_after, preformatted=True)\n </s> Add trailing comma for single `as` imports, too </s> add from com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent,  # NOT DRY\n)\nfrom com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent as component,  # DRY\n)\n </s> add .. autofunction:: black.bracket_split_build_line\n", "html_url": "https://github.com/psf/black/commit/1610fd6bc5d594c4f27698825913d2f791d3ea02", "file_name": "black.py"}
{"docstring_tokens": "keep keep add keep keep keep keep", "code_tokens": " <mask> Split functions\n <mask> ---------------\n <mask> \n <mask> .. autofunction:: black.bracket_split_succeeded_or_raise\n <mask> \n <mask> .. autofunction:: black.delimiter_split\n <mask> \n </s> Add trailing comma for single `as` imports, too </s> add from com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent,  # NOT DRY\n)\nfrom com.my_lovely_company.my_lovely_team.my_lovely_project.my_lovely_component import (\n    MyLovelyCompanyTeamProjectComponent as component,  # DRY\n)\n </s> remove             if original.is_import and len(leaves) == 1:\n                leaves.append(Leaf(token.COMMA, \",\"))\n </s> add             if original.is_import:\n                if leaves[-1].type != token.COMMA:\n                    leaves.append(Leaf(token.COMMA, \",\"))", "html_url": "https://github.com/psf/black/commit/1610fd6bc5d594c4f27698825913d2f791d3ea02", "file_name": "docs/reference/reference_functions.rst"}
